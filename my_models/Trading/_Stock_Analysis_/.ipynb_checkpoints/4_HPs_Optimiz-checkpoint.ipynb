{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d702d5b-d0fb-48ab-9a48-134bb847bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Wipe out all Python variables\n",
    "%reset -f\n",
    "# 2) Force Python’s garbage collector to run\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import importlib\n",
    "from libs import trades, plots, params, models\n",
    "importlib.reload(trades)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(params)\n",
    "importlib.reload(models)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.exceptions import TrialPruned\n",
    "from optuna.importance import get_param_importances\n",
    "\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9498b30-9abb-4123-87f1-0ed191478e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obv</th>\n",
       "      <th>hour</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>vwap_dev</th>\n",
       "      <th>open</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>ma_5</th>\n",
       "      <th>close</th>\n",
       "      <th>atr_14</th>\n",
       "      <th>macd_12_26</th>\n",
       "      <th>bb_width_20</th>\n",
       "      <th>in_trading</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>signal_smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-04-03 10:49:00</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>28.650</td>\n",
       "      <td>1.240040e-16</td>\n",
       "      <td>28.650</td>\n",
       "      <td>28.650000</td>\n",
       "      <td>28.65000</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>28.641405</td>\n",
       "      <td>28.658595</td>\n",
       "      <td>0.131792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 10:50:00</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>28.650</td>\n",
       "      <td>1.240040e-16</td>\n",
       "      <td>28.650</td>\n",
       "      <td>28.650000</td>\n",
       "      <td>28.65000</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>28.641405</td>\n",
       "      <td>28.658595</td>\n",
       "      <td>0.132326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 10:51:00</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>28.650</td>\n",
       "      <td>1.240040e-16</td>\n",
       "      <td>28.650</td>\n",
       "      <td>28.650000</td>\n",
       "      <td>28.65000</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>28.641405</td>\n",
       "      <td>28.658595</td>\n",
       "      <td>0.132862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 10:52:00</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>28.650</td>\n",
       "      <td>1.240040e-16</td>\n",
       "      <td>28.650</td>\n",
       "      <td>28.650000</td>\n",
       "      <td>28.65000</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>28.641405</td>\n",
       "      <td>28.658595</td>\n",
       "      <td>0.133399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 10:53:00</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>28.650</td>\n",
       "      <td>1.240040e-16</td>\n",
       "      <td>28.650</td>\n",
       "      <td>28.650000</td>\n",
       "      <td>28.65000</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>28.641405</td>\n",
       "      <td>28.658595</td>\n",
       "      <td>0.133939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:56:00</th>\n",
       "      <td>3.294477e+08</td>\n",
       "      <td>20</td>\n",
       "      <td>173.6771</td>\n",
       "      <td>173.215</td>\n",
       "      <td>1.249034e+00</td>\n",
       "      <td>173.375</td>\n",
       "      <td>174.838390</td>\n",
       "      <td>173.91300</td>\n",
       "      <td>173.5650</td>\n",
       "      <td>0.304529</td>\n",
       "      <td>-0.422065</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>1</td>\n",
       "      <td>173.512900</td>\n",
       "      <td>173.617100</td>\n",
       "      <td>0.001063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:57:00</th>\n",
       "      <td>3.288235e+08</td>\n",
       "      <td>20</td>\n",
       "      <td>173.5900</td>\n",
       "      <td>173.240</td>\n",
       "      <td>1.246621e+00</td>\n",
       "      <td>173.565</td>\n",
       "      <td>174.736890</td>\n",
       "      <td>173.73700</td>\n",
       "      <td>173.3800</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>-0.466939</td>\n",
       "      <td>0.016242</td>\n",
       "      <td>1</td>\n",
       "      <td>173.328000</td>\n",
       "      <td>173.432000</td>\n",
       "      <td>0.005465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:58:00</th>\n",
       "      <td>3.283690e+08</td>\n",
       "      <td>20</td>\n",
       "      <td>173.4100</td>\n",
       "      <td>173.200</td>\n",
       "      <td>1.245701e+00</td>\n",
       "      <td>173.390</td>\n",
       "      <td>174.634390</td>\n",
       "      <td>173.53500</td>\n",
       "      <td>173.3100</td>\n",
       "      <td>0.323814</td>\n",
       "      <td>-0.502359</td>\n",
       "      <td>0.017430</td>\n",
       "      <td>1</td>\n",
       "      <td>173.258000</td>\n",
       "      <td>173.362000</td>\n",
       "      <td>0.007152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:59:00</th>\n",
       "      <td>3.272742e+08</td>\n",
       "      <td>20</td>\n",
       "      <td>173.4000</td>\n",
       "      <td>173.230</td>\n",
       "      <td>1.245284e+00</td>\n",
       "      <td>173.315</td>\n",
       "      <td>174.527890</td>\n",
       "      <td>173.38100</td>\n",
       "      <td>173.2800</td>\n",
       "      <td>0.322743</td>\n",
       "      <td>-0.526778</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>1</td>\n",
       "      <td>173.228000</td>\n",
       "      <td>173.332000</td>\n",
       "      <td>0.007898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 21:00:00</th>\n",
       "      <td>3.349241e+08</td>\n",
       "      <td>21</td>\n",
       "      <td>174.0500</td>\n",
       "      <td>173.170</td>\n",
       "      <td>1.249352e+00</td>\n",
       "      <td>173.300</td>\n",
       "      <td>174.442375</td>\n",
       "      <td>173.42894</td>\n",
       "      <td>173.6097</td>\n",
       "      <td>0.374521</td>\n",
       "      <td>-0.513606</td>\n",
       "      <td>0.018282</td>\n",
       "      <td>0</td>\n",
       "      <td>173.557600</td>\n",
       "      <td>173.661800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1779401 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              obv  hour      high      low      vwap_dev  \\\n",
       "2014-04-03 10:49:00  0.000000e+00    10   28.6500   28.650  1.240040e-16   \n",
       "2014-04-03 10:50:00  0.000000e+00    10   28.6500   28.650  1.240040e-16   \n",
       "2014-04-03 10:51:00  0.000000e+00    10   28.6500   28.650  1.240040e-16   \n",
       "2014-04-03 10:52:00  0.000000e+00    10   28.6500   28.650  1.240040e-16   \n",
       "2014-04-03 10:53:00  0.000000e+00    10   28.6500   28.650  1.240040e-16   \n",
       "...                           ...   ...       ...      ...           ...   \n",
       "2025-06-18 20:56:00  3.294477e+08    20  173.6771  173.215  1.249034e+00   \n",
       "2025-06-18 20:57:00  3.288235e+08    20  173.5900  173.240  1.246621e+00   \n",
       "2025-06-18 20:58:00  3.283690e+08    20  173.4100  173.200  1.245701e+00   \n",
       "2025-06-18 20:59:00  3.272742e+08    20  173.4000  173.230  1.245284e+00   \n",
       "2025-06-18 21:00:00  3.349241e+08    21  174.0500  173.170  1.249352e+00   \n",
       "\n",
       "                        open       ma_20       ma_5     close    atr_14  \\\n",
       "2014-04-03 10:49:00   28.650   28.650000   28.65000   28.6500  0.000000   \n",
       "2014-04-03 10:50:00   28.650   28.650000   28.65000   28.6500  0.000000   \n",
       "2014-04-03 10:51:00   28.650   28.650000   28.65000   28.6500  0.000000   \n",
       "2014-04-03 10:52:00   28.650   28.650000   28.65000   28.6500  0.000000   \n",
       "2014-04-03 10:53:00   28.650   28.650000   28.65000   28.6500  0.000000   \n",
       "...                      ...         ...        ...       ...       ...   \n",
       "2025-06-18 20:56:00  173.375  174.838390  173.91300  173.5650  0.304529   \n",
       "2025-06-18 20:57:00  173.565  174.736890  173.73700  173.3800  0.317029   \n",
       "2025-06-18 20:58:00  173.390  174.634390  173.53500  173.3100  0.323814   \n",
       "2025-06-18 20:59:00  173.315  174.527890  173.38100  173.2800  0.322743   \n",
       "2025-06-18 21:00:00  173.300  174.442375  173.42894  173.6097  0.374521   \n",
       "\n",
       "                     macd_12_26  bb_width_20  in_trading         bid  \\\n",
       "2014-04-03 10:49:00    0.000000     0.000000           0   28.641405   \n",
       "2014-04-03 10:50:00    0.000000     0.000000           0   28.641405   \n",
       "2014-04-03 10:51:00    0.000000     0.000000           0   28.641405   \n",
       "2014-04-03 10:52:00    0.000000     0.000000           0   28.641405   \n",
       "2014-04-03 10:53:00    0.000000     0.000000           0   28.641405   \n",
       "...                         ...          ...         ...         ...   \n",
       "2025-06-18 20:56:00   -0.422065     0.014819           1  173.512900   \n",
       "2025-06-18 20:57:00   -0.466939     0.016242           1  173.328000   \n",
       "2025-06-18 20:58:00   -0.502359     0.017430           1  173.258000   \n",
       "2025-06-18 20:59:00   -0.526778     0.018221           1  173.228000   \n",
       "2025-06-18 21:00:00   -0.513606     0.018282           0  173.557600   \n",
       "\n",
       "                            ask  signal_smooth  \n",
       "2014-04-03 10:49:00   28.658595       0.131792  \n",
       "2014-04-03 10:50:00   28.658595       0.132326  \n",
       "2014-04-03 10:51:00   28.658595       0.132862  \n",
       "2014-04-03 10:52:00   28.658595       0.133399  \n",
       "2014-04-03 10:53:00   28.658595       0.133939  \n",
       "...                         ...            ...  \n",
       "2025-06-18 20:56:00  173.617100       0.001063  \n",
       "2025-06-18 20:57:00  173.432000       0.005465  \n",
       "2025-06-18 20:58:00  173.362000       0.007152  \n",
       "2025-06-18 20:59:00  173.332000       0.007898  \n",
       "2025-06-18 21:00:00  173.661800       0.000000  \n",
       "\n",
       "[1779401 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back      = params.look_back_tick\n",
    "features_cols  = params.features_cols_tick\n",
    "label_col      = params.label_col\n",
    "\n",
    "# USE GPU if available, otherwise fallback to CPU\n",
    "device = params.device\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "df_raw = pd.read_csv(params.ready_csv, index_col=0, parse_dates=True)\n",
    "df = models.feature_engineering(df_raw, features_cols, label_col)\n",
    "df.to_csv(params.final_csv)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5463b8a-3346-40be-8079-9892d8c97b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  X         = torch.Size([1441001, 120, 13]) (samples, look_back, features)\n",
      "  y         = torch.Size([1441001]) (samples,)\n",
      "  raw_close = torch.Size([1441001])\n",
      "  raw_bid   = torch.Size([1441001])\n",
      "  raw_ask   = torch.Size([1441001])\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Build LSTM input tensors (disk-backed memmaps)\n",
    "#    Returns five tensors on `device`:\n",
    "#      X        : (N, look_back, F)\n",
    "#      y        : (N,)\n",
    "#      raw_close: (N,)\n",
    "#      raw_bid  : (N,)\n",
    "#      raw_ask  : (N,)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "X, y, raw_close, raw_bid, raw_ask = models.build_lstm_tensors(\n",
    "    df             = df,\n",
    "    look_back      = look_back,\n",
    "    features_cols  = features_cols,\n",
    "    label_col      = label_col,\n",
    "    regular_start  = params.regular_start_pred\n",
    ")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X         =\", X.shape,    \"(samples, look_back, features)\")\n",
    "print(\"  y         =\", y.shape,    \"(samples,)\")\n",
    "print(\"  raw_close =\", raw_close.shape)\n",
    "print(\"  raw_bid   =\", raw_bid.shape)\n",
    "print(\"  raw_ask   =\", raw_ask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3c973a-29f1-4c75-abc6-ebc8c2d27f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  X_tr        = torch.Size([1013805, 120, 13])\n",
      "  y_tr        = torch.Size([1013805])\n",
      "  raw_close_te= torch.Size([215642])\n",
      "  raw_bid_te  = torch.Size([215642])\n",
      "  raw_ask_te  = torch.Size([215642])\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#    (We use the helper `chronological_split` that returns)\n",
    "#      (X_tr, y_tr),\n",
    "#      (X_val, y_val),\n",
    "#      (X_te, y_te, raw_close_te, raw_bid_te, raw_ask_te)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "(X_tr, y_tr), \\\n",
    "(X_val, y_val), \\\n",
    "(X_te, y_te, raw_close_te, raw_bid_te, raw_ask_te), \\\n",
    "samples_per_day, day_id_tr, day_id_val, day_id_te = models.chronological_split(\n",
    "    X, y, raw_close, raw_bid, raw_ask, df,\n",
    "    look_back       = look_back,\n",
    "    regular_start   = params.regular_start_pred,\n",
    "    train_prop      = params.train_prop,\n",
    "    val_prop        = params.val_prop,\n",
    "    train_batch     = params.hparams['TRAIN_BATCH']\n",
    ")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_tr        =\", X_tr.shape)\n",
    "print(\"  y_tr        =\", y_tr.shape)\n",
    "print(\"  raw_close_te=\", raw_close_te.shape)\n",
    "print(\"  raw_bid_te  =\", raw_bid_te.shape)\n",
    "print(\"  raw_ask_te  =\", raw_ask_te.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6824f1a4-92dd-4952-80c6-db456d7907ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Entered split_to_day_datasets\n",
      "1) building weekday arrays\n",
      "   Weekdays counts → tr=1013805, val=211554, te=215642\n",
      "2) moving all splits to CPU\n",
      "   CPU casts done\n",
      "3) zero-bas­ing day_id for val & test\n",
      "   val_day_id ∈ [0..413], total days=414\n",
      "   te_day_id  ∈ [0..421], total days=422\n",
      "4) instantiating DayWindowDatasets\n",
      "   ds_tr days: 1984\n",
      "   ds_val days: 414\n",
      "   ds_te days: 422\n",
      "5) building DataLoaders\n",
      "   train_loader ready\n",
      "   val_loader ready\n",
      "   test_loader ready\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Build DataLoaders over calendar‐days\n",
    "# -----------------------------------------------------------------------------\n",
    "train_loader, val_loader, test_loader = models.split_to_day_datasets(\n",
    "    # Training split arrays (from chronological_split)\n",
    "    X_tr, y_tr, day_id_tr,\n",
    "    # Validation split arrays\n",
    "    X_val, y_val, day_id_val,\n",
    "    # Test split arrays + raw prices for post‐tracking\n",
    "    X_te, y_te, day_id_te, raw_close_te, raw_bid_te, raw_ask_te,\n",
    "    # Original minute‐bar DataFrame for weekday mapping\n",
    "    df=df,\n",
    "    train_batch=params.hparams['TRAIN_BATCH'],\n",
    "    train_workers=params.hparams['NUM_WORKERS']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb4612b-f5bb-4e4a-8784-6d5689de67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Optuna objective definition\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def objective_train(trial):\n",
    "\n",
    "    hp = {\n",
    "        # ── Architecture ────────────────────────────────────────────────\n",
    "        \"DROPOUT_SHORT\": trial.suggest_float(\n",
    "            \"DROPOUT_SHORT\", 0.15, 0.25\n",
    "        ),\n",
    "    \n",
    "        \"DROPOUT_LONG\": trial.suggest_float(\n",
    "            \"DROPOUT_LONG\", 0.20, 0.35\n",
    "        ),\n",
    "    \n",
    "        \"ATT_DROPOUT\": trial.suggest_float(\n",
    "            \"ATT_DROPOUT\", 0.10, 0.25\n",
    "        ),\n",
    "    \n",
    "    \n",
    "        # ── Optimizer & Scheduler ──────────────────────────────────────\n",
    "        \"INITIAL_LR\": trial.suggest_float(\n",
    "            \"INITIAL_LR\", 3e-5, 3e-4\n",
    "        ),\n",
    "    \n",
    "        \"ETA_MIN\": trial.suggest_float(\n",
    "            \"ETA_MIN\", 5e-6, 5e-5\n",
    "        ),\n",
    "    \n",
    "        \"WEIGHT_DECAY\": trial.suggest_float(\n",
    "            \"WEIGHT_DECAY\", 5e-6, 5e-5\n",
    "        ),\n",
    "    \n",
    "        \"CLIPNORM\": trial.suggest_float(\n",
    "            \"CLIPNORM\", 0.5, 1.5\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "    print(f\"\\n▶ Trial {trial.number} starting with:\\n{hp}\\n\")#\n",
    "    # Build model\n",
    "    model = models.DualMemoryLSTM(\n",
    "        n_feats       = len(features_cols),\n",
    "        short_units   = params.hparams[\"SHORT_UNITS\"],\n",
    "        long_units    = params.hparams[\"LONG_UNITS\"],\n",
    "        dropout_short = hp[\"DROPOUT_SHORT\"],\n",
    "        dropout_long  = hp[\"DROPOUT_LONG\"],\n",
    "        att_drop      = hp[\"ATT_DROPOUT\"],\n",
    "    ).to(device)\n",
    "\n",
    "    # Build optimizer + schedulers + scaler\n",
    "    optimizer, plateau_sched, _ , scaler, clipnorm = \\\n",
    "        models.make_optimizer_and_scheduler(\n",
    "            model            = model,\n",
    "            initial_lr       = hp[\"INITIAL_LR\"],\n",
    "            weight_decay     = hp[\"WEIGHT_DECAY\"],\n",
    "            clipnorm         = hp[\"CLIPNORM\"]\n",
    "        )\n",
    "\n",
    "    cosine_sched = CosineAnnealingWarmRestarts(\n",
    "        optimizer, \n",
    "        T_0=params.hparams['T_0'], \n",
    "        T_mult=params.hparams['T_MULT'], \n",
    "        eta_min=hp['ETA_MIN']\n",
    "    )\n",
    "\n",
    "    # Run training & return best validation RMSE\n",
    "    best_rmse = models.custom_stateful_training_loop(\n",
    "        model               = model,\n",
    "        optimizer           = optimizer,\n",
    "        cosine_sched        = cosine_sched,\n",
    "        plateau_sched       = plateau_sched,\n",
    "        scaler              = scaler,\n",
    "        train_loader        = train_loader,\n",
    "        val_loader          = val_loader,\n",
    "        max_epochs          = params.hparams[\"MAX_EPOCHS\"],\n",
    "        early_stop_patience = params.hparams[\"EARLY_STOP_PATIENCE\"],\n",
    "        baseline_val_rmse   = baseline_val_rmse,\n",
    "        clipnorm            = clipnorm,\n",
    "        device              = device,\n",
    "    )\n",
    "\n",
    "    del model\n",
    "    del optimizer\n",
    "    del plateau_sched\n",
    "    del cosine_sched\n",
    "    del scaler\n",
    "\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return best_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce185de-1d62-49f9-9a96-00385e813521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sees 1984 calendar days per epoch\n",
      "\n",
      "Baseline (zero‐forecast) RMSE on validation = 0.466070\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Count how many calendar days we see each epoch and Compute baseline RMSE on validation (zero forecast)\n",
    "# -----------------------------------------------------------------------------\n",
    "n_train_days = len(train_loader.dataset)  # dataset length = # unique days\n",
    "print(f\"Training sees {n_train_days} calendar days per epoch\\n\")\n",
    "\n",
    "baseline_val_rmse = models.naive_rmse(val_loader)\n",
    "print(f\"Baseline (zero‐forecast) RMSE on validation = {baseline_val_rmse:.6f}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# create ONE figure\n",
    "# ----------------------------------------------------------\n",
    "# build blank figure & line\n",
    "fig, ax = plt.subplots(figsize=(7,3))\n",
    "line, = ax.plot([], [], \"bo-\")\n",
    "ax.set(xlabel=\"Trial #\", ylabel=\"Objective\",\n",
    "       title=\"Optuna optimization progress\")\n",
    "ax.grid(True)\n",
    "\n",
    "# display once and grab the handle\n",
    "handle = display(fig, display_id=True)\n",
    "plt.close(fig)\n",
    "\n",
    "# ask plots.py for a callback bound to these objects\n",
    "live_cb = plots.make_live_plot_callback(fig, ax, line, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7658050b-a604-4331-ac64-72b2c7fd3689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-04 16:34:48,745] A new study created in RDB with name: no-name-5e4b171c-8292-4d1f-803e-ec84eda88429\n",
      "[W 2025-08-04 16:34:49,828] Trial 0 failed with parameters: {'DROPOUT_SHORT': 0.24217259877738456, 'DROPOUT_LONG': 0.22688859993477017, 'ATT_DROPOUT': 0.21309972067454472} because of the following error: ValueError('The `low` value must be smaller than or equal to the `high` value (low=0.0003, high=3e-05).').\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_58072/4114717707.py\", line 22, in objective_train\n",
      "    \"INITIAL_LR\": trial.suggest_float(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optuna/trial/_trial.py\", line 160, in suggest_float\n",
      "    distribution = FloatDistribution(low, high, log=log, step=step)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optuna/distributions.py\", line 146, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: The `low` value must be smaller than or equal to the `high` value (low=0.0003, high=3e-05).\n",
      "[W 2025-08-04 16:34:49,836] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The `low` value must be smaller than or equal to the `high` value (low=0.0003, high=3e-05).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     17\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlive_cb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcleanup_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# ──────────────────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#  Print out the best hyperparameters & result\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# ──────────────────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:64\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 64\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    252\u001b[0m ):\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m, in \u001b[0;36mobjective_train\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mobjective_train\u001b[39m(trial):\n\u001b[1;32m      6\u001b[0m     hp \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# ── Architecture ────────────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROPOUT_SHORT\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROPOUT_SHORT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.15\u001b[39m, \u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m     10\u001b[0m         ),\n\u001b[1;32m     11\u001b[0m     \n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROPOUT_LONG\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROPOUT_LONG\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.20\u001b[39m, \u001b[38;5;241m0.35\u001b[39m\n\u001b[1;32m     14\u001b[0m         ),\n\u001b[1;32m     15\u001b[0m     \n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mATT_DROPOUT\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mATT_DROPOUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.10\u001b[39m, \u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m     18\u001b[0m         ),\n\u001b[1;32m     19\u001b[0m     \n\u001b[1;32m     20\u001b[0m     \n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m# ── Optimizer & Scheduler ──────────────────────────────────────\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINITIAL_LR\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mINITIAL_LR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3e-5\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     25\u001b[0m     \n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETA_MIN\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETA_MIN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m5e-6\u001b[39m, \u001b[38;5;241m5e-5\u001b[39m\n\u001b[1;32m     28\u001b[0m         ),\n\u001b[1;32m     29\u001b[0m     \n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWEIGHT_DECAY\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWEIGHT_DECAY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m5e-6\u001b[39m, \u001b[38;5;241m5e-5\u001b[39m\n\u001b[1;32m     32\u001b[0m         ),\n\u001b[1;32m     33\u001b[0m     \n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPNORM\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPNORM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m     36\u001b[0m         ),\n\u001b[1;32m     37\u001b[0m     }\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m▶ Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m starting with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mhp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Build model\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/trial/_trial.py:160\u001b[0m, in \u001b[0;36mTrial.suggest_float\u001b[0;34m(self, name, low, high, step, log)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msuggest_float\u001b[39m(\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     78\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     log: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     84\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Suggest a value for the floating point parameter.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m        :ref:`configurations` tutorial describes more details and flexible usages.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     distribution \u001b[38;5;241m=\u001b[39m \u001b[43mFloatDistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     suggested_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_suggest(name, distribution)\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_distribution(name, distribution)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/distributions.py:146\u001b[0m, in \u001b[0;36mFloatDistribution.__init__\u001b[0;34m(self, low, high, log, step)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe parameter `step` is not supported when `log` is true.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m low \u001b[38;5;241m>\u001b[39m high:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `low` value must be smaller than or equal to the `high` value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(low=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, high=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(low, high)\n\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log \u001b[38;5;129;01mand\u001b[39;00m low \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `low` value must be larger than 0 for a log distribution \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(low=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, high=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(low, high)\n\u001b[1;32m    155\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The `low` value must be smaller than or equal to the `high` value (low=0.0003, high=3e-05)."
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  Create Optuna study and run optimization\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "study = optuna.create_study(\n",
    "    storage=\"sqlite:///optuna_study.db\",    # Point it at an SQLite file so it writes out each result immediately instead of buffering in RAM\n",
    "    load_if_exists=True,\n",
    "    direction=\"minimize\",\n",
    "    pruner=MedianPruner(n_startup_trials=6, n_warmup_steps=12),\n",
    ")\n",
    "\n",
    "def cleanup_cb(study, trial):\n",
    "    # Python‐side\n",
    "    gc.collect()\n",
    "    # CUDA‐side (no‐op on CPU only)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "study.optimize(\n",
    "    objective_train,\n",
    "    n_trials = 100,\n",
    "    n_jobs   = 1,\n",
    "    callbacks=[live_cb, cleanup_cb],\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  Print out the best hyperparameters & result\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation RMSE:\", study.best_value)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  Compute and print parameter importances\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "imps = get_param_importances(study)\n",
    "print(\"\\nHyperparameter importances (higher ⇒ more impact on RMSE):\")\n",
    "for name, score in sorted(imps.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {name:20s} : {score:.3f}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  Dump study results to JSON\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Build your session‐only DataFrame once\n",
    "session_df = df.between_time(params.regular_start,\n",
    "                             params.regular_end)\n",
    "\n",
    "# 2) Derive the trading‐day boundaries\n",
    "first_day = session_df.index.normalize().min()\n",
    "last_day  = session_df.index.normalize().max()\n",
    "\n",
    "# 3) Format your file name\n",
    "start_date = first_day.strftime(\"%Y%m%d\")\n",
    "end_date   = last_day.strftime(\"%Y%m%d\")\n",
    "file_name  = f\"{params.ticker}_{start_date}-{end_date}_optuna_model_hpars.json\"\n",
    "file_path  = os.path.join(results_folder, file_name)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Dump study results (including importances)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params\": study.best_params,\n",
    "            \"best_value\" : study.best_value,\n",
    "            \"importances\": imps,\n",
    "            \"trials\": [\n",
    "                {\"number\": t.number, \"value\": t.value, \"params\": t.params, \n",
    "                 \"state\": t.state.name}\n",
    "                for t in study.trials\n",
    "            ],\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )\n",
    "\n",
    "print(f\"\\nOptuna results (and importances) saved to: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865782e-fc07-4354-a5b9-2cdeed1ebad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa9fb2-411b-4d9f-9a33-e6f6c59de7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
