{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f06a4f-691a-4a84-a305-e7212eb879bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c868158-e6bb-4d56-bbdd-8e8103f0b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Wipe out all Python variables\n",
    "%reset -f\n",
    "# 2) Force Python’s garbage collector to run\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import importlib\n",
    "from libs import trades, plots, params, models\n",
    "importlib.reload(trades)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(params)\n",
    "importlib.reload(models)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import math\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "from typing import Sequence, List, Tuple, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Funct\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b98406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>r_1</th>\n",
       "      <th>r_5</th>\n",
       "      <th>r_15</th>\n",
       "      <th>vol_15</th>\n",
       "      <th>volume_spike</th>\n",
       "      <th>vwap_dev</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>signal_smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:06:00</th>\n",
       "      <td>28.644845</td>\n",
       "      <td>28.644845</td>\n",
       "      <td>28.644845</td>\n",
       "      <td>28.644845</td>\n",
       "      <td>4580.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.568641</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.636251</td>\n",
       "      <td>28.653438</td>\n",
       "      <td>0.348124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:07:00</th>\n",
       "      <td>28.639690</td>\n",
       "      <td>28.639690</td>\n",
       "      <td>28.639690</td>\n",
       "      <td>28.639690</td>\n",
       "      <td>4540.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.570338</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.631098</td>\n",
       "      <td>28.648282</td>\n",
       "      <td>0.350528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:08:00</th>\n",
       "      <td>28.634534</td>\n",
       "      <td>28.634534</td>\n",
       "      <td>28.634534</td>\n",
       "      <td>28.634534</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.574408</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.625944</td>\n",
       "      <td>28.643125</td>\n",
       "      <td>0.352926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:09:00</th>\n",
       "      <td>28.629379</td>\n",
       "      <td>28.629379</td>\n",
       "      <td>28.629379</td>\n",
       "      <td>28.629379</td>\n",
       "      <td>4460.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.581017</td>\n",
       "      <td>-0.000705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.620791</td>\n",
       "      <td>28.637968</td>\n",
       "      <td>0.355320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:10:00</th>\n",
       "      <td>28.624224</td>\n",
       "      <td>28.624224</td>\n",
       "      <td>28.624224</td>\n",
       "      <td>28.624224</td>\n",
       "      <td>4420.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.590413</td>\n",
       "      <td>-0.000878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.615637</td>\n",
       "      <td>28.632811</td>\n",
       "      <td>0.357710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:56:00</th>\n",
       "      <td>173.375000</td>\n",
       "      <td>173.677100</td>\n",
       "      <td>173.215000</td>\n",
       "      <td>173.565000</td>\n",
       "      <td>621199.0</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>-0.004226</td>\n",
       "      <td>-0.009661</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>2.462713</td>\n",
       "      <td>1.257638</td>\n",
       "      <td>17.019768</td>\n",
       "      <td>173.512900</td>\n",
       "      <td>173.617100</td>\n",
       "      <td>0.002995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:57:00</th>\n",
       "      <td>173.565000</td>\n",
       "      <td>173.590000</td>\n",
       "      <td>173.240000</td>\n",
       "      <td>173.380000</td>\n",
       "      <td>624198.0</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>-0.005063</td>\n",
       "      <td>-0.010671</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>2.154838</td>\n",
       "      <td>1.255215</td>\n",
       "      <td>11.648165</td>\n",
       "      <td>173.328000</td>\n",
       "      <td>173.432000</td>\n",
       "      <td>0.002906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:58:00</th>\n",
       "      <td>173.390000</td>\n",
       "      <td>173.410000</td>\n",
       "      <td>173.200000</td>\n",
       "      <td>173.310000</td>\n",
       "      <td>454542.0</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>-0.005811</td>\n",
       "      <td>-0.011816</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>1.439161</td>\n",
       "      <td>1.254293</td>\n",
       "      <td>11.384870</td>\n",
       "      <td>173.258000</td>\n",
       "      <td>173.362000</td>\n",
       "      <td>0.005611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:59:00</th>\n",
       "      <td>173.315000</td>\n",
       "      <td>173.400000</td>\n",
       "      <td>173.230000</td>\n",
       "      <td>173.280000</td>\n",
       "      <td>1094746.0</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.004434</td>\n",
       "      <td>-0.011932</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>2.836382</td>\n",
       "      <td>1.253874</td>\n",
       "      <td>11.830567</td>\n",
       "      <td>173.228000</td>\n",
       "      <td>173.332000</td>\n",
       "      <td>0.006685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 21:00:00</th>\n",
       "      <td>173.300000</td>\n",
       "      <td>174.050000</td>\n",
       "      <td>173.170000</td>\n",
       "      <td>173.609700</td>\n",
       "      <td>7649838.0</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>-0.009290</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>8.568493</td>\n",
       "      <td>1.257962</td>\n",
       "      <td>22.962317</td>\n",
       "      <td>173.557600</td>\n",
       "      <td>173.661800</td>\n",
       "      <td>0.003506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1856408 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           open        high         low       close  \\\n",
       "2014-04-03 12:06:00   28.644845   28.644845   28.644845   28.644845   \n",
       "2014-04-03 12:07:00   28.639690   28.639690   28.639690   28.639690   \n",
       "2014-04-03 12:08:00   28.634534   28.634534   28.634534   28.634534   \n",
       "2014-04-03 12:09:00   28.629379   28.629379   28.629379   28.629379   \n",
       "2014-04-03 12:10:00   28.624224   28.624224   28.624224   28.624224   \n",
       "...                         ...         ...         ...         ...   \n",
       "2025-06-18 20:56:00  173.375000  173.677100  173.215000  173.565000   \n",
       "2025-06-18 20:57:00  173.565000  173.590000  173.240000  173.380000   \n",
       "2025-06-18 20:58:00  173.390000  173.410000  173.200000  173.310000   \n",
       "2025-06-18 20:59:00  173.315000  173.400000  173.230000  173.280000   \n",
       "2025-06-18 21:00:00  173.300000  174.050000  173.170000  173.609700   \n",
       "\n",
       "                        volume       r_1       r_5      r_15    vol_15  \\\n",
       "2014-04-03 12:06:00     4580.0 -0.000180 -0.000180 -0.000180  0.000046   \n",
       "2014-04-03 12:07:00     4540.0 -0.000180 -0.000360 -0.000360  0.000063   \n",
       "2014-04-03 12:08:00     4500.0 -0.000180 -0.000540 -0.000540  0.000075   \n",
       "2014-04-03 12:09:00     4460.0 -0.000180 -0.000720 -0.000720  0.000082   \n",
       "2014-04-03 12:10:00     4420.0 -0.000180 -0.000900 -0.000900  0.000088   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "2025-06-18 20:56:00   621199.0  0.001124 -0.004226 -0.009661  0.001493   \n",
       "2025-06-18 20:57:00   624198.0 -0.001066 -0.005063 -0.010671  0.001487   \n",
       "2025-06-18 20:58:00   454542.0 -0.000404 -0.005811 -0.011816  0.001436   \n",
       "2025-06-18 20:59:00  1094746.0 -0.000173 -0.004434 -0.011932  0.001432   \n",
       "2025-06-18 21:00:00  7649838.0  0.001901  0.001382 -0.009290  0.001592   \n",
       "\n",
       "                     volume_spike  vwap_dev     rsi_14         bid  \\\n",
       "2014-04-03 12:06:00      0.568641 -0.000178   0.000000   28.636251   \n",
       "2014-04-03 12:07:00      0.570338 -0.000355   0.000000   28.631098   \n",
       "2014-04-03 12:08:00      0.574408 -0.000531   0.000000   28.625944   \n",
       "2014-04-03 12:09:00      0.581017 -0.000705   0.000000   28.620791   \n",
       "2014-04-03 12:10:00      0.590413 -0.000878   0.000000   28.615637   \n",
       "...                           ...       ...        ...         ...   \n",
       "2025-06-18 20:56:00      2.462713  1.257638  17.019768  173.512900   \n",
       "2025-06-18 20:57:00      2.154838  1.255215  11.648165  173.328000   \n",
       "2025-06-18 20:58:00      1.439161  1.254293  11.384870  173.258000   \n",
       "2025-06-18 20:59:00      2.836382  1.253874  11.830567  173.228000   \n",
       "2025-06-18 21:00:00      8.568493  1.257962  22.962317  173.557600   \n",
       "\n",
       "                            ask  signal_smooth  \n",
       "2014-04-03 12:06:00   28.653438       0.348124  \n",
       "2014-04-03 12:07:00   28.648282       0.350528  \n",
       "2014-04-03 12:08:00   28.643125       0.352926  \n",
       "2014-04-03 12:09:00   28.637968       0.355320  \n",
       "2014-04-03 12:10:00   28.632811       0.357710  \n",
       "...                         ...            ...  \n",
       "2025-06-18 20:56:00  173.617100       0.002995  \n",
       "2025-06-18 20:57:00  173.432000       0.002906  \n",
       "2025-06-18 20:58:00  173.362000       0.005611  \n",
       "2025-06-18 20:59:00  173.332000       0.006685  \n",
       "2025-06-18 21:00:00  173.661800       0.003506  \n",
       "\n",
       "[1856408 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ticker         = params.ticker\n",
    "look_back      = params.look_back_tick \n",
    "features_cols  = params.features_cols\n",
    "label_col      = params.label_col\n",
    "save_path      = params.save_path\n",
    "\n",
    "date = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "regular_start_pred  = params.regular_start_pred\n",
    "\n",
    "save_path = params.save_path\n",
    "in_path   = save_path / f\"{ticker}_ready.csv\"\n",
    "out_path  = save_path / f\"{ticker}_final.csv\"\n",
    "\n",
    "# USE GPU if available, otherwise fallback to CPU\n",
    "device = params.device\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "df_raw = pd.read_csv(in_path, index_col=0, parse_dates=True)\n",
    "df  = models.feature_engineering(df_raw)\n",
    "df.to_csv(out_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b805fa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  X         = torch.Size([1348808, 180, 12]) (samples, look_back, features)\n",
      "  y         = torch.Size([1348808]) (samples,)\n",
      "  raw_close = torch.Size([1348808])\n",
      "  raw_bid   = torch.Size([1348808])\n",
      "  raw_ask   = torch.Size([1348808])\n"
     ]
    }
   ],
   "source": [
    "X, y, raw_close, raw_bid, raw_ask = models.build_lstm_tensors(\n",
    "    df=df,\n",
    "    look_back=look_back,\n",
    "    features_cols=features_cols,\n",
    "    label_col=label_col,\n",
    "    regular_start=regular_start_pred\n",
    ")\n",
    "\n",
    "# quick shapes\n",
    "print(\"Shapes:\")\n",
    "print(\"  X         =\", X.shape,    \"(samples, look_back, features)\")\n",
    "print(\"  y         =\", y.shape,    \"(samples,)\")\n",
    "print(\"  raw_close =\", raw_close.shape)\n",
    "print(\"  raw_bid   =\", raw_bid.shape)\n",
    "print(\"  raw_ask   =\", raw_ask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b4f1ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  X_tr        = torch.Size([881299, 180, 12])\n",
      "  y_tr        = torch.Size([881299])\n",
      "  raw_close_te= torch.Size([239319])\n",
      "  raw_bid_te  = torch.Size([239319])\n",
      "  raw_ask_te  = torch.Size([239319])\n"
     ]
    }
   ],
   "source": [
    "# Split into train/val/test by calendar day\n",
    "(X_tr, y_tr), \\\n",
    "(X_val, y_val), \\\n",
    "(X_te, y_te, raw_close_te, raw_bid_te, raw_ask_te), \\\n",
    "samples_per_day, day_id_tr, day_id_val, day_id_te = models.chronological_split(\n",
    "    X, y, raw_close, raw_bid, raw_ask, df,\n",
    "    look_back   = look_back,\n",
    "    regular_start   = regular_start_pred,\n",
    "    train_prop  = params.train_prop,\n",
    "    val_prop    = params.val_prop,\n",
    "    train_batch = params.hparams['TRAIN_BATCH']\n",
    ")\n",
    "\n",
    "# Print shapes of all tensors\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_tr        =\", X_tr.shape)\n",
    "print(\"  y_tr        =\", y_tr.shape)\n",
    "print(\"  raw_close_te=\", raw_close_te.shape)\n",
    "print(\"  raw_bid_te  =\", raw_bid_te.shape)\n",
    "print(\"  raw_ask_te  =\", raw_ask_te.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad9b6c4-3d79-45c0-b2c0-c4f46f1ad866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Entered split_to_day_datasets\n",
      "1) building weekday arrays\n",
      "   Weekdays counts → tr=881299, val=228190, te=239319\n",
      "2) moving all splits to CPU\n",
      "   CPU casts done\n",
      "3) zero-bas­ing day_id for val & test\n",
      "   val_day_id ∈ [0..413], total days=414\n",
      "   te_day_id  ∈ [0..421], total days=422\n",
      "4) instantiating DayWindowDatasets\n",
      "   ds_tr days: 1984\n",
      "   ds_val days: 414\n",
      "   ds_te days: 422\n",
      "5) building DataLoaders\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'pf' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#  Build DataLoaders over calendar‐days\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_to_day_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Training split arrays (from chronological_split)\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_id_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Validation split arrays\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_id_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Test split arrays + raw prices for post‐tracking\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_id_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_close_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_bid_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_ask_te\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Original minute‐bar DataFrame for weekday mapping\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTRAIN_BATCH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNUM_WORKERS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/my_models/Trading/_Stock_Analysis_/libs/models.py:493\u001b[0m, in \u001b[0;36msplit_to_day_datasets\u001b[0;34m(X_tr, y_tr, day_id_tr, X_val, y_val, day_id_val, X_te, y_te, day_id_te, raw_close_te, raw_bid_te, raw_ask_te, df, train_batch, train_workers, device)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# guard flags around persistent_workers and prefetch_factor\u001b[39;00m\n\u001b[1;32m    492\u001b[0m use_persistent \u001b[38;5;241m=\u001b[39m train_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mpf\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    494\u001b[0m     pf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# ensure at least 1 pre-fetched batch per worker\u001b[39;00m\n\u001b[1;32m    496\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m    497\u001b[0m     ds_tr,\n\u001b[1;32m    498\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mtrain_batch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m     prefetch_factor   \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m# each worker pulls 2 batches ahead of time (default in PyTorch)\u001b[39;00m\n\u001b[1;32m    509\u001b[0m )\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'pf' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "#  Build DataLoaders over calendar‐days\n",
    "# -----------------------------------------------------------------------------\n",
    "train_loader, val_loader, test_loader = models.split_to_day_datasets(\n",
    "    # Training split arrays (from chronological_split)\n",
    "    X_tr, y_tr, day_id_tr,\n",
    "    # Validation split arrays\n",
    "    X_val, y_val, day_id_val,\n",
    "    # Test split arrays + raw prices for post‐tracking\n",
    "    X_te, y_te, day_id_te, raw_close_te, raw_bid_te, raw_ask_te,\n",
    "    # Original minute‐bar DataFrame for weekday mapping\n",
    "    df=df,\n",
    "    train_batch=params.hparams['TRAIN_BATCH'],\n",
    "    train_workers=params.hparams['NUM_WORKERS']\n",
    "    train_prefetch_factor=params.hparams['TRAIN_PREFETCH_FACTOR']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec031f-6c8f-455f-9c72-ae411e03ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Instantiate the stateful DualMemoryLSTM & move to device\n",
    "# -----------------------------------------------------------------------------\n",
    "model = models.DualMemoryLSTM(\n",
    "    n_feats        = len(features_cols),                          \n",
    "    short_units    = params.hparams['SHORT_UNITS'],    \n",
    "    long_units     = params.hparams['LONG_UNITS'],     \n",
    "    dropout_short  = params.hparams['DROPOUT_SHORT'],  \n",
    "    dropout_long   = params.hparams['DROPOUT_LONG'],   \n",
    "    att_heads      = params.hparams['ATT_HEADS'],\n",
    "    att_drop       = params.hparams['ATT_DROPOUT']\n",
    ")\n",
    "model.to(device)   # place model parameters on GPU or CPU as specified\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512a0dd-d2c8-418e-bfca-4580fb4be995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Compute plateau_sched timing parameters\n",
    "# -----------------------------------------------------------------------------\n",
    "# Total training samples = total windows in X_tr (one window per row)\n",
    "n_train_samples = X_tr.shape[0]\n",
    "\n",
    "# How many optimizer steps (day‐bundles) constitute one epoch?\n",
    "steps_per_epoch = len(train_loader)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build optimizer, LR scheduler, AMP scaler, and gradient‐clip norm\n",
    "# -----------------------------------------------------------------------------\n",
    "optimizer, plateau_sched, cosine_sched, scaler, clipnorm = models.make_optimizer_and_scheduler(\n",
    "    model,\n",
    "    initial_lr        = params.hparams['INITIAL_LR'],       \n",
    "    weight_decay      = params.hparams['WEIGHT_DECAY'],     \n",
    "    clipnorm          = params.hparams['CLIPNORM']   \n",
    ")\n",
    "\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70105f-bbe5-4ce0-aabe-acf9193ef401",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# function to find the optimal learning rate\n",
    "############################################\n",
    "\n",
    "# # 1) Move model to CPU and build a fresh optimizer (no scheduler metadata)\n",
    "# model_cpu = model.cpu()\n",
    "# optimizer_cpu = torch.optim.AdamW(\n",
    "#     model_cpu.parameters(),\n",
    "#     lr=1e-3,        # placeholder; the finder will override this\n",
    "#     weight_decay=5e-4\n",
    "# )\n",
    "\n",
    "# # 2) Create a tiny DataLoader (batch_size=1) to save memory\n",
    "# small_loader = DataLoader(\n",
    "#     train_loader.dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0\n",
    "# )\n",
    "\n",
    "# # 3) Define an aligned MSE that permutes/expands your [1,1,D] or [D,1,1]\n",
    "# #    target → [D, T, 1] to match output shape exactly.\n",
    "# def aligned_mse(output, target):\n",
    "#     # output: [D, T, 1]\n",
    "#     # target might come in as [D,1,1] or [1,1,D]\n",
    "#     tgt = target\n",
    "\n",
    "#     # Case A: target == [D, 1, 1] → expand middle dim to T\n",
    "#     if tgt.dim() == 3 and tgt.shape[0] == output.shape[0] \\\n",
    "#        and tgt.shape[1] == 1 and tgt.shape[2] == 1:\n",
    "#         tgt = tgt.expand(-1, output.size(1), -1)\n",
    "\n",
    "#     # Case B: target == [1, 1, D] → permute to [D,1,1] then expand\n",
    "#     elif tgt.dim() == 3 and tgt.shape[0] == 1 \\\n",
    "#          and tgt.shape[1] == 1 and tgt.shape[2] == output.shape[0]:\n",
    "#         # permute (0,1,2) → (2,1,0) to get [D,1,1]\n",
    "#         tgt = tgt.permute(2, 1, 0)\n",
    "#         tgt = tgt.expand(-1, output.size(1), -1)\n",
    "\n",
    "#     else:\n",
    "#         # fallback: broadcast to exactly output.shape\n",
    "#         tgt = tgt.expand(output.shape)\n",
    "\n",
    "#     return Funct.mse_loss(output, tgt)\n",
    "\n",
    "# # 4) Free any lingering GPU memory\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # 5) Run the LR‐Finder on CPU for just 30 mini‐batches\n",
    "# lr_finder = LRFinder(\n",
    "#     model_cpu,\n",
    "#     optimizer_cpu,\n",
    "#     aligned_mse,\n",
    "#     device=\"cpu\"\n",
    "# )\n",
    "# lr_finder.range_test(\n",
    "#     small_loader,\n",
    "#     end_lr=1,     # maximum LR to try\n",
    "#     num_iter=30   # number of batches\n",
    "# )\n",
    "# lr_finder.plot()   # examine loss vs. LR curve\n",
    "# lr_finder.reset()  # restore original model & optimizer states\n",
    "\n",
    "# # 6) Move model back to GPU for your main training\n",
    "# model = model_cpu.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf94780-a876-4bf4-ad27-6abc2da1fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Count how many calendar days we see each epoch and Compute baseline RMSE on validation (zero forecast)\n",
    "# -----------------------------------------------------------------------------\n",
    "n_train_days = len(train_loader.dataset)  # dataset length = # unique days\n",
    "print(f\"Training sees {n_train_days} calendar days per epoch\\n\")\n",
    "\n",
    "baseline_val_rmse = models.naive_rmse(val_loader)\n",
    "print(f\"Baseline (zero‐forecast) RMSE on validation = {baseline_val_rmse:.6f}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run the custom stateful training loop\n",
    "# -----------------------------------------------------------------------------\n",
    "best_val_rmse  = models.custom_stateful_training_loop(\n",
    "    model               = model,\n",
    "    optimizer           = optimizer,\n",
    "    cosine_sched        = cosine_sched,\n",
    "    plateau_sched       = plateau_sched,\n",
    "    scaler              = scaler,\n",
    "    train_loader        = train_loader,\n",
    "    val_loader          = val_loader,\n",
    "    max_epochs          = params.hparams['MAX_EPOCHS'],\n",
    "    early_stop_patience = params.hparams['EARLY_STOP_PATIENCE'],\n",
    "    baseline_val_rmse   = baseline_val_rmse,\n",
    "    clipnorm            = clipnorm,\n",
    "    device              = device\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Final reporting: best RMSE and relative improvement\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\nChampion validation RMSE = {best_val_rmse:.6f}\")\n",
    "\n",
    "improvement = 100.0 * (1.0 - best_val_rmse / baseline_val_rmse)\n",
    "print(f\"Improvement over zero‐baseline = {improvement:5.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8660dd-d2db-434a-aa59-17814d343fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
