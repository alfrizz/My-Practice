{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0f1312-c2a5-4445-8d3e-f9d4ed733f43",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 4) Free any GPU buffers\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py:379\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    378\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSymInt\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m    Like an int (including magic methods), but redirects all operations on the\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    wrapped node. This is used in particular to symbolically record operations\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    in the symbolic shape workflow.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:463\u001b[0m, in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "# 1) Wipe out your namespace\n",
    "%reset -f\n",
    "\n",
    "# 2) Clear Jupyter’s stored outputs (and inputs if you like)\n",
    "try:\n",
    "    Out.clear()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    In.clear()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# 3) Force Python GC\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# 4) Free any GPU buffers\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "import importlib\n",
    "from libs import trades, plots, params, feats\n",
    "importlib.reload(trades)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(params)\n",
    "importlib.reload(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fcf85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "from pandas import Timestamp\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.importance import get_param_importances\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "\n",
    "import json\n",
    "from IPython.display import display, clear_output, update_display, HTML\n",
    "\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import contextlib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5559aef9-ab59-404e-b262-fff6e821626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 500\n",
    "n_jobs = 1\n",
    "\n",
    "base_csv = params.base_csv\n",
    "\n",
    "print(f\"Running process_splits …\")\n",
    "df_raw = trades.process_splits(\n",
    "    folder              = params.stocks_folder,\n",
    "    ticker              = params.ticker,\n",
    "    bidask_spread_pct   = params.bidask_spread_pct\n",
    ")\n",
    "\n",
    "# Once‐only minute grid build and interpolation\n",
    "print(f\"Running prepare_interpolate_data …\")\n",
    "df = trades.prepare_interpolate_data(\n",
    "    df              = df_raw,\n",
    "    sess_premark    = params.sess_premark,\n",
    "    sess_start      = params.sess_start,\n",
    "    sess_end        = params.sess_end\n",
    ")\n",
    "\n",
    "# Persist to base CSV and return\n",
    "df.to_csv(base_csv)\n",
    "print(f\"[process_splits] Saved processed data to: {base_csv}\")\n",
    "\n",
    "# df is now guaranteed to be the split‐adjusted, minute‐aligned DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db718e-a64f-4c1c-93e5-b52397b0b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_function(\n",
    "    df: pd.DataFrame,\n",
    "    min_prof_thr: float,\n",
    "    max_down_prop: float,\n",
    "    gain_tightening_factor: float,\n",
    "    merging_retracement_thr: float,\n",
    "    merging_time_gap_thr: float,\n",
    "    tau_time: int,\n",
    "    tau_dur: int,\n",
    "    trailing_stop_pct: float,\n",
    "    buy_threshold: float,\n",
    "    beta_sat: float,\n",
    "    smoothing_window: int\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    1) Run the full backtest pipeline to simulate trades and P&L per day.\n",
    "    2) Extract each day’s performance stats (strategy return and trade returns).\n",
    "    3) Free intermediate DataFrames and trade lists to minimize memory usage.\n",
    "    4) Compute total and average daily P&L across all trading days.\n",
    "    5) Compute total trades and average return per trade.\n",
    "    6) Print a summary of P&L metrics.\n",
    "    Returns the average daily P&L for Optuna’s objective.\n",
    "    \"\"\"\n",
    "    # A) Execute the end-to-end trading simulation\n",
    "    simulation = trades.run_trading_pipeline(\n",
    "        df, \n",
    "        col_signal=\"signal\",\n",
    "        col_action=\"signal_action\",\n",
    "        min_prof_thr=min_prof_thr,\n",
    "        max_down_prop=max_down_prop,\n",
    "        gain_tightening_factor=gain_tightening_factor,\n",
    "        merging_retracement_thr=merging_retracement_thr,\n",
    "        merging_time_gap_thr=merging_time_gap_thr,\n",
    "        tau_time=tau_time,\n",
    "        tau_dur=tau_dur,\n",
    "        trailing_stop_pct=trailing_stop_pct,\n",
    "        buy_threshold=buy_threshold,\n",
    "        beta_sat=beta_sat,\n",
    "        smoothing_window=smoothing_window\n",
    "    )\n",
    "    \n",
    "    # If pipeline returned None (no trading days), bail out\n",
    "    if not simulation:\n",
    "        return 0.0\n",
    "\n",
    "    # B) Extract per-day performance stats from simulation output\n",
    "    per_day_stats = [\n",
    "        stats \n",
    "        for (_, (_, _, stats)) \n",
    "        in simulation.items()\n",
    "    ]\n",
    "\n",
    "    # C) Release DataFrames and trade lists to free memory\n",
    "    for (_, (df_sim, trades_list, _)) in simulation.items():\n",
    "        del df_sim, trades_list\n",
    "    num_days = len(simulation)\n",
    "    del simulation\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # D) Compute total and average daily P&L\n",
    "    daily_returns = [s[\"Strategy Return ($)\"] for s in per_day_stats]\n",
    "    total_pnl     = float(np.sum(daily_returns))\n",
    "    avg_daily_pnl = total_pnl / num_days\n",
    "\n",
    "    # E) Compute trade-level metrics: total trades and avg return per trade\n",
    "    trades_only_days = [s for s in per_day_stats if s[\"Trades Returns ($)\"]]\n",
    "    total_trades     = sum(len(s[\"Trades Returns ($)\"]) for s in trades_only_days)\n",
    "    avg_per_trade    = (total_pnl / total_trades) if total_trades else 0.0\n",
    "\n",
    "    # F) Print a summary of results\n",
    "    print(f\"→ Total P&L over {num_days} days   : ${total_pnl:.2f}\")\n",
    "    print(f\"→ Avg daily P&L                    : ${avg_daily_pnl:.4f}\")\n",
    "    print(f\"→ Total trades                     : {total_trades}\")\n",
    "    print(f\"→ Avg return per trade            : ${avg_per_trade:.4f}\\n\")\n",
    "\n",
    "    return avg_daily_pnl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09be5dd-72b2-4823-a46a-6c62068eb3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    hyperpars = {\n",
    "        \"min_prof_thr\"            : trial.suggest_float(\"min_prof_thr\", 0.01, 0.1), # increasing min, to avoid creating too many trades\n",
    "        \"max_down_prop\"           : trial.suggest_float(\"max_down_prop\", 0.1, 3),\n",
    "        \"gain_tightening_factor\"  : trial.suggest_float(\"gain_tightening_factor\", 5, 50),\n",
    "        \"merging_retracement_thr\" : trial.suggest_float(\"merging_retracement_thr\", 0.1, 1),\n",
    "        \"merging_time_gap_thr\"    : trial.suggest_float(\"merging_time_gap_thr\", 1, 7),\n",
    "        \"tau_time\"                : trial.suggest_int(\"tau_time\", 1, 60),\n",
    "        \"tau_dur\"                 : trial.suggest_int(\"tau_dur\", 60, 240),\n",
    "        \"trailing_stop_pct\"       : trial.suggest_float(\"trailing_stop_pct\", 0.03, 0.1), # increasing min, to reproduce a realistic scenario of trailing stop loss\n",
    "        \"buy_threshold\"           : trial.suggest_float(\"buy_threshold\", 0.1, 0.7),\n",
    "        \"beta_sat\"                : trial.suggest_int(\"beta_sat\", 1, 20),\n",
    "        \"smoothing_window\"        : trial.suggest_int(\"smoothing_window\", 30, 30)\n",
    "    }\n",
    "    print('---------------------------------------------------------------------------------------------------------------\\n')\n",
    "    #    This will print Total P&L and Average Daily P&L, and return `avg_daily_pnl` for Optuna to maximize.\n",
    "    avg_daily_pnl = optimization_function(df=df, **hyperpars)\n",
    "\n",
    "    return avg_daily_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create and Run the Study ===\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=6, n_warmup_steps=12)\n",
    "\n",
    "study = optuna.create_study( # Point it at an SQLite file so it writes out each result immediately instead of buffering in RAM\n",
    "    storage=f\"sqlite:///{os.path.join(params.optuna_folder, \"optuna_study_target.db\")}\", \n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    "    pruner=pruner,\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=n_trials,\n",
    "    n_jobs=n_jobs,       # run trials concurrently\n",
    "    callbacks=[plots.cleanup_callback, plots.lightweight_plot_callback, plots.save_best_trial_callback],\n",
    "    gc_after_trial=True,\n",
    ")\n",
    "\n",
    "plt.close('all')   # safe here; the final image remains displayed in the notebook output\n",
    "gc.collect()       # optional extra sweep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc33d44-3190-496f-b395-af7dea712f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final plot\n",
    "ax = plot_optimization_history(study)\n",
    "ax.figure.set_size_inches(8, 4)\n",
    "plt.show()\n",
    "\n",
    "# === Print Final Results ===\n",
    "print(\"Best Parameters:\", study.best_params)\n",
    "print(\"Best Average Improvement:\", study.best_value)\n",
    "\n",
    "# === Compute & Print Hyperparameter Importances ===\n",
    "importances = get_param_importances(study)\n",
    "print(\"\\nHyperparameter importances (higher ⇒ more impact):\")\n",
    "for name, score in sorted(importances.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {name:20s} : {score:.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Dump study results (including importances)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "file_name  = f\"{params.ticker}_target.json\"\n",
    "file_path  = os.path.join(params.optuna_folder, file_name)\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params\":   study.best_params,\n",
    "            \"best_value\":    study.best_value,\n",
    "            \"importances\":   importances,\n",
    "            \"trials\": [\n",
    "                {\n",
    "                    \"number\": t.number,\n",
    "                    \"value\":  t.value,\n",
    "                    \"params\": t.params,\n",
    "                    \"state\":  t.state.name\n",
    "                }\n",
    "                for t in study.trials\n",
    "            ],\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )\n",
    "\n",
    "print(f\"\\nOptuna results (and importances) saved to: {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
