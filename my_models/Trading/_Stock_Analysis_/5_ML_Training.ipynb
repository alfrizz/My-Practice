{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f06a4f-691a-4a84-a305-e7212eb879bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c868158-e6bb-4d56-bbdd-8e8103f0b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Wipe out all Python variables\n",
    "%reset -f\n",
    "# 2) Force Python’s garbage collector to run\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import importlib\n",
    "from libs import trades, plots, params, models\n",
    "importlib.reload(trades)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(params)\n",
    "importlib.reload(models)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import math\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "from typing import Sequence, List, Tuple, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Funct\n",
    "from torch_lr_finder import LRFinder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b98406a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'libs.params' has no attribute 'look_back_tick'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m look_back      \u001b[38;5;241m=\u001b[39m \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlook_back_tick\u001b[49m \n\u001b[1;32m      2\u001b[0m features_cols  \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mfeatures_cols_tick\n\u001b[1;32m      3\u001b[0m label_col      \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mlabel_col\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'libs.params' has no attribute 'look_back_tick'"
     ]
    }
   ],
   "source": [
    "look_back      = params.look_back_tick \n",
    "features_cols  = params.features_cols_tick\n",
    "label_col      = params.label_col\n",
    "device         = params.device\n",
    "\n",
    "date = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "df_feat = pd.read_csv(params.feat_csv, index_col=0, parse_dates=True)\n",
    "\n",
    "df_features = df_feat[features_cols + ['signal','ask','bid']]\n",
    "df_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, raw_close, raw_bid, raw_ask = models.build_lstm_tensors(\n",
    "    df=df_features,\n",
    "    look_back=look_back,\n",
    "    features_cols=features_cols,\n",
    "    label_col=label_col,\n",
    "    regular_start=params.regular_start_pred\n",
    ")\n",
    "\n",
    "# quick shapes\n",
    "print(\"Shapes:\")\n",
    "print(\"  X         =\", X.shape,    \"(samples, look_back, features)\")\n",
    "print(\"  y         =\", y.shape,    \"(samples,)\")\n",
    "print(\"  raw_close =\", raw_close.shape)\n",
    "print(\"  raw_bid   =\", raw_bid.shape)\n",
    "print(\"  raw_ask   =\", raw_ask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/val/test by calendar day\n",
    "(X_tr, y_tr), \\\n",
    "(X_val, y_val), \\\n",
    "(X_te, y_te, raw_close_te, raw_bid_te, raw_ask_te), \\\n",
    "samples_per_day, day_id_tr, day_id_val, day_id_te = models.chronological_split(\n",
    "    X, y, raw_close, raw_bid, raw_ask, df_features,\n",
    "    look_back   = look_back,\n",
    "    regular_start   = params.regular_start_pred,\n",
    "    train_prop  = params.train_prop,\n",
    "    val_prop    = params.val_prop,\n",
    "    train_batch = params.hparams['TRAIN_BATCH']\n",
    ")\n",
    "\n",
    "# Print shapes of all tensors\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_tr        =\", X_tr.shape)\n",
    "print(\"  y_tr        =\", y_tr.shape)\n",
    "print(\"  raw_close_te=\", raw_close_te.shape)\n",
    "print(\"  raw_bid_te  =\", raw_bid_te.shape)\n",
    "print(\"  raw_ask_te  =\", raw_ask_te.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9b6c4-3d79-45c0-b2c0-c4f46f1ad866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Build DataLoaders over calendar‐days\n",
    "# -----------------------------------------------------------------------------\n",
    "train_loader, val_loader, test_loader = models.split_to_day_datasets(\n",
    "    # Training split arrays (from chronological_split)\n",
    "    X_tr, y_tr, day_id_tr,\n",
    "    # Validation split arrays\n",
    "    X_val, y_val, day_id_val,\n",
    "    # Test split arrays + raw prices for post‐tracking\n",
    "    X_te, y_te, day_id_te, raw_close_te, raw_bid_te, raw_ask_te,\n",
    "    # Original minute‐bar DataFrame for weekday mapping\n",
    "    df=df_features,\n",
    "    train_batch=params.hparams['TRAIN_BATCH'],\n",
    "    train_workers=params.hparams['NUM_WORKERS'],\n",
    "    train_prefetch_factor=params.hparams['TRAIN_PREFETCH_FACTOR']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec031f-6c8f-455f-9c72-ae411e03ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Instantiate the stateful DualMemoryLSTM & move to device\n",
    "# -----------------------------------------------------------------------------\n",
    "model = models.DualMemoryLSTM(\n",
    "    n_feats        = len(features_cols),                          \n",
    "    short_units    = params.hparams['SHORT_UNITS'],    \n",
    "    long_units     = params.hparams['LONG_UNITS'],     \n",
    "    dropout_short  = params.hparams['DROPOUT_SHORT'],  \n",
    "    dropout_long   = params.hparams['DROPOUT_LONG'],   \n",
    "    att_heads      = params.hparams['ATT_HEADS'],\n",
    "    att_drop       = params.hparams['ATT_DROPOUT']\n",
    ")\n",
    "model.to(device)   # place model parameters on GPU or CPU as specified\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512a0dd-d2c8-418e-bfca-4580fb4be995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Compute plateau_sched timing parameters\n",
    "# -----------------------------------------------------------------------------\n",
    "# Total training samples = total windows in X_tr (one window per row)\n",
    "n_train_samples = X_tr.shape[0]\n",
    "\n",
    "# How many optimizer steps (day‐bundles) constitute one epoch?\n",
    "steps_per_epoch = len(train_loader)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build optimizer, LR scheduler, AMP scaler, and gradient‐clip norm\n",
    "# -----------------------------------------------------------------------------\n",
    "optimizer, plateau_sched, cosine_sched, scaler, clipnorm = models.make_optimizer_and_scheduler(\n",
    "    model,\n",
    "    initial_lr        = params.hparams['INITIAL_LR'],       \n",
    "    weight_decay      = params.hparams['WEIGHT_DECAY'],     \n",
    "    clipnorm          = params.hparams['CLIPNORM']   \n",
    ")\n",
    "\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70105f-bbe5-4ce0-aabe-acf9193ef401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################################\n",
    "# # function to find the optimal learning rate\n",
    "# ###########################################\n",
    "\n",
    "# # 1) Move model to CPU and build a fresh optimizer (no scheduler metadata)\n",
    "# model_cpu = model.cpu()\n",
    "# optimizer_cpu = torch.optim.AdamW(\n",
    "#     model_cpu.parameters(),\n",
    "#     lr=1e-3,        # placeholder; the finder will override this\n",
    "#     weight_decay=5e-4\n",
    "# )\n",
    "\n",
    "# # 2) Create a tiny DataLoader (batch_size=1) to save memory\n",
    "# small_loader = DataLoader(\n",
    "#     train_loader.dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0\n",
    "# )\n",
    "\n",
    "# # 3) Define an aligned MSE that permutes/expands your [1,1,D] or [D,1,1]\n",
    "# #    target → [D, T, 1] to match output shape exactly.\n",
    "# def aligned_mse(output, target):\n",
    "#     # output: [D, T, 1]\n",
    "#     # target might come in as [D,1,1] or [1,1,D]\n",
    "#     tgt = target\n",
    "\n",
    "#     # Case A: target == [D, 1, 1] → expand middle dim to T\n",
    "#     if tgt.dim() == 3 and tgt.shape[0] == output.shape[0] \\\n",
    "#        and tgt.shape[1] == 1 and tgt.shape[2] == 1:\n",
    "#         tgt = tgt.expand(-1, output.size(1), -1)\n",
    "\n",
    "#     # Case B: target == [1, 1, D] → permute to [D,1,1] then expand\n",
    "#     elif tgt.dim() == 3 and tgt.shape[0] == 1 \\\n",
    "#          and tgt.shape[1] == 1 and tgt.shape[2] == output.shape[0]:\n",
    "#         # permute (0,1,2) → (2,1,0) to get [D,1,1]\n",
    "#         tgt = tgt.permute(2, 1, 0)\n",
    "#         tgt = tgt.expand(-1, output.size(1), -1)\n",
    "\n",
    "#     else:\n",
    "#         # fallback: broadcast to exactly output.shape\n",
    "#         tgt = tgt.expand(output.shape)\n",
    "\n",
    "#     return Funct.mse_loss(output, tgt)\n",
    "\n",
    "# # 4) Free any lingering GPU memory\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # 5) Run the LR‐Finder on CPU for just 30 mini‐batches\n",
    "# lr_finder = LRFinder(\n",
    "#     model_cpu,\n",
    "#     optimizer_cpu,\n",
    "#     aligned_mse,\n",
    "#     device=\"cpu\"\n",
    "# )\n",
    "# lr_finder.range_test(\n",
    "#     small_loader,\n",
    "#     end_lr=1,     # maximum LR to try\n",
    "#     num_iter=30   # number of batches\n",
    "# )\n",
    "# lr_finder.plot()   # examine loss vs. LR curve\n",
    "# lr_finder.reset()  # restore original model & optimizer states\n",
    "\n",
    "# # 6) Move model back to GPU for your main training\n",
    "# model = model_cpu.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf94780-a876-4bf4-ad27-6abc2da1fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Count how many calendar days we see each epoch and Compute baseline RMSE on validation (zero forecast)\n",
    "# -----------------------------------------------------------------------------\n",
    "n_train_days = len(train_loader.dataset)  # dataset length = # unique days\n",
    "print(f\"Training sees {n_train_days} calendar days per epoch\\n\")\n",
    "\n",
    "baseline_val_rmse = models.naive_rmse(val_loader)\n",
    "print(f\"Baseline (zero‐forecast) RMSE on validation = {baseline_val_rmse:.6f}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run the custom stateful training loop\n",
    "# -----------------------------------------------------------------------------\n",
    "best_val_rmse  = models.custom_stateful_training_loop(\n",
    "    model               = model,\n",
    "    optimizer           = optimizer,\n",
    "    cosine_sched        = cosine_sched,\n",
    "    plateau_sched       = plateau_sched,\n",
    "    scaler              = scaler,\n",
    "    train_loader        = train_loader,\n",
    "    val_loader          = val_loader,\n",
    "    max_epochs          = params.hparams['MAX_EPOCHS'],\n",
    "    early_stop_patience = params.hparams['EARLY_STOP_PATIENCE'],\n",
    "    baseline_val_rmse   = baseline_val_rmse,\n",
    "    clipnorm            = clipnorm,\n",
    "    device              = device\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Final reporting: best RMSE and relative improvement\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\nChampion validation RMSE = {best_val_rmse:.6f}\")\n",
    "\n",
    "improvement = 100.0 * (1.0 - best_val_rmse / baseline_val_rmse)\n",
    "print(f\"Improvement over zero‐baseline = {improvement:5.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8660dd-d2db-434a-aa59-17814d343fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c3b45-e00a-4a85-860d-4f87b71cbbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
