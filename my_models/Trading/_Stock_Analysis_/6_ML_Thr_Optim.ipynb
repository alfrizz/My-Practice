{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db53f869-3ce8-4b85-9c38-ba83b86b51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Wipe out all Python variables\n",
    "%reset -f\n",
    "# 2) Force Python’s garbage collector to run\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"BLIS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_WAIT_POLICY\"] = \"PASSIVE\"\n",
    "\n",
    "import importlib\n",
    "from libs import trades, plots, params, models\n",
    "importlib.reload(trades)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(params)\n",
    "importlib.reload(models)\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17c661b-bcae-4bdb-9bd4-6f8018a38d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off interactive plotting globally (we’ll manage our own display)\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # safe, headless-friendly\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Tuple, Set, List, Union\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from datetime import time\n",
    "\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as Funct\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.serialization.add_safe_globals([models.DayWindowDataset])\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import io\n",
    "import json\n",
    "from PIL import Image\n",
    "import IPython.display as disp\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.importance import get_param_importances\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "from optuna.storages import RDBStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9b44fb-0cf5-4b31-8cdf-39d8d587234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device               = params.device\n",
    "ticker               = params.ticker\n",
    "save_path            = params.save_path\n",
    "\n",
    "sess_start           = params.sess_start\n",
    "sess_end             = params.sess_end\n",
    "\n",
    "look_back            = params.look_back_tick\n",
    "sess_start_pred      = params.sess_start_pred_tick\n",
    "sess_start_shift     = params.sess_start_shift_tick\n",
    "\n",
    "n_trials = 100\n",
    "n_jobs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71fcfa66-3fa8-4cb4-a040-4e0b5b1804fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>atr_14</th>\n",
       "      <th>ma_5</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>ma_diff</th>\n",
       "      <th>macd_12_26</th>\n",
       "      <th>...</th>\n",
       "      <th>bb_width_20</th>\n",
       "      <th>stoch_k_14</th>\n",
       "      <th>stoch_d_3</th>\n",
       "      <th>in_trading</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02 13:09:00</th>\n",
       "      <td>-0.193147</td>\n",
       "      <td>-0.317313</td>\n",
       "      <td>-0.028125</td>\n",
       "      <td>-0.193762</td>\n",
       "      <td>-0.319224</td>\n",
       "      <td>-1.435516</td>\n",
       "      <td>-0.185561</td>\n",
       "      <td>-0.282361</td>\n",
       "      <td>0.123688</td>\n",
       "      <td>0.202706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.929333</td>\n",
       "      <td>-1.481580</td>\n",
       "      <td>-1.561625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.763664</td>\n",
       "      <td>0.764807</td>\n",
       "      <td>0.016650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 13:10:00</th>\n",
       "      <td>-0.201085</td>\n",
       "      <td>-0.324262</td>\n",
       "      <td>-0.037500</td>\n",
       "      <td>-0.201725</td>\n",
       "      <td>-0.283773</td>\n",
       "      <td>-1.432540</td>\n",
       "      <td>-0.192087</td>\n",
       "      <td>-0.284115</td>\n",
       "      <td>0.112444</td>\n",
       "      <td>0.193448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.921566</td>\n",
       "      <td>-1.481580</td>\n",
       "      <td>-1.561625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.763647</td>\n",
       "      <td>0.764790</td>\n",
       "      <td>0.018001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 13:11:00</th>\n",
       "      <td>-0.209022</td>\n",
       "      <td>-0.331210</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.209688</td>\n",
       "      <td>-0.248322</td>\n",
       "      <td>-1.429563</td>\n",
       "      <td>-0.200245</td>\n",
       "      <td>-0.286307</td>\n",
       "      <td>0.098388</td>\n",
       "      <td>0.183174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.913246</td>\n",
       "      <td>-1.481580</td>\n",
       "      <td>-1.561625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.763631</td>\n",
       "      <td>0.764773</td>\n",
       "      <td>0.019462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 13:12:00</th>\n",
       "      <td>-0.216960</td>\n",
       "      <td>-0.338159</td>\n",
       "      <td>-0.056250</td>\n",
       "      <td>-0.217651</td>\n",
       "      <td>-0.212872</td>\n",
       "      <td>-1.426587</td>\n",
       "      <td>-0.208402</td>\n",
       "      <td>-0.288939</td>\n",
       "      <td>0.085270</td>\n",
       "      <td>0.172220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.904541</td>\n",
       "      <td>-1.481580</td>\n",
       "      <td>-1.561625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.763614</td>\n",
       "      <td>0.764757</td>\n",
       "      <td>0.021042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 13:13:00</th>\n",
       "      <td>-0.224897</td>\n",
       "      <td>-0.345107</td>\n",
       "      <td>-0.065625</td>\n",
       "      <td>-0.225614</td>\n",
       "      <td>-0.177421</td>\n",
       "      <td>-1.423611</td>\n",
       "      <td>-0.216560</td>\n",
       "      <td>-0.292008</td>\n",
       "      <td>0.073088</td>\n",
       "      <td>0.160859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.895592</td>\n",
       "      <td>-1.481580</td>\n",
       "      <td>-1.561625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.763597</td>\n",
       "      <td>0.764740</td>\n",
       "      <td>0.022750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:56:00</th>\n",
       "      <td>0.475806</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.705997</td>\n",
       "      <td>5.467381</td>\n",
       "      <td>2.024482</td>\n",
       "      <td>0.367023</td>\n",
       "      <td>-0.130453</td>\n",
       "      <td>2.191746</td>\n",
       "      <td>1.957857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122381</td>\n",
       "      <td>0.619888</td>\n",
       "      <td>0.342752</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.146</td>\n",
       "      <td>196.667400</td>\n",
       "      <td>196.962600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:57:00</th>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.478780</td>\n",
       "      <td>6.628840</td>\n",
       "      <td>2.207440</td>\n",
       "      <td>0.460866</td>\n",
       "      <td>-0.093452</td>\n",
       "      <td>2.466615</td>\n",
       "      <td>1.999189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187641</td>\n",
       "      <td>0.223810</td>\n",
       "      <td>0.415204</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.146</td>\n",
       "      <td>196.527500</td>\n",
       "      <td>196.822500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:58:00</th>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.470665</td>\n",
       "      <td>7.630343</td>\n",
       "      <td>2.216153</td>\n",
       "      <td>0.497086</td>\n",
       "      <td>-0.060109</td>\n",
       "      <td>2.478653</td>\n",
       "      <td>2.004989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241322</td>\n",
       "      <td>0.209943</td>\n",
       "      <td>0.370103</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.146</td>\n",
       "      <td>196.522500</td>\n",
       "      <td>196.817500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:59:00</th>\n",
       "      <td>0.475806</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>-0.129032</td>\n",
       "      <td>-0.227217</td>\n",
       "      <td>31.658646</td>\n",
       "      <td>2.487280</td>\n",
       "      <td>0.408182</td>\n",
       "      <td>-0.062549</td>\n",
       "      <td>2.057321</td>\n",
       "      <td>1.614144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245429</td>\n",
       "      <td>-0.982637</td>\n",
       "      <td>-0.192907</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.146</td>\n",
       "      <td>196.092800</td>\n",
       "      <td>196.387200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 21:00:00</th>\n",
       "      <td>0.314516</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>-0.387097</td>\n",
       "      <td>0.259677</td>\n",
       "      <td>241.291957</td>\n",
       "      <td>2.861997</td>\n",
       "      <td>0.358792</td>\n",
       "      <td>-0.032866</td>\n",
       "      <td>1.670098</td>\n",
       "      <td>1.550358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236868</td>\n",
       "      <td>-0.173363</td>\n",
       "      <td>-0.332445</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.146</td>\n",
       "      <td>196.392600</td>\n",
       "      <td>196.687400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3601230 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close      volume  \\\n",
       "2004-01-02 13:09:00 -0.193147 -0.317313 -0.028125 -0.193762   -0.319224   \n",
       "2004-01-02 13:10:00 -0.201085 -0.324262 -0.037500 -0.201725   -0.283773   \n",
       "2004-01-02 13:11:00 -0.209022 -0.331210 -0.046875 -0.209688   -0.248322   \n",
       "2004-01-02 13:12:00 -0.216960 -0.338159 -0.056250 -0.217651   -0.212872   \n",
       "2004-01-02 13:13:00 -0.224897 -0.345107 -0.065625 -0.225614   -0.177421   \n",
       "...                       ...       ...       ...       ...         ...   \n",
       "2025-06-18 20:56:00  0.475806  0.704918  0.500000  0.705997    5.467381   \n",
       "2025-06-18 20:57:00  0.685484  0.836066  0.387097  0.478780    6.628840   \n",
       "2025-06-18 20:58:00  0.467742  0.508197  0.500000  0.470665    7.630343   \n",
       "2025-06-18 20:59:00  0.475806  0.524590 -0.129032 -0.227217   31.658646   \n",
       "2025-06-18 21:00:00  0.314516  0.360656 -0.387097  0.259677  241.291957   \n",
       "\n",
       "                       atr_14      ma_5     ma_20   ma_diff  macd_12_26  ...  \\\n",
       "2004-01-02 13:09:00 -1.435516 -0.185561 -0.282361  0.123688    0.202706  ...   \n",
       "2004-01-02 13:10:00 -1.432540 -0.192087 -0.284115  0.112444    0.193448  ...   \n",
       "2004-01-02 13:11:00 -1.429563 -0.200245 -0.286307  0.098388    0.183174  ...   \n",
       "2004-01-02 13:12:00 -1.426587 -0.208402 -0.288939  0.085270    0.172220  ...   \n",
       "2004-01-02 13:13:00 -1.423611 -0.216560 -0.292008  0.073088    0.160859  ...   \n",
       "...                       ...       ...       ...       ...         ...  ...   \n",
       "2025-06-18 20:56:00  2.024482  0.367023 -0.130453  2.191746    1.957857  ...   \n",
       "2025-06-18 20:57:00  2.207440  0.460866 -0.093452  2.466615    1.999189  ...   \n",
       "2025-06-18 20:58:00  2.216153  0.497086 -0.060109  2.478653    2.004989  ...   \n",
       "2025-06-18 20:59:00  2.487280  0.408182 -0.062549  2.057321    1.614144  ...   \n",
       "2025-06-18 21:00:00  2.861997  0.358792 -0.032866  1.670098    1.550358  ...   \n",
       "\n",
       "                     bb_width_20  stoch_k_14  stoch_d_3  in_trading   hour  \\\n",
       "2004-01-02 13:09:00    -0.929333   -1.481580  -1.561625           0  0.493   \n",
       "2004-01-02 13:10:00    -0.921566   -1.481580  -1.561625           0  0.493   \n",
       "2004-01-02 13:11:00    -0.913246   -1.481580  -1.561625           0  0.493   \n",
       "2004-01-02 13:12:00    -0.904541   -1.481580  -1.561625           0  0.493   \n",
       "2004-01-02 13:13:00    -0.895592   -1.481580  -1.561625           0  0.493   \n",
       "...                          ...         ...        ...         ...    ...   \n",
       "2025-06-18 20:56:00     0.122381    0.619888   0.342752           1 -0.939   \n",
       "2025-06-18 20:57:00     0.187641    0.223810   0.415204           1 -0.939   \n",
       "2025-06-18 20:58:00     0.241322    0.209943   0.370103           1 -0.939   \n",
       "2025-06-18 20:59:00     0.245429   -0.982637  -0.192907           1 -0.939   \n",
       "2025-06-18 21:00:00     0.236868   -0.173363  -0.332445           0 -0.960   \n",
       "\n",
       "                     day_of_week  month         bid         ask    signal  \n",
       "2004-01-02 13:09:00       -0.976  0.351    0.763664    0.764807  0.016650  \n",
       "2004-01-02 13:10:00       -0.976  0.351    0.763647    0.764790  0.018001  \n",
       "2004-01-02 13:11:00       -0.976  0.351    0.763631    0.764773  0.019462  \n",
       "2004-01-02 13:12:00       -0.976  0.351    0.763614    0.764757  0.021042  \n",
       "2004-01-02 13:13:00       -0.976  0.351    0.763597    0.764740  0.022750  \n",
       "...                          ...    ...         ...         ...       ...  \n",
       "2025-06-18 20:56:00        0.039  0.146  196.667400  196.962600  0.000000  \n",
       "2025-06-18 20:57:00        0.039  0.146  196.527500  196.822500  0.000000  \n",
       "2025-06-18 20:58:00        0.039  0.146  196.522500  196.817500  0.000000  \n",
       "2025-06-18 20:59:00        0.039  0.146  196.092800  196.387200  0.000000  \n",
       "2025-06-18 21:00:00        0.039  0.146  196.392600  196.687400  0.000000  \n",
       "\n",
       "[3601230 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = pd.read_csv(params.feat_csv, index_col=0, parse_dates=True)\n",
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3daba10b-3212-4a06-b607-748995bdc51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ATT_DROPOUT': 0.1,\n",
      " 'ATT_HEADS': 8,\n",
      " 'CLIPNORM': 1.0,\n",
      " 'DROPOUT_LONG': 0.1,\n",
      " 'DROPOUT_SHORT': 0.1,\n",
      " 'EARLY_STOP_PATIENCE': 15,\n",
      " 'ETA_MIN': 5e-06,\n",
      " 'INITIAL_LR': 0.0005,\n",
      " 'LONG_UNITS': 128,\n",
      " 'LR_EPOCHS_WARMUP': 5,\n",
      " 'MAX_EPOCHS': 90,\n",
      " 'MIN_LR': 1e-06,\n",
      " 'NUM_WORKERS': 2,\n",
      " 'PLATEAU_FACTOR': 0.9,\n",
      " 'PLATEAU_PATIENCE': 0,\n",
      " 'PLAT_EPOCHS_WARMUP': 999,\n",
      " 'SHORT_UNITS': 128,\n",
      " 'TRAIN_BATCH': 32,\n",
      " 'TRAIN_PREFETCH_FACTOR': 1,\n",
      " 'T_0': 90,\n",
      " 'T_MULT': 1,\n",
      " 'VAL_BATCH': 1,\n",
      " 'WEIGHT_DECAY': 1e-05}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAG4CAYAAAD7SXfsAACH5UlEQVR4Ae2dB3yURf7/v6mQBEISem9KR5qACAIKyGHDgieeBWygop4od3r+OU8sPzkUkUMRCyfFU04R8URFEQQEVBSRpoAU6SUkIQkhPfnPZzbPZndTdsOWPM/uZ16vJ0+bmWfmPU92P/udme+EFasgDCRAAiRAAiRAAiRAAiRwjgTCzzEdk5EACZAACZAACZAACZCAJkBByReBBEiABEiABEiABEjAKwIUlF7hY2ISIAESIAESIAESIAEKSr4DJEACJEACJEACJEACXhGgoPQKHxOTAAmQAAmQAAmQAAlQUPIdIAESIAESIAESIAES8IoABaVX+JiYBEiABEiABEiABEiAgpLvAAmQAAmQAAmQAAmQgFcEKCi9wsfEJEACJEACJEACJEACFJR8B0iABEiABEiABEiABLwiQEHpFT4mJgESIAESIAESIAESoKDkO0ACJEACJEACJEACJOAVAQpKr/AxMQmQAAmQAAmQAAmQAAUl3wESIAESIAESIAESIAGvCFBQeoWPiUmABEiABEiABEiABCgo+Q6QAAmQAAmQAAmQAAl4RYCC0it8TEwCJEACJEACJEACJEBByXeABEiABEiABEiABEjAKwIUlF7hY2ISIAESIAESIAESIAEKSr4DJEACJEACJEACJEACXhGgoPQKHxOTAAmQAAmQAAmQAAlQUPIdIAESIAESIAESIAES8IoABaVX+JiYBEiABEiABEiABEiAgpLvAAmQAAmQAAmQAAmQgFcEKCi9wsfEJEACJEACJEACJEACFJR8B0iABEiABEiABEiABLwiQEHpFT4mJgESIAESIAESIAESoKDkO0ACJEACJEACJEACJOAVAQpKr/AxMQmQAAmQAAmQAAmQAAUl3wESIIFqI3DbbbfJZZdd5tXz27dvL48//rhXeTAxCZAACZCAdwQivUvO1CRAAsFCAMLM0/D888/L9ddf72l0xiMBEiABEghyAmHFKgR5HVk9EiABDwh8/PHHTrH27dsnc+bMkQsvvFD++Mc/Ot3r2bOnNG/e3OnauZzk5eXpZNHR0eeSXKfJzc2V8PBwiYqKOuc8mJAESIAESMA7AhSU3vFjahIIWgLff/+93H777XLdddfJ1KlTK61nTk6OREZG6q3SiLxZKYEzZ85IrVq1Ko3jj5vV9Vx/1IV5kgAJVA8BjqGsHu58KglYloAx7vHIkSMyceJE6du3r3Tr1k2OHz+u6/Tuu+/KXXfdJQMHDpQuXbpIv3795MEHH5Tdu3eXqbORl+MN41pycrL85S9/0flfcMEFcsstt8i2bdsco+rj8sZQGte2bt2qRXGPHj20pRXlTUlJKZPHyZMn7c/q3r27/OlPf5IffvhBj830dCgAxoKi7Dt37pQ777xT8MxevXrJAw88IAcPHnR6JsQ68l2yZIksWrRIrr76aunatas8++yz9nj/+9//5MYbbxSUBxusxJ9++qn9vuPB2rVrdVxwAu/JkyfL6dOn9TMcx5cePnxYX5s1a5Z88cUXMmrUKN129913nz27X375RR566CGdD9pvyJAh8uKLL0p2drY9Dg7Q3n//+9/1GFiUHe8BhkHAqu0YUI+bbrpJ+vTpIyjf4MGDNZM9e/Y4RuMxCZCAxQlwDKXFG5DFJ4HqIJCVlaUFHoQExAfOY2NjdVHeeustLVIgABMTE+X333+XxYsXy/r162Xp0qXSokULt0U+e/aszr9z5846f4jAefPmyT333CNfffWVR1Y8CDvEHzlypFxxxRWyY8cO+eCDDyQjI0Pmzp1rL0NmZqZ+1qFDh+SGG24QPBPd/ePGjfOorPaM1AFEFqy6EJcQw8gHgnHz5s1aPDZs2NAxuixYsEBOnTqlxWKjRo0kLi5O3585c6bMnj1b2rVrJxMmTBCMTPrkk0/kkUceEZTz3nvvteezcuVKLdDq1aunyxwfHy+4dvfdd9vjuB7g/vz582X06NH62cbIJwhTPK9x48Zy6623CvIER7D/6aefdHlhiS4oKJA77rhD1xd5tGnTRtBmqO93331nLx/EJDhgiATyxTty4sQJgaDev3+/nHfeea5F4zkJkIBVCWAMJQMJkAAJuBJQwqBYCZrixx57zOmWEhr6+gsvvOB03ThR4tI4tO+VdbJYCbXip556yn4NB8jr0ksvLXMNz1WWLqfry5Yt089VAs3penllxDVlASzetGmTU1xlUdN5KOFjv/7SSy/pa++88479Gg6+/PJLfR15eRJQD8RVgtopupGPI0eDrRqfWqyso07xldAq7tChQ/E111xTrESa/R64XnXVVcUdO3YsVqJSX1fCrlhZ/IqVJbRYCTV73KKiomJlddTlcXwu0qGMnTp1Kt61a5c9Pg7UsIXi/v37FyurZbEal+p0b/ny5Tqdsqjq67/++qs+f/31153iuZ4oEVmsLLXFaqys6y2ekwAJBBkBdnlb9ZcAy00C1UwA1r/ygmGpVJ+VgrF5qampUrduXWndurVs2bKlvCRlrmGSzdixY52uX3zxxfocFk9PArqJYRlzDEow6VPHPFasWCF16tQpM/Fo2LBhusyO6d0dw8KIbm/HgHzatm0reI4Seo635Nprr5X69es7XYMFFvHANyYmxn4PXDGUoLCwUFsgcQNW16NHj2orbIMGDexxw8LCdHr7BZeDQYMGaeun4+UNGzYIhhlgzKzRbmg7bL1799ZlWbdunU5Su3ZtvYelEWkqCoiH8bVff/11mbpXlIbXSYAErEmAXd7WbDeWmgSqlUBSUpIWYeUVAmMPX331Vd3NCzHhGJo1a+Z4WuExxFGNGjWc7qP7HAFjAz0J5c1CT0hI0Ekd80AXsrLalTtLHF256Jr1NKA7v7wZ6+ja3bt3rxZn6EY2QqtWrYxD+x7lQUCZXINxzYhj7FFO1wARW1Eo77koH8KUKVP0Vl5adM8jNG3aVHezo1v+kksu0WXFeNGhQ4eKIdoRD2Mz0VWOMbQQ7RD4F110kShLq+5ORxwGEiCB4CBAQRkc7chakEBACThazhwfvH37dm1ZhHDEBBjsERcWs+eee67MxA7HtI7HERERjqdOx7B8ehJ8kYcnz/EmTkUcvcnTk7TlPdewnqLdMHmmvIDxmUaASMQkHIy7/PHHH0V17QsmZGESD35QoM0hsNVQBdm4caN8++23Ot4///lPwRjRN954Q1s+jfy4JwESsDYBCkprtx9LTwKmIoCJI5iwgYk5rhZCWAVdrY5mKDzKCUsfyo0JJ44Bk0yqEjCbG741Xa2UmNEMd0Cw7LoLxqQlpDEskkYaY6a8wdbYl1dOw+JopHW3x5AEBLSRMbzAXRpYKm+++Wa9gR9mlOMdgIDErG8E+AeF1dKwXGKSD2aX/+tf/5KFCxe6ewTvkwAJWIQAx1BapKFYTBKwAgGMfURwtSK+9957ejazGeuAbtr09HT573//61Q8jHmsSnc3EmO2u6tIQj4Qd3iOwcfpQS4nRjzMRIfTdiPAbQ+uwfIKKyACZqRjRjac0sP1kRHAH6K+KmHAgAG6GxrPKG9cJASjMVQAM+Pz8/OdsocYV5OJ9DUjHsZfugZ0xcNCasRxvc9zEiABaxJw/jluzTqw1CRAAiYhcPnll9vd+8BvYs2aNfUYOkzmgOUNE0rMFuBeB/4d4QMSPhjhexEC8MMPP9QCCRY1TwPqqGY+C6yL6DZGPnAbBMvkww8/7FE2LVu21G53MD4RDOGjEgIRLnhgoTSGEiAziEv4nET3M1wewd8jxipiYg/c+CCg69mTAJE3bdo0uf/++7WbJXRnY2wmRDIsrxDGjz76qO7mxmQcPNeYuITJN0Zd4RrJsHBiEhEmKmG1pSZNmughD5999pl23eTo+9KT8jEOCZCAuQlQUJq7fVg6ErAUATjzxvg5bHCeja5fTMT4z3/+oyd6wBm62QLGBWLsn3KDpMcBQlwqtzry5ptval+NjjPC3ZUdviRRbwgzbBBzcPCuXPdoS6K79Mb9P//5z4KJM8qVkc4P1+EIffr06XpCixEPe1g04Uwcz4WYRdc6LJgQbPCHWZVhBuiWhrN11F25CtJO4JEfxCAEK5ymI6Asw4cP12MiIRBhvYSQRFc2BLoxCxwO4pEP/JDCIonrsFDOmDFDi1adGf+QAAkEBQEuvRgUzchKkAAJ+IPAlVdeqd3dfP75526zh3jDmELXLm+3Cf0UAasEYaUdWBXhpJ2BBEiABPxJgGMo/UmXeZMACViCgOuygig0unjRdY2xhWYOGMsIC6FjwIxtWCsR4NaHgQRIgAT8TYBd3v4mzPxJgARMTwBLGcI/JMZPopse7o8w0QXXKnLgbpZKwbE5lnvE8pLoJkfXMsZQwkIJx+lqZR2zFJXlIAESCGICFJRB3LisGgmQgGcE1LKJWkDCpyIms2ASDdYAx2QXxxVoPMstsLHgrB2TXr744gs95hETeCAsMW5zzJgxgS0Mn0YCJBCyBDiGMmSbnhUnARIgARIgARIgAd8Q4BhK33BkLiRAAiRAAiRAAiQQsgQoKEO26VlxEiABEiABEiABEvANAQpK33BkLiRAAiRAAiRAAiQQsgQ4KcdHTZ+Tk6NXscBgftf1gH30CGZDAiRAAiRAAiRgIgJw2YUlRtu1a6dXBjNR0QJeFApKHyHHkmhwIsxAAiRAAiRAAiQQWgQ++OADvdxqaNXaubYUlM48zvkMlkkEvFSubkby8vIE6wF36NBB+7g754eEaELy867hyY/8vCPgXWq+f97xQ2oy9I6hP/mdPHlSG5MMDeBdSa2dmoLSR+1ndHNDTGI9X8eAlzk5OVlfh9NkhqoRIL+q8XKNTX6uRKp2Tn5V4+Uam/xciVT9nAyrzswxRSD4GRrA8bmhdsxJOaHW4qwvCZAACZAACZAACfiYAAWlj4EyOxIgARIgARIgARIINQIUlKHW4qwvCZAACZAACZAACfiYAMdQ+hgosyMBEiABEiCBQBDAuu2nTp0SuK0rLCwMxCMt+YyioiJd7sOHD0t4uGd2tIiICO0GqF69ehIWFmbJege60BSUgSbO55EACZAACZCAlwQgJo8cOSKZmZnaewgEEEP5BCAI69SpUyVhiIk8Z86ckdzcXGnatGmV0pZfiuC/SkEZ/G3MGpIACZAACQQZAVgmISbhWaRu3bpBVjvfVgcWyuzsbImJifHYQokSpKSkCNwCgXX9+vV9W6ggzM0z228QVpxVIgESIAESIAGrEkA3N9zQUUz6rwXBFozBmsE9AQpK94wYgwRIgARIgARMRQBjJtnN7f8mAWOOT/WMMwWlZ5wYiwRIgARIgARIgARIoAICFJQVgOFlEiABEiABEiABEiABzwhQUHrGibFIgARIgARIgARIgAQqIGB6Qbl371654447pHv37tK/f3+ZNm2aYDq/uzBp0iS5/PLLdbrevXvLLbfcIuvWrXNKBp9U7du3L7P98Y9/dIpXnSeH087KiJnfyKyVv1VnMfhsEiABEiABEvALga+++kr+85//+DTvyy67TJ5++mmf5snMKidgardB6enpMmbMGGnVqpXMmjVLTpw4IVOnTtUzrp588slKa5afny9jx47VaeFHavHixTJu3DhZsGCBXHjhhU5pH3nkEenbt6/9WlxcnP24ug9++D1Vfj2WIcfTs+XBIedXd3H4fBIgARIgARLwKQEIyu3bt2vDj68yfuWVVyQ+Pt5X2TEfDwiYWlAuWrRIsrKyBC9GQkKCrg5mW02ZMkXGjx8vDRs2rLCKM2fOdLo3cOBAGTJkiHz88cdlBGXLli21JdMpgUlO4mtG6ZKczs6XwqJiiQinx36TNA2LQQIkQAIkECACcOQOQxHc+HgSOnXq5Ek0xvEhAVN3ea9du1b69etnF5Oo94gRIwROStevX18lDJj6X7t2bf1CVilhNUdOirP986j/JTl91n1XfzUXl48nARIgARIgAY8JPP744/LRRx/Jb7/9Zh9+hmvYrrrqKlmzZo1cc8010rVrV1m1apWcPXtWd2UPHz5cunXrJujaRo8lnLw7Btcu73/84x9y9dVXy/fffy/XXnutNiKNGjVKW0Yd0/H43AmY2kK5b98+ueGGG5xqBxM2PNbjnruAXzSwaOJFW7JkiRw4cKDcMRVPPfWUTJw4UQtXWDEx/tKwiLp7hr/vG4ISz0nNypO6tWr4+5HMnwRIgARIwKIEcgsK5ejp6nHE3SShptSIrNoSkPfff7+kpqbq7/QXX3xRU09KSpLZs2frVWqeffZZue+++6Rx48bSpEkT+7rl+M5GvGPHjsmcOXME+SxcuLDSVsOKN8gPw99gYJo+fbo88MADsmLFComKsvUGVpoBb1ZKwNSCMiMjo9wxEFiTE+Mr3QWMm5w8ebKOFhsbKzNmzJAePXrYk8F0fvPNN8uAAQP0c7Zs2aJfTIzl+OCDD87pBcOEIddJQzDTIxh7ewE8OKgdVdrFfTL9rLRMDD1BaXAz9h5gYxQHAgY3Y+9wi4ceEDC4GXsPkjCKAwGDm7F3uMVDDwkY7Iw9kqGnDmtUY28EiMkhL62tVkG58pGBVRKVzZo1k8TERKlRo4ZccMEFRlUEBiF8z7/++uvaEmm/oQ5gbTRCQUGBXmsbE28xibd169b6FtJjAx/sEZAf5lGcf75tPkLNmjX1PI2ff/5ZevXqpeO4/jHycf1eN+JVdN24H0p7UwtKbxsC1sYOHTpIWlqaLF++XB5++GE9HnPQoEE6a6yBCuukEfr06aNfNIzPxC+WK664wrjl8X7nzp2SnJxcbnzcq2rAyxypNGWB+n/Y/OseqZlZs6pZBE38c+EXNJX3QUXIzzuI5Ed+3hHwPrXrOwjjCtaoNkJeQal4Mq4Fco/vq5zsHCmKrNpoOvQkIq1jXXANPYXt2rVzuo76LFu2TM8KP3jwoNO93bt3S6NGjXSVkR/EpmOe6N2EgDWuNW3aVMc9dOiQVDTmEuWAEIWOKC9gvW8GGwFTC0p0b7uOi0Cx0bj4R3IXYA7HhoBJOUj3wgsviCEoy0uPe7Bm7tix45wEJQSs8UIb+eNXJT4IcO9czOpJX6yVk5m5El+vsRpH0szINmT23vILGVAVVJT8KgDj4WXy8xBUBdHIrwIwVbhcHkO4vYOFMiYmxp4TjlY9OqhaLZRV7fJG4THHwbUuuIa1tB3rh7gw9mDMJNz7GUPVYMR58MEHcdseH/lFRkbqc4hLBGgKx/zQ7Y2A+47X9cWSPygHLKgQouWF48ePl3c5JK+ZWlC2adOmzFhJCEy8PLhX1dC5c2fBRB9/BnSjVzQLDWKyonuVlQnjJiEo03MKzyl9ZXlb6d658rNSHf1ZVvLzji75kZ93BLxP7fgOhofbrIDG3sg9Jjpc2jaw1nhAiD9sjnUxzh2voY5ffvmldOzYUZ555hmjyrJx40Z9bKTBiWOejsMCHPMzjh3T2TMtOTDyqei7u6LrrvmEwrntjTRpTWFV3LBhg2AspRHQdY2XAE7Oqxo2bdokzZs3rzTZ119/rWeRYUaZWUJSnO3DIUVNymEgARIgARIggWAiAKEMf9GehJycnDI9fZ988oknSRnHzwRMbaEcPXq0nrU1YcIE7XcSjs2xUg6uO/qghPPzo0ePalM4eK1evVqWLl0qgwcP1jPD0NWNMRdYKeell16yI4WTdPz66K5W4YEpfOvWrXoAcJcuXWTo0KH2eNV9kBRnm4iTRrdB1d0UfD4JkAAJkICPCbRt21Y+/PBD/T0Nv9DoYq4oXHzxxdpby6uvvqon2cKt0LfffltRdF4PIAFTC0qMk5w/f742bUNUYgUb+I3CuAnHAHM2Bs4aAVZIzLyCSwAMpMXLiSUW4VIAE2+MgJf4vffek/fff1+7IoBIRf4PPfSQHnthxKvufVKszUIJt0EMJEACJEACJBBMBPC9C4MOurFPnz4t1113XYXVg0EJ40ffeecdmTt3rvbSgu96My2ZXGHhg/yGqQUl2EP0zZs3r9JmcPU9hTTwYeUu3HjjjYLN7MGwUFJQmr2lWD4SIAESIIGqEqhVq5ZT72Fl6TFJ5rHHHtObY7xdu3Y5nmon6I4XsMKe68Qb9Ey6pnNMw+OqETD1GMqqVSV4YxtjKCkog7eNWTMSIAESIAESsDIBCkoLtJ6jhdJwf2CBYrOIJEACJEACJEACIUKAgtICDW0sv5irnNaezSsdK2qBorOIJEACJEACJEACIUCAgtICjWwIShSV3d4WaDAWkQRIgARIgARCjAAFpQUanILSAo3EIpIACZAACZBACBOgoLRA4yeUuA1CUWmhtECDsYgkQAIkQAIkEGIEKCgt0OBREeFSJ4a+KC3QVCwiCZAACZAACYQkAQpKizS70e1NC6VFGozFJAESIAESIIEQIkBBaZHGNgQl1/O2SIOxmCRAAiRAAiQQQgQoKC3S2IagTOPyixZpMRaTBEiABEggUAS+//57vcTytm3bAvVIPseFAAWlCxCznibFRuui0UJp1hZiuUiABEiABEggdAlQUFqk7ZNq2QRl2tk8i5SYxSQBEiABEiABEggVAhSUFmlpw0LJSTkWaTAWkwRIgARIwC2BJUuWSKdOneTUqVNOcU+fPi1dunSRRYsWyebNm+Xee++VAQMGSPfu3WXkyJGydOlSp/g8qX4CFJTV3wYelcAYQ0lB6REuRiIBEiABErAAgWHDhklERIQsX77cqbRffvmlPv/DH/4gR48elZ49e8pzzz0nr732mlx++eUyefJk+eijj5zS8KR6CURW7+P5dE8JGF3e6dn5kl9YJPBNyUACJEACJEACTgQKckXSDztdCthJnWYikTWq9LjatWvLoEGDZNmyZXLrrbfa0+K8f//+kpCQIFdeeaX9enFxsfTu3VtOnDgh//3vf+W6666z3+NB9RKgoKxe/h4/3ejyRgKMo2xQu6bHaRmRBEiABEggBAhATM7qpQTloeqpbJ3mIg9uqrKohGCcOHGitkQ2adJETp48KT/88IP885//1PVIT0+XWbNmycqVK7WQLCws1NchNhnMQ4BmLvO0RaUlMbq8ESktK7/SuLxJAiRAAiRAAlYhcOmll0pMTIx8+umnusiff/651KhRQ4YOHarPH3/8cW3BvPPOO2Xu3LmyePFiueGGGyQvj5NUzdTGtFCaqTUqKYujoEzJUr9CpXYlsXmLBEiABEgg5AiguxkWQgt1eaONatasqcXjZ599Jvfcc49gD5EZGxsrubm5snr1aoGovO222+xN+u6779qPeWAOAhSU5mgHt6WIjY6QGpHhkltQRAulW1qMQAIkQAIhSgCism5by1X+qquuknHjxsk333wjP//8sxaWqASskEVFat5AVJS9TmfOnJFVq1bZz3lgDgIUlOZoB7elCAsLE1gpj6XnSKq2ULpNwggkQAIkQAIkYAkCF198sZ6A88QTT0h8fLwMHDhQlxuTdrp27SpvvvmmJCUlSWRkpLzxxhtSq1YtSU1NtUTdQqWQHENpoZY2ur25Wo6FGo1FJQESIAEScEsAFsjhw4frCTlwCxQdbVvMAwmnT58uLVq00N3ezz77rI537bXXus2TEQJLgBbKwPL26mmGoOR63l5hZGISIAESIAETEnj66acFm2to2bKlzJ8/3/WyPPjgg/Zrffv2lV27dtnPeRB4ArRQBp75OT/REJS0UJ4zQiYkARIgARIgARLwAwEKSj9A9VeWhqDket7+Isx8SYAESIAESIAEzoUABeW5UKumNIZz85Qz9L1VTU3Ax5IACZAACZAACZRDgIKyHChmvWQsv0gLpVlbiOUiARIgARIggdAkQEFpoXY3LJSpWXmC9UwZSIAESIAESIAESMAMBCgozdAKHpbBGEOZX1gsmbkFHqZiNBIgARIggWAjEBERIcaa1sFWNzPVB4zBmsE9AQpK94xME6NurVK/XHQdZJpmYUFIgARIIOAEsFwhVpFJSUkJ+LND5YFgC8ZgzeCeAP1QumdkmhiJsaWCEq6DWtaNM03ZWBASIAESIIHAEahXr55e5/rkyZNy+vRpWtEqQY8hYoalEavOeRIQH2ISK/WANYN7ArRQumdkmhgJSlAa/wu0UJqmWVgQEiABEgg4AQijpk2barHjuKpMwAtigQdCUKanp1dp7gGYQkiCsaci1AIo/FpEWij9ite3mUeEh0lCTJSknc0XOjf3LVvmRgIkQAJWIwChU79+fasVO+DlhaUxLS1NmjVr5rSkY8ALEuQPpIXSYg1sTMzBTG8GEiABEiABEiABEjADAQpKM7RCFcpQN66Gjs0u7ypAY1QSIAESIAESIAG/EjC9oNy7d6/ccccd0r17d+nfv79MmzZND5R1R2XSpEly+eWX63S9e/eWW265RdatW1dpsvvvv1/at28vc+fOrTRedd5MjIvSj2eXd3W2Ap9NAiRAAiRAAiTgSMDUYygxiHbMmDHSqlUrmTVrlpw4cUKmTp0qOTk58uSTTzrWo8xxfn6+jB07VqfNzc2VxYsXy7hx42TBggVy4YUXlom/Zs0a2bJlS5nrZruQRAul2ZqE5SEBEiABEiCBkCdgakG5aNEiycrKkldeeUUSEhJ0Y2Eq/5QpU2T8+PHSsGHDChtw5syZTvcGDhwoQ4YMkY8//riMoMSA3eeee04eeeQReeKJJ5zSme0kiRZKszUJy0MCJEACJEACIU/A1F3ea9eulX79+tnFJFprxIgRUlRUJOvXr69S48HTPfxJwXLpGtDFHR8fL9dff73rLdOd2y2UZzkpx3SNwwKRAAmQAAmQQIgSMLWg3Ldvn7Rp08apaSD84CYB99wF+J4qKCjQ7gIgGg8cOCA33XSTU7KjR4/KG2+8IZMnT7aErynDQpl6hoLSqSF5QgIkQAIkQAIkUG0ETN3lnZGRoS2HrnTq1KmjnZS6Xnc9x7hJCEWE2NhYmTFjhvTo0cMp2vPPPy/Dhg3Tk3ecbpzjCbrPsTkGwypq7B3vVfU4Ptr2GwBreZ85myPRkab+TVDV6pUb3+Bm7MuNxIsVEjC4GfsKI/JGuQQMbsa+3Ei8WCEBg5uxrzAib1RIwGBn7CuMyBvlEjC4GftyI53jRdfv+3PMJiiSmVpQeksYYyY7dOigLZTLly+Xhx9+WI/HHDRokM4as76x4Z6vws6dOyU5Obnc7HDP25CaVtpl/+1PWyUpJnQWrfcFP2/5Wzk9+XnXeuRHft4R8D4130HvGPqDH9dSL20TUwtKdG9nZmaWlrbkCLO/YaV0F5KSkgQbAiblIN0LL7wghqB89tln5fbbb5eYmBiBNdQImBVekXXUiFPRHgK2UaNGTrfxqwgvMu5FRdnc/jhFqMJJ3dPZIl+t0ykatGgrHRvVrkJqa0b1JT9rEvCu1ORHft4R8C413z/v+CE1GXrH0J/8jh8/7l3hgii1qQUlxk+6jpWEwIQF0HVspSdt0rlzZ8FEHyPs379f5syZozfjGvaYIY5t69atUqOGzZG44/3KjrH+Z0XrqkJMVnSvsjwd7zVMKLVInskr9jo/x7zNfuwLfmavoz/LR37e0SU/8vOOgPep+Q56x9Af/Lz9TveuRuZKbWpBCasiBJ+jtRDd0+Hh4drJeVVRbtq0SZo3b25PBp+UrgEWy9GjR8sVV1zhtTXRNW9fnMdER0hMVIRk5xdyPW9fAGUeJEACJEACJEACXhMwtaCEsFu4cKFMmDBB+52EY3OslIPrjj4o4fwcs7VXrFihgaxevVqWLl0qgwcPlsaNG+uu7mXLlunxki+99JIdWt++fe3HjgctWrSQiu45xquuY6znfUR1faeeya2uIvC5JEACJEACJEACJGAnYGpBiXGS8+fPl2eeeUaLyri4OBk1apRMnDjRXgEcwC8lHJ4bAVZIzLyaPn26npCTmJiol1SEOO3Tp48RzbJ7u6A8WzpBx7KVYcFJgARIgARIgAQsT8DUghJ027ZtK/PmzasUNISiY0Ca2bNnO17y+HjXrl0ex62uiBCUCKlZtFBWVxvwuSRAAiRAAiRAAqUEwksPeWQVAnVLBGVaFi2UVmkzlpMESIAESIAEgpkABaUFWzexRFCm0EJpwdZjkUmABEiABEgg+AhQUFqwTY0ub1ooLdh4LDIJkAAJkAAJBCEBCkoLNqohKFOynJd4tGBVWGQSIAESIAESIIEgIEBBacFGNARl2tk8NcO92II1YJFJgARIgARIgASCiQAFpQVb05iUU6jEZGZOgQVrwCKTAAmQAAmQAAkEEwEKSgu2pjEpB0XnxBwLNiCLTAIkQAIkQAJBRoCC0oINalgoUXR0ezOQAAmQAAmQAAmQQHUSoKCsTvrn+Oz4mlESER6mU6ecoaA8R4xMRgIkQAIkQAIk4CMCFJQ+AhnIbMKVmEyMjdKPTOVM70Ci57NIgARIgARIgATKIUBBWQ4UK1xKjC1ZfpFd3lZoLpaRBEiABEiABIKaAAWlRZvXcB2Uyi5vi7Ygi00CJEACJEACwUOAgtKibVm3Fi2UFm06FpsESIAESIAEgo4ABaVFm9Te5c0xlBZtQRabBEiABEiABIKHAAWlRdvScB2URkFp0RZksUmABEiABEggeAhQUFq0LQ3n5lzP26INyGKTAAmQAAmQQBARoKC0aGPaJ+XQQmnRFmSxSYAESIAESCB4CFBQWrQtDUF5Nq9QcvILLVoLFpsESIAESIAESCAYCFBQWrQVDUGJ4tO5uUUbkcUmARIgARIggSAhQEFp0YasG1fDXnIKSjsKHpAACZAACZAACVQDAQrKaoDui0cmxtmWXkReFJS+IMo8SIAESIAESIAEzpUABeW5kqvmdDUiI6RWjUhdCgrKam4MPp4ESIAESIAEQpwABaWFXwDDSklBaeFGZNFJgARIgARIIAgIUFBauBGTSsZRUlBauBFZdBIgARIgARIIAgIUlBZuRGO1nNSzeRauBYtOAiRAAiRAAiRgdQIUlBZuQft63mcoKC3cjCw6CZAACZAACVieAAWlhZuwbq1oXXpaKC3ciCw6CZAACZAACQQBAQpKCzei3ULJ5Rct3IosOgmQAAmQAAlYnwAFpYXb0D6GkoLSwq3IopMACZAACZCA9QlQUFq4DRPjbF3ep9WknMKiYgvXhEUnARIgARIgARKwMgEKSgu3nrGeN7Rkena+hWvCopMACZAACZAACViZAAWlhVvP6PJGFeiL0sINyaKTAAmQAAmQgMUJUFBauAGNLm9UgYLSwg3JopMACZAACZCAxQlQUFq4AeNrRkpkeJiuQWpWroVrwqKTAAmQAAmQAAlYmQAFpYVbLywsTAwrZWoWx1BauClZdBIgARIgARKwNAHTC8q9e/fKHXfcId27d5f+/fvLtGnTJC/P/cowkyZNkssvv1yn6927t9xyyy2ybt06p8Y6dOiQjB8/XgYOHChdu3aVAQMGyEMPPST79+93imfmE2McJS2UZm4llo0ESIAESIAEgptApJmrl56eLmPGjJFWrVrJrFmz5MSJEzJ16lTJycmRJ598stKi5+fny9ixY3Xa3NxcWbx4sYwbN04WLFggF154oU6blZUl9erVk0ceeUQaN24sycnJ8vrrr8vtt98uH3/8sSQlJVX6DDPcLHVuTgulGdqDZSABEiABEiCBUCRgakG5aNEigeh75ZVXJCEhQbdPYWGhTJkyRVsWGzZsWGGbzZw50+kerJBDhgzRQtEQlB06dJDnnnvOKV6XLl1k+PDhsn79ern66qud7pnxJMlYfpFjKM3YPCwTCZAACZAACYQEAVN3ea9du1b69etnF5NokREjRkhRUZEWfFVpoYiICKldu7bAcllZMISru3iV5RHIe/Yu77OV1yuQZeKzSIAESIAESIAEQouAqQXlvn37pE2bNk4tEh8fL/Xr1xfccxeKi4uloKBA0tLSZO7cuXLgwAG56aabyiSDQIWAPHz4sDzzzDO6+3vYsGFl4pnxQmmXN2d5m7F9WCYSIAESIAESCAUCpu7yzsjIEAhI11CnTh3B+Ep3AeMmJ0+erKPFxsbKjBkzpEePHmWS/fWvf5VPPvlEX2/RooW8/fbb2ppZJqIHFzBhyHXSkGHtNPYeZONxlDo1I3TclDNln+txJiaPaHAz9iYvrumKZ3Az9qYroMkLZHAz9iYvrumKZ3Az9qYroAUKZLAz9hYosqmKaHAz9r4snOv3vS/ztlpephaU3sLEmEmMk4SFcvny5fLwww/r8ZiDBg1yyvrPf/6znohz7NgxmT9/vp5V/u6770qTJk2c4nlysnPnTj25p7y4uOfrcCYlW2eZciZHtm3b5uvsTZWfP/iZqoJ+Lgz5eQeY/MjPOwLep+Y76B1Df/BLSUnxrlBBlNrUghLWyczMzDK4YZ2EldJdwCxtY6Y2JuUg3QsvvCCugrJ58+aC7YILLtAuhOBu6K233nI7k7y850PANmrUyOkWfhXhRca9qKgop3venpyJSxX5bpPkFYq0bd9JYqNtFktv8zVTen/yM1M9/VUW8vOOLPmRn3cEvE/Nd9A7hv7kd/z4ce8KF0SpTS0oMX7SdawkBCbc+7iOrfSkTTp37iyY6FNZiImJkbZt2+rxlpXFq+hedHS0YCsvQExWdK+8+J5ca1An1h7tTH6xJJTM+rZfDKIDf/ALIjxuq0J+bhFVGoH8KsXj9ib5uUXkNgIZukVUaQR/8PP1d3qlFTD5TVNPyoFVccOGDYKxlEZA13V4eLh2cm5c83S/adMmbYmsLP6ZM2dk165dbuNVlkcg7xmzvPFMrucdSPJ8FgmQAAmQAAmQgEHA1BbK0aNHy8KFC2XChAna7yQcm2OlHFx39EEJ5+dHjx6VFStW6HqtXr1ali5dKoMHD9YzttHVvWzZMr1SzksvvWTUXTtLh8WzZ8+eumv8yJEj+nkYZIs8rRCMpRdR1pQs9ysIWaFOLCMJkAAJkAAJkIC1CJhaUGKcJCbJwJUPRGVcXJyMGjVKJk6c6EQZbn/g8NwIGA8JUTh9+nQ9IScxMVHat2+vxWKfPn2MaNKpUyeZN2+ednZ+9uxZLVKxTCOcoiMPK4SoiHCpXTNSMnOUeyQKSis0GctIAiRAAiRAAkFHwNSCErQxnhGir7IAK6ZjQJrZs2c7Xir3GLPAsVk9oNsbgpJd3lZvSZafBEiABEiABKxJwNRjKK2JNPClNrq9KSgDz55PJAESIAESIAESEKGgDIK3wJiYQ0EZBI3JKpAACZAACZCABQlQUFqw0VyLnKS6vBEoKF3J8JwESIAESIAESCAQBCgoA0HZz89gl7efATN7EiABEiABEiCBSglQUFaKxxo32eVtjXZiKUmABEiABEggWAlQUAZByybGlnR5n6UfyiBoTlaBBEiABEiABCxHgILSck1WtsB1S5ZbPH02XwoKi8pG4BUSIAESIAESIAES8CMBCko/wg1U1oaFEs87nZ0fqMfyOSRAAiRAAiRAAiSgCVBQBsGLUDeuhr0WnOltR8EDEiABEiABEiCBABGgoAwQaH8+JqmkyxvPSDnDcZT+ZM28SYAESIAESIAEyhKgoCzLxHJX4qIjJFqt6Y2Qxok5lms/FpgESIAESIAErE6AgtLqLajKHxYWJoZz85QsWiiDoElZBRIgARIgARKwFAEKSks1V8WFNZybp1FQVgyJd0iABEiABEiABPxCgILSL1gDnymdmweeOZ9IAiRAAiRAAiRgI0BBGSRvgmGh5CzvIGlQVoMESIAESIAELESAgtJCjVVZUWmhrIwO75EACZAACZAACfiTAAWlP+kGMG9OygkgbD6KBEiABEiABEjAiQAFpRMO654YXd6clGPdNmTJSYAESIAESMCqBCgordpyLuV27PIuLi52uctTEiABEiABEiABEvAfAQpK/7ENaM7Get55hUWSlVcY0GfzYSRAAiRAAiRAAqFNgIIySNq/rsPyi6lcfjFIWpXVIAESIAESIAFrEKCgtEY7uS2lMSkHEVOyct3GZwQSIAESIAESIAES8BUBCkpfkazmfBJiouwl4HredhQ8IAESIAESIAESCAABCsoAQA7EIyIjwiUh1iYqU9jlHQjkfAYJkAAJkAAJkEAJAQrKIHoVkmKjdW1ooQyiRmVVSIAESIAESMACBCgoLdBInhbRGEeZkpXnaRLGIwESIAESIAESIAGvCVBQeo3QPBnQubl52oIlIQESIAESIIFQIkBBGUSt7ejcPIiqxaqQAAmQAAmQAAmYnAAFpckbqCrFY5d3VWgxLgmQAAmQAAmQgK8IBFRQFhQUyIkTJ3xVdubjQsAQlFzP2wUMT0mABEiABEiABPxKwCeCslu3brJt2zZ7QbGW9J133ikHDhywX8PBjh07ZPDgwU7XeOI7Aoag5KQc3zFlTiRAAiRAAiRAAu4J+ERQ5ubmCkSkEYqKimTDhg1y5swZ4xL3ASBgTMrJzCmQfLWmNwMJkAAJkAAJkAAJBIKATwRlIArKZ7gnYEzKQUx2e7vnxRgkQAIkQAIkQAK+IUBB6RuOpsglscSxOQrDbm9TNAkLQQIkQAIkQAIhQSDS7LXcu3evPPvss7J582aJi4uTkSNHysMPPyzR0bZVYSoq/6RJk2Tr1q1y8uRJiYqKknbt2sl9990nAwYMsCfB/ffee09+/PFHHa9hw4YyfPhwHS82NtYezyoHdWuVMqGF0iqtxnKSAAmQAAmQgPUJ+ExQLlu2TDZt2qSJYAxlWFiYfPLJJ7Jx40Y7paNHj9qPPTlIT0+XMWPGSKtWrWTWrFl6hvjUqVMlJydHnnzyyUqzyM/Pl7Fjx+q0GOO5ePFiGTdunCxYsEAuvPBCnfbzzz/XE4fuvvtuHW/Pnj3yr3/9S7Zs2aLjVfoAE96MjY6UmlHhkpNfRAulCduHRSIBEiABEiCBYCXgM0EJoeYa5s2b53pJC80yFyu4sGjRIsnKypJXXnlFEhISdKzCwkKZMmWKjB8/XmBRrCjMnDnT6dbAgQNlyJAh8vHHH9sF5T333CNJSUn2eH379pX4+HiBdXP79u3SpUsX+z2rHGA976PpOcL1vK3SYiwnCZAACZAACVifgE8E5c6dO/1CYu3atdKvXz+7mMRDRowYIf/4xz9k/fr1cv3113v83IiICKldu7bAcmkERzFpXOvUqZM+RFe5FUOS6vaGoEw5k2fF4rPMJEACJEACJEACFiRg6kk5+/btkzZt2jhhhQWxfv36gnvuAlwZwZl6WlqazJ07V3dv33TTTZUmM7rtXZ9baSIT3TQm5tBCaaJGYVFIgARIgARIIMgJ+MRCWREjjHXE2EVMrKlXr562KDZu3Lii6GWuZ2Rk6C5o1xt16tQRjK90F/DsyZMn62iYZDNjxgzp0aNHhclSU1P1WE10jWPc5rmEvLw8weYYDKuosXe85+vjxBhbkyZn5pQph6+fFaj8DG7GPlDPDZbnGNyMfbDUK1D1MLgZ+0A9N1ieY3Az9sFSr0DWw2Bn7AP57GB4lsHN2PuyTq7f977M22p5+URQQqitWrVKT8IxAGRnZ8uoUaO0JdFweo5xlhB5zZs3N6L5dQ9h2KFDB22hXL58uZ4djvGYgwYNKvNcvGiPPPKIvv7UU0+Vue/pBXT/JycnlxvdX0MDHB9WlJ2hTw+dSHNavcgxjlWPA8HPqmw8KTf5eUKp4jjkVzEbT+6QnyeUKo9DhpXzcXfXH/xSUlLcPTZk7vtEUGI846WXXuoEbf78+doyef/998tdd90l+/fvl4ceekjmzJkjzz33nFPcik7QvZ2ZmVnmNqyTsFK6CxgjaYyTxKQcpHvhhRfKCEoI3ieeeEK7GXr33XelQYMG7rKu8D4EbKNGjZzuQ6ziRcY9uDDyZzg/VQ0F+G2v5IdHS9euXf35qIDlHUh+AatUAB9Eft7BJj/y846A96n5DnrH0J/8jh8/7l3hgii1TwTloUOHyoiXL7/8Upo0aaJFJHhhxjTc85Q387sinhjH6DpWEgITFsBzGePYuXNnwUQf1/DPf/5T4ELozTff1KLP9X5VzuEfsyIfmRCTFd2ryjMqi1s/PlbfTj2b7/dnVVYOf9wLBD9/lNsseZKfdy1BfuTnHQHvU/Md9I6hP/j5+zvduxoHNnW4Lx4HP4+wJhrh7NmzsmvXLj1D27iG/fnnn699STpeq+wYVkWsCY6xlEZA13V4eLj079/fuOTxHhNuXLvb33jjDS1y4d8SM8qtHpLibBZQODY3hhpYvU4sPwmQAAmQAAmQgLkJ+MRC2bRpU/n1118FfhwR4Mwc/iKNcwMBhCZWu/E0jB49WhYuXCgTJkzQfidPnDgh06ZNE1x39EEJ5+dwmr5ixQqd9erVq2Xp0qUyePBgwSQgdHXD8fq6devkpZdesj8ejtenT58u11xzjTRr1kx+/vln+70WLVrYu8vtFy1wkBRXQ5eyoKhYMnIKpE6Mf7vYLYCERSQBEiABEiABEvAzAZ8ISviGxNhIjFeESx+Itlq1apUZVwkLYcuWLT2uEsZJYizmM888o0UlxCgm+kycONEpD6zMAwFrBFghMfMKYhEugxITE6V9+/ZanPbp08eIpn1Z4uR///uf3uw31MHzzz9fJT+Xjmmr89iwUKIMqcpKSUFZna3BZ5MACZAACZBAaBDwiaDE2EgsV/jXv/5VU4OLHky8gSNxI6BbfMmSJdq6aFzzZN+2bVu34y5hxXQMSDN79mzHS+Ueo5sbWzAFw0KJOkFQtq7nuUU4mDiwLiRAAiRAAiRAAoEj4BNBWbNmTT2h5eDBg7p7uXXr1tpC6VgNOBiHFbMqFkrH9Dz2jAAskuFhIqrHWwtKz1IxFgmQAAmQAAmQAAmcOwGfCErj8Rh3WFFAd7UV18auqD5mvR6h1GSCWs8b1klMzGEgARIgARIgARIgAX8T8Img/OGHH6pUzt69e1cpPiNXjUBSnE1QplBQVg0cY5MACZAACZAACZwTAZ8Iyttuu03CwlQ/qwruXNUgHmaEM/iPQJKyUCJwPW//MWbOJEACJEACJEACpQR8IiiRXUxMjAwbNkyuuOIKJ5c+pY/iUaAIwEKJkHKGXd6BYs7nkAAJkAAJkEAoE/CJoPziiy+0n8dPP/1U73v16iVXX321DB8+3MnheSiDDmTdE0sEZWpWbiAfy2eRAAmQAAmQAAmEKAGfrJSDmdtwPv7ZZ5/JBx98oJdhhNserGZz3333CYRmTk5OiCIOfLXrGoJSLb/IQAIkQAIkQAIkQAL+JuATQelYyE6dOslf/vIX+frrr7X/yLp162r/lIaPSse4PPYPAaPLmxZK//BlriRAAiRAAiRAAs4EfNLl7Zyl7ey7777Tlkkshwg/lV27di0vGq/5gYAhKNOyaKH0A15mSQIkQAIkQAIk4ELAp4ISq+VgzezPP/9cMjMzZdCgQXrZRKypHR1tmyji8nye+oGAISjP5BZIbkGh1IiM8MNTmCUJkAAJkAAJkAAJ2Aj4RFBi7W6Mnzx+/LhcfPHFMmnSJBk6dGiZ1XIIPTAEDEGJp8HBeeM6MYF5MJ9CAiRAAiRAAiQQkgR8IijfeOMNwUo4mNWdmJgo27dv11tFRCdPnlzRLV73AQEKSh9AZBYkQAIkQAIkQAIeE/CJoGzSpIl+4ObNm90+GI7NKSjdYvIqgqug9CozJiYBEiABEiABEiABNwR8IihXrVrl5jGlt8+cOVN6wiO/EKgZFSGx0RFyNq9Qd3n75SHMlARIgARIgARIgARKCPjcbVBFZFNSUgRjLS+77LKKovC6DwkYVkqMoWQgARIgARIgARIgAX8S8ImFEgX8+eef5aOPPpJjx45J8+bNBet7t2rVSk6dOiWvvvqqLFmyRAoKCvTSjP6sEPO2EYCgPJyWLWkUlHwlSIAESIAESIAE/EzAJ4JyzZo1ekWc4uJiSUpKkg0bNmj3QdOmTZPHHntMMjIy5Morr5T7779fWrdu7ecqMXsQMCyUKRSUfCFIgARIgARIgAT8TMAngvL111+Xjh07CpZbbNiwoWRlZemJN1iOsX79+vLWW29Jly5d/FwVZu9IICnW5veTXd6OVHhMAiRAAiRAAiTgDwI+GUO5d+9ebaGEmESACyEsv4gu7kcffZRi0h8t5yZPw0JJQekGFG+TAAmQAAmQAAl4TcAngjI9PV0aNGjgVBhDXLZs2dLpOk8CQyCpFi2UgSHNp5AACZAACZAACfhEUFaGMSKCy/5Vxsdf94wu77SznOXtL8bMlwRIgARIgARIwEbAJ2MokdWYMWMETstdwy233OJ0HXE2bdrkGo3nPiZgdHmnnc2XoqJiCQ8v2zY+fiSzIwESIAESIAESCFECPhGUDzzwQIjiM2+1DUFZqMRkena+JCo3QgwkQAIkQAIkQAIk4A8CFJT+oGqCPA1BiaKkqm5vCkoTNAqLQAIkQAIkQAJBSsDvYyiDlJvpq+UkKOmL0vTtxQKSAAmQAAmQgJUJUFBaufUqKXt8zSiJKBk3SddBlYDiLRIgARIgARIgAa8JUFB6jdCcGWASTiKdm5uzcVgqEiABEiABEggyAhSUQdagjtVJiovSp7RQOlLhMQmQAAmQAAmQgK8JUFD6mqiJ8jPGUVJQmqhRWBQSIAESIAESCEICFJRB2KhGlSgoDRLckwAJkAAJkAAJ+JMABaU/6VZz3hSU1dwAfDwJkAAJkAAJhAgBCsogbuikuBq6duzyDuJGZtVIgARIgARIwAQEKChN0Aj+KkJSLCfl+Ist8yUBEiABEiABEiglQEFZyiLojpJq0UIZdI3KCpEACZAACZCACQlQUJqwUXxVpKQSP5TZ+YWSnVfoq2yZDwmQAAmQAAmQAAk4EfDJWt5OOfr4ZO/evfLss8/K5s2bJS4uTkaOHCkPP/ywREdHV/qkSZMmydatW+XkyZMSFRUl7dq1k/vuu08GDBhgT5eXlycvv/yybNmyRXbs2CHZ2dny7bffSlJSkj2OlQ+MSTmoA9bzbhodY+XqsOwkQAIkQAIkQAImJWBqC2V6erqMGTNG8vPzZdasWTJx4kR5//33ZerUqW5xIs3YsWNl9uzZMm3aNElISJBx48bJjz/+aE+bk5MjH3zwgdSoUUN69eplvx4sB06C8kxesFSL9SABEiABEiABEjAZAVNbKBctWiRZWVnyyiuvaEEIdoWFhTJlyhQZP368NGzYsEKcM2fOdLo3cOBAGTJkiHz88cdy4YUX6nvx8fGyceNGCQsLkyVLlsi6deuc0lj9JLFkpRzUAxZKBhIgARIgARIgARLwBwFTWyjXrl0r/fr1s4tJABgxYoQUFRXJ+vXrq8QjIiJCateura2djgkhJoM11IhUda5h+82QmpUbrNVkvUiABEiABEiABKqZgKkF5b59+6RNmzZOiGBVrF+/vuCeu1BcXCwFBQWSlpYmc+fOlQMHDshNN93kLllQ3U+Ms401Tc3KD6p6sTIkQAIkQAIkQALmIWDqLu+MjAyBgHQNderUEYyvdBcWL14skydP1tFiY2NlxowZ0qNHD3fJvLqPiT7YHAPGcyIYe8d7/j5OVL4oD6aKJGdklymXv5/tq/wNbsbeV/mGSj4GN2MfKvX2VT0NbsbeV/mGSj4GN2MfKvX2ZT0Ndsbel3mHQl4GN2Pvyzq7ft/7Mm+r5WVqQektTIyZ7NChg7ZQLl++XM8Ox3jMQYMGeZt1hel37twpycnJ5d7HvUCHyMIc/cg9h47Ltm3ZgX68T59XHfx8WoFqzoz8vGsA8iM/7wh4n5rvoHcM/cEvJSXFu0IFUWpTC0pYJzMzM8vghnUSVkp3Ae5/DBdAmJSDdC+88IJfBSUEbKNGjZyKhl9FeJFxDy6MAhla7tkhm44dlbCataVr166BfLTPnlWd/HxWiWrMiPy8g09+5OcdAe9T8x30jqE/+R0/fty7wgVRalMLSoyfdB0rCYEJC6Dr2EpP2qRz586CiT7+DPCPWZGPTIjJiu75q0z1atfUWZ/Ozg/4s31dp+rg5+s6VGd+5OcdffIjP+8IeJ+a76B3DP3BL9Df6d4R8G9qU0/KgVVxw4YNgrGURkDXdXh4uPTv39+45PF+06ZN0rx5c4/jB0NEwxflsfQcST/LiTnB0KasAwmQAAmQAAmYjYCpLZSjR4+WhQsXyoQJE7TfyRMnTmgn5bju6IMSzs+PHj0qK1as0HxXr14tS5culcGDB0vjxo11V/eyZcu0n8mXXnrJqQ3WrFmjV8jZvn27vv7111/rFXnOO+88wWb1UL9kPe/DadnS69kV0rdNkgzr2FCGdmoozRJjrV49lp8ESIAESIAESMAEBEwtKDFOcv78+fLMM89oUYmlF0eNGqVXzHFkB7+UcHhuBFghMfNq+vTpekJOYmKitG/fXovTPn36GNH0Hk7Sjxw5Yr/2xBNP6OMHHnhAHnzwQft1qx4MVeLxsg4NZM3uZCkoKpb1e1L09tQnv0inxvEyTAlLbJ2bxGsH71atJ8tNAiRAAiRAAiRQfQRMLSiBpW3btjJv3rxKCcGK6RiQBksuehJWrVrlSTTLxqmj3Ab9e2xvOa1Wyvl610lZ8csJWbMrWbLyCuWXYxl6m7nyN2maECNDOzZQ4rKRtmJGRZh6NIRl24MFJwESIAESIIFgJGB6QRmM0KujTgmx0XJdj2Z6yy0olA17U7S4/EoJzJOZuXLkdLbM//aA3mrXjJRL20NcNpTB7etL7ZqBnZleHXz4TBIgARIgARIggXMnQEF57uwsmxJLMkIwYnt2ZBfZeiRdicvjWmDuPnFGMnMK5H9bjuotKiJMLmpTV+4c0FrHt2ylWXASIAESIAESIAG/EaCg9Btaa2QcHh4m3Zsn6O0vwzvIgZQsLSy/VJbLH39PlfzCYvnmt1Nq3OUpmTm6h1zdrYk1KsZSkgAJkAAJkAAJBIwABWXAUFvjQS3rxsndl7TRW2pWnqzaeVLmrNkre06ekYn//VlioiL0DHFr1IalJAESIAESIAESCAQBzrwIBGWLPgM+LEf1aibv3XORtKkXp2eJ3//uT9paadEqsdgkQAIkQAIkQAJ+IEBB6QeowZZl/do15J27++qZ4HkFRXL3/B91d3iw1ZP1IQESIAESIAESODcCFJTnxi3kUjVRboXevaevNFDiMju/UO54+wfZribzMJAACZAACZAACZAABSXfAY8JYHzlf5SlEl3hmbkFctvc72X3iUyP0zMiCZAACZAACZBAcBKgoAzOdvVbrc5vWFsW3NlH+aaMlDS1Nvgtb30vv5/K8tvzmDEJkAAJkAAJkID5CVBQmr+NTFfCLk3ryLw7ektsdIQkK6foEJVwjM5AAiRAAiRAAiQQmgQoKEOz3b2uda+WSfLW7RdKdGS4FpO3KlF5MjPH63yZAQmQAAmQAAmQgPUIUFBar81MU+KLz6snc27tKZHKOfp+1e1921sbJU35rmQgARIgARIgARIILQIUlKHV3j6v7WUdGuoVdJSmlF1qgs7t/94oGTn5Pn8OMyQBEiABEiABEjAvAQpK87aNZUp25QWNZdqobrq825Qrobvm/SBn8wosU34WlARIgARIgARIwDsCFJTe8WPqEgJYUefpkZ312Q+/p8n4hZskR/mrZCABEiABEiABEgh+AhSUwd/GAavh7f1ayeMjOujnffPbKXnwvc2SX1gUsOfzQSRAAiRAAiRAAtVDgIKyergH7VPvHdRWHrrsPF2/Fb+ckEff3yKFRcVBW19WjARIgARIgARIQISCkm+BzwlMHNZO7uzfWuf7vy1H5Ykl26SIotLnnJkhCZAACZAACZiFAAWlWVoiiMoRFhYmf7+qo4zu3VzX6r8/HpInPtomWWq5RgYSIAESIAESIIHgI0BBGXxtaooaQVQ+d11XGdm9iS7Poh8OydCX1sjn245JcTG7wE3RSCwECZAACZAACfiIAAWlj0Aym7IEIpRzyhdv7CbjB7bRzs+PpefIff/5SfuqhCN0BhIgARIgARIggeAgQEEZHO1o2lpERYTL367oKJ/9+RLp2zpJlxMzwIfPWCsvfrFLsvPoWsi0jceCkQAJkAAJkICHBCgoPQTFaN4RaNewtiwad5G8fFN3qVerhuQpd0KvfL1Hhs1YI5gNzkACJEACJEACJGBdAhSU1m07y5Uc4yqv7dFUVk0aJHf0byVYrvFwWrbcs+BHvbrOwZSzlqsTC0wCJEACJEACJEC3QXwHqoFAfM0o+cfVnWXZg5dIr5aJugQrd57U1sqZX/3GFXaqoU34SBIgARIgARLwhgAtlN7QY1qvCHRqEi8fjO8nL4y6QOrGRUtuQZHM+Gq3DH95rXy966RXeTMxCZAACZAACZBA4AhQUAaONZ9UDoFw1e9944XNZdWjg+W2i1qK6hWXA6rr+463f5Bxqiv8cBq7wcvBxkskQAIkQAIkYCoCFJSmao7QLUyd2Ch55tou8r8JA6Rb8wQN4ks1WQe+K+es3S/5XGkndF8O1pwESIAESMD0BCgoTd9EoVXArs3qyEf3XSzPX99VEpTIzMkvkpe+2iMPLz8lH285xnXBQ+t1YG1JgARIgAQsQoCC0iINFUrFRDf4zX1ayNeqG/zmPrblG49nFcpfPtwuf1DjK7HaDtcGD6U3gnUlARIgARIwOwEKSrO3UAiXL1FN1Hn++gvko3v7Ss9GNTSJ306e0avtXP3KOlm18wSXcQzh94NVJwESIAESMA8BCkrztAVLUgGBzmo2+P+7JFEW3d1bLm5bV8facTRD7pz3o1z/2gZZv+dUBSl5mQRIgARIgARIIBAEKCgDQZnP8AmBni0S5N17LpJ371YWS3WMsPngabnlre/l5je+kx9/T9XX+IcESIAESIAESCCwBCgoA8ubT/MBgYvPqycfqok7b9/RW7o0jdc5frsvRUbN+VbGvr1Rth1O98FTmAUJkAAJkAAJkICnBEwvKPfu3St33HGHdO/eXfr37y/Tpk2TvLw8t/WbNGmSXH755Tpd79695ZZbbpF169aVSZeZmSlPPPGE9OnTR3r06CEPPfSQnDxJp9plQJnsApZxvLR9A/nkgQEy59aecn6DWrqEq3clC8ZXjl/4o+w6nmmyUrM4JEACJEACJBCcBCLNXK309HQZM2aMtGrVSmbNmiUnTpyQqVOnSk5Ojjz55JOVFj0/P1/Gjh2r0+bm5srixYtl3LhxsmDBArnwwgvtaR9++GHZs2ePPPXUU1KjRg15+eWX5Z577pEPP/xQIiNNjcdeh1A+gLD8Q5fGMqxTI1m29ajMWLFbfleO0b/YcULgx/Kabk3k4aHtpHW9uFDGxLqTAAmQAAmQgF8JmFoxLVq0SLKysuSVV16RhIQEDaKwsFCmTJki48ePl4YNG1YIZ+bMmU73Bg4cKEOGDJGPP/7YLig3b96srZZz586VAQMG6PitW7eWK664Qr788ku9d8qEJ6YlEKFcDY3s3lSu6NpYlvx0WP61co8cOZ0tH/98VAnNYzK8c0MZ1K6+DDi/vjRNiDFtPVgwEiABEiABErAiAVN3ea9du1b69etnF5MAPGLECOWDsEjWr19fJd4RERFSu3ZtgeXSCMg/Pj5ed6Ub19q0aSMdO3YU3GOwHoGoiHC5qXcLWTVpkDw9srPUr11DO0P/bNtxeezDbdJ/6iq57MXV8vel25UV87hk5JS+D9arLUtMAiRAAiRAAuYgYGoL5b59++SGG25wIgUBWL9+fcE9d6G4uFhg0cQ4ySVLlsiBAwfk6aeftidDHrBIotvUMUBUepK/Yxoem4tAjcgIub1fK7mxV3N5/8dD8tWvJ2Tj/lTJLSiSfaey9LbwuwMCy2Y3tToPLJcD1GSfHmr2OEQpAwmQAAmQAAmQgOcETC0oMzIytAXRtTp16tQRjK90FzBucvLkyTpabGyszJgxQ0+8MdIhf1gtXQPy3759u+tlj84xYch10pBhFTX2HmXESHYCBjdjb7/hwUGEinPzhU30lptfKJuUm6EN+1Jlw94U2XEsU1svf1LXsP1r5W8SFx0hfVolSv/z6iqfl0nSVo29dP3B4cFjTRXF4GbsTVU4CxTG4GbsLVBkUxXR4GbsTVU4ixTGYGfsLVJs0xTT4GbsfVkw1+97X+ZttbxMLSi9hYkxkx06dJC0tDRZvny5YAIOxmMOGjTI26wrTL9z505JTk4u9z7uMZw7AV/ww8+H4Y2wxUlGboxsO5krW0/k6e3k2ULJyiuUr3ef0htKmhQTLhc0iJYuDWpIu7pR0rhWhIS7WLTPvUaBTekLfoEtsbmeRn7etQf5eccPqcnQO4b+4JeSkuJdoYIotakFJbq30V3tGmCdhBXRXUhKShJsCJiUg3QvvPCCXVAi/+PHj5fJxtP8yyRUFyBgGzVSisUh4FcRXmTci4qKcrjDQ08I+JNf/5ICYHjEwdRsWa8sl7Bgfqe2jJwCSc0uktUHcvSGqPE1I3UX+QWqm7xbs3h9nBgb7Uk1qi2OP/lVW6UC+GDy8w42+XnHD6nJ0DuG/uRXnobwrrTWTW1qQVneWEYITFgAca+qoXPnzk6TbZDHt99+q9eDduzW3L9/v7Rr166q2ev40dHRgq28ADFZ0b3y4vOaMwF/8zu/cQ05v3GCjB3QVneFbz18Wi/r+M1vp2SLOs7JL9Ii85s9KYLNCK3qxqqxl4nSvXmC3jo2jpfoSPONw/Q3P4NHsO7Jz7uWJT/v+CE1GXrH0B/8+J1e2iamFpSwKs6ZM0ccx1Ki6zo8PNxpZnZpdSo/2rRpkzRv3tweCfnPnj1bi8qLL75YX4eY/OWXX+Tuu++2x+NB6BHAZB2IRGwPXHa+5BcWaUfpmw+dlp/VeMvNh9JkX3KWBgO/l9g+2nxEn0NMdlHrjzuKzGaJMZYfixl6bwFrTAIkQAIk4CkBUwvK0aNHy8KFC2XChAna7yQcm2OlHFx39EEJ5+dHjx6VFStW6HqvXr1ali5dKoMHD5bGjRvrru5ly5Zpn5MvvfSSnQ1WxoH/SayU89hjj2nH5pi40759e73Kjj0iD0KeAGZ+d2laR2+3XdRS80g/m68tl1hP/GclMCE2T6treWomuTHRxwBXW3WVN0uM1T4wIS6xwR9mU30cK4mxURScBizuSYAESIAELEfA1IIS4yTnz58vzzzzjBaVcXFxMmrUKJk4caITaPilhHsgI8AKiZlX06dP1xNyEhMTtUiEOMUSi44BK+M8//zzeuWdgoICLTAxM5yr5DhS4nF5BOooEThQOUvHhoBxmAeUpfJnJSw3H0zT+1+OZSjrZrFkqvGYv6pjbOWFmKgIm8gsEZpafJYcN1f7erVqKMu8s3ur8vLx9bXcgkI5mZGrxK5Ikzox1VIGX9eJ+ZEACZAACfiegKkFJarbtm1bmTdvXqU1h1B0DEiDrmxPAtwG/d///Z/ePInPOCRQEQGMw22l3Axhu7ZHUx0tR7kq2nE0Q3WPn5HDadl69Z4jan/49Fk5djpHCoqKdbxsFe+3k2f0Vl7+kUpM1q0VrR21Q1zWV1s95bQdezhv19dKzuNjIt1aOwtUF37ymVw5ocTiiYwcJRpz7McnMnNLznMkTVlcjQDR27ZBnFo3vbacp9ZOx4Y11FskxUokfXcamLgnARIggZAkYHpBGZKtwkoHDYGaSoT1apmoN9dKFSoxeTIzxyY0S8Tm4bSzTsITjtgRIDxt4i/XNZsy59FK3NUrEZ8Qm+hOP52WLgVbNktyVp7O55QSk8qgWqUA0bv9SIbeHBPieVgr/byGNoFpCM5W9WIFDuYZSIAESIAEgp8ABWXwtzFraFICmPjTWHUjY+vdqmwh0YV+6kyeEphn7SIwWVkPYVk8ZezVMbqkDeGJXPKU9fFoeo7enHPNdj4tOUM5YOlsGF9DGsTX1PuGtbGvqc5xvaYUqG77PcmZ8tuJM7JHWVKx/Z6SJTCw4nm7TmTqzfEByLelmgF/Xv1a0klNUuqvViLCTHiuRORIicf+JrDpQJpeKevKro31GGh/P4/5m4tAtvItvFwtvbv1tyw5KMflD12bSoxawILB9wQoKH3PlDmSgE8IoAsdFkZslQUIzzO5BVp8asGpxCYskDjG/kR6tmQod1ttm9STxgmxWiBCPBqCsW5cDb0EZWXPwL2uyvemY8D4yv1qGUuIS0No/nYyU1/DuFFYYDETHtuXv5yQl7/6TWrViJSL2iTpZS6x3GXb+tZficiRCY/NQ+AXNdRk+pe7ZOXOk7pQr63eK9d0ayKTLm8vLdQPHYbgJzBv/X55Qb0DWbklcyx+3iZ//9+v6h1oJ2P7tw5+AAGuIQVlgIFX+XFZyt/hkntEzh8mctF9VU7OBMFPAMKzds0ovaHr2TVggtq2bduka9dOPvWDiu7sDo3i9eb4TLhYOph6tkRkKqumEpywEmEMKYTvV7+e1BvSNK5Ts0Rc1tMWTIwFZSABbwjgR86MFbvlf1uO2rOpoVx5wYqPa59vPya39G2p3IGdp8ce2yPxIKgIQEw+9ckvZeqEzyDjOkVlGTxeXaCg9ApfABIf2SSyd6Vtq99ezVK6LAAP5SNI4NwJoEu7rermxiZiWzXKmAH/zZ5Tsu63ZL2WOma+H1Nd8x9sOqw3PBFO4S85v54WmX1aJwnGoHoSkH9GtrLSZuVKihomkIJhAXpTx+qa0rh6AlGHRrWlvdrqUrh6gtVScY4pS/y/Vu6R9388pK3jKDzccz0yrJ1cobq7cX2mspKnqHHE8zb8Lh+o8/GD2spdA1pLnLKcMwQPgbN5BdoyWVmNXvxyt9zUuwW7vyuDVMV7/C+qIrCAR28zWH0nXyByfKvIxw+I3LdBJCYh4MXgA0nAGwKOM+DhxxOzzLceSVfiEgLzlPLbmaYnHhmuld5Yu0+vNtS7VaK2XEIIpmXla3GIcaUQixCOxh6iEd3sngZYQg1x2b6hTWS2U3uOrfKUoHnipSqB+NrqPTL/2wPaByxKhmEiDykLJASDsWrV7f1ayfU9m8mb6t1685t9kqXG1r2kLJkLVLo/Dz1fRvduzvG95mlWr0qyUvWC2Lu5K8jJ1ltyQq5WwyAYfEOAgtI3HP2XS2S0yHVzRN4YLJKhVmJZ/jd1/pr/nsecSSAABOBmqKdahQjbQ0POVx/+BfL9frWkZYnARDc5HMSvV0tcYqtqwMxzuFmCcMQe4zl3q4lDmCmPACG6bg+2U/as4WuzpXKBBAtme92VbxOaTWpH2ePwwDwEMnPyZe66/fLWN/v1UAqUrE5MlNyrrI5jLm4psdFlv94whneisljeqn7UzFr1m7z7/UH9Lvx96Xb5t8rrL8Pby4gujdy63TIPBZbElQB6KzDExpOAceYMviNQ9j/Od3kzJ18RaNhZ5NInRL56SmTLu6pf8CqRDlf6KnfmQwLVTgBdjpd1aKg3FOa46gqH2EP3+DolKCEA49VqQxCIhkgsFYzqWpwSj8oqVbdkX1vlB6uoazh9Nk92Hlcz0tVm22cooXlGCxL1PaSX0MQyml/sOGFPivF3zWqHS/c9O6Rz0wTdLd+xcW1JiFU/9kwSipRgBqMjp22+To+q/VHl5xTjVnGcnp2vhXUDxQgz+bHXk7Ic9hgGgJn5VQ16uIEavoDnGxPBjP2pTLipypZk5baqg+LXXg1pMNxKYaWoc3HWD9+u73x3QF79eo/dTyp8pKLr+p6BbbSodFcHWDCfHtlF7lQTMzBp49Otx/Rksvv/85N0U54I/jaig5o8VtddNrxvIgIH1f/tks2HZclPR/QYbk+K5m7Coyd5ME4pAQrKUhbmPrr4IZGdn4kc3ijyyZ9FmvcViatn7jKzdCRwjgQaqck6o3o10xsEC/xw+sLdEEQghIKjWED+EF4Qmdr9UYng3Kuc0eO5mMyxNw3bUflw81F7jTChCGM+0XWOPTZMijoXUWbPtIIDiCiMN4U4hGN8R+GIYzjJh/umygLiVRagJSHWtaso5TYK+wYl+3g16StNiXFDKGKfjCEHep9r72quLP8dyYqdAz9XR/lwkn++GnaAlaHKc5SPyV6L1XhbjIM8rhzxI8AS/ae+LWTCpee59YZQXtmwCMGrf+op4y45LVM/3ynf7kuRLWqlq9FvfCeXtq8vf/1DB92u5aXlteonkKGs1PgxsOSnw/LD785WSfyexI/EigKs1UM7NqzoNq+fAwEKynOAVi1JwtXkBHR9v9ZfJCtZZNlEkT8uEGWGqZbi8KEkECgCsDRGRfjvPUf+zVVXN7ahnUq/YNDlvu/UGdlxOE2+2bZfUgprym7VFW90m0PgYVtV4pYGPGDNRJd5R9VlDiumFpxKaKIrFsI1U3XtYw14WAyNDeu/G8fp2Xn62Omauo90ngaIrCYJNdVmWy8eezi3x2QUvSqSEoGoQ7Jyqo9rxpeu0s7K0b7ya6q27VL+EqGelAFjFh1XckqKjZSsjDQ5I7GyV83AhnhHqMxRfhvlTqp0NabaStQXqi7qPdqKiLQQvxgP+bAa+4hlSr0NsEq+e09fWauGXEBYYizv17uSZfXuZLm+RzN5RLmZgUWVofoJYPw1hsZ8qEQk3JHh/9QIeM/hGgrvxk8HUmXKsl+NW2X2cB3EMdNlsHh1gYLSK3wBTly3rciwp0U+/4vIr/8T2f6hcg44KsCF4ONIIDQIQBjBLVKbpJrSKuyUcrvUVbtdwgxydJdDdGCt9p3H4BopU08KgjVz6+F0vTlSQnc9JoFgLKe3AeIU4gZCEbOYIR6bKv+ieo9135VfUU+7kmH1Q1c1nOMbYhPLcEJU2s/VcYYSwElqOAG6CGHFtAlGdY4hCOqafa+OXYcblLqtsvHDDNy9J5X/0hJH+RgvC1+mBxwc5YMvtvICxjg+qsTAeWoJUF8G/LAY1K6+XKIc8H+85Yi8+MVubQmGcPmfOm9VN05gOYfV1vDjimEDxjHY+MKK7ss6BVNeO46m6+7sj38+qt9Zo274sXlZhwZaRF7avoF9EhZ+JKBNMZsbE3CMAMsk/VAaNHy7p6D0LU//59b7btX1/YnI/rUinz6qZhEoi2V8Y/8/l08gARLQBDDWsP952OrZiUCYoYvcNkvdJjZ/VUITYg0hQ40xLC/AmlhHWVUgEhPUhn3pebQ6j9Tn6Ko3RCS+EH0VIICM1Zp8lae7fDBZBk7yXR3lo1v/dyUq4STfJjIztdCEX0nM4Ic7KUyauaBZgrtHeHUfYvw6ZZWEq6GFagb4K2qsJizGKBO2ioLSLmoMr23FKZvQLBWbEOGFRUWSk1+kLbNYvQUWWtS59Bj3bddLr9ni4Hp0WKE0/2mTGooQUyLsHQR+idBPVO+JP4ZcVFRnf12HFXKP+n/C8IMt6gfaj7+n6rHOjs+DYBzVs6lcdUETSVQ/dsoL8DOJmf7Ltx1RK+X8Lhec34or5ZQHykfXfPfJ5KMCMRs3BMLDRUbOFpndTyTntMj/HhS55QN2fbvBxtsk4E8CEGaGk/frepQ+CWMNITJh7Ys3RKMSkAkxEItRys9meLmTh0pzCJ0j+Bw1GDrWGmIdXgACPQkKjvvvvqSN/FG5E1r56wk9yQntiO24sugallzD6oyhA/gBgW2HWqXHH+Fgemql2UJMwpKsrchaZNpEp7YgK1GLiWwQvfVqR0uSEp/ljVWt9AF+uImhIFgIAcIRAnLr4dOy/UiGFtyuj2uiLMTXKREJwY8hEZ4EdGtf2bWRtJBk1cvQSPUyRHiSjHHOgQAF5TlAq/YkCc1FRkxVfikniOxZIfLTApFeY6q9WCwACZCAMwF0g9avXd/5Is+qRABiPdBi0rGAmJAEAVNegJiEH0xDaGJsaukxxCfGpOYokZmnxwFDNGMyEkQO9jjHjwrjmv1+yT3Ew7VwKZLd+w9LeFyipKnhB5g9nwzxqn6wOI6vRXn0hCn9Q6a8Epdeg0UVVnGITy001R7CE54SYIWvB/HpsI9FOTB41csAIQ7xCOFo7GEBLi/EqfrDkt1NWaUxHAGT6XxRhvKexWveE6Cg9J5h9eTQ/RY1jlJ1fe9eLvKFcinUZrBIYsvqKQufSgIkQAIhSAAWQduPhhrSpWmdCgnACofxfOca9DjUmNPKwtahzPKp6A63zbq3CUyIV5zDUmrfq2MsBOA4lhAW1TQl5LD9dtKzkmFccU211SgRwjWVFReCF5PRDHGMe/ZzfT9cd8PDDyzGF2MiW3kBwz8wkQ1d2RjW0E0JyTZqta1g6MIvr77BeI2C0qqtig+nq2eqru+L1HTJNJGl94uMUQITXeIMJEACJEACpiHgjZh0VwkIOcNLgbu4EJ+Y2Q/LJlaXgqXTWK4UAtRYfQqiNFXdd51DhhnVelZ1BWOC3T3fuI+vL7iJMoQjRCS8I2CYAYN1CVBQWrftRGo3ErnyJZHFd4gcWCey8XWRi+6zco1YdhIgARIgAT8RgPjE5C5PXCDBWf5pdK+XCM3s/AI9qQgunDC5COIUXg2wdzzPxbmKk4s4JXEhQlsot1zdmtfRIhLWXF9OLvMTLmZbRQIUlFUEZrroXa63dX3vWGJbSee8oco78fmmKyYLRAIkQAIkYB0CGKuICT7YpNQ9q3UqwJIGnAD7RwOO3A8PvHK6WjWngUiBGpvy0XiRwvJdlPjhycySBEiABEiABEiABNTkMQbrE4hNErlmlq0eRzaJrH/Z+nViDUiABEiABEiABCxDgILSMk3lpqDt/yDS41ZbpNVTRY5vc5OAt0mABEiABEiABEjANwQoKH3D0Ry5DH9epI7yUVmkfHp9dK/qAret0mGOwrEUJEACJEACJEACwUqAgjKYWrZmvFpF5xVbjU5sF1nzz3OvHcZhHtigJvpMEZl7uciXfxeB4zIGEiABEiABEiABEnAhwFneLkAsf9pmsEifccqF0Bsi62aItL9CpNmFnlUr46haeWelbfWdvatFctNL0x36XgSCdeBfSq/xiARIgARIgARIgAQUAQrKYHwNhiqrIoRh6l7brO/x34hEx5ataaHqGodQ/G2Fiv+VCKyariGxlUhMosjRzSKrnlUuidqJdBrpGovnJEACJEACJEACIUyAgjIYGx/i8drXRN5WE3VS9oisfNq29jfqmn7EZoGEiNy3RiQv05lAZE2RVgNEzhumljJQW1IbkfxsldcIkWM/iyxRbokSWoo06e6cjmckQAIkQAIkQAIhS4CCMlibvkVfkYsfsrkQ+l6Jy/yzIod/EDn5S9kaQzQaAhJiMirGOQ4E6s3vibx5mUjmMZH3Rovc87VIfGPneDwjARIgARIgARIISQIUlMHc7Jc+obqzv7SJyJ/ml9Y0UgnG1pfYROR5Q0Tqti29V9FRfBOR0e8qS+UVNlG56GaRsZ+V35VeUR68TgIkQAIkQAIkEJQEKCiDsllLKhVZQ+T6N0XevUlZHVVXtrZCDhVp2b+sFdITDk17ilz3msgHY21jKpfeJzLqbZHwcE9SMw4JkAAJkAAJkECQEqCgDNKGtVerUReRR3bYT70+6HydyKnfRL5+TuSXpco1UQeRS//mdbbMgARIgARIgARIwLoEaFqybttVX8nhOqjLDbbnr5kqsm1x9ZWFTyYBEiABEiABEqh2AhSU1d4EFixAWJhyoP6qSNNetsJ/PEFN+NlkwYqwyCRAAiRAAiRAAr4gQEHpC4qhmAdmgmOSTnxTtcRjjggm6cAlEQMJkAAJkAAJkEDIEaCgDLkm92GFazeyuROKihU5c8LmTigvy4cPYFYkQAIkQAIkQAJWIGB6Qbl371654447pHv37tK/f3+ZNm2a5OXlVcr25MmTOt7IkSOlR48eMnDgQHn00UflyJGyFrTNmzfLn/70J7ngggvk4osvlmeeeUays7MrzZ83HQg07qZmkr9hu3B8q21lnqIihwg8JAESIAESIAESCHYCphaU6enpMmbMGMnPz5dZs2bJxIkT5f3335epU9VEkErCjh07ZMWKFTJixAiZPXu2PP7447J792658cYbJTU11Z4SAnPs2LESExNjz3/ZsmXy2GOP2ePwwAMCHa8WGfKkLeKvn9hmgHuQzKMoannIsN+/kRqZBz2KzkgkQAIkQAIkQAKBJ2Bqt0GLFi2SrKwseeWVVyQhIUHTKSwslClTpsj48eOlYcOG5RLr1auXfP755xIZWVq9nj17yuDBg2Xp0qVy55136nSvv/66xMfHy2uvvSbR0dH6Gs4feugh+eWXX6RTp07l5s+L5RAY8IhI8m6RrYtEvnlRpH57kQv+WE5EDy4VF9vWGN/2gciOjyTqbIp0DouQwrAnRC5Rz6HfSw8gMgoJkAAJkAAJBI5AeOAeVfUnrV27Vvr162cXk8gBVsci1aW6fv36CjOEKHQUk4jYqFEjSUpKEnSHG+HXX3+V3r1728Ukrg8YoJYeVGHVqlV6zz8eEsDM72v+JdK8ry3Bxw8oUbjRw8Ql0U7utK07PvMCkX8PF/nhLRElJhHCigsl8utnRBaOFMk4WpKAOxIgARIgARIgATMQMLWg3Ldvn7Rp08aJE8Ri/fr1BfeqEvbv3y8pKSnStm1be7Lc3FwnMYkbUVFREqbEUVXzt2caygdYmeem/4jUaS5SmKtmfv9J5PTByolgZvj6mSKvKSE/W4nRb6aXpklSbTX4b5J/50pJaapW+EHYv1bFvVgEXesMJEACJEACJEACpiBQ2idsiuI4FyIjI0N3STtfVXqlTh3B+EpPQ7HqQn322WelQYMGcuWVV9qTtWrVSrZt2ya4DxGJsHXrVn1elfztGaoDTBhynTSEMaAIxl6fBOuf6DoSduNCiVxwpYRlJUvRf26Sgts/FalRq7TG2aclfOcnEr5jsYQd/FbCRHVxl4TiuAZS1Ok6Kep8gxQ37q5Mk2Ga2+89n5C47tdKjRWPS1h2msh/b5XC7rdL4dCn1XricUZy7sshYLx3xr6cKLxUCQGDm7GvJCpvlUPA4Gbsy4nCS24IGOyMvZvovO1CwOBm7F1ue3Xq+n3vVWYWT2xqQekrtpjQ891338lbb70lsbGx9mxvvvlmPSln+vTpelwlusMxPjMiIsIep6oHO3fulOTk5HKT4V6ohDrd/iZtf/i7hCf/ImffuUX29/x/En/ye6l7eKXehxcX2FEURsZKWuNLJLXpEMms10OJSMUfPd0p2+1xcLAjvJNED5gjrTf/n9RK+0Uifl4g+b99Lft6TZbsOuc7xeVJWQKh9P6Vrb33V8jPO4bk5x0/pCZD7xj6gx96PhlsBEwtKNG9nZmZWaatYD2EldKTgFnhr776qjz33HN6PKZjGozPnDRpkp708+abb6q5HuEyevRo3e0Na+a5hA4dOujxmo5p8asILzLuoUs9JELXrlJYu0AiVz0lCSc2SPcvr5Owwjx71YsjoqW47VAphCXyvGESrxylx9vvOh848+sq0meIFKqJP+EbZkjNrEPScd0DUnjpZCnqc68So+HOiXmmLbwh9/75sN2d378Q+f8lPx8S8D4rvoPeMfQnv+PHj3tXuCBKbWpBifGTrmMZITBhAXQdW1lem8B10FNPPaVnbY8aNaq8KHLPPffILbfcIocOHdJjMyFiL7roIvnjH89thjJmixszxl0fCDFZ0T3XuEFxfsnDIql7RH5+p0RMqmEFrQaIdB0lYZ1GSlhMolRF/pXyixYZ9qRIu6EiS8ZJWPohiVz5DzW+crXIdXNE4HCdoQyBUn5lbvGCBwTIzwNIlUQhv0rgeHiLDD0EVUE0f/ALqe/0Crgal00tKOGQfM6cOeI4lnL58uXakggn55WF77//Xh555BHte3LChAmVRdXd4O3bt9dxFi9erMdQYjY5g5cEMC71qhkiSa1FMGGn83VqAGwzLzN1SN5STc65d53IsomqP3yJyL6vbRN2sM54e7afAykekgAJkAAJkIBfCZhaUKL7eeHChQJBCL+TJ06c0Cvg4LqjD0o4Pz969Kh2Zg5aWF0HaTDpBqvl/Pzzz3aIcB3UokULfQ6rJPxSYpUcBIyzXLBggfzf//2fx13qOiH/VEwgUlkTB06q+L63d2ISREb9W+T8YSKfqufAzdB7o0UuvEvk8mfVhJ3SMbPePorpSYAESIAESIAEyidgakGJcZLz58/XyyFCIMbFxQm6rrFijmOAX0o4PDfCli1b9NhLdI9j4o1juO666+wr7cD8vXHjRv0MjLHAGEc4Ub/00ksdk/DY7ARgCe3+J5sPzA/vFjn6k8iPc0UOrBe5Qe0bdal6DbB8ZHaqWqP8pIiarS61Goo06FD1fJiCBEiABEiABEKAgKkFJfjDb+S8efMqbQpYMR3D9ddfL9jcBTg7d03rLg3vm5hA3bYid32pln78P5F1qqs9eafIm+rHwbCnRfreK1JUoMThKbUpkXhGiUS9LxGMEI2GeMT+rIpXrESlY6jfUaTLDWpT7xaexUACJEACJEACJKAJmF5Qsp1IoEoEItQs3KFqgk7by0Q+Gq9W1TkisvxxtfTRc8pJaGaVsioTOflXJVaftW1NepaKy/gmZaKa4sKJHcqx6vsStf1D6XY2XcJ39RdpM1ik9UBlbVXiuMT3qinKykKQAAmQgD8I5J2V8F8+kQb7tkh4xB6RTldzKJQ/OKs8KSj9BJbZVjOB1pfYJux88me1qs7/yheTNeuIKEfqUkttcfUcjuuXXFP7OGzq3tHNIkqYyS8fq67wNFu3OrrWv5ws0lIJNVgtO12r4tat3oqnHxbZtlgLSTmpBKUKakCA7R999+ci2BBQr1aKEcQltqQ2FJg2MvxLAiQQLAS+f10v5xuZd0aao074SPy8tshlf1e9VsrgwOBTAhSUPsXJzExFIDZJ5I8L1Ozv1TZLpRaPEIglG2aeexoM4TXiBdtscojLnZ8qoXpGjdVcZ9s++4uyjKou9i6jRDpcKVIz3tPcvYunVh7SQnfbByK/q7I4rDwktRtLoVp56OiZMGmav1/CD64XyUm3jQvFzHhsCPHNSsUlxLgvZ+PbnlA9fwtylbj+r205T0zUim9cPeXgU0mABKpOQK1iJxlHRU7tVmnVcVSczboYFWtbIc3Yh0eUzRti8vO/lr2em1l6naKyLB8vrkR6kZZJScD8BNCtC5Hnq4BZ6+2G2zbVlSK/faksl8oiuFvtsX75nq9sW4QSq+0ut4lLxFeO230aIJR2f6Gske/b9g5O46WGErIdrxG54EZthSwsKJSTaonRhsrZfHSk+uA9vtW2Jvr+b5QQ3qDWBM1SH9qHRba8a9tQUFgsDRHdaqCy2Nb3afH9nllOhsimt0W+na3Gxh63PW7DKyL9Joj0f0iJ/Tp+LwIfcI4ECvNtPwBS9io/tmrDHhPkzhtq6wWg5wb3YA2GqfsUw/0imUfVMJfOiuEQEfzQNluAcMTYdQwrOumwYRx8rvpfdhfUQhliiEvso2qKYMhPZWHVMyI9bmP3d2WMqniPgrKKwBidBOwE8MXW+VrbBqvfzs9s4nLv1zZx+esnqrtdbdG1RFr0s80UR/e67mJXAk3vS86Vk3e3Yxox8xwz1yEi0fWOZxohPEq5TrrcJiLb/cFFwBYasUQNIhJp0sO29f+zKqf68j7yU4nAXCNyaKOt7PqLSH0ZbZpnS9uwS4mQHiHStJfKJ7w0TzMdYbLV96+JbHxLfREZfMJsXzYQzmqFJfnx38qV1V9Eet9l849qpvKHSlmK1DupFiTQYhHvmqN4PH3ANoHOlQV6BT5/TC+MID1vt73DrnF8eY6hLfj/xRCSg9+pBRMaitTvIFKvndq3V3u11VfH+N+tjpCn3ue0322CEQzT9qtjtYeABFvXSYUoI5a1bXFRyf+y+pxAXQI9ljorxVk4QjSe/MU2lOhcOeIHNbac057nAEslhgBhoiWDTwhQUPoEIzMJeQKweHW/2bbhA/OXpUpcLrEJQHSL71lROSIIQnTFwxIIF0X27vkGNuEJq+I29YUKS6JjaHGxTURi/Oa5WB4wialFX9s26C/KWpkjcliJyv1rbduRTbYv9xPb1S9+tX0z3VbO84cr5/HqC6nNpSI1ajmWqHqO8cW6YZbI5ndEClQdEMAUbXLxn21sUPaNb9isXV/8zSY8MZYKQxTMKpALC2wCHxZp1Cs/27bp47O29spXe6d7iIO4xnV1DHGByWMJzdVwBrUltLANa/C15dxGXj2vWHlKSNWWsbDUg1Lv9x8k4qQSZqd/t4lHiB9Hq7qRznWPoRh126j2ibQNXYG1Cj8IsDW6QLSw7HqjEnUJrinP7Ry9DhAZ+F/D/6xjGU8ftFlO0SvhGPC/CoHpKDIhNrFiV1XFGn40YvIgxA6s7NirOoefOSWNdm+UiAOqfCgHhKNheXcsS3nHtVW7Yxw4RBs8XeBHKbYVT4oktlLicoRNYGIsOHpgfBVQ9pM71bZDbb/ano9zeNeoLKC8cNEGrxqYPIgNbGGFhIjGe412wg9E/D8Yx477/WtsPUWVPQf3YBVl8BkB9V/KQAIk4FMCmJgD6xe29CO2SUH4FQ7r2ZkTpW6LCtSHoRGK8m3dUuiachdgJbngj8pSc6NNGLiLX5X76CoyurqRDl8KB761fbnuWq7qo77M4GJJLaepN3zIIz6solidKNBjL49vF1n/sk28FxfaagqL8IV3iFx0v01E2a6KDH/ONhAfbqW2LLJ9MS+5R6X/l3It9ZQaGjGk6gLAyLu8PURV8i7bsAiIcYg+WIQhDiFU9F4dF6hjDJfQe8djda08K1N5zzrXa/gRowWmITRbOohOda28oQH4Ese4tsxjajvucKzOM3AN99T1EjEWpcqmcq041Gpkc8OFYRZwx5Wktrrn2VbYchS8eObP/xH5aaFquwO2oRufTbJNjMMPKlgtsXpWVUUcuO9dZetdQC8DhIoRIGTR1d7+CluPANrzlNqSd6v/jXRbLAgkbL9/Y6Sy7WvUUUKonc2SCVGMHwcQxHrLdBKMdgFZgScKVQpp6px76RmsjvihAH6JrW17rE6G8wRF3hgigLHWe1fahshAFMMCix9isOhji65tGx6E/2X0dng6zAX8Un5TPzh/KRGNJXsI38oC3j0tFjvaBGSDTjbhWJnFV497T6osV9u9OooWhh+5C+glYvAZgbBiFXyWWwhnhAXiBw0aJGvWrBH4t3QMeXl5sk2NYeuKMWxqrW+GqhEISn74t4PlEr+QseELSe+Ty78Woz5Eu1ynROQflWWma5W+NH3GD2WGlWPX5+pLabmyZP6oGtLl46OhKhssl7B6oGvdX5Y/iNx1L9nEmvE6xdZVgvE+kT53u++GhBBdOcU5PYTxUHWtaU8jR72vEj+ILYxNxRf2b1/YRKtTbn44wXhd/BDA2LFI7GNsWyT2JedoO3gAQFcoVpPyNEAUQazA+o0fRBCRVelWLHlOfnSiRDQ4T8Lrnm+zOGrR2NYmemrU9rQ0tniw4v2+VgnLBbYuaUcrIvKFsMRCB5WJBXS5w0qH7mx4gYC4socwNfZ4gK1rHWORy7P8gyd+HGqBuVvtd5Ye47qPQ7Fq25wa9aVG4w6KYQk3LR5bq/Zpoax3UVV7Iup/+Afb/zF+KGLsolNQDJpdaLNcQmBiyAvqDCGPzwBsWkCqdBCTsHxWFPCjBGJRWxvVHj+IcQyrqb8CrJUvqncNn7EVBbx3j6q2MwR3RfHcXK/su99N0qC7TUHpoyat7KWq0heSj8oTTNmQn3et6Td+EMAQThCYGDfqaNlBkdF1D0sHLJf4gsZkoapajxyrDiGB58Fp/aHvSu/UUV+oFz+oBtjfWvUvB4i/r/6hxpFuKs0Pa86jK7zEeb1bfrDEoFyYmIWhAo6WZ+SKHwOwnOELDBZdWFnsexwrMeB6DV2PEIo6XsmxIRSxN8Qi9lUV7eg2hLg8fchmcdZ7dYx64Bii0fWHQikd5yOIWOVJQG+YQe903ETPqs9TYnLbr7v984Ma3eqYxb9pvrMogmURQqjnGNtEFIwdhiDCeGFMosNwFNcuY4wNxvAHtL833gAgTk8pkWW3Zu5SlkAlxNDGEFd4D/QWb9vDG4Q+d7hnv2a7l1dY7F+jBCyVeH/xQxGWVkeRjhbH/3KuEmeu/+OObwPeV3RNN+xcIh7VvmEn2zvhzf+94zOqclzRLG8jjxHTfOI6qLLvfuNRobJX/3UMJEACJHAOBGABgojDhjF7cFmE8WeweGCsJyw1mxfaNmSPrjl8oeLLUu9xjC/Rkr39mut9dY5JEejahmXECBhjNWCiEgHX20SZcb0qe7hIunulbZLTyqfV2LS9ypXSRzbLV687RAb9VYnUBOcc0XV56HubBRJfwmWsOyo6rMjnD7dZePQkJlV3s4ToONsXP778ywvowsSCALBmGmITwg1doBjf5igc0WbuxEKeys9fAdbDi+5TwuBe24+Cn+bbxj9C+OxcZtvim9q6rSH2MXbTMcBaBhHpy9Wv0GXbvI9tc3yWN8euAs+bvMpLi7GUfcfZNgjHfV/bxCXeb917ov6XjRAWbrMsa6tjJ5toxDG62Mtz32OkC/TecAmE2dwYumMEiHf6oTRo+HQf6dPcmBkJkEBoEkDX6vlDbdsVL9om8EBYQmAa1j+McYT7F2zehOZ9lZB8xGb9rKp1rrznQhBhtj58h6IbdfVU25foD2+qMXvvSkTf+yW6RncJ36bE7L6VamzWKvUFle6cE/zjtRmsBOTltnKZdfUk51KXfwbrqB6D17r8+2a8ijZEFy224f9ns0CiLY/8aBPHEJpGQBexXkJ1lM2a5k4QG+lCZY9Jdh2vtm3oFTi2WQ0P2KC6/uvauq7xQ8RxbKuZuUBUKtdABWqlnGO/bZHG53eTSK6U47cWi/RbzsyYBEggNAngCxoWOmyYOZ6prBtwTIzJCHB1ZN+M89Ol1xzjuE5IgcUPFsmW/fzDFV3PmEh1wU0i372mLKIz1RisTIlY94KompQNsMhoK6QSkXqGbI2ycXgl8ARggeo1xrbBFyEm8cBzQVMlNrsqEdmst3urauBLbc4n4gcbLOzYrBrUGMkitbjDycLzVA+8+k/mPAa/tSQFpd/QMmMSIAFNAP77sFUlYLwbBtTDdQoEKKwmsCwFIuBZEMKYKb72BSn+Ya6EqVn4xcoNUVir/jYRibGh9c4LRGn4DG8IYDzfCGVxZiABEvA7AQpKvyPmA0iABKpMAFZOPVFBWZvgAqQ6Amahjvin5Pe+V/ZvWimtL75eeVZJqo6S8JkkQAIkYHoCyp7NQAIkQAIkUCEBNanjTL0eNitphZF4gwRIgARCmwAFZWi3P2tPAiRAAiRAAiRAAl4ToKD0GiEzIAESIAESIAESIIHQJkBBGdrtz9qTAAmQAAmQAAmQgNcEKCi9RsgMSIAESIAESIAESCC0CVBQhnb7s/YkQAIkQAIkQAIk4DUBCkqvETIDEiABEiABEiABEghtAhSUod3+rD0JkAAJkAAJkAAJeE2AgtJrhMyABEiABEiABEiABEKbAAVlaLc/a08CJEACJEACJEACXhOgoPQaITMgARIgARIgARIggdAmQEEZ2u3P2pMACZAACZAACZCA1wQoKL1GyAxIgARIgARIgARIILQJRIZ29X1X+4KCAp3ZyZMny2Sal5cnKSkpcvz4cYmOji5znxcqJ0B+lfNxd5f83BGq/D75Vc7H3V3yc0fI/X0ydM+oshj+5Gd85xsaoLJyBPs9CkoftXBqaqrO6cYbb/RRjsyGBEiABEiABEjACgSgAZo1a2aFovqtjGHFKvgt9xDKOCcnR3bv3i1JSUkSGUmdHkJNz6qSAAmQAAmEKAFYJiEm27VrJzVr1gxRCrZqU1CGdPOz8iRAAiRAAiRAAiTgPQFOyvGeIXMgARIgARIgARIggZAmQEEZ0s3PypMACZAACZAACZCA9wQoKL1nyBxIgARIgARIgARIIKQJUFCGdPOz8iRAAiRAAiRAAiTgPQEKSu8ZMgcSIAESIAESIAESCGkCFJQh3fysPAmQAAmQAAmQAAl4T4CC0nuGzIEESIAESIAESIAEQpoABaUfm3/v3r1yxx13SPfu3aV///4ybdo0wRJQDO4JLFmyRNq3b19me/HFF90nDsEYBw4ckCeffFJGjhwpnTp1kquuuqpcCh988IEMHz5cunbtKtdcc418/fXX5cYLtYue8LvtttvKvI94R/F/Hurh888/l/vuu08GDhyoP+/wHi5evFhc183g+1f+m+IJP75/5bPD1TVr1sitt94qF110kXTp0kWGDBkizz//vGRmZjolWrVqlf7cw+cfPgc//PBDp/s88Y4Al3Txjl+FqdPT02XMmDHSqlUrmTVrlpw4cUKmTp0qWFEHX/wMnhF46623pHbt2vbIDRs2tB/zoJTAb7/9pj9Uu3XrJkVFRWW+yBHz008/lb///e9y77336g/ezz77TB544AH5z3/+o0VAaW6hd+QJP1Dp2bOnPPbYY06AQn25NcCYN2+eNG3aVB5//HFJTEyUDRs26Hft+PHj+h1DHL5/oFB+8IQfUvL9K5/f6dOn5YILLhCI7oSEBMH/M753sf/3v/+tE/3444/6XRw1apQ88cQT8t1338n/+3//T+Li4uQPf/hD+RnzatUIYOlFBt8TmDNnTrGyTBanpaXZM1+0aFFxx44di9WHrP0aD8onoH45FqulrIpTUlLKj8CrTgQKCwvt50rwFF955ZX2c+Pg8ssvL37kkUeMU72/6aabiu+++26na6F44gk/ZQEpHjduXCjicVvn8v5PJ0+eXKwEULHBlu9fxRg94cf3r2J+5d3573//q79DjO/bO++8sxifd44Bn4cjRoxwvMRjLwiwy7tq+tvj2GvXrpV+/frpX0tGIvXiauvR+vXrjUvck4BPCISHV/6vfOjQIfn9998F76BjuOKKK+Tbb78N+aEY7vg5MuNxWQJJSUllLqofz3LmzBk5e/as8P0rg8fpgjt+TpF54hEBWCoR8vPz9efb999/X8YSic8/DFk5fPiwjss/3hGo/FvIu7xDOvW+ffukTZs2Tgzi4+Olfv36gnsMnhHAWEB8MWFMzOuvvy7K2uFZQsZyImC8c61bt3a63rZtW/2Biy98BvcENm7cqIcHYAwWxmz98MMP7hOFaIxNmzYJhqjUqlXL/pnH98/zl8GRn5GK759Bovw9vh9yc3Nlx44d8uqrr8pll10mGJJy8OBB/Tnn+p2Mzz8E4/Ox/Fx51VMCHEPpKakqxsvIyBAISNdQp04dwfhKhsoJQHg/+OCDgjGBYWFhgsHUL7/8sh6LyjGolbMr767xzrm+k8a5cb+8tLxmI9C7d2896Qnjok+ePClz587Vk+4WLlwoPXr0ICYHAhivhjG6xnhT4/0y3jcjqnFu3Deuh/relR948P1z/1Zceuml+jsCMS+55BKZPn26TmS8X8b7ZuRknBv3jevcnxsBCspz48ZUfiaADwNsRhgwYIDUqFFD5s+fryeVNGjQwLjFPQkEhMBDDz3k9JzBgwfr2fSzZ8+WN9980+leKJ9gIs7EiROlb9++cvvtt4cyinOqe0X8+P65x/nGG29Idna27NmzR1577TX9XfH222+7T8gYPiHALm+fYCybCX75uLosQCz8EoKVkqHqBDD+D10av/76a9UTh3gK451zfSdhSUcw7oc4pipVPzY2VgYNGqS716qUMIgj432655579NhxzLI1xqYa7xffv8obvyJ+5aXi+1eWSocOHXRvwY033ij4oYdxkytWrLB/vvH9K8vMl1coKH1J0yEvjNVwHZeBlzk5ObnM2EqHZDwkAb8QMMYOub6TOI+KipLmzZv75bnMNHQIwCXa+PHj9Q9pV3dffP/cvweV8XOfmjFcCcBHLD7bMH6yRYsW+ri8zz+kM95P1zx4XjUCFJRV4+VxbDj4hS82wwKEhMuXL9e/2OHknKHqBDAmKyIiQjvurnrq0E4BwYixf3gHHQOYwhtBdHS042Uee0AAs5dXr16tncR7ED2ooxQUFMjDDz+sf0RDTLr6i+X7V3nzu+NXXmq+f+VRKb22ZcsWPREHk3Lw+YYhGF988UVpBHWEzz9MzKEvWScs53zCMZTnjK7yhKNHjxYM1p8wYYL+1Q7H5lgpB9ddP2wrzyk079511136AwC/MhFWrlwp77//vh6ThQk7DM4EMG4Iq0UgHDlyRLtrMcRjnz59BG5JMMlp0qRJ+tc6PlzxYbp161Z55513nDMLwTN3/GDZgFAaNmyYduCNSTkYm4Ueh5kzZ4YgMecqT5kyRa+6BMfmcBX0888/2yNg5SZ8ofP9syMpc+COH/5P+f6VwWa/gAUasEIOvi9q1qwpO3fu1JPmcD506FAdDys5YUzvU089pd2noTt82bJlMmPGDHs+PPCOQBh8WHqXBVNXRAD+rZ555hnZvHmz9saP5cgwWJ3WoIqIlV5/9tln5ZtvvhEMUMfKL7CuYVwMVkLArG8GZwLwowbXSuWFBQsWaHGOe1j6DhNIjh49KnDhohz7CmZGhnpwx69Ro0by9NNPy65duwSrcsTExOixWvgiwwodoR7gngU/ZMoL+DFoWID4/pVHSLR7m8r4Yew437/y2eEqJuPgBzK6tyFpsGoTfvzBMAG3VUbAuwhvIfv375cmTZqIWqhAsHIOg28IUFD6hiNzIQESIAESIAESIIGQJcAxlCHb9Kw4CZAACZAACZAACfiGAAWlbzgyFxIgARIgARIgARIIWQIUlCHb9Kw4CZAACZAACZAACfiGAAWlbzgyFxIgARIgARIgARIIWQIUlCHb9Kw4CZAACZAACZAACfiGAAWlbzgyFxIgARIgARIgARIIWQIUlCHb9Kw4CZAACZAACZAACfiGAAWlbzgyFxIgARIgARIgARIIWQIUlCHb9Kw4CZCAGQjMmjVLr7pjhrKwDCRAAiRwrgQoKM+VHNORAAmQAAmQAAmQAAloAhSUfBFIgARIgARIgARIgAS8IkBB6RU+JiYBErAigc2bN8vtt98u3bt3l169esmjjz4qKSkpuiqHDx+W9u3by0cffSRPPPGEvt+nTx95/vnnpaCgwKm6u3btkrvuusuez0MPPSRHjx51ilNUVCRvv/22jBgxQrp06SL9+/cXxMvMzHSKh7xuvvlm6datm1x11VXyzTffON3nCQmQAAmYmQAFpZlbh2UjARLwOQGIydtuu01q164tM2bMkGeeeUa2bdsm999/v9OzXnrpJSkuLpaXX35Zi8Z33nlHHxuRjh07JrfeequkpaXJCy+8IFOmTJEdO3boa2fOnDGi6fxxf/DgwTJnzhx58sknJS4uTs6ePWuPk5+fL5MmTZLrr79eXnnlFUlKStKiE3kzkAAJkIAVCERaoZAsIwmQAAn4isD06dO1pRDCLSwsTGfbrl07bRVcs2aNtG3bVl9r0aKFtkri5JJLLpGcnBxtabznnnukTp06Mm/ePG2x/Pe//y0JCQk6TceOHeXKK6/U1k2I1v3798t7770nEydOlPHjx+s4+DN8+HD7MQ4MQTlo0CB9vXXr1jJkyBBZu3atjBw50ikuT0iABEjAjARooTRjq7BMJEACfiGQnZ0tP/30k/zhD3+QwsJCLQjRjd2qVStp3LixtlQaDx42bJhxqPcQgUi/e/duff7jjz9K37597WISFyFGO3ToIJs2bdJxvvvuO23lHDVqlD6v6E94eLj069fPfrtZs2ZSs2ZNOXHihP0aD0iABEjAzARooTRz67BsJEACPiWQkZGhhSTGQ2JzDejGNgK6nR1DvXr19GlycrLeIy9YJF1D3bp1JT09XV8+ffq0REZGCq5VFiAeo6OjnaJERUVJbm6u0zWekAAJkIBZCVBQmrVlWC4SIAGfE8C4SXRzo/t56NChZfJPTEy0X0tNTbUf4+DUqVP6vH79+nqPbm9jIo++UPIH12DxREBXOCyguOZOVOoE/EMCJEACFiXALm+LNhyLTQIkUHUCsbGxekb2vn37pGvXrmU2dDUbYcWKFcah3n/xxRcSExMjGG+JgNnh6NI2rJG4hnwxWxv3EC666CItYD/88EN9zj8kQAIkEKwEaKEM1pZlvUiABMol8Ne//lXGjBkjDz/8sJ5AEx8fL8ePH5cNGzboWdZNmzbV6Q4ePCh/+9vf5IorrpBffvlF3njjDZ0OlkmEsWPHypIlS+TOO++U++67T3dPY0Y4xmJed911Og4m14wePVpmzpyphSfGSWJyz+rVq+XBBx+Uhg0b6nj8QwIkQAJWJ0BBafUWZPlJgASqRKBnz57y7rvvCpY8hGDEDOtGjRppa2LLli3tviYxM3vjxo3y5z//WSIiIuRPf/qTnq1tPAzCceHChTJt2jTt8gcTa+Bj8vHHH5datWoZ0bSbIFg+P/jgA5k/f77uBu/du7d2HWSPxAMSIAESsDiBMOVnrdjidWDxSYAESMBnBODYHC57YFXEbHAGEiABEiAB9wQ4htI9I8YgARIgARIgARIgARKohAAFZSVweIsESIAESIAESIAESMA9AXZ5u2fEGCRAAiRAAiRAAiRAApUQoIWyEji8RQIkQAIkQAIkQAIk4J7A/wfZqQBg1cSWgwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=660x440>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DualMemoryLSTM(\n",
       "  (short_lstm): LSTM(15, 128, batch_first=True)\n",
       "  (attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (do_short): Dropout(p=0.1, inplace=False)\n",
       "  (ln_short): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (long_lstm): LSTM(128, 128, batch_first=True)\n",
       "  (do_long): Dropout(p=0.1, inplace=False)\n",
       "  (ln_long): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (pred): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the entire model object (architecture + weights)# 1) load your checkpoint dict\n",
    "ckpt = torch.load(params.model_path, map_location=device, weights_only=False)\n",
    "\n",
    "# 2) grab the full model object you saved\n",
    "model_best = ckpt[\"model_obj\"]\n",
    "\n",
    "# 3) move to device and set eval mode\n",
    "model_best = model_best.to(device).eval()\n",
    "\n",
    "# 4) show parameters, training plot, and model\n",
    "saved_hparams = ckpt[\"hparams\"]\n",
    "pprint(saved_hparams)\n",
    "\n",
    "png_bytes = ckpt.get(\"train_plot_png\")\n",
    "img = Image.open(io.BytesIO(png_bytes))\n",
    "disp.display(img)\n",
    "\n",
    "model_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c93385fa-870a-4259-ad0c-05d68180afcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing <build_lstm_tensors>...\n",
      "executing <chronological_split>...\n",
      "executing <split_to_day_datasets>...\n",
      "▶️ Entered split_to_day_datasets\n",
      "1) building weekday arrays\n",
      "   Weekdays counts → tr=1694522, val=353129, te=364691\n",
      "2) moving all splits to CPU\n",
      "   CPU casts done\n",
      "3) zero-bas­ing day_id for val & test\n",
      "   val_day_id ∈ [0..782], total days=783\n",
      "   te_day_id  ∈ [0..808], total days=809\n",
      "4) instantiating DayWindowDatasets\n",
      "   ds_tr days: 3808\n",
      "   ds_val days: 783\n",
      "   ds_te days: 809\n",
      "5) building DataLoaders\n",
      "   train_loader ready\n",
      "   val_loader ready\n",
      "   test_loader ready\n",
      "dataloaders generated!\n"
     ]
    }
   ],
   "source": [
    "print('executing <build_lstm_tensors>...')\n",
    "X, y, raw_close, raw_bid, raw_ask = models.build_lstm_tensors(\n",
    "    df            = df_feat,\n",
    "    look_back     = look_back,\n",
    "    features_cols = params.features_cols_tick,\n",
    "    label_col     = params.label_col,\n",
    "    sess_start    = False # predictions from sess_start_pred\n",
    ")\n",
    "\n",
    "print('executing <chronological_split>...')\n",
    "(X_tr, y_tr), \\\n",
    "(X_val, y_val), \\\n",
    "(X_te, y_te, raw_close_te, raw_bid_te, raw_ask_te), \\\n",
    "samples_per_day, day_id_tr, day_id_val, day_id_te = models.chronological_split(\n",
    "    X, y, raw_close, raw_bid, raw_ask, df_feat,\n",
    "    look_back    = look_back,\n",
    "    train_prop   = params.train_prop,\n",
    "    val_prop     = params.val_prop,\n",
    "    train_batch  = params.hparams['TRAIN_BATCH'],\n",
    "    sess_start   = False # predictions from sess_start_pred\n",
    ")\n",
    "\n",
    "print('executing <split_to_day_datasets>...')\n",
    "train_loader, val_loader, test_loader = models.split_to_day_datasets(\n",
    "    # Training split arrays (from chronological_split)\n",
    "    X_tr, y_tr, day_id_tr,\n",
    "    # Validation split arrays\n",
    "    X_val, y_val, day_id_val,\n",
    "    # Test split arrays + raw prices for post‐tracking\n",
    "    X_te, y_te, day_id_te, raw_close_te, raw_bid_te, raw_ask_te,\n",
    "    # Original minute‐bar DataFrame for weekday mapping\n",
    "    df=df_feat,\n",
    "    train_batch=params.hparams['TRAIN_BATCH'],\n",
    "    train_workers=params.hparams['NUM_WORKERS']\n",
    ")\n",
    "\n",
    "print('dataloaders generated!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc3bb61-a03f-466d-9fde-ed65753fc6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val zero‐forecast baseline RMSE  = 0.45447\n",
      "Test zero‐forecast baseline RMSE = 0.43857\n"
     ]
    }
   ],
   "source": [
    "# zero‐forecast baseline on val vs test\n",
    "# √( mean( (yᵢ – 0)² ) )\n",
    "\n",
    "val_baseline  = models.naive_rmse(val_loader)\n",
    "test_baseline = models.naive_rmse(test_loader)\n",
    "\n",
    "print(f\"Val zero‐forecast baseline RMSE  = {val_baseline:.5f}\")\n",
    "print(f\"Test zero‐forecast baseline RMSE = {test_baseline:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce154412-6773-4774-bc9f-7bc5f74f981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std val: 0.35366103\n",
      "std test: 0.34320843\n"
     ]
    }
   ],
   "source": [
    "# to confirm the baseline proportions, calculate the STD\n",
    "# σ = √( mean( (yᵢ – ȳ)² ) )\n",
    "\n",
    "y_vals = np.concatenate([batch[1].view(-1).numpy()\n",
    "                         for batch in val_loader])\n",
    "y_tes  = np.concatenate([batch[1].view(-1).numpy()\n",
    "                         for batch in test_loader])\n",
    "print(\"std val:\", np.std(y_vals))\n",
    "print(\"std test:\", np.std(y_tes))\n",
    "\n",
    "plt.hist(y_vals, bins=100, alpha=0.5, label=\"val\")\n",
    "plt.hist(y_tes,  bins=100, alpha=0.5, label=\"test\")\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3fd008-4a5d-44fd-9bb4-c4e70e4c8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(\n",
    "#     model: torch.nn.Module,\n",
    "#     loader: torch.utils.data.DataLoader,\n",
    "#     device: torch.device,\n",
    "#     split_name: str\n",
    "# ) -> Tuple[float, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Fast per-day RMSE + preds, exactly matching  val‐phase logic:\n",
    "\n",
    "#     • Expects each batch from `loader` to be a tuple of at least\n",
    "#       (xb_batch, yb_batch, day_id_batch, …). We only use the first 3.\n",
    "#     • xb_batch: Tensor(B, W, look_back, F)\n",
    "#     • yb_batch: Tensor(B, W)\n",
    "#     • day_id_batch: Tensor(B,) or (B, W) weekday/day‐id\n",
    "#     \"\"\"\n",
    "\n",
    "#     model.to(device).eval()\n",
    "#     model.h_short = model.h_long = None\n",
    "\n",
    "#     prev_day_id   = None\n",
    "#     total_sq_err  = 0.0\n",
    "#     total_windows = 0\n",
    "#     all_preds     = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(loader, desc=split_name, unit=\"batch\"):\n",
    "#             # grab only the first three outputs, ignore raw_close/raw_bid/etc.\n",
    "#             xb_batch, yb_batch, day_id_batch = batch[:3]\n",
    "\n",
    "#             # move to device once\n",
    "#             xb_batch     = xb_batch.to(device, non_blocking=True)\n",
    "#             yb_batch     = yb_batch.to(device, non_blocking=True)\n",
    "#             day_id_batch = day_id_batch.to(device, non_blocking=True)\n",
    "\n",
    "#             # if we got one day_id per window, reduce to one/day\n",
    "#             if day_id_batch.dim() > 1:\n",
    "#                 day_id_batch = day_id_batch[:, 0]\n",
    "\n",
    "#             B, W = xb_batch.shape[0], xb_batch.shape[1]\n",
    "\n",
    "#             for i in range(B):\n",
    "#                 x_day  = xb_batch[i]             # (W, look_back, F)\n",
    "#                 y_day  = yb_batch[i].view(-1)    # (W,)\n",
    "#                 day_id = int(day_id_batch[i].item())\n",
    "\n",
    "#                 # reset LSTM states exactly as in val loop\n",
    "#                 model.reset_short()\n",
    "#                 if prev_day_id is not None and day_id < prev_day_id:\n",
    "#                     model.reset_long()\n",
    "#                 prev_day_id = day_id\n",
    "\n",
    "#                 out      = model(x_day)          # (W, look_back, 1)\n",
    "#                 pred_day = out[:, -1, 0]         # (W,)\n",
    "\n",
    "#                 total_sq_err  += (pred_day - y_day).pow(2).sum().item()\n",
    "#                 total_windows += y_day.numel()\n",
    "#                 all_preds.append(pred_day.cpu().numpy())\n",
    "\n",
    "#     rmse  = math.sqrt(total_sq_err / total_windows)\n",
    "#     preds = np.concatenate(all_preds, axis=0)\n",
    "\n",
    "#     print(f\"\\n{split_name} RMSE over {total_windows} windows = {rmse:.5f}\")\n",
    "#     return rmse, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a357730-b90e-498e-a670-fef046bab196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 1) Your existing evaluate_model (unchanged, already working)\n",
    "# -----------------------------------------------------------------------------\n",
    "def evaluate_model(\n",
    "    model: torch.nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    "    split_name: str\n",
    ") -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Fast per-day RMSE + preds, exactly matching val‐phase logic.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rmse: float\n",
    "        Root‐mean‐squared error over all sliding windows.\n",
    "    preds: np.ndarray of shape (N_windows,)\n",
    "        Stacked predictions in the exact order the loader emits them.\n",
    "    \"\"\"\n",
    "    model.to(device).eval()\n",
    "    model.h_short = model.h_long = None\n",
    "\n",
    "    prev_day_id   = None\n",
    "    total_sq_err  = 0.0\n",
    "    total_windows = 0\n",
    "    all_preds     = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=split_name, unit=\"batch\"):\n",
    "            xb, yb, day_ids = batch[:3]\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            day_ids = day_ids.to(device, non_blocking=True)\n",
    "\n",
    "            # if day_ids is (B, W), reduce to one id per window\n",
    "            if day_ids.dim() > 1:\n",
    "                day_ids = day_ids[:, 0]\n",
    "\n",
    "            B, W = xb.shape[0], xb.shape[1]\n",
    "            for i in range(B):\n",
    "                x_day  = xb[i]                   # (W, look_back, F)\n",
    "                y_day  = yb[i].view(-1)         # (W,)\n",
    "                day_id = int(day_ids[i].item())\n",
    "\n",
    "                # exactly as in your validation loop\n",
    "                model.reset_short()\n",
    "                if prev_day_id is not None and day_id < prev_day_id:\n",
    "                    model.reset_long()\n",
    "                prev_day_id = day_id\n",
    "\n",
    "                out      = model(x_day)          # (W, look_back, 1)\n",
    "                pred_day = out[:, -1, 0]         # (W,)\n",
    "\n",
    "                total_sq_err  += (pred_day - y_day).pow(2).sum().item()\n",
    "                total_windows += y_day.numel()\n",
    "                all_preds.append(pred_day.cpu().numpy())\n",
    "\n",
    "    rmse  = math.sqrt(total_sq_err / total_windows)\n",
    "    preds = np.concatenate(all_preds, axis=0)\n",
    "    print(f\"\\n{split_name} RMSE over {total_windows} windows = {rmse:.5f}\")\n",
    "    return rmse, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d557c7f6-8653-4b5c-afc2-e16ba8daf319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f989a57791a54850ac2a7a4d22f9ad07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/119 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train RMSE over 1708320 windows = 0.29699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2ebf2710be4df0bf2cb7b9ebd184da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/783 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation RMSE over 353129 windows = 0.28768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dc0632cec247dea1183743620e0ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/809 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE over 364691 windows = 0.29494\n",
      "\n",
      "Train preds: 1708320\n",
      "Val   preds: 353129\n",
      "Test  preds: 364691\n"
     ]
    }
   ],
   "source": [
    "train_rmse, train_preds = evaluate_model(\n",
    "    model_best, train_loader, device,\n",
    "    split_name=\"Train\"\n",
    ")\n",
    "val_rmse, val_preds     = evaluate_model(\n",
    "    model_best, val_loader,   device,\n",
    "    split_name=\"Validation\"\n",
    ")\n",
    "test_rmse, test_preds   = evaluate_model(\n",
    "    model_best, test_loader,  device,\n",
    "    split_name=\"Test\"\n",
    ")\n",
    "\n",
    "print(\"\\nTrain preds:\", len(train_preds))\n",
    "print(\"Val   preds:\", len(val_preds))\n",
    "print(\"Test  preds:\", len(test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448d0b9-9243-4c68-a579-797c681e4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_pred_and_split(\n",
    "#     df: pd.DataFrame,\n",
    "#     train_preds: np.ndarray,\n",
    "#     val_preds: np.ndarray,\n",
    "#     test_preds: np.ndarray,\n",
    "#     day_id_tr: np.ndarray,\n",
    "#     day_id_val: np.ndarray,\n",
    "#     day_id_te: np.ndarray\n",
    "# ) -> Tuple[pd.DataFrame, Set[pd.Timestamp], pd.DataFrame, List[pd.Timestamp]]:\n",
    "#     \"\"\"\n",
    "#     Attach model predictions to each bar at the end of sliding windows, then split.\n",
    "\n",
    "#     Predictions are only applied to the last bar of each look_back-length window,\n",
    "#     starting at sess_start_pred each trading day.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     df_train_val\n",
    "#         Subset of df for train+val days, with two new columns:\n",
    "#         - pred_signal: stamped predictions at window-end bars\n",
    "#         - pred_action: int placeholder for your downstream logic\n",
    "#     train_val_days\n",
    "#         Set of calendar dates used for training + validation.\n",
    "#     df_test\n",
    "#         Same as df_train_val but only for test days.\n",
    "#     te_days\n",
    "#         Sorted list of test-day dates.\n",
    "#     \"\"\"\n",
    "#     # 1) Prepare output DataFrame\n",
    "#     df_pred = df.copy()\n",
    "#     df_pred[\"pred_signal\"] = np.nan\n",
    "#     df_pred[\"pred_action\"] = 0\n",
    "\n",
    "#     # 2) Map day-id arrays to actual calendar dates\n",
    "#     all_days = sorted(df_pred.index.normalize().unique())\n",
    "#     tr_days  = [all_days[i] for i in np.unique(day_id_tr).astype(int)]\n",
    "#     val_days = [all_days[i] for i in np.unique(day_id_val).astype(int)]\n",
    "#     te_days  = [all_days[i] for i in np.unique(day_id_te).astype(int)]\n",
    "\n",
    "#     def stamp_split(days: List[pd.Timestamp], preds: np.ndarray, name: str):\n",
    "#         \"\"\"\n",
    "#         Stamp preds onto df_pred at each window’s end bar for the given days.\n",
    "#         \"\"\"\n",
    "#         # Collect all window-end timestamps\n",
    "#         end_timestamps = []\n",
    "#         for day in tqdm(days, desc=f\"Stamping {name}\", leave=False):\n",
    "#             # All bars on that day at or after session start\n",
    "#             mask = (\n",
    "#                 (df_pred.index.normalize() == day)\n",
    "#                 & (df_pred.index.time >= sess_start_pred)\n",
    "#             )\n",
    "#             bars = df_pred.index[mask]\n",
    "#             # Drop the first (look_back-1) bars—they can’t end a full window\n",
    "#             end_timestamps.append(bars[look_back - 1 :])\n",
    "\n",
    "#         # Flatten into one DatetimeIndex\n",
    "#         end_idx = pd.DatetimeIndex(np.concatenate(end_timestamps))\n",
    "\n",
    "#         # Sanity check: one pred per window-end\n",
    "#         if len(end_idx) != len(preds):\n",
    "#             raise ValueError(\n",
    "#                 f\"{name}: expected {len(end_idx)} slots, got {len(preds)} preds\"\n",
    "#             )\n",
    "\n",
    "#         # Write predictions\n",
    "#         df_pred.loc[end_idx, \"pred_signal\"] = preds\n",
    "\n",
    "#     # 3) Stamp each split\n",
    "#     stamp_split(tr_days, train_preds, name=\"Train\")\n",
    "#     stamp_split(val_days, val_preds,   name=\"Val\")\n",
    "#     stamp_split(te_days,  test_preds,  name=\"Test\")\n",
    "\n",
    "#     # 4) Split DataFrames back out\n",
    "#     train_val_days = set(tr_days + val_days)\n",
    "#     df_train_val   = df_pred[df_pred.index.normalize().isin(train_val_days)].copy()\n",
    "#     df_test        = df_pred[df_pred.index.normalize().isin(te_days)].copy()\n",
    "\n",
    "#     return df_train_val, train_val_days, df_test, te_days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f24212f-d138-4700-8e5b-efc010cb5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pred_and_split(\n",
    "    df: pd.DataFrame,\n",
    "    train_preds: np.ndarray,\n",
    "    val_preds: np.ndarray,\n",
    "    test_preds: np.ndarray,\n",
    "    day_id_tr: np.ndarray,\n",
    "    day_id_val: np.ndarray,\n",
    "    day_id_te: np.ndarray\n",
    ") -> Tuple[pd.DataFrame, Set[pd.Timestamp], pd.DataFrame, List[pd.Timestamp]]:\n",
    "\n",
    "    print(\"⚡️ Starting add_pred_and_split\")\n",
    "    df2 = df.copy()\n",
    "    df2[\"pred_signal\"] = np.nan\n",
    "    df2[\"pred_action\"] = 0\n",
    "\n",
    "    # 1) Map day-ids → calendar dates\n",
    "    days = df2.index.normalize()\n",
    "    uniq = sorted(days.unique())\n",
    "    tr_days = [uniq[i] for i in np.unique(day_id_tr).astype(int)]\n",
    "    vl_days = [uniq[i] for i in np.unique(day_id_val).astype(int)]\n",
    "    te_days = [uniq[i] for i in np.unique(day_id_te).astype(int)]\n",
    "    print(f\" • Found {len(uniq)} total days → \"\n",
    "          f\"{len(tr_days)} train, {len(vl_days)} val, {len(te_days)} test days\")\n",
    "\n",
    "    # 2) Compute per-day position\n",
    "    df2[\"day\"] = days\n",
    "    df2[\"cnt\"] = df2.groupby(\"day\").cumcount()\n",
    "\n",
    "    # 3) Build window-end mask\n",
    "    end_mask = (\n",
    "        (df2.index.time >= sess_start_pred)\n",
    "        & (df2[\"cnt\"] >= look_back - 1)\n",
    "    )\n",
    "    print(f\" • Window-end mask hits {end_mask.sum()} bars out of {len(df2)} total\")\n",
    "\n",
    "    # 4) Grab the exact end-bar indices for each split\n",
    "    idx_tr  = df2.index[end_mask & df2[\"day\"].isin(tr_days)]\n",
    "    idx_val = df2.index[end_mask & df2[\"day\"].isin(vl_days)]\n",
    "    idx_te  = df2.index[end_mask & df2[\"day\"].isin(te_days)]\n",
    "    print(f\" • Train windows: {len(idx_tr)},  Val windows: {len(idx_val)},  Test windows: {len(idx_te)}\")\n",
    "\n",
    "    # 5) Stamp preds (silently truncates if preds array is longer)\n",
    "    n_tr_use  = min(len(idx_tr),  len(train_preds))\n",
    "    n_val_use = min(len(idx_val), len(val_preds))\n",
    "    n_te_use  = min(len(idx_te),  len(test_preds))\n",
    "    print(f\" • Using {n_tr_use}/{len(train_preds)} train preds, \"\n",
    "          f\"{n_val_use}/{len(val_preds)} val preds, \"\n",
    "          f\"{n_te_use}/{len(test_preds)} test preds\")\n",
    "\n",
    "    df2.loc[idx_tr[:n_tr_use],  \"pred_signal\"] = train_preds[:n_tr_use]\n",
    "    df2.loc[idx_val[:n_val_use], \"pred_signal\"] = val_preds[:n_val_use]\n",
    "    df2.loc[idx_te[:n_te_use],  \"pred_signal\"] = test_preds[:n_te_use]\n",
    "\n",
    "    # 6) Split back into train+val vs test\n",
    "    tv_set   = set(tr_days + vl_days)\n",
    "    df_trval = df2[df2[\"day\"].isin(tv_set)].copy().drop(columns=[\"day\",\"cnt\"])\n",
    "    df_test  = df2[df2[\"day\"].isin(te_days)].copy().drop(columns=[\"day\",\"cnt\"])\n",
    "    print(f\" • Output shapes → df_train_val: {df_trval.shape}, df_test: {df_test.shape}\")\n",
    "    print(\"✅ Finished add_pred_and_split\\n\")\n",
    "\n",
    "    return df_trval, tv_set, df_test, te_days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f034e056-e275-4946-b78e-4af6154dda55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡️ Starting add_pred_and_split\n",
      " • Found 5400 total days → 3808 train, 783 val, 809 test days\n",
      " • Window-end mask hits 2412892 bars out of 3601230 total\n",
      " • Train windows: 1695072,  Val windows: 353129,  Test windows: 364691\n",
      " • Using 1695072/1708320 train preds, 353129/353129 val preds, 364691/364691 test preds\n",
      " • Output shapes → df_train_val: (3033528, 31), df_test: (567702, 31)\n",
      "✅ Finished add_pred_and_split\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>atr_14</th>\n",
       "      <th>ma_5</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>ma_diff</th>\n",
       "      <th>macd_12_26</th>\n",
       "      <th>...</th>\n",
       "      <th>stoch_d_3</th>\n",
       "      <th>in_trading</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>signal</th>\n",
       "      <th>pred_signal</th>\n",
       "      <th>pred_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02 13:09:00</th>\n",
       "      <td>-0.193147</td>\n",
       "      <td>-0.317313</td>\n",
       "      <td>-0.028125</td>\n",
       "      <td>-0.193762</td>\n",
       "      <td>-0.319224</td>\n",
       "      <td>-1.435516</td>\n",
       "      <td>-0.185561</td>\n",
       "      <td>-0.282361</td>\n",
       "      <td>0.123688</td>\n",
       "      <td>0.202706</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.561625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.763664</td>\n",
       "      <td>0.764807</td>\n",
       "      <td>0.016650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 13:10:00</th>\n",
       "      <td>-0.201085</td>\n",
       "      <td>-0.324262</td>\n",
       "      <td>-0.037500</td>\n",
       "      <td>-0.201725</td>\n",
       "      <td>-0.283773</td>\n",
       "      <td>-1.432540</td>\n",
       "      <td>-0.192087</td>\n",
       "      <td>-0.284115</td>\n",
       "      <td>0.112444</td>\n",
       "      <td>0.193448</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.561625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.763647</td>\n",
       "      <td>0.764790</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 13:11:00</th>\n",
       "      <td>-0.209022</td>\n",
       "      <td>-0.331210</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.209688</td>\n",
       "      <td>-0.248322</td>\n",
       "      <td>-1.429563</td>\n",
       "      <td>-0.200245</td>\n",
       "      <td>-0.286307</td>\n",
       "      <td>0.098388</td>\n",
       "      <td>0.183174</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.561625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.763631</td>\n",
       "      <td>0.764773</td>\n",
       "      <td>0.019462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 13:12:00</th>\n",
       "      <td>-0.216960</td>\n",
       "      <td>-0.338159</td>\n",
       "      <td>-0.056250</td>\n",
       "      <td>-0.217651</td>\n",
       "      <td>-0.212872</td>\n",
       "      <td>-1.426587</td>\n",
       "      <td>-0.208402</td>\n",
       "      <td>-0.288939</td>\n",
       "      <td>0.085270</td>\n",
       "      <td>0.172220</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.561625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.763614</td>\n",
       "      <td>0.764757</td>\n",
       "      <td>0.021042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 13:13:00</th>\n",
       "      <td>-0.224897</td>\n",
       "      <td>-0.345107</td>\n",
       "      <td>-0.065625</td>\n",
       "      <td>-0.225614</td>\n",
       "      <td>-0.177421</td>\n",
       "      <td>-1.423611</td>\n",
       "      <td>-0.216560</td>\n",
       "      <td>-0.292008</td>\n",
       "      <td>0.073088</td>\n",
       "      <td>0.160859</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.561625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.763597</td>\n",
       "      <td>0.764740</td>\n",
       "      <td>0.022750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-28 20:56:00</th>\n",
       "      <td>0.736230</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.784043</td>\n",
       "      <td>0.790310</td>\n",
       "      <td>2.263197</td>\n",
       "      <td>0.652514</td>\n",
       "      <td>0.741828</td>\n",
       "      <td>0.738415</td>\n",
       "      <td>0.274413</td>\n",
       "      <td>0.321477</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211724</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.979</td>\n",
       "      <td>175.238500</td>\n",
       "      <td>175.501500</td>\n",
       "      <td>0.566043</td>\n",
       "      <td>0.186670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-28 20:57:00</th>\n",
       "      <td>0.786714</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.841489</td>\n",
       "      <td>0.822932</td>\n",
       "      <td>3.136585</td>\n",
       "      <td>0.765180</td>\n",
       "      <td>0.784641</td>\n",
       "      <td>0.743795</td>\n",
       "      <td>0.743839</td>\n",
       "      <td>0.520116</td>\n",
       "      <td>...</td>\n",
       "      <td>1.289475</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.979</td>\n",
       "      <td>175.316000</td>\n",
       "      <td>175.579200</td>\n",
       "      <td>0.395597</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-28 20:58:00</th>\n",
       "      <td>0.824577</td>\n",
       "      <td>0.839583</td>\n",
       "      <td>0.881915</td>\n",
       "      <td>0.880694</td>\n",
       "      <td>3.910116</td>\n",
       "      <td>0.836338</td>\n",
       "      <td>0.825969</td>\n",
       "      <td>0.753591</td>\n",
       "      <td>1.139913</td>\n",
       "      <td>0.770887</td>\n",
       "      <td>...</td>\n",
       "      <td>1.438055</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.979</td>\n",
       "      <td>175.453300</td>\n",
       "      <td>175.716700</td>\n",
       "      <td>0.014998</td>\n",
       "      <td>0.237760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-28 20:59:00</th>\n",
       "      <td>0.881372</td>\n",
       "      <td>0.897917</td>\n",
       "      <td>0.911702</td>\n",
       "      <td>0.882796</td>\n",
       "      <td>9.226442</td>\n",
       "      <td>0.943074</td>\n",
       "      <td>0.855498</td>\n",
       "      <td>0.762535</td>\n",
       "      <td>1.398787</td>\n",
       "      <td>0.960884</td>\n",
       "      <td>...</td>\n",
       "      <td>1.284055</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.979</td>\n",
       "      <td>175.458300</td>\n",
       "      <td>175.721700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-28 21:00:00</th>\n",
       "      <td>0.887683</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.911702</td>\n",
       "      <td>0.865980</td>\n",
       "      <td>4.323623</td>\n",
       "      <td>0.788899</td>\n",
       "      <td>0.882260</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>1.603213</td>\n",
       "      <td>1.067536</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148916</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.979</td>\n",
       "      <td>175.418300</td>\n",
       "      <td>175.681700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3033528 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close    volume  \\\n",
       "2004-01-02 13:09:00 -0.193147 -0.317313 -0.028125 -0.193762 -0.319224   \n",
       "2004-01-02 13:10:00 -0.201085 -0.324262 -0.037500 -0.201725 -0.283773   \n",
       "2004-01-02 13:11:00 -0.209022 -0.331210 -0.046875 -0.209688 -0.248322   \n",
       "2004-01-02 13:12:00 -0.216960 -0.338159 -0.056250 -0.217651 -0.212872   \n",
       "2004-01-02 13:13:00 -0.224897 -0.345107 -0.065625 -0.225614 -0.177421   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2022-03-28 20:56:00  0.736230  0.747917  0.784043  0.790310  2.263197   \n",
       "2022-03-28 20:57:00  0.786714  0.797917  0.841489  0.822932  3.136585   \n",
       "2022-03-28 20:58:00  0.824577  0.839583  0.881915  0.880694  3.910116   \n",
       "2022-03-28 20:59:00  0.881372  0.897917  0.911702  0.882796  9.226442   \n",
       "2022-03-28 21:00:00  0.887683  0.843750  0.911702  0.865980  4.323623   \n",
       "\n",
       "                       atr_14      ma_5     ma_20   ma_diff  macd_12_26  ...  \\\n",
       "2004-01-02 13:09:00 -1.435516 -0.185561 -0.282361  0.123688    0.202706  ...   \n",
       "2004-01-02 13:10:00 -1.432540 -0.192087 -0.284115  0.112444    0.193448  ...   \n",
       "2004-01-02 13:11:00 -1.429563 -0.200245 -0.286307  0.098388    0.183174  ...   \n",
       "2004-01-02 13:12:00 -1.426587 -0.208402 -0.288939  0.085270    0.172220  ...   \n",
       "2004-01-02 13:13:00 -1.423611 -0.216560 -0.292008  0.073088    0.160859  ...   \n",
       "...                       ...       ...       ...       ...         ...  ...   \n",
       "2022-03-28 20:56:00  0.652514  0.741828  0.738415  0.274413    0.321477  ...   \n",
       "2022-03-28 20:57:00  0.765180  0.784641  0.743795  0.743839    0.520116  ...   \n",
       "2022-03-28 20:58:00  0.836338  0.825969  0.753591  1.139913    0.770887  ...   \n",
       "2022-03-28 20:59:00  0.943074  0.855498  0.762535  1.398787    0.960884  ...   \n",
       "2022-03-28 21:00:00  0.788899  0.882260  0.773077  1.603213    1.067536  ...   \n",
       "\n",
       "                     stoch_d_3  in_trading   hour  day_of_week  month  \\\n",
       "2004-01-02 13:09:00  -1.561625           0  0.493       -0.976  0.351   \n",
       "2004-01-02 13:10:00  -1.561625           0  0.493       -0.976  0.351   \n",
       "2004-01-02 13:11:00  -1.561625           0  0.493       -0.976  0.351   \n",
       "2004-01-02 13:12:00  -1.561625           0  0.493       -0.976  0.351   \n",
       "2004-01-02 13:13:00  -1.561625           0  0.493       -0.976  0.351   \n",
       "...                        ...         ...    ...          ...    ...   \n",
       "2022-03-28 20:56:00   1.211724           1 -0.939        0.973  0.979   \n",
       "2022-03-28 20:57:00   1.289475           1 -0.939        0.973  0.979   \n",
       "2022-03-28 20:58:00   1.438055           1 -0.939        0.973  0.979   \n",
       "2022-03-28 20:59:00   1.284055           1 -0.939        0.973  0.979   \n",
       "2022-03-28 21:00:00   1.148916           0 -0.960        0.973  0.979   \n",
       "\n",
       "                            bid         ask    signal  pred_signal  \\\n",
       "2004-01-02 13:09:00    0.763664    0.764807  0.016650          NaN   \n",
       "2004-01-02 13:10:00    0.763647    0.764790  0.018001          NaN   \n",
       "2004-01-02 13:11:00    0.763631    0.764773  0.019462          NaN   \n",
       "2004-01-02 13:12:00    0.763614    0.764757  0.021042          NaN   \n",
       "2004-01-02 13:13:00    0.763597    0.764740  0.022750          NaN   \n",
       "...                         ...         ...       ...          ...   \n",
       "2022-03-28 20:56:00  175.238500  175.501500  0.566043     0.186670   \n",
       "2022-03-28 20:57:00  175.316000  175.579200  0.395597     0.223000   \n",
       "2022-03-28 20:58:00  175.453300  175.716700  0.014998     0.237760   \n",
       "2022-03-28 20:59:00  175.458300  175.721700  0.000000     0.262166   \n",
       "2022-03-28 21:00:00  175.418300  175.681700  0.000000     0.240825   \n",
       "\n",
       "                     pred_action  \n",
       "2004-01-02 13:09:00            0  \n",
       "2004-01-02 13:10:00            0  \n",
       "2004-01-02 13:11:00            0  \n",
       "2004-01-02 13:12:00            0  \n",
       "2004-01-02 13:13:00            0  \n",
       "...                          ...  \n",
       "2022-03-28 20:56:00            0  \n",
       "2022-03-28 20:57:00            0  \n",
       "2022-03-28 20:58:00            0  \n",
       "2022-03-28 20:59:00            0  \n",
       "2022-03-28 21:00:00            0  \n",
       "\n",
       "[3033528 rows x 31 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_val, train_val_days, df_test, te_days = add_pred_and_split(\n",
    "    df=df_feat,\n",
    "    train_preds=train_preds,\n",
    "    val_preds=val_preds,\n",
    "    test_preds=test_preds,\n",
    "    day_id_tr=day_id_tr,\n",
    "    day_id_val=day_id_val,\n",
    "    day_id_te=day_id_te\n",
    ")\n",
    "\n",
    "df_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3637fbaf-8ede-4ab4-a2d3-2adedb3bcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    # —————— 1) Clean slate for this trial ——————\n",
    "    df_master[\"pred_action\"].values[:] = 0\n",
    "\n",
    "    # —————— 2) Hyper-parameter suggestions ——————\n",
    "    pred_threshold     = trial.suggest_float(\"pred_threshold\",     0.15, 0.95)\n",
    "    trailing_stop_pred = trial.suggest_float(\"trailing_stop_pred\", 0.01, 0.3)\n",
    "\n",
    "    # —————— 3) Generate actions per day ——————\n",
    "    print('-----------------------------------')\n",
    "    print(\"Generate actions per day...\")\n",
    "    for day, idxs in day_positions.items():\n",
    "        day_df = day_dfs[day]\n",
    "        day_act = trades.generate_trade_actions(\n",
    "            df=day_df,\n",
    "            col_signal=\"pred_signal\",\n",
    "            col_action=\"pred_action\",\n",
    "            buy_threshold=pred_threshold,\n",
    "            trailing_stop_pcs=trailing_stop_pred,\n",
    "            sess_start=params.sess_start\n",
    "        )[\"pred_action\"].fillna(0).astype(np.int8).values\n",
    "        df_master[\"pred_action\"].values[idxs] = day_act\n",
    "\n",
    "    # —————— 4) Simulate & score ——————\n",
    "    print(\"Simulate and compute average daily P&L...\")\n",
    "    sim_results = trades.simulate_trading(\n",
    "        results_by_day_sign=df_master,\n",
    "        col_action=\"pred_action\",\n",
    "        sess_start=params.sess_start,\n",
    "        sess_end=params.sess_end,\n",
    "        ticker=params.ticker\n",
    "    )\n",
    "\n",
    "    # — include all actual trading days in the average —\n",
    "    all_stats  = [stats for _, (_, _, stats) in sim_results.items()]\n",
    "\n",
    "    # free up every df_sim and trades_list before proceeding\n",
    "    for _, (df_sim, trades_list, _) in sim_results.items():\n",
    "        del df_sim, trades_list\n",
    "    del sim_results\n",
    "    gc.collect()\n",
    "    \n",
    "    num_trade_days  = len(sim_results)\n",
    "\n",
    "    daily_returns = [s[\"Strategy Return ($)\"] for s in all_stats]\n",
    "    total_pnl     = float(np.sum(daily_returns))\n",
    "    avg_daily_pnl = total_pnl / num_trade_days if num_trade_days else 0.0\n",
    "\n",
    "    total_trades  = sum(len(s[\"Trades Returns ($)\"]) for s in all_stats)\n",
    "    avg_per_trade = total_pnl / total_trades if total_trades else 0.0\n",
    "\n",
    "    print(f\"→ Total return across {num_trade_days} trading days: ${total_pnl:.2f}\")\n",
    "    print(f\"→ Avg daily return (all days)             : ${avg_daily_pnl:.4f}\")\n",
    "    print(f\"→ Total trades                            : {total_trades}\")\n",
    "    print(f\"→ Avg return per trade                    : ${avg_per_trade:.4f}\\n\")\n",
    "\n",
    "    return avg_daily_pnl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd926c51-3501-42ab-897f-6496b3eec1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 21:51:53,131] A new study created in RDB with name: no-name-c6707a3f-362b-4077-9440-7fd03fb5b18e\n",
      "[W 2025-08-21 21:51:53,162] Trial 0 failed with parameters: {} because of the following error: NameError(\"name 'df_master' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1338/2284338488.py\", line 3, in objective\n",
      "    df_master[\"pred_action\"].values[:] = 0\n",
      "    ^^^^^^^^^\n",
      "NameError: name 'df_master' is not defined\n",
      "[W 2025-08-21 21:51:53,168] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_master' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m storage \u001b[38;5;241m=\u001b[39m RDBStorage(\n\u001b[1;32m      4\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///optuna_study.db\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_same_thread\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}}\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      8\u001b[0m     storage        \u001b[38;5;241m=\u001b[39m storage,\n\u001b[1;32m      9\u001b[0m     load_if_exists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     direction      \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     pruner         \u001b[38;5;241m=\u001b[39m pruner,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightweight_plot_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mMemoryError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)   \u001b[38;5;66;03m# safe here; the final image remains displayed in the notebook output\u001b[39;00m\n\u001b[1;32m     24\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()       \u001b[38;5;66;03m# optional extra sweep\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:64\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 64\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    252\u001b[0m ):\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mobjective\u001b[39m(trial):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# —————— 1) Clean slate for this trial ——————\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mdf_master\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_action\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# —————— 2) Hyper-parameter suggestions ——————\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     pred_threshold     \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m,     \u001b[38;5;241m0.15\u001b[39m, \u001b[38;5;241m0.95\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_master' is not defined"
     ]
    }
   ],
   "source": [
    "# rest of your Optuna setup & study.optimize() \n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=6, n_warmup_steps=12)\n",
    "storage = RDBStorage(\n",
    "    url=\"sqlite:///optuna_study.db\",\n",
    "    engine_kwargs={\"connect_args\": {\"timeout\": 20, \"check_same_thread\": False}}\n",
    ")\n",
    "study = optuna.create_study(\n",
    "    storage        = storage,\n",
    "    load_if_exists = True,\n",
    "    direction      = \"maximize\",\n",
    "    pruner         = pruner,\n",
    ")\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials          = n_trials,\n",
    "    n_jobs            = n_jobs,\n",
    "    callbacks         = [plots.cleanup_callback, plots.lightweight_plot_callback],\n",
    "    gc_after_trial    = True,\n",
    "    show_progress_bar = False,\n",
    "    catch             = (MemoryError,),\n",
    ")\n",
    "\n",
    "plt.close('all')   # safe here; the final image remains displayed in the notebook output\n",
    "gc.collect()       # optional extra sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58134eda-1dfe-421a-a2e4-a4c78f4f4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final plots & JSON dump (unchanged)...\n",
    "ax = plot_optimization_history(study)\n",
    "ax.figure.set_size_inches(8, 4)\n",
    "plt.show()\n",
    "\n",
    "print(\"Best Parameters       :\", study.best_params)\n",
    "print(\"Best Average Daily P&L:\", study.best_value)\n",
    "\n",
    "importances = get_param_importances(study)\n",
    "print(\"\\nHyperparameter importances (higher ⇒ more impact):\")\n",
    "for name, score in sorted(importances.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {name:20s}: {score:.3f}\")\n",
    "\n",
    "first_day = df_train_val.index.normalize().min().strftime(\"%Y%m%d\")\n",
    "last_day  = df_train_val.index.normalize().max().strftime(\"%Y%m%d\")\n",
    "file_name = f\"{params.ticker}_{first_day}-{last_day}_optuna_predsig_pars_{study.best_value}_{params.model_path}.json\"\n",
    "file_path = os.path.join(params.optuna_folder, file_name)\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"best_params\": study.best_params,\n",
    "        \"best_value\" : study.best_value,\n",
    "        \"importances\": importances,\n",
    "        \"trials\": [\n",
    "            {\"number\": t.number, \"value\": t.value, \"params\": t.params, \"state\": t.state.name}\n",
    "            for t in study.trials\n",
    "        ],\n",
    "    }, f, indent=4)\n",
    "\n",
    "print(f\"\\nOptuna results (and importances) saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f919a-ddf0-4fcd-a8b9-3baa5cf8b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Descriptive Statistics\n",
    "# Statistics show whether your model systematically over/under-estimates (compare means) and how tightly it tracks (std & correlation).\n",
    "\n",
    "# assume df is your DataFrame\n",
    "stats = df_test[['signal','pred_signal']].describe().T\n",
    "\n",
    "# add range and error\n",
    "stats['range'] = stats['max'] - stats['min']\n",
    "corr = df_test['signal'].corr(df_test['pred_signal'])\n",
    "stats['pearson_r_with_other'] = [corr, corr]\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaafb9d-df9d-43f5-9b3d-1ca0b5c74d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Overlay\n",
    "# Histogram overlay reveals any bias or mismatched shape in the two distributions.\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df_test['signal'], color='C0', alpha=0.5, bins=50, label='true signal')\n",
    "sns.histplot(df_test['pred_signal'],   color='C1', alpha=0.5, bins=50, label='pred signal')\n",
    "plt.legend()\n",
    "plt.xlabel('Signal Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of true signal vs. pred signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62b6a4-d566-4425-afee-25289d9397d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot: Relationship\n",
    "# Scatter against the 45° line instantly shows under/over‐prediction regions and non‐linear errors.\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df_test['signal'], df_test['pred_signal'],\n",
    "            s=5, alpha=0.3, color='C2')\n",
    "plt.plot([0,1],[0,1], 'k--', linewidth=1)  # 45° reference line\n",
    "plt.xlabel('signal')\n",
    "plt.ylabel('pred_signal')\n",
    "plt.title('pred_signal vs. signal')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbeb73-c57c-415b-8172-d1fba5f117cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Series Comparison (Sample)\n",
    "# Time‐series plots let you see if the model lags or leads the signal on a given day.\n",
    "\n",
    "# pick a single day or time span\n",
    "day = df_test.index.normalize().unique()[-1]\n",
    "mask = df_test.index.normalize() == day\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(df_test.index[mask], df_test.loc[mask,'signal'], label='signal')\n",
    "plt.plot(df_test.index[mask], df_test.loc[mask,'pred_signal'],   label='pred_signal')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(f'Signals on {day.date()}')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Signal')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086846a-45f7-48c5-8a71-c9ed215a3230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis \n",
    "# Error plots quantify where and when the model struggles most, guiding you to fix lag, amplitude scaling, or threshold issues.\n",
    "\n",
    "# create error column\n",
    "df_test['error'] = df_test['pred_signal'] - df_test['signal']\n",
    "\n",
    "# Distribution of prediction error\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(df_test['error'], bins=50, color='C3', kde=True)\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.title('Error Distribution: pred signal − true signal')\n",
    "plt.show()\n",
    "\n",
    "# Time evolution of error on that same sample day\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(df_test.index[mask], df_test.loc[mask,'error'], color='C4')\n",
    "plt.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "plt.title(f'Prediction Error over time on {day.date()}')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Error')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b957c-f93a-41b6-bce1-08806c2b0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('generating sim_results as a dict: { date → (df_sim, trades_list, perf_stats) } ...')\n",
    "\n",
    "# Run the simulator on your DataFrame of predictions/actions\n",
    "sim_results = trades.simulate_trading(\n",
    "    results_by_day_sign = df_train_val,              # DF with pred_action\n",
    "    col_action          = \"pred_action\",              # name of the discrete action column\n",
    "    sess_start          = params.sess_start,   \n",
    "    sess_end            = params.sess_end,         \n",
    "    ticker              = params.ticker\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08efbd70-ae18-4653-a023-aa7f2cc81b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(params)\n",
    "# month to inspect (YYYY-MM)\n",
    "date_to_test = params.date_to_test\n",
    "\n",
    "year, month = map(int, date_to_test.split(\"-\"))\n",
    "\n",
    "# 1) Build lists of days in that month + accumulate ALL days\n",
    "days_in_month = []\n",
    "performance_month = []\n",
    "performance_all   = []\n",
    "\n",
    "for day, (df_sim, trades_list, perf_stats) in sim_results.items():\n",
    "    # always collect for the global summary\n",
    "    performance_all.append(perf_stats)\n",
    "\n",
    "    # pick out this month for plotting\n",
    "    if day.year == year and day.month == month:\n",
    "        days_in_month.append(day)\n",
    "        performance_month.append(perf_stats)\n",
    "\n",
    "# 2) Plot & print per-day stats for the month\n",
    "if not days_in_month:\n",
    "    print(f\"No simulation data for {date_to_test}\")\n",
    "else:\n",
    "    print(f\"\\nPlotting days in {date_to_test}:\")\n",
    "    for day in days_in_month:\n",
    "        df_sim, trades_list, perf_stats = sim_results[day]\n",
    "        plots.plot_trades(\n",
    "            df                = df_sim,\n",
    "            col_signal1       = \"signal\",\n",
    "            col_signal2       = \"pred_signal\",\n",
    "            col_action        = \"pred_action\",\n",
    "            trades            = trades_list,\n",
    "            buy_threshold     = params.pred_threshold_tick,\n",
    "            performance_stats = perf_stats\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n=== Performance for {day} ===\")\n",
    "        for k, v in perf_stats.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "# 3) Monthly summary\n",
    "df_month = df_test[df_test.index.to_period(\"M\") == date_to_test]\n",
    "plots.aggregate_performance(performance_month, df_month)\n",
    "\n",
    "# 4) Overall summary across ALL days, with date range\n",
    "plots.aggregate_performance(performance_all, df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a6f11-54e4-4778-ac70-903606897ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cee26d-0227-49cc-8d3d-6da977a39753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
