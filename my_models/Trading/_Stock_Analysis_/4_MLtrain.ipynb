{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed6c184-8438-497e-8ae7-82cc35ac4819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'libs.models_core' from '/workspace/my_models/Trading/_Stock_Analysis_/libs/models_core.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 1) Wipe out your namespace\n",
    "%reset -f\n",
    "\n",
    "# 2) Clear Jupyter’s stored outputs (and inputs if you like)\n",
    "try:\n",
    "    Out.clear()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    In.clear()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# 3) Force Python GC\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# 4) Free any GPU buffers\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "import importlib\n",
    "from libs import params, trades, feats, plots, models_core\n",
    "importlib.reload(params)\n",
    "importlib.reload(trades)\n",
    "importlib.reload(feats)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(models_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c868158-e6bb-4d56-bbdd-8e8103f0b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy  as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "from typing import Sequence, List, Tuple, Optional, Union\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Funct\n",
    "from torch_lr_finder import LRFinder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts #, ReduceLROnPlateau\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b98406a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_feat_sel \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeat_all_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[params\u001b[38;5;241m.\u001b[39mfeatures_cols_tick \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_raw\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [params\u001b[38;5;241m.\u001b[39mlabel_col]]\n\u001b[1;32m      3\u001b[0m df_feat_sel\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_feat_sel = pd.read_csv(params.feat_all_csv, index_col=0, parse_dates=True)[params.features_cols_tick + ['close_raw'] + [params.label_col]]\n",
    "    \n",
    "df_feat_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8d933-8402-45de-a838-4335b2a37d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, end_times_tr, end_times_val, end_times_te = models_core.model_core_pipeline(\n",
    "    df             = df_feat_sel,\n",
    "    look_back      = params.look_back_tick,\n",
    "    sess_start     = params.sess_start_pred_tick,\n",
    "    train_prop     = params.train_prop,\n",
    "    val_prop       = params.val_prop,\n",
    "    train_batch    = params.hparams[\"TRAIN_BATCH\"],\n",
    "    num_workers    = params.hparams[\"NUM_WORKERS\"],\n",
    "    prefetch_factor= params.hparams[\"TRAIN_PREFETCH_FACTOR\"],\n",
    "    signal_thresh  = params.best_optuna_params[\"buy_threshold\"],\n",
    "    return_thresh  = params.return_threshold_tick\n",
    ")\n",
    "\n",
    "for name, ld, tm in zip(\n",
    "    [\"train\",\"val\",\"test\"],\n",
    "    [train_loader, val_loader, test_loader],\n",
    "    [end_times_tr, end_times_val, end_times_te]\n",
    "):\n",
    "    models_core.summarize_split(name, ld, tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec031f-6c8f-455f-9c72-ae411e03ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(params.model_selected) #############\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Instantiate the ModelClass & move to device\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model = params.model_selected.ModelClass(\n",
    "    n_feats          = len(params.features_cols_tick),                          \n",
    "    short_units      = params.hparams['SHORT_UNITS'],    \n",
    "    long_units       = params.hparams['LONG_UNITS'],     \n",
    "    dropout_short    = params.hparams['DROPOUT_SHORT'],  \n",
    "    dropout_long     = params.hparams['DROPOUT_LONG'],   \n",
    "    # att_heads        = params.hparams['ATT_HEADS'],\n",
    "    # att_drop         = params.hparams['ATT_DROPOUT'],\n",
    "    conv_k           = params.hparams['CONV_K'],\n",
    "    conv_dilation    = params.hparams['CONV_DILATION'],\n",
    "    # smooth_k         = params.hparams['SMOOTH_K'],\n",
    "    # smooth_dilation  = params.hparams['SMOOTH_DILATION']\n",
    "    pred_hidden      = params.hparams['PRED_HIDDEN'],\n",
    ")\n",
    "model.to(params.device)  \n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7ec8c-5882-486b-bdfd-371b8db260f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate([batch[1].cpu().numpy().ravel() for batch in train_loader])\n",
    "y_val = np.concatenate([batch[1].cpu().numpy().ravel() for batch in val_loader])\n",
    "\n",
    "# Visualize the true‐signal distributions on train vs. validation\n",
    "plt.hist(y_train, bins=100, alpha=0.5, label=\"train true\")\n",
    "plt.hist(y_val,   bins=100, alpha=0.5, label=\"val true\")\n",
    "plt.xlabel(\"Signal value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"True Signal Distribution: Train vs. Validation\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f537a-e322-480d-9f3b-f9bd7fd999c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# import torch\n",
    "\n",
    "# def full_sanity_check(train_loader, val_loader, model):\n",
    "#     \"\"\"\n",
    "#     Run end-to-end sanity checks on:\n",
    "#       1) _compute_metrics vs. sklearn\n",
    "#       2) compute_baselines vs. manual baselines\n",
    "#       3) eval_on_loader metrics vs. manual flatten+_compute_metrics\n",
    "#     Raises AssertionError on any mismatch; prints summary if all pass.\n",
    "#     \"\"\"\n",
    "#     # 1) Test _compute_metrics against sklearn on random data\n",
    "#     rng = np.random.RandomState(42)\n",
    "#     targs = rng.rand(50)\n",
    "#     preds = rng.rand(50)\n",
    "#     m = params.model_selected._compute_metrics(preds, targs)\n",
    "#     mse = mean_squared_error(targs, preds)\n",
    "#     assert np.isclose(m[\"rmse\"], np.sqrt(mse), atol=1e-8), \"RMSE mismatch\"\n",
    "#     assert np.isclose(m[\"mae\"], mean_absolute_error(targs, preds), atol=1e-8), \"MAE mismatch\"\n",
    "#     assert np.isclose(m[\"r2\"], r2_score(targs, preds), atol=1e-8), \"R2 mismatch\"\n",
    "\n",
    "#     # 2) Test compute_baselines vs. manual\n",
    "#     def manual_baselines(loader):\n",
    "#         nexts, pers_preds, pers_targs = [], [], []\n",
    "#         for xb, y_r, *_ignore, wd, ts_list, lengths in loader:\n",
    "#             for i, L in enumerate(lengths):\n",
    "#                 if L < 1: continue\n",
    "#                 y = y_r[i, :L].view(-1).cpu().numpy()\n",
    "#                 nexts.append(y[-1])\n",
    "#                 if L > 1:\n",
    "#                     pers_preds.append(y[-2])\n",
    "#                     pers_targs.append(y[-1])\n",
    "#         nexts = np.array(nexts, dtype=float)\n",
    "#         mean_rmse_manual = float(np.sqrt(((nexts - nexts.mean())**2).mean()))\n",
    "#         if pers_preds:\n",
    "#             pers_preds = np.array(pers_preds)\n",
    "#             pers_targs = np.array(pers_targs)\n",
    "#             pers_rmse_manual = float(np.sqrt(((pers_preds - pers_targs)**2).mean()))\n",
    "#         else:\n",
    "#             pers_rmse_manual = float(\"nan\")\n",
    "#         return mean_rmse_manual, pers_rmse_manual\n",
    "\n",
    "#     # run on train_loader and val_loader\n",
    "#     for name, loader in [(\"TRAIN\", train_loader), (\"VAL\", val_loader)]:\n",
    "#         base_mean_fn, base_pers_fn = params.model_selected.compute_baselines(loader)\n",
    "#         mean_m, pers_m = manual_baselines(loader)\n",
    "#         assert np.isclose(base_mean_fn, mean_m, atol=1e-8), f\"{name} mean baseline mismatch\"\n",
    "#         assert np.isclose(base_pers_fn, pers_m, atol=1e-8), f\"{name} persistence baseline mismatch\"\n",
    "\n",
    "#     # 3) Test eval_on_loader vs. manual flatten + _compute_metrics\n",
    "#     def manual_eval(loader):\n",
    "#         all_preds, all_targs = [], []\n",
    "#         device = next(model.parameters()).device\n",
    "#         model.to(device).eval()\n",
    "#         model.h_short = model.h_long = None\n",
    "#         prev_day = None\n",
    "#         with torch.no_grad():\n",
    "#             for xb, y_reg, *_ignore, wd, ts_list, lengths in loader:\n",
    "#                 xb, y_reg, wd = xb.to(device), y_reg.to(device), wd.to(device)\n",
    "#                 B = xb.size(0)\n",
    "#                 for i in range(B):\n",
    "#                     prev_day = params.model_selected._reset_states(model, wd[i], prev_day)\n",
    "#                     W = int(lengths[i])\n",
    "#                     if W == 0: continue\n",
    "#                     seqs = xb[i, :W]\n",
    "#                     raw = model(seqs)\n",
    "#                     raw_reg = raw[0] if isinstance(raw, (tuple,list)) else raw\n",
    "#                     if raw_reg.dim()==3 and raw_reg.size(-1)!=1:\n",
    "#                         raw_reg = model.pred(raw_reg)\n",
    "#                     elif raw_reg.dim()==2:\n",
    "#                         raw_reg = model.pred(raw_reg.unsqueeze(0)).squeeze(0)\n",
    "#                     preds_win = raw_reg.squeeze(-1)[:, -1]\n",
    "#                     targs_win = y_reg[i, :W].view(-1)\n",
    "#                     all_preds.extend(preds_win.cpu().tolist())\n",
    "#                     all_targs.extend(targs_win.cpu().tolist())\n",
    "#         preds = np.array(all_preds, dtype=float)\n",
    "#         targs = np.array(all_targs, dtype=float)\n",
    "#         return params.model_selected._compute_metrics(preds, targs)\n",
    "\n",
    "#     # run manual_eval on val_loader and compare to eval_on_loader\n",
    "#     manual_metrics = manual_eval(val_loader)\n",
    "#     fn_metrics, _      = params.model_selected.eval_on_loader(val_loader, model)\n",
    "#     for key in (\"rmse\", \"mae\", \"r2\"):\n",
    "#         assert np.isclose(fn_metrics[key], manual_metrics[key], atol=1e-8), \\\n",
    "#             f\"eval_on_loader {key} mismatch: {fn_metrics[key]} vs {manual_metrics[key]}\"\n",
    "\n",
    "#     print(\"✅ FULL SANITY CHECK PASSED: metrics, baselines, eval align perfectly.\")\n",
    "\n",
    "# full_sanity_check(train_loader, val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5fd61e-6118-4247-b7c3-f360ee15a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# def metrics_proof(loader, model):\n",
    "#     # 1) Re-compute mean‐baseline and persistence‐baseline by hand\n",
    "#     manual_nexts, manual_deltas = [], []\n",
    "#     for xb, y_r, *_ignored, wd, ts, lengths in loader:\n",
    "#         for i, L in enumerate(lengths):\n",
    "#             if L < 1: \n",
    "#                 continue\n",
    "#             y = y_r[i, :L].view(-1).cpu().numpy()\n",
    "#             manual_nexts.append(y[-1])\n",
    "#             if L > 1:\n",
    "#                 manual_deltas.append(y[-1] - y[-2])\n",
    "\n",
    "#     nxt = np.array(manual_nexts, dtype=float)\n",
    "#     deltas = np.array(manual_deltas, dtype=float)\n",
    "#     mean_rmse_manual = np.sqrt(((nxt - nxt.mean())**2).mean())\n",
    "#     pers_rmse_manual = np.sqrt((deltas**2).mean())\n",
    "\n",
    "#     # 2) Call your compute_baselines()\n",
    "#     mean_rmse_fn, pers_rmse_fn = params.model_selected.compute_baselines(loader)\n",
    "\n",
    "#     # 3) Flatten preds/targs via eval_on_loader (no clamp)\n",
    "#     (metrics, preds) = params.model_selected.eval_on_loader(loader, model)\n",
    "#     # we need the targets too—so do a tiny mod:\n",
    "#     #   return _compute_metrics(preds,targs), preds, targs\n",
    "#     # in eval_on_loader, then unpack here:\n",
    "#     #    metrics, preds, targs = eval_on_loader(...)\n",
    "#     # For now we’ll reconstruct targs manually:\n",
    "#     all_targs = []\n",
    "#     for xb, y_r, *_ignored, wd, ts, lengths in loader:\n",
    "#         for i, L in enumerate(lengths):\n",
    "#             if L < 1:\n",
    "#                 continue\n",
    "#             all_targs.extend(y_r[i, :L].view(-1).cpu().tolist())\n",
    "#     targs = np.array(all_targs[: len(preds) ], dtype=float)\n",
    "\n",
    "#     manual_rmse_flat = np.sqrt(((preds - targs)**2).mean())\n",
    "\n",
    "#     print(f\"Mean baseline:  fn={mean_rmse_fn:.5f}  manual={mean_rmse_manual:.5f}\")\n",
    "#     print(f\"Pers baseline:  fn={pers_rmse_fn:.5f}  manual={pers_rmse_manual:.5f}\")\n",
    "#     print(f\"Eval RMSE:      fn={metrics['rmse']:.5f}  flat={manual_rmse_flat:.5f}\")\n",
    "#     print(\"Sample deltas:\", deltas[:10])\n",
    "#     print(\"Sample preds:\", preds[:10])\n",
    "#     print(\"Sample targs:\", targs[:10])\n",
    "\n",
    "#     assert np.isclose(mean_rmse_fn, mean_rmse_manual, atol=1e-8)\n",
    "#     assert np.isclose(pers_rmse_fn, pers_rmse_manual, atol=1e-8)\n",
    "#     assert np.isclose(metrics['rmse'], manual_rmse_flat, atol=1e-8)\n",
    "#     print(\"✅ All RMSEs and baselines match the textbook formula exactly.\")\n",
    "\n",
    "# # Run it on train then val\n",
    "# metrics_proof(train_loader, model)\n",
    "# metrics_proof(val_loader,   model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf94780-a876-4bf4-ad27-6abc2da1fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(params) #############\n",
    "importlib.reload(params.model_selected) #############\n",
    "importlib.reload(models_core) #############\n",
    "\n",
    "# How many unique trading days does each epoch see?\n",
    "n_days = len(train_loader.dataset)\n",
    "print(f\"Training sees {n_days} unique trading days per epoch.\\n\")\n",
    "\n",
    "print('Using HyperParameters:\\n \"look_back\":', params.look_back_tick, params.hparams)\n",
    "\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=params.hparams['INITIAL_LR'],\n",
    "    weight_decay=params.hparams['WEIGHT_DECAY']\n",
    ")\n",
    "\n",
    "cosine_sched = CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0   = params.hparams['T_0'],\n",
    "    T_mult= params.hparams['T_MULT'],\n",
    "    eta_min=params.hparams['ETA_MIN']\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run the custom stateful training loop\n",
    "# -----------------------------------------------------------------------------\n",
    "best_val_rmse  = params.model_selected.model_training_loop(\n",
    "    model               = model,\n",
    "    optimizer           = optimizer,\n",
    "    cosine_sched        = cosine_sched,\n",
    "    scaler              = GradScaler(),\n",
    "    train_loader        = train_loader,\n",
    "    val_loader          = val_loader,\n",
    "    max_epochs          = params.hparams['MAX_EPOCHS'],\n",
    "    early_stop_patience = params.hparams['EARLY_STOP_PATIENCE'],\n",
    "    clipnorm            = params.hparams['CLIPNORM'],\n",
    "    # cls_loss_weight     = params.hparams['CLS_LOSS_WEIGHT'],\n",
    "    # smooth_alpha        = params.hparams['SMOOTH_ALPHA'],\n",
    "    # smooth_beta         = params.hparams['SMOOTH_BETA'],\n",
    "    # smooth_delta        = params.hparams['SMOOTH_DELTA'],\n",
    "    # diff1_weight        = params.hparams['DIFF1_WEIGHT'],\n",
    "    # diff2_weight        = params.hparams['DIFF2_WEIGHT'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad57d0a0-6f4f-4b23-8d83-71d1a1f99c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
