{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f06a4f-691a-4a84-a305-e7212eb879bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c868158-e6bb-4d56-bbdd-8e8103f0b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Wipe out all Python variables\n",
    "%reset -f\n",
    "# 2) Force Python’s garbage collector to run\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import importlib\n",
    "from libs import trades, plots, params, models\n",
    "importlib.reload(trades)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(params)\n",
    "importlib.reload(models)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy  as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "from typing import Sequence, List, Tuple, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Funct\n",
    "from torch_lr_finder import LRFinder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b98406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.feat_sel == 'auto': # automatic feature selection, based on feature importance notebook\n",
    "    \n",
    "    df_feat_sel = pd.read_csv(params.feat_sel_auto_csv, index_col=0, parse_dates=True)\n",
    "    \n",
    "elif params.feat_sel == 'man': # alternative manual feature selection, based on the features selected in the params.py\n",
    "    \n",
    "    df_feat_sel = pd.read_csv(params.feat_all_csv, index_col=0, parse_dates=True)[params.features_cols_tick + ['bid','ask'] + [params.label_col]]\n",
    "    \n",
    "df_feat_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM input tensors (disk-backed memmaps)\n",
    "X, y_sig, y_ret, raw_close, raw_bid, raw_ask, end_times = models.build_lstm_tensors(\n",
    "    df            = df_feat_sel,\n",
    "    sess_start    = params.sess_start_pred_tick \n",
    ")\n",
    "\n",
    "# quick shapes\n",
    "print(\"Shapes:\")\n",
    "print(\"  X         =\", X.shape,    \"(samples, look_back, features)\")\n",
    "print(\"  y_sig     =\", y_sig.shape, \"(samples,)\")\n",
    "print(\"  y_ret     =\", y_ret.shape, \"(samples,)\")\n",
    "print(\"  raw_close =\", raw_close.shape)\n",
    "print(\"  raw_bid   =\", raw_bid.shape)\n",
    "print(\"  raw_ask   =\", raw_ask.shape)\n",
    "print(\"  end_times =\", end_times.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/val/test by calendar day\n",
    "(\n",
    "(X_tr,  y_sig_tr,  y_ret_tr),\n",
    "(X_val, y_sig_val, y_ret_val),\n",
    "(X_te,  y_sig_te,  y_ret_te,  raw_close_te, raw_bid_te, raw_ask_te),\n",
    "samples_per_day,\n",
    "day_id_tr, day_id_val, day_id_te\n",
    ") = models.chronological_split(\n",
    "    X, y_sig, y_ret,\n",
    "    raw_close, raw_bid, raw_ask,\n",
    "    end_times   = end_times,\n",
    "    train_prop  = params.train_prop,\n",
    "    val_prop    = params.val_prop,\n",
    "    train_batch = params.hparams['TRAIN_BATCH']\n",
    ")\n",
    "\n",
    "# Print shapes of all tensors\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_tr  =\", X_tr.shape)\n",
    "print(\"  y_sig_tr, y_ret_tr =\", y_sig_tr.shape, y_ret_tr.shape)\n",
    "print(\"  X_val =\", X_val.shape)\n",
    "print(\"  y_sig_val, y_ret_val =\", y_sig_val.shape, y_ret_val.shape)\n",
    "print(\"  X_te  =\", X_te.shape)\n",
    "print(\"  y_sig_te, y_ret_te =\", y_sig_te.shape, y_ret_te.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9b6c4-3d79-45c0-b2c0-c4f46f1ad866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carve `end_times` into the same three splits:\n",
    "n_tr  = day_id_tr .shape[0] \n",
    "n_val = day_id_val.shape[0]\n",
    "i_tr  = n_tr\n",
    "i_val = n_tr + n_val\n",
    "\n",
    "end_times_tr  = end_times[:i_tr]\n",
    "end_times_val = end_times[i_tr:i_val]\n",
    "end_times_te  = end_times[i_val:]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "#  Build DataLoaders over calendar‐days\n",
    "# -----------------------------------------------------------------------------\n",
    "train_loader, val_loader, test_loader = models.split_to_day_datasets(\n",
    "    # train split:   \n",
    "    X_tr,            y_sig_tr,     y_ret_tr,   end_times_tr,\n",
    "    # val split:\n",
    "    X_val,           y_sig_val,    y_ret_val,  end_times_val,\n",
    "    # test split + raw‐prices\n",
    "    X_te,            y_sig_te,     y_ret_te,   end_times_te,\n",
    "    raw_close_te, raw_bid_te, raw_ask_te,\n",
    "    \n",
    "    sess_start_time       = params.sess_start_pred_tick,\n",
    "    signal_thresh         = params.best_optuna_params[\"buy_threshold\"],\n",
    "    return_thresh         = 0.01,  # flat‐zone threshold for returns (to tune)\n",
    "    train_batch           = params.hparams[\"TRAIN_BATCH\"],\n",
    "    train_workers         = params.hparams[\"NUM_WORKERS\"],\n",
    "    train_prefetch_factor = params.hparams[\"TRAIN_PREFETCH_FACTOR\"]\n",
    ")\n",
    "\n",
    "print(f\"Days  → train={len(train_loader.dataset)}, val={len(val_loader.dataset)}, test={len(test_loader.dataset)}\")\n",
    "print(f\"Batches → train={len(train_loader)},   val={len(val_loader)},   test={len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec031f-6c8f-455f-9c72-ae411e03ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Instantiate the stateful DualMemoryLSTM & move to device\n",
    "# -----------------------------------------------------------------------------\n",
    "model = models.DualMemoryLSTM(\n",
    "    n_feats        = X.shape[-1],                          \n",
    "    short_units    = params.hparams['SHORT_UNITS'],    \n",
    "    long_units     = params.hparams['LONG_UNITS'],     \n",
    "    dropout_short  = params.hparams['DROPOUT_SHORT'],  \n",
    "    dropout_long   = params.hparams['DROPOUT_LONG'],   \n",
    "    att_heads      = params.hparams['ATT_HEADS'],\n",
    "    att_drop       = params.hparams['ATT_DROPOUT']\n",
    ")\n",
    "model.to(params.device)  \n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512a0dd-d2c8-418e-bfca-4580fb4be995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------------------------\n",
    "# # Compute plateau_sched timing parameters\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # Total training samples = total windows in X_tr (one window per row)\n",
    "# n_train_samples = X_tr.shape[0]\n",
    "\n",
    "# # How many optimizer steps (day‐bundles) constitute one epoch?\n",
    "# steps_per_epoch = len(train_loader)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build optimizer, LR scheduler, AMP scaler, and gradient‐clip norm\n",
    "# -----------------------------------------------------------------------------\n",
    "optimizer, plateau_sched, cosine_sched, scaler, clipnorm = models.make_optimizer_and_scheduler(\n",
    "    model,\n",
    "    initial_lr        = params.hparams['INITIAL_LR'],       \n",
    "    weight_decay      = params.hparams['WEIGHT_DECAY'],     \n",
    "    clipnorm          = params.hparams['CLIPNORM']   \n",
    ")\n",
    "\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5fc27-f31d-4adc-a247-5468674f83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Helper: extract the true “signal” values from any loader into a flat array\n",
    "# -----------------------------------------------------------------------------\n",
    "def extract_y(loader):\n",
    "    return np.concatenate([batch[1].cpu().numpy().ravel() for batch in loader])\n",
    "\n",
    "# Pull out train & validation targets\n",
    "y_train = extract_y(train_loader)\n",
    "y_val   = extract_y(val_loader)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Zero‐forecast baseline RMSE (predict 0 always)\n",
    "#    RMSE_zero = √(mean(y²))\n",
    "# -----------------------------------------------------------------------------\n",
    "rmse_zero_train = np.sqrt(np.mean(y_train**2))\n",
    "rmse_zero_val   = np.sqrt(np.mean(y_val**2))\n",
    "print(f\"Zero‐forecast RMSE (predict 0): train = {rmse_zero_train:.6f},  val = {rmse_zero_val:.6f}\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Compute mean, variance & std for train/validation targets\n",
    "#    and derive the mean‐predictor baseline (R² = 0)\n",
    "# -----------------------------------------------------------------------------\n",
    "for split, y in [(\"Train\", y_train), (\"Validation\", y_val)]:\n",
    "    mean_y    = y.mean()\n",
    "    std_y     = y.std(ddof=0)     # population std = √variance\n",
    "    var_y     = std_y**2\n",
    "    rmse_mean = std_y            # RMSE_baseline = std(target)\n",
    "\n",
    "    print(f\"{split} target stats:\")\n",
    "    print(f\"  mean = {mean_y:.4f},  var = {var_y:.4f},  std = {std_y:.4f}\")\n",
    "    print(f\"{split} mean‐predictor baseline:\")\n",
    "    print(f\"  RMSE_baseline = {rmse_mean:.6f}\")\n",
    "    print(\"  R²_baseline   = 0.00\\n\")\n",
    "\n",
    "    if split == \"Validation\":\n",
    "        rmse_mean_val = rmse_mean # used afterwards for the final reporting\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7ec8c-5882-486b-bdfd-371b8db260f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the true‐signal distributions on train vs. validation\n",
    "plt.hist(y_train, bins=100, alpha=0.5, label=\"train true\")\n",
    "plt.hist(y_val,   bins=100, alpha=0.5, label=\"val true\")\n",
    "plt.xlabel(\"Signal value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"True Signal Distribution: Train vs. Validation\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf94780-a876-4bf4-ad27-6abc2da1fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique trading days does each epoch see?\n",
    "n_days = len(train_loader.dataset)\n",
    "print(f\"Training sees {n_days} unique trading days per epoch.\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run the custom stateful training loop\n",
    "# -----------------------------------------------------------------------------\n",
    "best_val_rmse  = models.custom_stateful_training_loop(\n",
    "    model               = model,\n",
    "    optimizer           = optimizer,\n",
    "    cosine_sched        = cosine_sched,\n",
    "    plateau_sched       = plateau_sched,\n",
    "    scaler              = scaler,\n",
    "    train_loader        = train_loader,\n",
    "    val_loader          = val_loader,\n",
    "    max_epochs          = params.hparams['MAX_EPOCHS'],\n",
    "    early_stop_patience = params.hparams['EARLY_STOP_PATIENCE'],\n",
    "    clipnorm            = clipnorm,\n",
    "    device              = params.device\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Final reporting: best RMSE and relative improvement\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\nChampion validation RMSE = {best_val_rmse:.6f}\")\n",
    "\n",
    "improvement_zero = 100.0 * (1.0 - best_val_rmse / rmse_zero_val)\n",
    "print(f\"Improvement over zero‐baseline = {improvement_zero:5.1f}%\")\n",
    "\n",
    "improvement_mean = 100.0 * (1.0 - best_val_rmse / rmse_mean_val)\n",
    "print(f\"Improvement over zero‐baseline = {improvement_mean:5.1f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b25c89-05c3-4a16-b013-97143f173e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
