{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed6c184-8438-497e-8ae7-82cc35ac4819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'libs.models_core' from '/workspace/my_models/Trading/_Stock_Analysis_/libs/models_core.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 1) Wipe out your namespace\n",
    "%reset -f\n",
    "\n",
    "# 2) Clear Jupyter’s stored outputs (and inputs if you like)\n",
    "try:\n",
    "    Out.clear()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    In.clear()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# 3) Force Python GC\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# 4) Free any GPU buffers\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "import importlib\n",
    "from libs import params, trades, feats, plots, models_core\n",
    "importlib.reload(params)\n",
    "importlib.reload(trades)\n",
    "importlib.reload(feats)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(models_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c868158-e6bb-4d56-bbdd-8e8103f0b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy  as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "from typing import Sequence, List, Tuple, Optional, Union\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss, Dropout\n",
    "import torch.nn.functional as Funct\n",
    "from torch_lr_finder import LRFinder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau, OneCycleLR\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b98406a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sma_pct_14</th>\n",
       "      <th>atr_pct_14</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>bb_w_20</th>\n",
       "      <th>plus_di_14</th>\n",
       "      <th>range_pct</th>\n",
       "      <th>eng_ma</th>\n",
       "      <th>minus_di_14</th>\n",
       "      <th>eng_macd</th>\n",
       "      <th>macd_diff_12_26_9</th>\n",
       "      <th>body_pct</th>\n",
       "      <th>macd_line_12_26_9</th>\n",
       "      <th>volume</th>\n",
       "      <th>obv_diff_14</th>\n",
       "      <th>eng_rsi</th>\n",
       "      <th>eng_atr_div</th>\n",
       "      <th>eng_adx</th>\n",
       "      <th>adx_14</th>\n",
       "      <th>hour</th>\n",
       "      <th>body</th>\n",
       "      <th>close_raw</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02 09:33:00</th>\n",
       "      <td>0.499798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624765</td>\n",
       "      <td>0.506696</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.489532</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.488177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353456</td>\n",
       "      <td>0.519392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.002425</td>\n",
       "      <td>0.506538</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>6.967909e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 09:34:00</th>\n",
       "      <td>0.499798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624765</td>\n",
       "      <td>0.506696</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.489532</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.488177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353456</td>\n",
       "      <td>0.519392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.002425</td>\n",
       "      <td>0.506538</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>7.448270e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 09:35:00</th>\n",
       "      <td>0.499798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624765</td>\n",
       "      <td>0.506696</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.489532</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.488177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353456</td>\n",
       "      <td>0.519392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.002425</td>\n",
       "      <td>0.506538</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>7.961747e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 09:36:00</th>\n",
       "      <td>0.499798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624765</td>\n",
       "      <td>0.506696</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.489532</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.488177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353456</td>\n",
       "      <td>0.519392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.002425</td>\n",
       "      <td>0.506538</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>8.510623e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-02 09:37:00</th>\n",
       "      <td>0.499798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624765</td>\n",
       "      <td>0.506696</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.489532</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.488177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353456</td>\n",
       "      <td>0.519392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.002425</td>\n",
       "      <td>0.506538</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>9.097338e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:56:00</th>\n",
       "      <td>0.751690</td>\n",
       "      <td>0.323886</td>\n",
       "      <td>0.672166</td>\n",
       "      <td>0.273759</td>\n",
       "      <td>0.363125</td>\n",
       "      <td>0.254109</td>\n",
       "      <td>0.532431</td>\n",
       "      <td>0.074852</td>\n",
       "      <td>0.634772</td>\n",
       "      <td>0.888941</td>\n",
       "      <td>0.624850</td>\n",
       "      <td>0.971125</td>\n",
       "      <td>0.362651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664288</td>\n",
       "      <td>0.537709</td>\n",
       "      <td>0.301944</td>\n",
       "      <td>-0.975989</td>\n",
       "      <td>0.854984</td>\n",
       "      <td>196.815000</td>\n",
       "      <td>1.654708e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:57:00</th>\n",
       "      <td>0.650094</td>\n",
       "      <td>0.336016</td>\n",
       "      <td>0.616686</td>\n",
       "      <td>0.290460</td>\n",
       "      <td>0.347207</td>\n",
       "      <td>0.420131</td>\n",
       "      <td>0.532016</td>\n",
       "      <td>0.067044</td>\n",
       "      <td>0.633511</td>\n",
       "      <td>0.840741</td>\n",
       "      <td>0.374057</td>\n",
       "      <td>0.981544</td>\n",
       "      <td>0.434283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.676887</td>\n",
       "      <td>0.541855</td>\n",
       "      <td>0.328685</td>\n",
       "      <td>-0.975989</td>\n",
       "      <td>0.158091</td>\n",
       "      <td>196.675000</td>\n",
       "      <td>1.484384e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:58:00</th>\n",
       "      <td>0.631153</td>\n",
       "      <td>0.322169</td>\n",
       "      <td>0.614734</td>\n",
       "      <td>0.304199</td>\n",
       "      <td>0.336272</td>\n",
       "      <td>0.121620</td>\n",
       "      <td>0.531618</td>\n",
       "      <td>0.064933</td>\n",
       "      <td>0.631866</td>\n",
       "      <td>0.777896</td>\n",
       "      <td>0.494766</td>\n",
       "      <td>0.983006</td>\n",
       "      <td>0.496049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.584662</td>\n",
       "      <td>0.545337</td>\n",
       "      <td>0.353515</td>\n",
       "      <td>-0.975989</td>\n",
       "      <td>0.493632</td>\n",
       "      <td>196.670000</td>\n",
       "      <td>1.477119e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:59:00</th>\n",
       "      <td>0.375519</td>\n",
       "      <td>0.346959</td>\n",
       "      <td>0.475401</td>\n",
       "      <td>0.305249</td>\n",
       "      <td>0.290578</td>\n",
       "      <td>0.565110</td>\n",
       "      <td>0.531157</td>\n",
       "      <td>0.160021</td>\n",
       "      <td>0.623450</td>\n",
       "      <td>0.456523</td>\n",
       "      <td>0.090577</td>\n",
       "      <td>0.884486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645760</td>\n",
       "      <td>0.531521</td>\n",
       "      <td>0.348960</td>\n",
       "      <td>-0.975989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>196.240000</td>\n",
       "      <td>1.166764e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 21:00:00</th>\n",
       "      <td>0.535073</td>\n",
       "      <td>0.374297</td>\n",
       "      <td>0.551738</td>\n",
       "      <td>0.303059</td>\n",
       "      <td>0.249733</td>\n",
       "      <td>0.630630</td>\n",
       "      <td>0.531913</td>\n",
       "      <td>0.176984</td>\n",
       "      <td>0.622570</td>\n",
       "      <td>0.422962</td>\n",
       "      <td>0.462226</td>\n",
       "      <td>0.868408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708780</td>\n",
       "      <td>0.525575</td>\n",
       "      <td>0.336212</td>\n",
       "      <td>-0.993518</td>\n",
       "      <td>0.403294</td>\n",
       "      <td>196.540000</td>\n",
       "      <td>8.667170e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3715200 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sma_pct_14  atr_pct_14    rsi_14   bb_w_20  plus_di_14  \\\n",
       "2004-01-02 09:33:00    0.499798    0.000000  1.000000  0.000000    0.000000   \n",
       "2004-01-02 09:34:00    0.499798    0.000000  1.000000  0.000000    0.000000   \n",
       "2004-01-02 09:35:00    0.499798    0.000000  1.000000  0.000000    0.000000   \n",
       "2004-01-02 09:36:00    0.499798    0.000000  1.000000  0.000000    0.000000   \n",
       "2004-01-02 09:37:00    0.499798    0.000000  1.000000  0.000000    0.000000   \n",
       "...                         ...         ...       ...       ...         ...   \n",
       "2025-06-18 20:56:00    0.751690    0.323886  0.672166  0.273759    0.363125   \n",
       "2025-06-18 20:57:00    0.650094    0.336016  0.616686  0.290460    0.347207   \n",
       "2025-06-18 20:58:00    0.631153    0.322169  0.614734  0.304199    0.336272   \n",
       "2025-06-18 20:59:00    0.375519    0.346959  0.475401  0.305249    0.290578   \n",
       "2025-06-18 21:00:00    0.535073    0.374297  0.551738  0.303059    0.249733   \n",
       "\n",
       "                     range_pct    eng_ma  minus_di_14  eng_macd  \\\n",
       "2004-01-02 09:33:00   0.000000  0.516453     0.000000  0.624765   \n",
       "2004-01-02 09:34:00   0.000000  0.516453     0.000000  0.624765   \n",
       "2004-01-02 09:35:00   0.000000  0.516453     0.000000  0.624765   \n",
       "2004-01-02 09:36:00   0.000000  0.516453     0.000000  0.624765   \n",
       "2004-01-02 09:37:00   0.000000  0.516453     0.000000  0.624765   \n",
       "...                        ...       ...          ...       ...   \n",
       "2025-06-18 20:56:00   0.254109  0.532431     0.074852  0.634772   \n",
       "2025-06-18 20:57:00   0.420131  0.532016     0.067044  0.633511   \n",
       "2025-06-18 20:58:00   0.121620  0.531618     0.064933  0.631866   \n",
       "2025-06-18 20:59:00   0.565110  0.531157     0.160021  0.623450   \n",
       "2025-06-18 21:00:00   0.630630  0.531913     0.176984  0.622570   \n",
       "\n",
       "                     macd_diff_12_26_9  body_pct  macd_line_12_26_9    volume  \\\n",
       "2004-01-02 09:33:00           0.506696  0.499412           0.489532  0.020724   \n",
       "2004-01-02 09:34:00           0.506696  0.499412           0.489532  0.020724   \n",
       "2004-01-02 09:35:00           0.506696  0.499412           0.489532  0.020724   \n",
       "2004-01-02 09:36:00           0.506696  0.499412           0.489532  0.020724   \n",
       "2004-01-02 09:37:00           0.506696  0.499412           0.489532  0.020724   \n",
       "...                                ...       ...                ...       ...   \n",
       "2025-06-18 20:56:00           0.888941  0.624850           0.971125  0.362651   \n",
       "2025-06-18 20:57:00           0.840741  0.374057           0.981544  0.434283   \n",
       "2025-06-18 20:58:00           0.777896  0.494766           0.983006  0.496049   \n",
       "2025-06-18 20:59:00           0.456523  0.090577           0.884486  1.000000   \n",
       "2025-06-18 21:00:00           0.422962  0.462226           0.868408  1.000000   \n",
       "\n",
       "                     obv_diff_14  eng_rsi  eng_atr_div   eng_adx    adx_14  \\\n",
       "2004-01-02 09:33:00     0.488177      1.0     0.353456  0.519392  0.000000   \n",
       "2004-01-02 09:34:00     0.488177      1.0     0.353456  0.519392  0.000000   \n",
       "2004-01-02 09:35:00     0.488177      1.0     0.353456  0.519392  0.000000   \n",
       "2004-01-02 09:36:00     0.488177      1.0     0.353456  0.519392  0.000000   \n",
       "2004-01-02 09:37:00     0.488177      1.0     0.353456  0.519392  0.000000   \n",
       "...                          ...      ...          ...       ...       ...   \n",
       "2025-06-18 20:56:00     1.000000      0.0     0.664288  0.537709  0.301944   \n",
       "2025-06-18 20:57:00     0.000000      0.0     0.676887  0.541855  0.328685   \n",
       "2025-06-18 20:58:00     0.000000      0.0     0.584662  0.545337  0.353515   \n",
       "2025-06-18 20:59:00     0.000000      0.0     0.645760  0.531521  0.348960   \n",
       "2025-06-18 21:00:00     1.000000      0.0     0.708780  0.525575  0.336212   \n",
       "\n",
       "                         hour      body   close_raw        signal  \n",
       "2004-01-02 09:33:00  1.002425  0.506538    0.764286  6.967909e-09  \n",
       "2004-01-02 09:34:00  1.002425  0.506538    0.764286  7.448270e-09  \n",
       "2004-01-02 09:35:00  1.002425  0.506538    0.764286  7.961747e-09  \n",
       "2004-01-02 09:36:00  1.002425  0.506538    0.764286  8.510623e-09  \n",
       "2004-01-02 09:37:00  1.002425  0.506538    0.764286  9.097338e-09  \n",
       "...                       ...       ...         ...           ...  \n",
       "2025-06-18 20:56:00 -0.975989  0.854984  196.815000  1.654708e-01  \n",
       "2025-06-18 20:57:00 -0.975989  0.158091  196.675000  1.484384e-01  \n",
       "2025-06-18 20:58:00 -0.975989  0.493632  196.670000  1.477119e-01  \n",
       "2025-06-18 20:59:00 -0.975989  0.000000  196.240000  1.166764e-01  \n",
       "2025-06-18 21:00:00 -0.993518  0.403294  196.540000  8.667170e-02  \n",
       "\n",
       "[3715200 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_sel = pd.read_csv(params.feat_all_csv, index_col=0, parse_dates=True)[params.features_cols_tick + ['close_raw'] + [params.label_col]]\n",
    "    \n",
    "df_feat_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a8d933-8402-45de-a838-4335b2a37d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside build_tensors, features: ['sma_pct_14', 'atr_pct_14', 'rsi_14', 'bb_w_20', 'plus_di_14', 'range_pct', 'eng_ma', 'minus_di_14', 'eng_macd', 'macd_diff_12_26_9', 'body_pct', 'macd_line_12_26_9', 'volume', 'obv_diff_14', 'eng_rsi', 'eng_atr_div', 'eng_adx', 'adx_14', 'hour', 'body']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebda4dcc43984f4480f453ed2612268d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing days:   0%|          | 0/5400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b57891a358f4e118025bb8bff04cfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing days:   0%|          | 0/5400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3cdd0b94fd4dc9b54a4bb7a7b25711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating DayWindowDatasets:   0%|          | 0/3 [00:00<?, ?split/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TRAIN ---\n",
      " calendar days : 3840  (2004-01-02 → 2019-04-04)\n",
      " windows       : 1847040  (per-day min=481, max=481, mean=481.0)\n",
      " window shape  : look_back=90, n_features=20\n",
      " dataloader    : batches= 60, batch_size=64, workers=12, pin_memory=True\n",
      "\n",
      "--- VAL ---\n",
      " calendar days : 751  (2019-04-05 → 2022-03-28)\n",
      " windows       : 361231  (per-day min=481, max=481, mean=481.0)\n",
      " window shape  : look_back=90, n_features=20\n",
      " dataloader    : batches=751, batch_size=1, workers=0, pin_memory=True\n",
      "\n",
      "--- TEST ---\n",
      " calendar days : 809  (2022-03-29 → 2025-06-18)\n",
      " windows       : 389129  (per-day min=481, max=481, mean=481.0)\n",
      " window shape  : look_back=90, n_features=20\n",
      " dataloader    : batches=809, batch_size=1, workers=0, pin_memory=True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, end_times_tr, end_times_val, end_times_te = models_core.model_core_pipeline(\n",
    "    df             = df_feat_sel,\n",
    "    look_back      = params.look_back_tick,\n",
    "    sess_start     = params.sess_start_pred_tick,\n",
    "    train_prop     = params.train_prop,\n",
    "    val_prop       = params.val_prop,\n",
    "    train_batch    = params.hparams[\"TRAIN_BATCH\"],\n",
    "    num_workers    = params.hparams[\"NUM_WORKERS\"],\n",
    "    prefetch_factor= params.hparams[\"TRAIN_PREFETCH_FACTOR\"],\n",
    "    signal_thresh  = params.best_optuna_params[\"buy_threshold\"],\n",
    "    return_thresh  = params.return_threshold_tick\n",
    ")\n",
    "\n",
    "for name, ld, tm in zip(\n",
    "    [\"train\",\"val\",\"test\"],\n",
    "    [train_loader, val_loader, test_loader],\n",
    "    [end_times_tr, end_times_val, end_times_te]\n",
    "):\n",
    "    models_core.summarize_split(name, ld, tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeec031f-6c8f-455f-9c72-ae411e03ba34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelClass(\n",
       "  (conv): Identity()\n",
       "  (bn): Identity()\n",
       "  (ln_short): Identity()\n",
       "  (do_short): Identity()\n",
       "  (short2long): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (ln_proj): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (do_proj): Dropout(p=0.2, inplace=False)\n",
       "  (ln_long): Identity()\n",
       "  (do_long): Identity()\n",
       "  (pred): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importlib.reload(params.model_selected) #############\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Instantiate the ModelClass & move to device\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model = params.model_selected.ModelClass(\n",
    "    n_feats         = len(params.features_cols_tick),\n",
    "    short_units     = params.hparams[\"SHORT_UNITS\"],\n",
    "    long_units      = params.hparams[\"LONG_UNITS\"],\n",
    "    dropout_short   = params.hparams[\"DROPOUT_SHORT\"],\n",
    "    dropout_long    = params.hparams[\"DROPOUT_LONG\"],\n",
    "    conv_k          = params.hparams[\"CONV_K\"],\n",
    "    conv_dilation   = params.hparams[\"CONV_DILATION\"],\n",
    "    pred_hidden     = params.hparams[\"PRED_HIDDEN\"],\n",
    "\n",
    "    # Gating flags\n",
    "    use_conv        = params.hparams[\"USE_CONV\"],\n",
    "    use_short_lstm  = params.hparams[\"USE_SHORT_LSTM\"],\n",
    "    use_long_lstm   = params.hparams[\"USE_LONG_LSTM\"],\n",
    ")\n",
    "\n",
    "model.to(params.device)  \n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60683d75-5de6-4685-9593-f451788ebbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model check: overfit one batch: force your model to train on the exact same small set of examples over and over.\n",
    "# # You should see loss → 0 in a few dozen steps on a single batch.\n",
    "\n",
    "# # 1) Grab a single batch (no shuffle issues)\n",
    "# batch = next(iter(train_loader))\n",
    "# x_pad, y_sig, *_, lengths = batch\n",
    "\n",
    "# # 2) Move to device\n",
    "# device = next(model.parameters()).device\n",
    "# x_pad = x_pad.to(device)\n",
    "# y_sig = y_sig.to(device)\n",
    "\n",
    "# # 3) Extract just the first day’s valid windows\n",
    "# #    lengths[0] might be a tensor or int\n",
    "# W = lengths[0].item() if isinstance(lengths[0], torch.Tensor) else lengths[0]\n",
    "# x_day = x_pad[0, :W]       # shape (W, features…)\n",
    "# y_day = y_sig[0, :W]       # shape (W,)\n",
    "\n",
    "# # 4) Our single target is the last tick of that day\n",
    "# target_val = y_day[-1].unsqueeze(0)   # shape (1,)\n",
    "\n",
    "# # 5) Turn off dropout so we can memorize perfectly\n",
    "# for m in model.modules():\n",
    "#     if isinstance(m, Dropout):\n",
    "#         m.p = 0.0\n",
    "\n",
    "# # 6) Clear any saved LSTM state (if your model uses h_short/h_long)\n",
    "# if hasattr(model, \"h_short\"): model.h_short = None\n",
    "# if hasattr(model, \"h_long\"):  model.h_long  = None\n",
    "\n",
    "# # 7) Set up optimizer & loss\n",
    "# optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "# criterion = MSELoss()\n",
    "\n",
    "# # 8) Overfit loop: reset state every pass, predict last‐tick, compare scalar→scalar\n",
    "# model.train()\n",
    "# for step in range(100):\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # reset hidden state each iteration\n",
    "#     if hasattr(model, \"h_short\"): model.h_short = None\n",
    "#     if hasattr(model, \"h_long\"):  model.h_long  = None\n",
    "\n",
    "#     # forward on the full day sequence\n",
    "#     raw_out = model(x_day)  \n",
    "#     raw_reg = raw_out[0] if isinstance(raw_out, (tuple, list)) else raw_out\n",
    "\n",
    "#     # collapse to shape (W,)\n",
    "#     if raw_reg.dim() == 3:\n",
    "#         raw_reg = raw_reg[0].squeeze(-1)\n",
    "#     elif raw_reg.dim() == 2:\n",
    "#         raw_reg = raw_reg.squeeze(-1)\n",
    "\n",
    "#     # take *only* the final-tick prediction → scalar\n",
    "#     pred_val = raw_reg[-1].unsqueeze(0)   # shape (1,)\n",
    "\n",
    "#     # compute scalar loss\n",
    "#     loss = criterion(pred_val, target_val)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if (step + 1) % 10 == 0 or step == 0:\n",
    "#         print(f\"Step {step+1:02d}  loss={loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7ec8c-5882-486b-bdfd-371b8db260f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate([batch[1].cpu().numpy().ravel() for batch in train_loader])\n",
    "y_val = np.concatenate([batch[1].cpu().numpy().ravel() for batch in val_loader])\n",
    "\n",
    "# Visualize the true‐signal distributions on train vs. validation\n",
    "plt.hist(y_train, bins=100, alpha=0.5, label=\"train true\")\n",
    "plt.hist(y_val,   bins=100, alpha=0.5, label=\"val true\")\n",
    "plt.xlabel(\"Signal value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"True Signal Distribution: Train vs. Validation\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf94780-a876-4bf4-ad27-6abc2da1fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(params) #############\n",
    "importlib.reload(params.model_selected) #############\n",
    "importlib.reload(models_core) #############\n",
    "\n",
    "# How many unique trading days does each epoch see?\n",
    "n_days = len(train_loader.dataset)\n",
    "print(f\"Training sees {n_days} unique trading days per epoch.\\n\")\n",
    "\n",
    "print('Using HyperParameters:\\n \"look_back\":', params.look_back_tick, params.hparams)\n",
    "\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr = params.hparams[\"ONECYCLE_MAX_LR\"],      \n",
    "    weight_decay = params.hparams[\"WEIGHT_DECAY\"]\n",
    ")\n",
    "\n",
    "total_steps = len(train_loader) * params.hparams[\"MAX_EPOCHS\"] # batches × epochs\n",
    "\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr              = params.hparams[\"ONECYCLE_MAX_LR\"],\n",
    "    total_steps         = total_steps,\n",
    "    pct_start           = params.hparams[\"ONECYCLE_PCT_START\"],\n",
    "    div_factor          = params.hparams[\"ONECYCLE_DIV_FACTOR\"],\n",
    "    final_div_factor    = params.hparams[\"ONECYCLE_FINAL_DIV\"],\n",
    "    anneal_strategy     = params.hparams[\"ONECYCLE_STRATEGY\"]\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run the custom stateful training loop\n",
    "# -----------------------------------------------------------------------------\n",
    "best_val_rmse  = params.model_selected.model_training_loop(\n",
    "    model               = model,\n",
    "    optimizer           = optimizer,\n",
    "    scheduler           = scheduler,\n",
    "    scaler              = GradScaler(),\n",
    "    train_loader        = train_loader,\n",
    "    val_loader          = val_loader,\n",
    "    max_epochs          = params.hparams['MAX_EPOCHS'],\n",
    "    early_stop_patience = params.hparams['EARLY_STOP_PATIENCE'],\n",
    "    clipnorm            = params.hparams['CLIPNORM'],\n",
    "    alpha_smooth        = params.hparams['ALPHA_SMOOTH']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad57d0a0-6f4f-4b23-8d83-71d1a1f99c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
