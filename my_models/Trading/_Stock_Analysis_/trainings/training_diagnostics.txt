
------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-11-03T11:48:00.611142Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=7216 groups=1 seq_len_full=20 feat=20 : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : single-line deterministic dump of snapshot keys printed as key=value (sorted); human-readable units used where applicable
    -> B: number of batch samples used to build windows (snapshot.B)
    -> groups: number of logical groups used when flattening windows (snapshot.groups)
    -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
    -> feat / feat_dim: feature dimension used to build windows (snapshot.feat_dim)
    -> activation_mb: estimated activation footprint in MB computed from GPU allocation delta (snapshot.activation_mb)
    -> backward_ms: backward pass ms placeholder (snapshot.backward_ms)
    -> collector_ms: total wall-clock ms spent by the collector including sampling, CPU work and device synchronizations (snapshot.collector_ms)
    -> cpu_copy_bytes: bytes copied to host for predictions shown human-readable in the log (snapshot.cpu_copy_bytes)
    -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
    -> device_syncs_count: number of explicit device synchronizations performed during snapshot (snapshot.device_syncs_count)
    -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
    -> expected_segments: nominal B * groups used to estimate workload (snapshot.expected_segments)
    -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
    -> pred_extra_ms: estimated CPU-side post-forward ms = collector_ms - full_forward_ms - summed per-seg time (snapshot.pred_extra_ms)
    -> gpu_allocated_bytes: raw GPU bytes allocated after forward (snapshot.gpu_allocated_bytes)
    -> gpu_peak_mb: peak GPU memory in MB (snapshot.gpu_peak_mb)
    -> gpu_reserved_bytes / gpu_reserved_mb: reserved GPU bytes and MB (snapshot.gpu_reserved_bytes, snapshot.gpu_reserved_mb)
    -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
    -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
    -> mean_seg_len: average per-segment time-series length in timesteps computed as sum_seg_lens / num_segments (snapshot.mean_seg_len)
    -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
    -> sum_seg_lens: sum of non-empty segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
    -> out_bytes / out_dtype / out_numel / out_shape: model output bytes, dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
    -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
    -> total_params / trainable_params: canonical parameter counts stamped by init_log (snapshot.total_params, snapshot.trainable_params)
    -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
    -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
    -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
    -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lr_main}|cnts=[c1,c2,...]] : optimizer groups count; lr_main is the representative LR (first group); cnts lists per-group parameter counts
  GN[name:val,...,TOT=val] : per-bucket gradient L2 norms printed as short_name:curr_norm; TOT is sqrt(sum squares over reported buckets)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, index-based 90th-percentile, and maximum
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : representative main LR and explicit first-group lr printed in scientific notation
  TR[...metrics...]       : training metrics reported for the epoch (rmse, mae, r2, etc.; see TR composition in code)
  VAL[...metrics...]      : validation metrics reported for the epoch (rmse, mae, r2, etc.; see VAL composition in code)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_tot_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults 0.00/0.000 when missing)
  FMB={val:.4f}           : first-mini-batch diagnostic metric from the first-batch snapshot if set (snapshot.FMB)
  T={elapsed:.1f}s,TP={throughput:.1f} : epoch elapsed seconds and throughput (segments/sec inferred from sampled forward)
  chk={val}               : checkpoint marker token printed as chk in the line (implementation-specific; integerized when boolean)
  GPU={GiB:.2f}GiB        : optional GPU memory high-water printed in GiB when CUDA available (torch.cuda.max_memory_allocated / (1024**3))
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy (separate visual marker outside numeric chk token)
  LAYER_GN[...]           : optional small set of monitored layer norms printed as name_short:curr_norm/ratio where ratio = curr / baseline_observed_on_first_epoch
  G/U=name:grad/update_ratio,... : parameter buckets printed sorted by descending gradient norm; every short-name bucket is emitted in compact form
      - format for each token is short_name:{g:.3e}/{u:.1e} where g is the gradient norm and u is the lr-scaled update ratio
      - short_name uses the last 1â€“3 name segments (see short_name logic); entries are deduped by short_name keeping the highest-g representative
      - the G/U list is printed every epoch (values change per epoch) and contains both large and very small gradients in scientific notation

BASELINES:
  TRAIN mean RMSE        = 0.11379
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.10862
  VAL   persistence RMSE = 0.01200

HYPERPARAMS:
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  CONV_CHANNELS = 64
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  TCN_CHANNELS = 64
  USE_SHORT_LSTM = False
  SHORT_UNITS = 128
  DROPOUT_SHORT = 0.1
  USE_TRANSFORMER = True
  TRANSFORMER_D_MODEL = 128
  TRANSFORMER_LAYERS = 3
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_TRANS = 0.1
  USE_LONG_LSTM = False
  DROPOUT_LONG = 0.1
  LONG_UNITS = 128
  FLATTEN_MODE = last
  PRED_HIDDEN = 128
  ALPHA_SMOOTH = 0.05
  WARMUP_STEPS = 5
  USE_HUBER = True
  HUBER_DELTA = 0.1
  USE_DELTA = False
  LAMBDA_DELTA = 0.1
  MAX_EPOCHS = 70
  EARLY_STOP_PATIENCE = 7
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 3
  ONECYCLE_MAX_LR = 0.0005
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 100
  ONECYCLE_PCT_START = 0.1
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 16
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  LOOK_BACK = 60
  MICRO_SAMPLE_K = 16

DEBUG_OPT GROUPS=1 LRS=['7.2e-05'] COUNTS=[48] | MODEL_STATIC: total_params=614,786 trainable=614,786 frozen=0 | param_bytes=2.35MB
BATCH_SHAPE B=7216 groups=1 seq_len_full=20 feat=20
MICRODETAIL ms: B=7216 activation_mb=27 backward_ms=112.05 collector_ms=273.45 cpu_copy_bytes=68B dataloader_ms=136.12 device_syncs_count=2 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=7216 feat_dim=20 full_forward_ms=13.61 gpu_allocated_bytes=153.23MB gpu_peak_mb=187 gpu_reserved_bytes=8974.00MB gpu_reserved_mb=8974 grads={'backbone': True, 'head': True} group_nonzero_counts=[48] groups=1 mean_seg_len=1.00 num_segments=34 out_bytes=68B out_dtype=torch.float16 out_numel=34 out_shape=(34, 1) param_bytes=2.35MB per_segment_p50_ms=2.42 per_segment_p90_ms=8.09 pred_extra_ms=190.95 raw_reg_shape=(34, 1) segments_per_sec=2497.53 seq_len_full=20 sum_seg_lens=34 total_params=614786 trainable_params=614786 windows_bytes=159.4KB

E01 | OPTS[1:7.2e-05|cnts=[48]] | GN[head_flat=0.034,transformer=0.008,feature_proj=0.001,ln_flat=0.001,ln_proj=0.001,TOT=0.035] | GD[4.7e-04,2.6e-03,2.8e-02] | UR[3.3e-08,9.1e-03] | LR_MAIN=7.2e-05 | lr=7.2e-05 | TR[0.1205,0.0807,-0.1212,BASE_RMSE=0.1205,DELTA_RMSE=nan] | VAL[0.1050,0.0719,0.0655,BASE_RMSE=0.1050] | BASE_LOSS=4.7413e-03,DELTA_LOSS=0.0000e+00,DELTA_RATIO=0.000e+00,BASE_RMSE=0.12049,DELTA_RMSE=nan | SCHED_PCT=1.4% | SR=0.011 | SL=0.00,HR=0.000 | FMB=0.0000 | T=50.2s,TP=34086.7seg/s | chk=0 | GPU=0.18GiB | LAYER_GN[weight:9.819e-04/1.00]
G/U=head_flat.2.bias:8.0e-03/9.1e-03,2.linear2.weight:4.9e-03/5.4e-08,1.linear2.weight:3.0e-03/3.3e-08,self_attn.out_proj.weight:2.6e-03/2.9e-08,0.linear2.weight:2.5e-03/2.7e-08,2.linear1.weight:2.3e-03/1.3e-08,2.self_attn.in_proj_weight:2.1e-03/1.1e-08,head_flat.0.bias:1.7e-03/2.2e-07,0.self_attn.in_proj_weight:1.5e-03/7.9e-09,1.self_attn.in_proj_weight:1.3e-03/7.0e-09,1.linear1.weight:1.3e-03/7.1e-09,0.linear1.weight:1.1e-03/5.8e-09,feature_proj.weight:9.8e-04/1.1e-08,ln_flat.bias:7.1e-04/4.5e-06,ln_proj.bias:6.6e-04/2.8e-06,2.norm2.bias:6.5e-04/2.8e-06,2.linear2.bias:4.9e-04/1.2e-07,feature_proj.bias:4.8e-04/2.4e-08,2.norm1.bias:4.7e-04/2.2e-06,1.norm2.bias:3.7e-04/1.9e-06,self_attn.out_proj.bias:3.7e-04/2.2e-06,ln_flat.weight:3.4e-04/2.2e-09,ln_proj.weight:3.3e-04/2.1e-09,2.norm2.weight:3.3e-04/2.1e-09,1.norm1.bias:3.1e-04/1.7e-06,0.norm2.bias:3.1e-04/1.7e-06,1.linear2.bias:3.0e-04/7.6e-08,0.norm1.bias:3.0e-04/1.7e-06,0.linear2.bias:2.8e-04/7.0e-08,2.norm1.weight:2.4e-04/1.5e-09,0.self_attn.in_proj_bias:2.2e-04/9.7e-07,1.norm2.weight:2.1e-04/1.3e-09,2.linear1.bias:2.1e-04/1.3e-08,2.self_attn.in_proj_bias:2.1e-04/8.9e-07,0.norm1.weight:1.9e-04/1.2e-09,1.norm1.weight:1.8e-04/1.2e-09,0.norm2.weight:1.8e-04/1.2e-09,1.self_attn.in_proj_bias:1.5e-04/6.6e-07,1.linear1.bias:1.2e-04/7.7e-09,0.linear1.bias:1.1e-04/6.8e-09
