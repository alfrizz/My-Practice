
------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-10-26T17:48:28.619262Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=... groups=... seq_len_full=... feat=... : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : deterministic single-line dump of snapshot keys (sorted). Notable printed keys below reference exact snapshot field names and formats.
      -> B: number of batch samples used to build windows (snapshot.B)
      -> activation_mb: estimated activation footprint in MB computed from allocation delta (snapshot.activation_mb)
      -> backward_ms: placeholder for backward pass ms (None here; snapshot.backward_ms)
      -> collector_ms: total wall-clock ms spent by the collector (includes sampling, CPU/GPU syncs) (snapshot.collector_ms)
      -> cpu_copy_bytes: bytes copied to host for predictions, shown human-readable in log (snapshot.cpu_copy_bytes)
      -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
      -> device_syncs_count: count of explicit torch.cuda.synchronize() calls used for timing accuracy (snapshot.device_syncs_count)
      -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
      -> expected_segments: nominal B * groups (snapshot.expected_segments)
      -> feat_dim: feature dimension of inputs used to build windows (snapshot.feat_dim)
      -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
      -> gpu_allocated_bytes / gpu_reserved_bytes: raw GPU bytes allocated/reserved (snapshot.gpu_allocated_bytes, snapshot.gpu_reserved_bytes)
      -> gpu_peak_mb / gpu_reserved_mb: peak/reserved GPU memory in MB (snapshot.gpu_peak_mb, snapshot.gpu_reserved_mb)
      -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
      -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
      -> groups: number of logical groups used when flattening windows (snapshot.groups)
      -> mean_seg_len: average per-segment time-series length in timesteps (snapshot.mean_seg_len)
      -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
      -> out_bytes / out_dtype / out_numel / out_shape: model output bytes (human-readable in log), dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
      -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
      -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
      -> pred_extra_ms / preds_cpu_ms: placeholder for extra pred cost and ms to detach+copy preds to CPU (snapshot.pred_extra_ms, snapshot.preds_cpu_ms)
      -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
      -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
      -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
      -> step_block_ms: placeholder for step-block timing if measured (snapshot.step_block_ms)
      -> sum_seg_lens: sum of segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
      -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lrs}|cnts=[c1,c2,...]] : optimizer groups count, compact LR preview (first up to 3) and per-group parameter counts (from optimizer.param_groups)
  GN[reg,cls,ter,tot]      : gradient norms for name-buckets reg/cls/ter and total (sqrt of sum squares over matching named parameters; zero means no matching names found)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, 90th-percentile, and maximum (index-based p90)
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : primary LR token and explicit current lr printed in scientific notation
  TR[rmse,r2,mae]         : training metrics (RMSE, R^2, MAE) reported for the epoch (train_metrics)
  VL[rmse,r2,mae]         : validation metrics (RMSE, R^2, MAE) reported for the epoch (val_metrics)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults to 0.00/0.000 when missing)
  SCHED_PCT={pct:.1f}%     : optional scheduler percent-complete when scheduler exposes _total_steps and a step counter
  T={elapsed:.1f}s,TP={throughput:.1f}s/s : optional epoch elapsed and throughput if model stored _last_epoch_elapsed and _last_epoch_samples
  GPU={GiB:.2f}GiB         : optional high-water GPU memory in GiB when CUDA available (torch.cuda.max_memory_allocated)
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy
  LAYER_GN[...]           : optional small set of monitored layer norms and ratio-to-baseline printed as name_short:curr_norm/ratio
  TOP_K(G/U)=param:grad_norm/update_ratio,... : top-k parameter entries by gradient norm with their update ratios (short names use last two name segments)

BASELINES:
  TRAIN mean RMSE        = 0.04190
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.06583
  VAL   persistence RMSE = 0.01214

HYPERPARAMS:
  LOOK_BACK = 60
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  USE_SHORT_LSTM = True
  SHORT_UNITS = 64
  DROPOUT_SHORT = 0.0
  USE_TRANSFORMER = True
  TRANSFORMER_LAYERS = 1
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_LONG = 0.0
  USE_LONG_LSTM = False
  LONG_UNITS = 64
  FLATTEN_MODE = last
  PRED_HIDDEN = 64
  ALPHA_SMOOTH = 0.1
  MAX_EPOCHS = 90
  EARLY_STOP_PATIENCE = 9
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 5
  ONECYCLE_MAX_LR = 0.001
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 50
  ONECYCLE_PCT_START = 0.2
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 64
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  MICRO_SAMPLE_K = 16

BATCH_SHAPE B=64 groups=451 seq_len_full=60 feat=20
MICRODETAIL ms: B=64 activation_mb=4166 backward_ms=None collector_ms=949.92 cpu_copy_bytes=46KB dataloader_ms=722.76 device_syncs_count=35 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=28864 feat_dim=20 full_forward_ms=54.87 gpu_allocated_bytes=4800MB gpu_peak_mb=6479 gpu_reserved_bytes=13828MB gpu_reserved_mb=13828 grads={'backbone': True, 'head': True} group_nonzero_counts=[36] groups=451 mean_seg_len=2.53 num_segments=23903 out_bytes=46KB out_dtype=torch.float16 out_numel=23903 out_shape=(23903, 1, 1) param_bytes=300KB per_segment_p50_ms=1.79 per_segment_p90_ms=3.01 pred_extra_ms=None preds_cpu_ms=0.35 raw_reg_shape=(23903, 1, 1) segments_per_sec=435613.15 seq_len_full=60 step_block_ms=None sum_seg_lens=134 windows_bytes=109MB

E01 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.104,0.000,0.000,0.129] | GD[5.2e-03,3.2e-02,8.0e-02] | UR[6.9e-07,4.8e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.147,-0.67,0.104] | VL[0.109,0.01,0.077] | SR=0.013 | SL=0.00,HR=0.000 |  | T=21.0s,TP=82331.4s/s | GPU=6.33GiB | LAYER_GN[weight_ih_l0:1.215e-02/1.00,weight:5.652e-02/1.00,weight:3.159e-02/1.00] | 
TOP_K(G/U)=weight.original1:0.080/1.5e-05, weight.original1:0.061/1.3e-06, short2long.weight:0.057/1.2e-06, feature_proj.weight:0.032/6.9e-07, 2.bias:0.022/2.7e-05, linear2.weight:0.018/3.9e-07, out_proj.weight:0.015/3.3e-07, self_attn.in_proj_weight:0.014/1.4e-07, linear1.weight:0.013/1.4e-07, short_lstm.weight_ih_l0:0.012/2.3e-07, short_lstm.bias_ih_l0:0.009/7.5e-07, short_lstm.bias_hh_l0:0.009/6.9e-07, weight.original0:0.008/1.6e-06, weight.original0:0.008/1.8e-07, 0.bias:0.008/1.5e-06, short_lstm.weight_ih_l0_reverse:0.007/1.3e-07, short2long.bias:0.007/1.2e-06, short_lstm.weight_hh_l0:0.005/8.0e-08, short_lstm.bias_ih_l0_reverse:0.005/4.0e-07, short_lstm.bias_hh_l0_reverse:0.005/3.9e-07, ln_flat.bias:0.004/4.8e-05, ln_proj.bias:0.004/4.3e-05, ln_proj.weight:0.004/4.8e-08, ln_flat.weight:0.004/4.8e-08, norm2.weight:0.004/4.7e-08, feature_proj.bias:0.004/6.7e-07, norm1.weight:0.004/4.5e-08, out_proj.bias:0.003/4.1e-05, norm2.bias:0.003/3.8e-05, linear2.bias:0.003/1.1e-06, norm1.bias:0.003/3.6e-05, self_attn.in_proj_bias:0.002/2.0e-05, ln_short.weight:0.002/2.8e-08, short_lstm.weight_hh_l0_reverse:0.002/3.2e-08, ln_short.bias:0.002/2.0e-05, linear1.bias:0.002/1.3e-07

E02 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.076,0.000,0.000,0.094] | GD[3.9e-03,2.2e-02,5.9e-02] | UR[4.9e-07,3.5e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.112,0.03,0.077] | VL[0.103,0.12,0.074] | SR=0.012 | SL=0.00,HR=0.000 |  | T=17.9s,TP=96831.3s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:8.873e-03/0.73,weight:4.103e-02/0.73,weight:2.221e-02/0.70] | 
TOP_K(G/U)=weight.original1:0.059/1.1e-05, weight.original1:0.045/9.7e-07, short2long.weight:0.041/8.9e-07, feature_proj.weight:0.022/4.9e-07, 2.bias:0.017/2.1e-05, linear2.weight:0.013/2.9e-07, out_proj.weight:0.011/2.4e-07, self_attn.in_proj_weight:0.010/1.0e-07, linear1.weight:0.009/9.9e-08, short_lstm.weight_ih_l0:0.009/1.7e-07, short_lstm.bias_ih_l0:0.006/5.5e-07, short_lstm.bias_hh_l0:0.006/5.1e-07, weight.original0:0.006/1.3e-07, 0.bias:0.006/1.1e-06, weight.original0:0.005/1.0e-06, short2long.bias:0.005/8.7e-07, short_lstm.weight_ih_l0_reverse:0.005/9.5e-08, short_lstm.weight_hh_l0:0.004/6.0e-08, short_lstm.bias_ih_l0_reverse:0.003/2.8e-07, short_lstm.bias_hh_l0_reverse:0.003/2.7e-07, ln_flat.bias:0.003/3.5e-05, ln_proj.bias:0.003/3.0e-05, ln_proj.weight:0.003/3.6e-08, ln_flat.weight:0.003/3.6e-08, norm2.weight:0.003/3.5e-08, feature_proj.bias:0.003/4.9e-07, norm1.weight:0.003/3.2e-08, out_proj.bias:0.003/2.6e-05, norm2.bias:0.003/2.5e-05, linear2.bias:0.002/7.7e-07, norm1.bias:0.002/2.3e-05, self_attn.in_proj_bias:0.002/1.2e-05, ln_short.weight:0.002/1.9e-08, short_lstm.weight_hh_l0_reverse:0.001/2.1e-08, ln_short.bias:0.001/1.4e-05, linear1.bias:0.001/9.4e-08

E03 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.020,0.000,0.000,0.025] | GD[1.2e-03,6.6e-03,1.6e-02] | UR[1.1e-07,9.0e-06] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.107,0.11,0.074] | VL[0.100,0.16,0.069] | SR=0.014 | SL=0.00,HR=0.000 |  | T=16.9s,TP=102401.3s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:4.879e-03/0.40,weight:1.058e-02/0.19,weight:6.575e-03/0.21] | 
TOP_K(G/U)=weight.original1:0.016/3.0e-06, weight.original1:0.011/2.5e-07, short2long.weight:0.011/2.3e-07, feature_proj.weight:0.007/1.4e-07, short_lstm.weight_ih_l0:0.005/9.4e-08, 2.bias:0.004/5.1e-06, linear2.weight:0.004/7.7e-08, out_proj.weight:0.003/6.6e-08, linear1.weight:0.003/3.0e-08, self_attn.in_proj_weight:0.003/2.7e-08, weight.original0:0.002/4.2e-07, short_lstm.weight_ih_l0_reverse:0.002/3.8e-08, weight.original0:0.002/3.5e-08, 0.bias:0.001/2.8e-07, short_lstm.weight_hh_l0:0.001/1.9e-08, short2long.bias:0.001/2.1e-07, short_lstm.bias_ih_l0:0.001/1.1e-07, short_lstm.bias_hh_l0:0.001/9.8e-08, ln_proj.weight:0.001/1.0e-08, ln_flat.weight:0.001/9.8e-09, ln_flat.bias:0.001/9.0e-06, ln_proj.bias:0.001/7.8e-06, norm2.weight:0.001/9.0e-09, feature_proj.bias:0.001/1.3e-07, norm1.weight:0.001/8.7e-09, short_lstm.bias_ih_l0_reverse:0.001/5.9e-08, short_lstm.bias_hh_l0_reverse:0.001/5.7e-08, out_proj.bias:0.001/6.8e-06, norm2.bias:0.001/6.1e-06, norm1.bias:0.001/5.7e-06, linear2.bias:0.001/2.0e-07, ln_short.weight:0.000/6.0e-09, short_lstm.weight_hh_l0_reverse:0.000/6.2e-09, self_attn.in_proj_bias:0.000/2.8e-06, ln_short.bias:0.000/4.1e-06, linear1.bias:0.000/2.7e-08

E04 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.072,0.000,0.000,0.089] | GD[4.3e-03,2.2e-02,5.5e-02] | UR[5.1e-07,3.4e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.105,0.15,0.072] | VL[0.099,0.18,0.066] | SR=0.015 | SL=0.00,HR=0.000 |  | T=17.4s,TP=99362.7s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:1.287e-02/1.06,weight:3.772e-02/0.67,weight:2.187e-02/0.69] | 
TOP_K(G/U)=weight.original1:0.055/1.0e-05, weight.original1:0.041/9.0e-07, short2long.weight:0.038/8.1e-07, feature_proj.weight:0.022/4.8e-07, 2.bias:0.016/1.9e-05, short_lstm.weight_ih_l0:0.013/2.5e-07, linear2.weight:0.012/2.6e-07, out_proj.weight:0.011/2.4e-07, self_attn.in_proj_weight:0.010/1.0e-07, linear1.weight:0.009/1.0e-07, short_lstm.bias_ih_l0:0.006/5.5e-07, short_lstm.bias_hh_l0:0.006/5.1e-07, short_lstm.weight_ih_l0_reverse:0.006/1.2e-07, weight.original0:0.006/1.2e-07, weight.original0:0.006/1.1e-06, 0.bias:0.005/1.1e-06, short2long.bias:0.005/8.2e-07, short_lstm.weight_hh_l0:0.004/6.6e-08, short_lstm.bias_ih_l0_reverse:0.003/2.9e-07, short_lstm.bias_hh_l0_reverse:0.003/2.8e-07, ln_flat.bias:0.003/3.4e-05, ln_proj.bias:0.003/3.0e-05, feature_proj.bias:0.003/5.1e-07, ln_proj.weight:0.003/3.4e-08, ln_flat.weight:0.003/3.4e-08, norm2.weight:0.003/3.3e-08, out_proj.bias:0.003/2.6e-05, norm1.weight:0.003/3.2e-08, norm2.bias:0.002/2.4e-05, norm1.bias:0.002/2.2e-05, linear2.bias:0.002/7.5e-07, ln_short.weight:0.002/2.1e-08, self_attn.in_proj_bias:0.002/1.0e-05, short_lstm.weight_hh_l0_reverse:0.002/2.4e-08, ln_short.bias:0.002/1.6e-05, linear1.bias:0.001/9.7e-08

E05 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.106,0.000,0.000,0.133] | GD[6.8e-03,3.4e-02,8.2e-02] | UR[7.9e-07,5.1e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.104,0.17,0.071] | VL[0.098,0.20,0.065] | SR=0.016 | SL=0.00,HR=0.000 |  | T=17.3s,TP=100354.1s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:1.964e-02/1.62,weight:5.655e-02/1.00,weight:3.378e-02/1.07] | 
TOP_K(G/U)=weight.original1:0.082/1.6e-05, weight.original1:0.062/1.3e-06, short2long.weight:0.057/1.2e-06, feature_proj.weight:0.034/7.4e-07, 2.bias:0.024/2.9e-05, short_lstm.weight_ih_l0:0.020/3.8e-07, linear2.weight:0.019/4.0e-07, out_proj.weight:0.017/3.7e-07, self_attn.in_proj_weight:0.015/1.6e-07, linear1.weight:0.014/1.5e-07, short_lstm.bias_ih_l0:0.010/9.1e-07, short_lstm.bias_hh_l0:0.010/8.4e-07, short_lstm.weight_ih_l0_reverse:0.010/1.9e-07, weight.original0:0.009/1.9e-07, 0.bias:0.008/1.6e-06, weight.original0:0.008/1.5e-06, short2long.bias:0.007/1.2e-06, short_lstm.weight_hh_l0:0.007/1.1e-07, short_lstm.bias_ih_l0_reverse:0.005/4.7e-07, short_lstm.bias_hh_l0_reverse:0.005/4.5e-07, feature_proj.bias:0.004/7.9e-07, ln_flat.bias:0.004/5.1e-05, ln_proj.bias:0.004/4.5e-05, ln_proj.weight:0.004/5.1e-08, norm2.weight:0.004/5.1e-08, ln_flat.weight:0.004/5.0e-08, out_proj.bias:0.004/3.9e-05, norm1.weight:0.004/4.7e-08, norm2.bias:0.004/3.7e-05, norm1.bias:0.003/3.2e-05, linear2.bias:0.003/1.1e-06, ln_short.weight:0.003/3.2e-08, short_lstm.weight_hh_l0_reverse:0.002/3.8e-08, self_attn.in_proj_bias:0.002/1.6e-05, ln_short.bias:0.002/2.4e-05, linear1.bias:0.002/1.5e-07

E06 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.113,0.000,0.000,0.142] | GD[7.6e-03,3.7e-02,8.7e-02] | UR[8.6e-07,5.4e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.103,0.18,0.071] | VL[0.098,0.21,0.065] | SR=0.016 | SL=0.00,HR=0.000 |  | T=17.5s,TP=98809.8s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:2.168e-02/1.78,weight:6.022e-02/1.07,weight:3.677e-02/1.16] | 
TOP_K(G/U)=weight.original1:0.087/1.6e-05, weight.original1:0.065/1.4e-06, short2long.weight:0.060/1.3e-06, feature_proj.weight:0.037/8.0e-07, 2.bias:0.025/3.1e-05, short_lstm.weight_ih_l0:0.022/4.2e-07, linear2.weight:0.020/4.3e-07, out_proj.weight:0.019/4.0e-07, self_attn.in_proj_weight:0.016/1.7e-07, linear1.weight:0.015/1.7e-07, short_lstm.bias_ih_l0:0.012/1.0e-06, short_lstm.bias_hh_l0:0.012/9.5e-07, short_lstm.weight_ih_l0_reverse:0.011/2.0e-07, weight.original0:0.009/2.0e-07, 0.bias:0.008/1.7e-06, weight.original0:0.008/1.6e-06, short2long.bias:0.008/1.3e-06, short_lstm.weight_hh_l0:0.008/1.2e-07, short_lstm.bias_ih_l0_reverse:0.006/5.2e-07, short_lstm.bias_hh_l0_reverse:0.006/5.0e-07, feature_proj.bias:0.005/8.6e-07, ln_flat.bias:0.004/5.4e-05, ln_proj.bias:0.004/4.8e-05, ln_proj.weight:0.004/5.4e-08, norm2.weight:0.004/5.4e-08, ln_flat.weight:0.004/5.4e-08, out_proj.bias:0.004/4.1e-05, norm1.weight:0.004/5.1e-08, norm2.bias:0.004/3.9e-05, norm1.bias:0.004/3.4e-05, linear2.bias:0.004/1.2e-06, ln_short.weight:0.003/3.6e-08, short_lstm.weight_hh_l0_reverse:0.003/4.3e-08, self_attn.in_proj_bias:0.003/1.6e-05, ln_short.bias:0.003/2.6e-05, linear1.bias:0.002/1.6e-07

E07 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.110,0.000,0.000,0.140] | GD[7.5e-03,3.7e-02,8.5e-02] | UR[8.6e-07,5.4e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.102,0.19,0.070] | VL[0.097,0.21,0.065] | SR=0.016 | SL=0.00,HR=0.000 |  | T=18.3s,TP=94787.0s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:2.186e-02/1.80,weight:5.917e-02/1.05,weight:3.673e-02/1.16] | 
TOP_K(G/U)=weight.original1:0.085/1.6e-05, weight.original1:0.064/1.4e-06, short2long.weight:0.059/1.3e-06, feature_proj.weight:0.037/8.0e-07, 2.bias:0.025/3.0e-05, short_lstm.weight_ih_l0:0.022/4.2e-07, linear2.weight:0.020/4.2e-07, out_proj.weight:0.019/3.9e-07, self_attn.in_proj_weight:0.017/1.7e-07, linear1.weight:0.015/1.7e-07, short_lstm.bias_ih_l0:0.012/1.0e-06, short_lstm.bias_hh_l0:0.012/9.7e-07, short_lstm.weight_ih_l0_reverse:0.011/2.0e-07, weight.original0:0.009/2.0e-07, 0.bias:0.008/1.6e-06, weight.original0:0.008/1.5e-06, short_lstm.weight_hh_l0:0.008/1.2e-07, short2long.bias:0.007/1.3e-06, short_lstm.bias_ih_l0_reverse:0.006/5.2e-07, short_lstm.bias_hh_l0_reverse:0.006/5.0e-07, feature_proj.bias:0.005/8.6e-07, ln_flat.bias:0.004/5.4e-05, ln_proj.bias:0.004/4.8e-05, norm2.weight:0.004/5.4e-08, ln_proj.weight:0.004/5.3e-08, out_proj.bias:0.004/4.1e-05, ln_flat.weight:0.004/5.3e-08, norm1.weight:0.004/5.0e-08, norm2.bias:0.004/3.9e-05, norm1.bias:0.004/3.3e-05, linear2.bias:0.004/1.2e-06, short_lstm.weight_hh_l0_reverse:0.003/4.4e-08, ln_short.weight:0.003/3.6e-08, self_attn.in_proj_bias:0.003/1.6e-05, ln_short.bias:0.003/2.6e-05, linear1.bias:0.002/1.6e-07

E08 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.093,0.000,0.000,0.118] | GD[6.3e-03,3.1e-02,7.2e-02] | UR[7.4e-07,4.5e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.102,0.20,0.070] | VL[0.097,0.22,0.066] | SR=0.017 | SL=0.00,HR=0.000 |  | T=19.0s,TP=91301.5s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:1.872e-02/1.54,weight:4.969e-02/0.88,weight:3.135e-02/0.99] | 
TOP_K(G/U)=weight.original1:0.072/1.4e-05, weight.original1:0.054/1.2e-06, short2long.weight:0.050/1.1e-06, feature_proj.weight:0.031/6.9e-07, 2.bias:0.021/2.5e-05, short_lstm.weight_ih_l0:0.019/3.6e-07, linear2.weight:0.017/3.6e-07, out_proj.weight:0.016/3.4e-07, self_attn.in_proj_weight:0.014/1.5e-07, linear1.weight:0.013/1.4e-07, short_lstm.bias_ih_l0:0.010/8.9e-07, short_lstm.bias_hh_l0:0.010/8.3e-07, short_lstm.weight_ih_l0_reverse:0.009/1.7e-07, weight.original0:0.008/1.7e-07, 0.bias:0.007/1.4e-06, weight.original0:0.007/1.3e-06, short_lstm.weight_hh_l0:0.006/1.0e-07, short2long.bias:0.006/1.1e-06, short_lstm.bias_ih_l0_reverse:0.005/4.5e-07, short_lstm.bias_hh_l0_reverse:0.005/4.3e-07, feature_proj.bias:0.004/7.4e-07, ln_flat.bias:0.004/4.5e-05, ln_proj.bias:0.004/4.0e-05, norm2.weight:0.004/4.6e-08, out_proj.bias:0.004/3.4e-05, ln_proj.weight:0.004/4.5e-08, ln_flat.weight:0.004/4.5e-08, norm1.weight:0.003/4.2e-08, norm2.bias:0.003/3.3e-05, norm1.bias:0.003/2.8e-05, linear2.bias:0.003/1.0e-06, short_lstm.weight_hh_l0_reverse:0.003/3.9e-08, ln_short.weight:0.002/3.1e-08, self_attn.in_proj_bias:0.002/1.3e-05, ln_short.bias:0.002/2.2e-05, linear1.bias:0.002/1.4e-07

E09 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.063,0.000,0.000,0.081] | GD[4.3e-03,2.2e-02,4.9e-02] | UR[5.1e-07,3.1e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.101,0.20,0.070] | VL[0.097,0.23,0.067] | SR=0.017 | SL=0.00,HR=0.000 |  | T=18.0s,TP=96427.1s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:1.302e-02/1.07,weight:3.387e-02/0.60,weight:2.168e-02/0.69] | 
TOP_K(G/U)=weight.original1:0.049/9.3e-06, weight.original1:0.037/7.9e-07, short2long.weight:0.034/7.3e-07, feature_proj.weight:0.022/4.7e-07, 2.bias:0.014/1.7e-05, short_lstm.weight_ih_l0:0.013/2.5e-07, linear2.weight:0.011/2.4e-07, out_proj.weight:0.011/2.3e-07, self_attn.in_proj_weight:0.010/1.0e-07, linear1.weight:0.009/9.7e-08, short_lstm.bias_ih_l0:0.007/6.2e-07, short_lstm.bias_hh_l0:0.007/5.7e-07, short_lstm.weight_ih_l0_reverse:0.006/1.2e-07, weight.original0:0.005/1.1e-07, weight.original0:0.005/9.1e-07, 0.bias:0.005/9.4e-07, short_lstm.weight_hh_l0:0.004/6.8e-08, short2long.bias:0.004/7.4e-07, short_lstm.bias_ih_l0_reverse:0.004/3.1e-07, short_lstm.bias_hh_l0_reverse:0.004/3.0e-07, feature_proj.bias:0.003/5.1e-07, out_proj.bias:0.003/2.4e-05, ln_flat.bias:0.003/3.1e-05, norm2.weight:0.002/3.1e-08, ln_proj.bias:0.002/2.7e-05, ln_proj.weight:0.002/3.1e-08, ln_flat.weight:0.002/3.0e-08, norm1.weight:0.002/2.9e-08, norm2.bias:0.002/2.2e-05, norm1.bias:0.002/1.9e-05, linear2.bias:0.002/7.0e-07, short_lstm.weight_hh_l0_reverse:0.002/2.8e-08, ln_short.weight:0.002/2.2e-08, self_attn.in_proj_bias:0.002/8.5e-06, ln_short.bias:0.002/1.5e-05, linear1.bias:0.001/9.4e-08

E10 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.027,0.000,0.000,0.035] | GD[1.8e-03,9.3e-03,2.1e-02] | UR[2.2e-07,1.3e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.101,0.21,0.070] | VL[0.097,0.23,0.068] | SR=0.018 | SL=0.00,HR=0.000 |  | T=18.6s,TP=92932.0s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:5.878e-03/0.48,weight:1.454e-02/0.26,weight:9.291e-03/0.29] | 
TOP_K(G/U)=weight.original1:0.021/4.0e-06, weight.original1:0.016/3.4e-07, short2long.weight:0.015/3.1e-07, feature_proj.weight:0.009/2.0e-07, 2.bias:0.006/7.4e-06, short_lstm.weight_ih_l0:0.006/1.1e-07, linear2.weight:0.005/1.1e-07, out_proj.weight:0.005/1.0e-07, self_attn.in_proj_weight:0.004/4.4e-08, linear1.weight:0.004/4.3e-08, short_lstm.bias_ih_l0:0.003/2.7e-07, short_lstm.bias_hh_l0:0.003/2.5e-07, short_lstm.weight_ih_l0_reverse:0.003/5.4e-08, weight.original0:0.002/4.9e-08, weight.original0:0.002/4.2e-07, 0.bias:0.002/4.0e-07, short_lstm.weight_hh_l0:0.002/2.9e-08, short2long.bias:0.002/3.2e-07, short_lstm.bias_ih_l0_reverse:0.002/1.3e-07, short_lstm.bias_hh_l0_reverse:0.002/1.3e-07, feature_proj.bias:0.001/2.2e-07, out_proj.bias:0.001/1.0e-05, ln_flat.bias:0.001/1.3e-05, norm2.weight:0.001/1.3e-08, ln_proj.bias:0.001/1.2e-05, ln_proj.weight:0.001/1.3e-08, ln_flat.weight:0.001/1.3e-08, norm1.weight:0.001/1.2e-08, norm2.bias:0.001/9.6e-06, norm1.bias:0.001/8.4e-06, linear2.bias:0.001/3.0e-07, short_lstm.weight_hh_l0_reverse:0.001/1.2e-08, ln_short.weight:0.001/9.3e-09, self_attn.in_proj_bias:0.001/3.5e-06, ln_short.bias:0.001/6.5e-06, linear1.bias:0.000/4.1e-08

------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-10-26T17:53:48.483738Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=... groups=... seq_len_full=... feat=... : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : deterministic single-line dump of snapshot keys (sorted). Notable printed keys below reference exact snapshot field names and formats.
      -> B: number of batch samples used to build windows (snapshot.B)
      -> activation_mb: estimated activation footprint in MB computed from allocation delta (snapshot.activation_mb)
      -> backward_ms: placeholder for backward pass ms (None here; snapshot.backward_ms)
      -> collector_ms: total wall-clock ms spent by the collector (includes sampling, CPU/GPU syncs) (snapshot.collector_ms)
      -> cpu_copy_bytes: bytes copied to host for predictions, shown human-readable in log (snapshot.cpu_copy_bytes)
      -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
      -> device_syncs_count: count of explicit torch.cuda.synchronize() calls used for timing accuracy (snapshot.device_syncs_count)
      -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
      -> expected_segments: nominal B * groups (snapshot.expected_segments)
      -> feat_dim: feature dimension of inputs used to build windows (snapshot.feat_dim)
      -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
      -> gpu_allocated_bytes / gpu_reserved_bytes: raw GPU bytes allocated/reserved (snapshot.gpu_allocated_bytes, snapshot.gpu_reserved_bytes)
      -> gpu_peak_mb / gpu_reserved_mb: peak/reserved GPU memory in MB (snapshot.gpu_peak_mb, snapshot.gpu_reserved_mb)
      -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
      -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
      -> groups: number of logical groups used when flattening windows (snapshot.groups)
      -> mean_seg_len: average per-segment time-series length in timesteps (snapshot.mean_seg_len)
      -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
      -> out_bytes / out_dtype / out_numel / out_shape: model output bytes (human-readable in log), dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
      -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
      -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
      -> pred_extra_ms / preds_cpu_ms: placeholder for extra pred cost and ms to detach+copy preds to CPU (snapshot.pred_extra_ms, snapshot.preds_cpu_ms)
      -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
      -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
      -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
      -> step_block_ms: placeholder for step-block timing if measured (snapshot.step_block_ms)
      -> sum_seg_lens: sum of segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
      -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lrs}|cnts=[c1,c2,...]] : optimizer groups count, compact LR preview (first up to 3) and per-group parameter counts (from optimizer.param_groups)
  GN[reg,cls,ter,tot]      : gradient norms for name-buckets reg/cls/ter and total (sqrt of sum squares over matching named parameters; zero means no matching names found)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, 90th-percentile, and maximum (index-based p90)
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : primary LR token and explicit current lr printed in scientific notation
  TR[rmse,r2,mae]         : training metrics (RMSE, R^2, MAE) reported for the epoch (train_metrics)
  VL[rmse,r2,mae]         : validation metrics (RMSE, R^2, MAE) reported for the epoch (val_metrics)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults to 0.00/0.000 when missing)
  SCHED_PCT={pct:.1f}%     : optional scheduler percent-complete when scheduler exposes _total_steps and a step counter
  T={elapsed:.1f}s,TP={throughput:.1f}s/s : optional epoch elapsed and throughput if model stored _last_epoch_elapsed and _last_epoch_samples
  GPU={GiB:.2f}GiB         : optional high-water GPU memory in GiB when CUDA available (torch.cuda.max_memory_allocated)
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy
  LAYER_GN[...]           : optional small set of monitored layer norms and ratio-to-baseline printed as name_short:curr_norm/ratio
  TOP_K(G/U)=param:grad_norm/update_ratio,... : top-k parameter entries by gradient norm with their update ratios (short names use last two name segments)

BASELINES:
  TRAIN mean RMSE        = 0.04190
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.06583
  VAL   persistence RMSE = 0.01214

HYPERPARAMS:
  LOOK_BACK = 60
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  USE_SHORT_LSTM = True
  SHORT_UNITS = 64
  DROPOUT_SHORT = 0.0
  USE_TRANSFORMER = True
  TRANSFORMER_LAYERS = 1
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_LONG = 0.0
  USE_LONG_LSTM = False
  LONG_UNITS = 64
  FLATTEN_MODE = last
  PRED_HIDDEN = 64
  ALPHA_SMOOTH = 0.1
  MAX_EPOCHS = 90
  EARLY_STOP_PATIENCE = 9
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 5
  ONECYCLE_MAX_LR = 0.001
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 50
  ONECYCLE_PCT_START = 0.2
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 64
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  MICRO_SAMPLE_K = 16

BATCH_SHAPE B=64 groups=451 seq_len_full=60 feat=20
MICRODETAIL ms: B=64 activation_mb=4166 backward_ms=None collector_ms=684.99 cpu_copy_bytes=46KB dataloader_ms=399.33 device_syncs_count=35 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=28864 feat_dim=20 full_forward_ms=55.83 gpu_allocated_bytes=5065MB gpu_peak_mb=6744 gpu_reserved_bytes=13828MB gpu_reserved_mb=13828 grads={'backbone': True, 'head': True} group_nonzero_counts=[36] groups=451 mean_seg_len=2.53 num_segments=23903 out_bytes=46KB out_dtype=torch.float16 out_numel=23903 out_shape=(23903, 1, 1) param_bytes=300KB per_segment_p50_ms=2.24 per_segment_p90_ms=3.33 pred_extra_ms=None preds_cpu_ms=0.28 raw_reg_shape=(23903, 1, 1) segments_per_sec=428140.55 seq_len_full=60 step_block_ms=None sum_seg_lens=134 windows_bytes=109MB

E01 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.121,0.000,0.000,0.164] | GD[8.6e-03,5.3e-02,8.7e-02] | UR[1.1e-06,1.5e-04] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.111,0.04,0.077] | VL[0.099,0.18,0.066] | SR=0.015 | SL=0.00,HR=0.000 |  | T=17.2s,TP=100439.7s/s | GPU=6.59GiB | LAYER_GN[weight_ih_l0:2.374e-02/1.00,weight:6.785e-02/1.00,weight:5.283e-02/1.00] | 
TOP_K(G/U)=weight.original1:0.087/1.9e-06, weight.original1:0.077/1.5e-05, short2long.weight:0.068/1.5e-06, feature_proj.weight:0.053/1.1e-06, linear2.weight:0.034/7.4e-07, out_proj.weight:0.033/7.1e-07, 2.bias:0.032/4.7e-05, short_lstm.weight_ih_l0:0.024/4.5e-07, self_attn.in_proj_weight:0.023/2.3e-07, linear1.weight:0.016/1.8e-07, short_lstm.weight_ih_l0_reverse:0.014/2.8e-07, short_lstm.bias_ih_l0:0.013/1.1e-06, short_lstm.bias_hh_l0:0.013/1.2e-06, 0.bias:0.011/2.0e-06, weight.original0:0.010/1.9e-06, weight.original0:0.009/2.0e-07, short_lstm.weight_hh_l0:0.009/1.3e-07, short2long.bias:0.009/1.7e-06, short_lstm.bias_ih_l0_reverse:0.008/6.4e-07, short_lstm.bias_hh_l0_reverse:0.008/6.9e-07, feature_proj.bias:0.007/1.2e-06, ln_flat.weight:0.007/8.4e-08, ln_proj.weight:0.006/8.1e-08, out_proj.bias:0.006/1.5e-04, norm1.weight:0.006/7.6e-08, norm2.weight:0.006/7.3e-08, ln_flat.bias:0.006/9.6e-05, norm1.bias:0.006/1.4e-04, ln_proj.bias:0.006/1.2e-04, norm2.bias:0.006/1.1e-04, linear2.bias:0.006/1.8e-06, ln_short.weight:0.004/5.3e-08, ln_short.bias:0.004/7.1e-05, self_attn.in_proj_bias:0.003/2.8e-05, linear1.bias:0.002/1.8e-07, short_lstm.weight_hh_l0_reverse:0.002/3.0e-08

E02 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.146,0.000,0.000,0.206] | GD[1.1e-02,7.1e-02,1.0e-01] | UR[1.6e-06,2.0e-04] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.104,0.15,0.073] | VL[0.099,0.19,0.065] | SR=0.017 | SL=0.00,HR=0.000 |  | T=18.7s,TP=92571.4s/s | GPU=8.72GiB *CHKPT | LAYER_GN[weight_ih_l0:3.620e-02/1.53,weight:8.463e-02/1.25,weight:7.091e-02/1.34] | 
TOP_K(G/U)=weight.original1:0.104/2.2e-06, weight.original1:0.092/1.8e-05, short2long.weight:0.085/1.9e-06, feature_proj.weight:0.071/1.5e-06, linear2.weight:0.044/9.4e-07, out_proj.weight:0.043/9.3e-07, 2.bias:0.039/5.7e-05, short_lstm.weight_ih_l0:0.036/6.8e-07, self_attn.in_proj_weight:0.029/2.9e-07, linear1.weight:0.022/2.4e-07, short_lstm.bias_ih_l0:0.020/1.7e-06, short_lstm.bias_hh_l0:0.020/1.9e-06, short_lstm.weight_ih_l0_reverse:0.020/3.9e-07, short_lstm.weight_hh_l0:0.013/2.0e-07, 0.bias:0.013/2.4e-06, short_lstm.bias_ih_l0_reverse:0.011/9.4e-07, short_lstm.bias_hh_l0_reverse:0.011/1.0e-06, weight.original0:0.011/2.4e-07, short2long.bias:0.011/2.2e-06, weight.original0:0.010/2.0e-06, feature_proj.bias:0.009/1.6e-06, out_proj.bias:0.009/2.0e-04, ln_flat.weight:0.008/1.0e-07, ln_proj.weight:0.008/1.0e-07, norm1.weight:0.008/9.7e-08, norm1.bias:0.008/1.8e-04, norm2.weight:0.008/9.4e-08, ln_flat.bias:0.007/1.1e-04, ln_proj.bias:0.007/1.3e-04, norm2.bias:0.007/1.3e-04, linear2.bias:0.007/2.3e-06, ln_short.weight:0.006/7.4e-08, ln_short.bias:0.005/9.8e-05, self_attn.in_proj_bias:0.004/2.7e-05, linear1.bias:0.003/2.4e-07, short_lstm.weight_hh_l0_reverse:0.003/3.9e-08

E03 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.056,0.000,0.000,0.078] | GD[4.3e-03,2.6e-02,4.0e-02] | UR[6.0e-07,7.1e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.101,0.20,0.070] | VL[0.098,0.21,0.067] | SR=0.017 | SL=0.00,HR=0.000 |  | T=18.2s,TP=95283.1s/s | GPU=8.72GiB *CHKPT | LAYER_GN[weight_ih_l0:1.422e-02/0.60,weight:3.136e-02/0.46,weight:2.589e-02/0.49] | 
TOP_K(G/U)=weight.original1:0.040/8.7e-07, weight.original1:0.035/6.8e-06, short2long.weight:0.031/6.9e-07, feature_proj.weight:0.026/5.5e-07, linear2.weight:0.016/3.5e-07, out_proj.weight:0.015/3.4e-07, 2.bias:0.015/2.2e-05, short_lstm.weight_ih_l0:0.014/2.7e-07, self_attn.in_proj_weight:0.010/1.1e-07, linear1.weight:0.008/9.1e-08, short_lstm.weight_ih_l0_reverse:0.008/1.5e-07, short_lstm.bias_ih_l0:0.008/6.5e-07, short_lstm.bias_hh_l0:0.008/7.2e-07, short_lstm.weight_hh_l0:0.005/7.8e-08, 0.bias:0.005/9.2e-07, weight.original0:0.004/8.6e-07, short_lstm.bias_ih_l0_reverse:0.004/3.6e-07, short_lstm.bias_hh_l0_reverse:0.004/3.8e-07, weight.original0:0.004/9.3e-08, short2long.bias:0.004/8.0e-07, feature_proj.bias:0.003/6.0e-07, out_proj.bias:0.003/7.1e-05, ln_flat.weight:0.003/3.9e-08, ln_proj.weight:0.003/3.7e-08, norm1.weight:0.003/3.5e-08, norm1.bias:0.003/6.5e-05, norm2.weight:0.003/3.4e-08, ln_flat.bias:0.003/4.2e-05, ln_proj.bias:0.003/4.9e-05, norm2.bias:0.003/4.7e-05, linear2.bias:0.003/8.6e-07, ln_short.weight:0.002/2.7e-08, ln_short.bias:0.002/3.9e-05, self_attn.in_proj_bias:0.002/9.4e-06, linear1.bias:0.001/9.0e-08, short_lstm.weight_hh_l0_reverse:0.001/1.5e-08

E04 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.010,0.000,0.000,0.014] | GD[7.0e-04,5.0e-03,7.1e-03] | UR[1.1e-07,1.3e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.101,0.21,0.069] | VL[0.098,0.21,0.069] | SR=0.018 | SL=0.00,HR=0.000 |  | T=17.7s,TP=98043.2s/s | GPU=8.72GiB *CHKPT | LAYER_GN[weight_ih_l0:3.034e-03/0.13,weight:5.636e-03/0.08,weight:5.035e-03/0.10] | 
TOP_K(G/U)=weight.original1:0.007/1.5e-07, weight.original1:0.006/1.2e-06, short2long.weight:0.006/1.2e-07, feature_proj.weight:0.005/1.1e-07, short_lstm.weight_ih_l0:0.003/5.7e-08, linear2.weight:0.003/6.4e-08, out_proj.weight:0.003/5.9e-08, 2.bias:0.003/3.8e-06, self_attn.in_proj_weight:0.002/1.9e-08, linear1.weight:0.002/1.9e-08, short_lstm.weight_ih_l0_reverse:0.002/3.3e-08, short_lstm.bias_ih_l0:0.001/1.2e-07, short_lstm.bias_hh_l0:0.001/1.3e-07, short_lstm.weight_hh_l0:0.001/1.5e-08, 0.bias:0.001/1.6e-07, short_lstm.bias_ih_l0_reverse:0.001/6.2e-08, short_lstm.bias_hh_l0_reverse:0.001/6.6e-08, weight.original0:0.001/1.5e-08, short2long.bias:0.001/1.4e-07, weight.original0:0.001/1.2e-07, ln_flat.weight:0.001/7.4e-09, feature_proj.bias:0.001/1.1e-07, ln_proj.weight:0.001/7.3e-09, out_proj.bias:0.001/1.3e-05, norm1.weight:0.001/6.7e-09, norm2.weight:0.001/6.5e-09, ln_flat.bias:0.000/7.4e-06, ln_proj.bias:0.000/8.9e-06, norm1.bias:0.000/1.2e-05, linear2.bias:0.000/1.5e-07, norm2.bias:0.000/7.9e-06, ln_short.weight:0.000/5.1e-09, ln_short.bias:0.000/6.9e-06, self_attn.in_proj_bias:0.000/1.6e-06, linear1.bias:0.000/1.8e-08, short_lstm.weight_hh_l0_reverse:0.000/2.7e-09

E05 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.019,0.000,0.000,0.027] | GD[1.5e-03,9.0e-03,1.3e-02] | UR[2.1e-07,2.5e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.100,0.22,0.069] | VL[0.097,0.22,0.068] | SR=0.018 | SL=0.00,HR=0.000 |  | T=18.1s,TP=95658.7s/s | GPU=8.72GiB | LAYER_GN[weight_ih_l0:5.084e-03/0.21,weight:1.059e-02/0.16,weight:9.018e-03/0.17] | 
TOP_K(G/U)=weight.original1:0.013/2.9e-07, weight.original1:0.012/2.3e-06, short2long.weight:0.011/2.3e-07, feature_proj.weight:0.009/1.9e-07, linear2.weight:0.006/1.2e-07, out_proj.weight:0.005/1.1e-07, short_lstm.weight_ih_l0:0.005/9.6e-08, 2.bias:0.005/7.5e-06, self_attn.in_proj_weight:0.004/3.7e-08, linear1.weight:0.003/3.3e-08, short_lstm.weight_ih_l0_reverse:0.003/5.7e-08, short_lstm.bias_ih_l0:0.003/2.2e-07, short_lstm.bias_hh_l0:0.003/2.5e-07, short_lstm.weight_hh_l0:0.002/2.8e-08, 0.bias:0.002/3.1e-07, short_lstm.bias_ih_l0_reverse:0.002/1.3e-07, short_lstm.bias_hh_l0_reverse:0.002/1.4e-07, weight.original0:0.001/2.9e-07, weight.original0:0.001/3.1e-08, short2long.bias:0.001/2.7e-07, feature_proj.bias:0.001/2.1e-07, ln_flat.weight:0.001/1.3e-08, out_proj.bias:0.001/2.5e-05, ln_proj.weight:0.001/1.3e-08, norm1.weight:0.001/1.2e-08, norm2.weight:0.001/1.2e-08, norm1.bias:0.001/2.2e-05, ln_flat.bias:0.001/1.4e-05, ln_proj.bias:0.001/1.7e-05, linear2.bias:0.001/3.0e-07, norm2.bias:0.001/1.5e-05, ln_short.weight:0.001/9.6e-09, ln_short.bias:0.001/1.3e-05, self_attn.in_proj_bias:0.001/3.0e-06, linear1.bias:0.000/3.3e-08, short_lstm.weight_hh_l0_reverse:0.000/5.7e-09

E06 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.026,0.000,0.000,0.037] | GD[2.0e-03,1.2e-02,1.9e-02] | UR[2.9e-07,3.3e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.100,0.22,0.069] | VL[0.097,0.22,0.067] | SR=0.018 | SL=0.00,HR=0.000 |  | T=18.2s,TP=95179.6s/s | GPU=8.72GiB *CHKPT | LAYER_GN[weight_ih_l0:7.036e-03/0.30,weight:1.473e-02/0.22,weight:1.248e-02/0.24] | 
TOP_K(G/U)=weight.original1:0.019/4.1e-07, weight.original1:0.017/3.2e-06, short2long.weight:0.015/3.2e-07, feature_proj.weight:0.012/2.7e-07, linear2.weight:0.008/1.6e-07, out_proj.weight:0.007/1.6e-07, short_lstm.weight_ih_l0:0.007/1.3e-07, 2.bias:0.007/1.0e-05, self_attn.in_proj_weight:0.005/5.1e-08, linear1.weight:0.004/4.7e-08, short_lstm.weight_ih_l0_reverse:0.004/7.9e-08, short_lstm.bias_ih_l0:0.004/3.2e-07, short_lstm.bias_hh_l0:0.004/3.6e-07, short_lstm.weight_hh_l0:0.003/3.9e-08, 0.bias:0.002/4.3e-07, short_lstm.bias_ih_l0_reverse:0.002/1.9e-07, short_lstm.bias_hh_l0_reverse:0.002/2.0e-07, weight.original0:0.002/4.0e-07, weight.original0:0.002/4.3e-08, short2long.bias:0.002/3.8e-07, feature_proj.bias:0.002/2.9e-07, ln_flat.weight:0.001/1.8e-08, out_proj.bias:0.001/3.3e-05, ln_proj.weight:0.001/1.8e-08, norm1.weight:0.001/1.7e-08, norm2.weight:0.001/1.7e-08, ln_flat.bias:0.001/1.9e-05, norm1.bias:0.001/3.0e-05, ln_proj.bias:0.001/2.3e-05, linear2.bias:0.001/4.1e-07, norm2.bias:0.001/2.1e-05, ln_short.weight:0.001/1.3e-08, ln_short.bias:0.001/1.8e-05, self_attn.in_proj_bias:0.001/3.9e-06, short_lstm.weight_hh_l0_reverse:0.001/8.8e-09, linear1.bias:0.001/4.6e-08

E07 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.035,0.000,0.000,0.049] | GD[2.7e-03,1.7e-02,2.5e-02] | UR[3.8e-07,4.2e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.100,0.22,0.069] | VL[0.097,0.22,0.067] | SR=0.018 | SL=0.00,HR=0.000 |  | T=18.9s,TP=91676.5s/s | GPU=8.72GiB *CHKPT | LAYER_GN[weight_ih_l0:9.393e-03/0.40,weight:1.949e-02/0.29,weight:1.650e-02/0.31] | 
TOP_K(G/U)=weight.original1:0.025/5.4e-07, weight.original1:0.022/4.2e-06, short2long.weight:0.019/4.3e-07, feature_proj.weight:0.017/3.5e-07, linear2.weight:0.010/2.2e-07, out_proj.weight:0.010/2.1e-07, short_lstm.weight_ih_l0:0.009/1.8e-07, 2.bias:0.009/1.4e-05, self_attn.in_proj_weight:0.007/6.8e-08, linear1.weight:0.006/6.2e-08, short_lstm.weight_ih_l0_reverse:0.006/1.1e-07, short_lstm.bias_ih_l0:0.005/4.3e-07, short_lstm.bias_hh_l0:0.005/4.8e-07, short_lstm.weight_hh_l0:0.003/5.2e-08, 0.bias:0.003/5.7e-07, short_lstm.bias_ih_l0_reverse:0.003/2.6e-07, short_lstm.bias_hh_l0_reverse:0.003/2.7e-07, weight.original0:0.003/5.3e-07, weight.original0:0.003/5.7e-08, short2long.bias:0.002/5.0e-07, feature_proj.bias:0.002/3.8e-07, out_proj.bias:0.002/4.2e-05, ln_flat.weight:0.002/2.4e-08, ln_proj.weight:0.002/2.4e-08, norm1.weight:0.002/2.2e-08, norm2.weight:0.002/2.2e-08, ln_flat.bias:0.002/2.5e-05, ln_proj.bias:0.002/3.0e-05, norm1.bias:0.002/3.8e-05, linear2.bias:0.002/5.4e-07, norm2.bias:0.002/2.7e-05, ln_short.weight:0.001/1.8e-08, ln_short.bias:0.001/2.3e-05, self_attn.in_proj_bias:0.001/4.8e-06, short_lstm.weight_hh_l0_reverse:0.001/1.3e-08, linear1.bias:0.001/6.1e-08

E08 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.044,0.000,0.000,0.061] | GD[3.4e-03,2.1e-02,3.1e-02] | UR[4.7e-07,5.1e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.100,0.22,0.069] | VL[0.097,0.22,0.067] | SR=0.018 | SL=0.00,HR=0.000 |  | T=18.8s,TP=91905.4s/s | GPU=8.72GiB *CHKPT | LAYER_GN[weight_ih_l0:1.182e-02/0.50,weight:2.426e-02/0.36,weight:2.050e-02/0.39] | 
TOP_K(G/U)=weight.original1:0.031/6.8e-07, weight.original1:0.027/5.3e-06, short2long.weight:0.024/5.3e-07, feature_proj.weight:0.021/4.4e-07, linear2.weight:0.013/2.7e-07, short_lstm.weight_ih_l0:0.012/2.2e-07, out_proj.weight:0.012/2.6e-07, 2.bias:0.012/1.7e-05, self_attn.in_proj_weight:0.008/8.6e-08, linear1.weight:0.007/7.8e-08, short_lstm.weight_ih_l0_reverse:0.007/1.4e-07, short_lstm.bias_ih_l0:0.007/5.5e-07, short_lstm.bias_hh_l0:0.007/6.1e-07, short_lstm.weight_hh_l0:0.004/6.5e-08, 0.bias:0.004/7.1e-07, short_lstm.bias_ih_l0_reverse:0.004/3.3e-07, short_lstm.bias_hh_l0_reverse:0.004/3.5e-07, weight.original0:0.003/6.7e-07, weight.original0:0.003/7.1e-08, short2long.bias:0.003/6.2e-07, feature_proj.bias:0.003/4.7e-07, out_proj.bias:0.002/5.1e-05, ln_flat.weight:0.002/3.0e-08, ln_proj.weight:0.002/2.9e-08, ln_flat.bias:0.002/3.1e-05, norm2.weight:0.002/2.7e-08, norm1.weight:0.002/2.7e-08, ln_proj.bias:0.002/3.7e-05, norm1.bias:0.002/4.5e-05, linear2.bias:0.002/6.7e-07, norm2.bias:0.002/3.4e-05, ln_short.weight:0.002/2.2e-08, ln_short.bias:0.002/2.8e-05, self_attn.in_proj_bias:0.001/5.6e-06, short_lstm.weight_hh_l0_reverse:0.001/1.7e-08, linear1.bias:0.001/7.7e-08

E09 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.048,0.000,0.000,0.067] | GD[3.8e-03,2.2e-02,3.4e-02] | UR[5.1e-07,5.3e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.100,0.22,0.069] | VL[0.097,0.22,0.066] | SR=0.018 | SL=0.00,HR=0.000 |  | T=18.9s,TP=91633.2s/s | GPU=8.72GiB *CHKPT | LAYER_GN[weight_ih_l0:1.296e-02/0.55,weight:2.642e-02/0.39,weight:2.226e-02/0.42] | 
TOP_K(G/U)=weight.original1:0.034/7.4e-07, weight.original1:0.030/5.8e-06, short2long.weight:0.026/5.8e-07, feature_proj.weight:0.022/4.7e-07, linear2.weight:0.014/2.9e-07, short_lstm.weight_ih_l0:0.013/2.4e-07, 2.bias:0.013/1.9e-05, out_proj.weight:0.013/2.8e-07, self_attn.in_proj_weight:0.009/9.3e-08, linear1.weight:0.008/8.5e-08, short_lstm.weight_ih_l0_reverse:0.008/1.5e-07, short_lstm.bias_ih_l0:0.007/6.0e-07, short_lstm.bias_hh_l0:0.007/6.7e-07, short_lstm.weight_hh_l0:0.005/7.2e-08, short_lstm.bias_ih_l0_reverse:0.004/3.6e-07, short_lstm.bias_hh_l0_reverse:0.004/3.9e-07, 0.bias:0.004/7.8e-07, weight.original0:0.004/7.3e-07, weight.original0:0.004/7.8e-08, short2long.bias:0.003/6.8e-07, feature_proj.bias:0.003/5.1e-07, ln_flat.weight:0.003/3.3e-08, out_proj.bias:0.003/5.3e-05, ln_proj.weight:0.003/3.2e-08, ln_flat.bias:0.002/3.3e-05, ln_proj.bias:0.002/3.9e-05, norm2.weight:0.002/2.9e-08, norm1.weight:0.002/2.9e-08, norm1.bias:0.002/4.6e-05, linear2.bias:0.002/7.3e-07, norm2.bias:0.002/3.6e-05, ln_short.weight:0.002/2.4e-08, ln_short.bias:0.002/3.0e-05, self_attn.in_proj_bias:0.001/5.7e-06, short_lstm.weight_hh_l0_reverse:0.001/2.0e-08, linear1.bias:0.001/8.4e-08

------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-10-26T17:57:23.156972Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=... groups=... seq_len_full=... feat=... : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : deterministic single-line dump of snapshot keys (sorted). Notable printed keys below reference exact snapshot field names and formats.
      -> B: number of batch samples used to build windows (snapshot.B)
      -> activation_mb: estimated activation footprint in MB computed from allocation delta (snapshot.activation_mb)
      -> backward_ms: placeholder for backward pass ms (None here; snapshot.backward_ms)
      -> collector_ms: total wall-clock ms spent by the collector (includes sampling, CPU/GPU syncs) (snapshot.collector_ms)
      -> cpu_copy_bytes: bytes copied to host for predictions, shown human-readable in log (snapshot.cpu_copy_bytes)
      -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
      -> device_syncs_count: count of explicit torch.cuda.synchronize() calls used for timing accuracy (snapshot.device_syncs_count)
      -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
      -> expected_segments: nominal B * groups (snapshot.expected_segments)
      -> feat_dim: feature dimension of inputs used to build windows (snapshot.feat_dim)
      -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
      -> gpu_allocated_bytes / gpu_reserved_bytes: raw GPU bytes allocated/reserved (snapshot.gpu_allocated_bytes, snapshot.gpu_reserved_bytes)
      -> gpu_peak_mb / gpu_reserved_mb: peak/reserved GPU memory in MB (snapshot.gpu_peak_mb, snapshot.gpu_reserved_mb)
      -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
      -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
      -> groups: number of logical groups used when flattening windows (snapshot.groups)
      -> mean_seg_len: average per-segment time-series length in timesteps (snapshot.mean_seg_len)
      -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
      -> out_bytes / out_dtype / out_numel / out_shape: model output bytes (human-readable in log), dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
      -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
      -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
      -> pred_extra_ms / preds_cpu_ms: placeholder for extra pred cost and ms to detach+copy preds to CPU (snapshot.pred_extra_ms, snapshot.preds_cpu_ms)
      -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
      -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
      -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
      -> step_block_ms: placeholder for step-block timing if measured (snapshot.step_block_ms)
      -> sum_seg_lens: sum of segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
      -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lrs}|cnts=[c1,c2,...]] : optimizer groups count, compact LR preview (first up to 3) and per-group parameter counts (from optimizer.param_groups)
  GN[reg,cls,ter,tot]      : gradient norms for name-buckets reg/cls/ter and total (sqrt of sum squares over matching named parameters; zero means no matching names found)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, 90th-percentile, and maximum (index-based p90)
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : primary LR token and explicit current lr printed in scientific notation
  TR[rmse,r2,mae]         : training metrics (RMSE, R^2, MAE) reported for the epoch (train_metrics)
  VL[rmse,r2,mae]         : validation metrics (RMSE, R^2, MAE) reported for the epoch (val_metrics)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults to 0.00/0.000 when missing)
  SCHED_PCT={pct:.1f}%     : optional scheduler percent-complete when scheduler exposes _total_steps and a step counter
  T={elapsed:.1f}s,TP={throughput:.1f}s/s : optional epoch elapsed and throughput if model stored _last_epoch_elapsed and _last_epoch_samples
  GPU={GiB:.2f}GiB         : optional high-water GPU memory in GiB when CUDA available (torch.cuda.max_memory_allocated)
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy
  LAYER_GN[...]           : optional small set of monitored layer norms and ratio-to-baseline printed as name_short:curr_norm/ratio
  TOP_K(G/U)=param:grad_norm/update_ratio,... : top-k parameter entries by gradient norm with their update ratios (short names use last two name segments)

BASELINES:
  TRAIN mean RMSE        = 0.04190
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.06583
  VAL   persistence RMSE = 0.01214

HYPERPARAMS:
  LOOK_BACK = 60
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  USE_SHORT_LSTM = True
  SHORT_UNITS = 64
  DROPOUT_SHORT = 0.0
  USE_TRANSFORMER = True
  TRANSFORMER_LAYERS = 1
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_LONG = 0.0
  USE_LONG_LSTM = False
  LONG_UNITS = 64
  FLATTEN_MODE = last
  PRED_HIDDEN = 64
  ALPHA_SMOOTH = 0.1
  MAX_EPOCHS = 90
  EARLY_STOP_PATIENCE = 9
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 5
  ONECYCLE_MAX_LR = 0.001
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 50
  ONECYCLE_PCT_START = 0.2
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 64
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  MICRO_SAMPLE_K = 16

BATCH_SHAPE B=64 groups=451 seq_len_full=60 feat=20
MICRODETAIL ms: B=64 activation_mb=4166 backward_ms=None collector_ms=965.36 cpu_copy_bytes=46KB dataloader_ms=563.25 device_syncs_count=35 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=28864 feat_dim=20 full_forward_ms=59.55 gpu_allocated_bytes=4800MB gpu_peak_mb=6479 gpu_reserved_bytes=13828MB gpu_reserved_mb=13828 grads={'backbone': True, 'head': True} group_nonzero_counts=[36] groups=451 mean_seg_len=2.53 num_segments=23903 out_bytes=46KB out_dtype=torch.float16 out_numel=23903 out_shape=(23903, 1, 1) param_bytes=300KB per_segment_p50_ms=4.65 per_segment_p90_ms=5.89 pred_extra_ms=None preds_cpu_ms=0.37 raw_reg_shape=(23903, 1, 1) segments_per_sec=401365.50 seq_len_full=60 step_block_ms=None sum_seg_lens=134 windows_bytes=109MB

E01 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.495,0.000,0.000,0.585] | GD[2.0e-02,1.3e-01,3.6e-01] | UR[2.4e-06,2.3e-04] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.247,-3.73,0.171] | VL[0.122,-0.23,0.073] | SR=0.014 | SL=0.00,HR=0.000 |  | T=22.0s,TP=78638.0s/s | GPU=6.33GiB | LAYER_GN[weight_ih_l0:5.324e-02/1.00,weight:2.266e-01/1.00,weight:1.289e-01/1.00] | 
TOP_K(G/U)=weight.original1:0.357/6.1e-05, weight.original1:0.318/6.8e-06, short2long.weight:0.227/4.9e-06, feature_proj.weight:0.129/2.8e-06, 2.bias:0.118/2.3e-04, linear2.weight:0.087/1.9e-06, out_proj.weight:0.071/1.5e-06, self_attn.in_proj_weight:0.057/5.8e-07, short_lstm.weight_ih_l0:0.053/1.0e-06, linear1.weight:0.044/4.8e-07, 0.bias:0.040/8.0e-06, short_lstm.weight_ih_l0_reverse:0.036/6.9e-07, weight.original0:0.035/7.5e-07, short_lstm.bias_ih_l0:0.029/2.6e-06, short_lstm.bias_hh_l0:0.029/2.4e-06, short2long.bias:0.028/5.0e-06, ln_flat.weight:0.020/2.5e-07, ln_proj.weight:0.020/2.5e-07, short_lstm.weight_hh_l0:0.020/3.0e-07, short_lstm.bias_ih_l0_reverse:0.020/1.7e-06, short_lstm.bias_hh_l0_reverse:0.020/1.6e-06, ln_flat.bias:0.019/1.1e-04, ln_proj.bias:0.019/1.1e-04, feature_proj.bias:0.016/2.7e-06, norm2.weight:0.016/2.0e-07, norm2.bias:0.016/9.1e-05, out_proj.bias:0.015/9.1e-05, norm1.bias:0.015/8.7e-05, linear2.bias:0.014/5.1e-06, norm1.weight:0.014/1.7e-07, ln_short.bias:0.009/4.7e-05, self_attn.in_proj_bias:0.008/3.4e-05, ln_short.weight:0.007/9.0e-08, linear1.bias:0.006/5.0e-07, short_lstm.weight_hh_l0_reverse:0.006/8.5e-08, weight.original0:0.004/7.0e-07

E02 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.177,0.000,0.000,0.205] | GD[6.6e-03,4.3e-02,1.3e-01] | UR[7.7e-07,7.9e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.112,0.03,0.078] | VL[0.106,0.06,0.068] | SR=0.012 | SL=0.00,HR=0.000 |  | T=19.0s,TP=91202.6s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:1.806e-02/0.34,weight:7.489e-02/0.33,weight:4.270e-02/0.33] | 
TOP_K(G/U)=weight.original1:0.128/2.2e-05, weight.original1:0.114/2.4e-06, short2long.weight:0.075/1.6e-06, feature_proj.weight:0.043/9.3e-07, 2.bias:0.041/7.9e-05, linear2.weight:0.030/6.4e-07, out_proj.weight:0.024/5.1e-07, self_attn.in_proj_weight:0.019/1.9e-07, short_lstm.weight_ih_l0:0.018/3.5e-07, linear1.weight:0.015/1.6e-07, 0.bias:0.014/2.9e-06, short_lstm.weight_ih_l0_reverse:0.013/2.5e-07, weight.original0:0.013/2.7e-07, short2long.bias:0.009/1.7e-06, short_lstm.bias_ih_l0:0.009/8.3e-07, short_lstm.bias_hh_l0:0.009/7.7e-07, ln_flat.weight:0.007/8.4e-08, short_lstm.bias_ih_l0_reverse:0.007/5.6e-07, short_lstm.bias_hh_l0_reverse:0.007/5.6e-07, ln_proj.weight:0.007/8.2e-08, short_lstm.weight_hh_l0:0.007/1.0e-07, ln_flat.bias:0.006/3.6e-05, ln_proj.bias:0.006/3.6e-05, norm2.weight:0.006/7.1e-08, feature_proj.bias:0.005/9.0e-07, norm2.bias:0.005/3.0e-05, out_proj.bias:0.005/2.9e-05, norm1.bias:0.005/2.8e-05, linear2.bias:0.005/1.7e-06, norm1.weight:0.005/6.0e-08, ln_short.bias:0.003/1.6e-05, self_attn.in_proj_bias:0.003/1.1e-05, ln_short.weight:0.002/3.1e-08, weight.original0:0.002/3.6e-07, short_lstm.weight_hh_l0_reverse:0.002/3.0e-08, linear1.bias:0.002/1.7e-07

E03 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.073,0.000,0.000,0.085] | GD[2.7e-03,1.8e-02,5.3e-02] | UR[3.1e-07,3.2e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.107,0.11,0.075] | VL[0.104,0.11,0.069] | SR=0.012 | SL=0.00,HR=0.000 |  | T=18.0s,TP=96385.5s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:7.967e-03/0.15,weight:3.091e-02/0.14,weight:1.782e-02/0.14] | 
TOP_K(G/U)=weight.original1:0.053/9.1e-06, weight.original1:0.047/1.0e-06, short2long.weight:0.031/6.8e-07, feature_proj.weight:0.018/3.9e-07, 2.bias:0.017/3.2e-05, linear2.weight:0.012/2.7e-07, out_proj.weight:0.010/2.1e-07, short_lstm.weight_ih_l0:0.008/1.5e-07, self_attn.in_proj_weight:0.008/8.1e-08, linear1.weight:0.007/7.2e-08, 0.bias:0.006/1.2e-06, short_lstm.weight_ih_l0_reverse:0.006/1.1e-07, weight.original0:0.005/1.1e-07, short2long.bias:0.004/6.8e-07, short_lstm.bias_ih_l0:0.003/3.1e-07, short_lstm.bias_hh_l0:0.003/2.9e-07, ln_flat.weight:0.003/3.5e-08, short_lstm.weight_hh_l0:0.003/4.1e-08, ln_flat.bias:0.003/1.5e-05, ln_proj.weight:0.003/3.3e-08, ln_proj.bias:0.003/1.4e-05, short_lstm.bias_ih_l0_reverse:0.003/2.1e-07, short_lstm.bias_hh_l0_reverse:0.003/2.1e-07, norm2.weight:0.002/3.0e-08, feature_proj.bias:0.002/3.7e-07, norm2.bias:0.002/1.2e-05, out_proj.bias:0.002/1.2e-05, norm1.bias:0.002/1.2e-05, norm1.weight:0.002/2.5e-08, linear2.bias:0.002/7.1e-07, weight.original0:0.002/3.3e-07, ln_short.bias:0.001/6.6e-06, self_attn.in_proj_bias:0.001/4.5e-06, ln_short.weight:0.001/1.3e-08, linear1.bias:0.001/7.5e-08, short_lstm.weight_hh_l0_reverse:0.001/1.2e-08

E04 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.028,0.000,0.000,0.032] | GD[1.0e-03,7.0e-03,2.0e-02] | UR[1.0e-07,1.2e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.105,0.14,0.073] | VL[0.102,0.14,0.069] | SR=0.012 | SL=0.00,HR=0.000 |  | T=18.3s,TP=94848.5s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:3.665e-03/0.07,weight:1.166e-02/0.05,weight:7.037e-03/0.05] | 
TOP_K(G/U)=weight.original1:0.020/3.5e-06, weight.original1:0.018/3.7e-07, short2long.weight:0.012/2.5e-07, feature_proj.weight:0.007/1.5e-07, 2.bias:0.006/1.2e-05, linear2.weight:0.005/1.0e-07, short_lstm.weight_ih_l0:0.004/7.0e-08, out_proj.weight:0.004/7.7e-08, linear1.weight:0.003/3.3e-08, self_attn.in_proj_weight:0.003/3.1e-08, short_lstm.weight_ih_l0_reverse:0.002/4.8e-08, 0.bias:0.002/4.3e-07, weight.original0:0.002/4.2e-08, weight.original0:0.001/2.5e-07, short2long.bias:0.001/2.5e-07, short_lstm.weight_hh_l0:0.001/1.6e-08, ln_flat.weight:0.001/1.3e-08, short_lstm.bias_ih_l0:0.001/9.0e-08, short_lstm.bias_hh_l0:0.001/8.3e-08, ln_flat.bias:0.001/5.4e-06, ln_proj.bias:0.001/5.3e-06, norm2.weight:0.001/1.2e-08, ln_proj.weight:0.001/1.2e-08, feature_proj.bias:0.001/1.4e-07, norm2.bias:0.001/4.6e-06, norm1.weight:0.001/1.0e-08, norm1.bias:0.001/4.5e-06, out_proj.bias:0.001/4.4e-06, linear2.bias:0.001/2.6e-07, short_lstm.bias_ih_l0_reverse:0.001/6.0e-08, short_lstm.bias_hh_l0_reverse:0.001/6.0e-08, ln_short.bias:0.000/2.6e-06, ln_short.weight:0.000/5.8e-09, self_attn.in_proj_bias:0.000/1.7e-06, linear1.bias:0.000/3.4e-08, short_lstm.weight_hh_l0_reverse:0.000/4.2e-09

E05 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.025,0.000,0.000,0.029] | GD[1.1e-03,6.6e-03,1.8e-02] | UR[1.1e-07,1.1e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.104,0.16,0.072] | VL[0.100,0.16,0.068] | SR=0.013 | SL=0.00,HR=0.000 |  | T=17.7s,TP=97823.8s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:3.717e-03/0.07,weight:1.064e-02/0.05,weight:6.557e-03/0.05] | 
TOP_K(G/U)=weight.original1:0.018/3.2e-06, weight.original1:0.016/3.4e-07, short2long.weight:0.011/2.3e-07, feature_proj.weight:0.007/1.4e-07, 2.bias:0.006/1.1e-05, linear2.weight:0.004/9.5e-08, short_lstm.weight_ih_l0:0.004/7.1e-08, out_proj.weight:0.003/7.3e-08, self_attn.in_proj_weight:0.003/2.9e-08, linear1.weight:0.003/3.0e-08, short_lstm.weight_ih_l0_reverse:0.002/4.6e-08, 0.bias:0.002/3.9e-07, weight.original0:0.002/3.8e-08, weight.original0:0.001/2.3e-07, short2long.bias:0.001/2.3e-07, short_lstm.bias_ih_l0:0.001/1.1e-07, short_lstm.bias_hh_l0:0.001/9.7e-08, short_lstm.weight_hh_l0:0.001/1.7e-08, ln_flat.weight:0.001/1.1e-08, ln_flat.bias:0.001/5.0e-06, norm2.weight:0.001/1.1e-08, ln_proj.bias:0.001/4.9e-06, ln_proj.weight:0.001/1.1e-08, feature_proj.bias:0.001/1.3e-07, short_lstm.bias_ih_l0_reverse:0.001/6.7e-08, short_lstm.bias_hh_l0_reverse:0.001/6.7e-08, norm1.weight:0.001/9.8e-09, norm2.bias:0.001/4.3e-06, norm1.bias:0.001/4.3e-06, out_proj.bias:0.001/4.3e-06, linear2.bias:0.001/2.5e-07, ln_short.bias:0.000/2.6e-06, ln_short.weight:0.000/5.9e-09, self_attn.in_proj_bias:0.000/1.6e-06, linear1.bias:0.000/3.1e-08, short_lstm.weight_hh_l0_reverse:0.000/4.4e-09

E06 | OPTS[1:1.0e-04|cnts=[36]] | GN[0.056,0.000,0.000,0.067] | GD[2.7e-03,1.6e-02,4.1e-02] | UR[3.4e-07,2.5e-05] | LR_MAIN=1.0e-04 | lr=1.0e-04 | TR[0.103,0.18,0.071] | VL[0.100,0.17,0.067] | SR=0.014 | SL=0.00,HR=0.000 |  | T=18.4s,TP=94353.7s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:9.117e-03/0.17,weight:2.430e-02/0.11,weight:1.585e-02/0.12] | 
TOP_K(G/U)=weight.original1:0.041/7.0e-06, weight.original1:0.036/7.6e-07, short2long.weight:0.024/5.3e-07, feature_proj.weight:0.016/3.4e-07, 2.bias:0.013/2.5e-05, linear2.weight:0.010/2.2e-07, short_lstm.weight_ih_l0:0.009/1.8e-07, out_proj.weight:0.009/1.9e-07, self_attn.in_proj_weight:0.007/7.0e-08, linear1.weight:0.007/7.0e-08, short_lstm.weight_ih_l0_reverse:0.005/1.0e-07, 0.bias:0.005/9.0e-07, short_lstm.bias_ih_l0:0.005/4.1e-07, short_lstm.bias_hh_l0:0.005/3.8e-07, weight.original0:0.004/8.5e-08, short_lstm.weight_hh_l0:0.003/4.8e-08, short2long.bias:0.003/5.4e-07, short_lstm.bias_ih_l0_reverse:0.003/2.2e-07, short_lstm.bias_hh_l0_reverse:0.003/2.2e-07, ln_flat.weight:0.002/2.6e-08, ln_flat.bias:0.002/1.2e-05, ln_proj.bias:0.002/1.1e-05, feature_proj.bias:0.002/3.4e-07, ln_proj.weight:0.002/2.5e-08, norm2.weight:0.002/2.5e-08, out_proj.bias:0.002/1.1e-05, norm1.weight:0.002/2.3e-08, norm2.bias:0.002/1.0e-05, norm1.bias:0.002/1.0e-05, linear2.bias:0.002/5.9e-07, weight.original0:0.001/2.6e-07, ln_short.bias:0.001/6.9e-06, ln_short.weight:0.001/1.4e-08, self_attn.in_proj_bias:0.001/4.0e-06, linear1.bias:0.001/7.4e-08, short_lstm.weight_hh_l0_reverse:0.001/1.2e-08

------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-10-26T18:00:02.901195Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=... groups=... seq_len_full=... feat=... : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : deterministic single-line dump of snapshot keys (sorted). Notable printed keys below reference exact snapshot field names and formats.
      -> B: number of batch samples used to build windows (snapshot.B)
      -> activation_mb: estimated activation footprint in MB computed from allocation delta (snapshot.activation_mb)
      -> backward_ms: placeholder for backward pass ms (None here; snapshot.backward_ms)
      -> collector_ms: total wall-clock ms spent by the collector (includes sampling, CPU/GPU syncs) (snapshot.collector_ms)
      -> cpu_copy_bytes: bytes copied to host for predictions, shown human-readable in log (snapshot.cpu_copy_bytes)
      -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
      -> device_syncs_count: count of explicit torch.cuda.synchronize() calls used for timing accuracy (snapshot.device_syncs_count)
      -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
      -> expected_segments: nominal B * groups (snapshot.expected_segments)
      -> feat_dim: feature dimension of inputs used to build windows (snapshot.feat_dim)
      -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
      -> gpu_allocated_bytes / gpu_reserved_bytes: raw GPU bytes allocated/reserved (snapshot.gpu_allocated_bytes, snapshot.gpu_reserved_bytes)
      -> gpu_peak_mb / gpu_reserved_mb: peak/reserved GPU memory in MB (snapshot.gpu_peak_mb, snapshot.gpu_reserved_mb)
      -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
      -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
      -> groups: number of logical groups used when flattening windows (snapshot.groups)
      -> mean_seg_len: average per-segment time-series length in timesteps (snapshot.mean_seg_len)
      -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
      -> out_bytes / out_dtype / out_numel / out_shape: model output bytes (human-readable in log), dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
      -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
      -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
      -> pred_extra_ms / preds_cpu_ms: placeholder for extra pred cost and ms to detach+copy preds to CPU (snapshot.pred_extra_ms, snapshot.preds_cpu_ms)
      -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
      -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
      -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
      -> step_block_ms: placeholder for step-block timing if measured (snapshot.step_block_ms)
      -> sum_seg_lens: sum of segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
      -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lrs}|cnts=[c1,c2,...]] : optimizer groups count, compact LR preview (first up to 3) and per-group parameter counts (from optimizer.param_groups)
  GN[reg,cls,ter,tot]      : gradient norms for name-buckets reg/cls/ter and total (sqrt of sum squares over matching named parameters; zero means no matching names found)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, 90th-percentile, and maximum (index-based p90)
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : primary LR token and explicit current lr printed in scientific notation
  TR[rmse,r2,mae]         : training metrics (RMSE, R^2, MAE) reported for the epoch (train_metrics)
  VL[rmse,r2,mae]         : validation metrics (RMSE, R^2, MAE) reported for the epoch (val_metrics)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults to 0.00/0.000 when missing)
  SCHED_PCT={pct:.1f}%     : optional scheduler percent-complete when scheduler exposes _total_steps and a step counter
  T={elapsed:.1f}s,TP={throughput:.1f}s/s : optional epoch elapsed and throughput if model stored _last_epoch_elapsed and _last_epoch_samples
  GPU={GiB:.2f}GiB         : optional high-water GPU memory in GiB when CUDA available (torch.cuda.max_memory_allocated)
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy
  LAYER_GN[...]           : optional small set of monitored layer norms and ratio-to-baseline printed as name_short:curr_norm/ratio
  TOP_K(G/U)=param:grad_norm/update_ratio,... : top-k parameter entries by gradient norm with their update ratios (short names use last two name segments)

BASELINES:
  TRAIN mean RMSE        = 0.04190
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.06583
  VAL   persistence RMSE = 0.01214

HYPERPARAMS:
  LOOK_BACK = 60
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  USE_SHORT_LSTM = True
  SHORT_UNITS = 64
  DROPOUT_SHORT = 0.0
  USE_TRANSFORMER = True
  TRANSFORMER_LAYERS = 1
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_LONG = 0.0
  USE_LONG_LSTM = False
  LONG_UNITS = 64
  FLATTEN_MODE = last
  PRED_HIDDEN = 64
  ALPHA_SMOOTH = 0.1
  MAX_EPOCHS = 90
  EARLY_STOP_PATIENCE = 9
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 5
  ONECYCLE_MAX_LR = 0.001
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 50
  ONECYCLE_PCT_START = 0.2
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 64
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  MICRO_SAMPLE_K = 16

BATCH_SHAPE B=64 groups=451 seq_len_full=60 feat=20
MICRODETAIL ms: B=64 activation_mb=4166 backward_ms=None collector_ms=1219.52 cpu_copy_bytes=46KB dataloader_ms=919.58 device_syncs_count=35 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=28864 feat_dim=20 full_forward_ms=55.81 gpu_allocated_bytes=4800MB gpu_peak_mb=6479 gpu_reserved_bytes=13828MB gpu_reserved_mb=13828 grads={'backbone': True, 'head': True} group_nonzero_counts=[36] groups=451 mean_seg_len=2.53 num_segments=23903 out_bytes=46KB out_dtype=torch.float16 out_numel=23903 out_shape=(23903, 1, 1) param_bytes=300KB per_segment_p50_ms=1.96 per_segment_p90_ms=2.58 pred_extra_ms=None preds_cpu_ms=0.33 raw_reg_shape=(23903, 1, 1) segments_per_sec=428322.61 seq_len_full=60 step_block_ms=None sum_seg_lens=134 windows_bytes=109MB

E01 | OPTS[1:1.1e-04|cnts=[36]] | GN[0.189,0.000,0.000,0.240] | GD[1.2e-02,6.5e-02,1.4e-01] | UR[1.4e-06,1.6e-04] | LR_MAIN=1.1e-04 | lr=1.1e-04 | TR[0.117,-0.05,0.080] | VL[0.106,0.06,0.070] | SR=0.014 | SL=0.00,HR=0.000 |  | T=20.8s,TP=83271.9s/s | GPU=6.33GiB | LAYER_GN[weight_ih_l0:3.201e-02/1.00,weight:1.021e-01/1.00,weight:6.534e-02/1.00] | 
TOP_K(G/U)=weight.original1:0.137/2.6e-05, weight.original1:0.123/2.8e-06, short2long.weight:0.102/2.3e-06, feature_proj.weight:0.065/1.5e-06, linear2.weight:0.043/9.9e-07, 2.bias:0.038/1.0e-04, short_lstm.weight_ih_l0:0.032/6.6e-07, out_proj.weight:0.027/6.2e-07, self_attn.in_proj_weight:0.026/2.8e-07, short_lstm.weight_ih_l0_reverse:0.024/4.9e-07, linear1.weight:0.022/2.5e-07, short_lstm.bias_ih_l0:0.016/1.5e-06, short_lstm.bias_hh_l0:0.016/1.5e-06, weight.original0:0.016/3.7e-07, 0.bias:0.016/2.9e-06, short2long.bias:0.013/2.3e-06, short_lstm.bias_ih_l0_reverse:0.012/1.1e-06, short_lstm.bias_hh_l0_reverse:0.012/1.1e-06, short_lstm.weight_hh_l0:0.009/1.4e-07, feature_proj.bias:0.008/1.4e-06, ln_flat.bias:0.008/1.6e-04, ln_proj.bias:0.008/1.3e-04, out_proj.bias:0.008/1.1e-04, ln_flat.weight:0.007/9.8e-08, ln_proj.weight:0.007/9.6e-08, norm1.weight:0.007/9.6e-08, norm2.bias:0.007/9.3e-05, norm2.weight:0.007/9.2e-08, norm1.bias:0.007/8.5e-05, linear2.bias:0.007/2.4e-06, ln_short.weight:0.005/6.3e-08, ln_short.bias:0.005/6.7e-05, self_attn.in_proj_bias:0.004/4.6e-05, short_lstm.weight_hh_l0_reverse:0.004/5.8e-08, linear1.bias:0.003/2.7e-07, weight.original0:0.003/4.8e-07

E02 | OPTS[1:1.3e-04|cnts=[36]] | GN[0.147,0.000,0.000,0.189] | GD[9.8e-03,5.1e-02,1.1e-01] | UR[1.3e-06,1.4e-04] | LR_MAIN=1.3e-04 | lr=1.3e-04 | TR[0.106,0.12,0.074] | VL[0.102,0.13,0.069] | SR=0.015 | SL=0.00,HR=0.000 |  | T=19.1s,TP=90605.7s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:3.197e-02/1.00,weight:7.950e-02/0.78,weight:5.127e-02/0.78] | 
TOP_K(G/U)=weight.original1:0.106/2.4e-05, weight.original1:0.096/2.6e-06, short2long.weight:0.079/2.2e-06, feature_proj.weight:0.051/1.4e-06, linear2.weight:0.033/9.1e-07, short_lstm.weight_ih_l0:0.032/7.9e-07, 2.bias:0.030/9.4e-05, out_proj.weight:0.021/5.9e-07, self_attn.in_proj_weight:0.021/2.7e-07, short_lstm.weight_ih_l0_reverse:0.019/4.7e-07, linear1.weight:0.018/2.5e-07, short_lstm.bias_ih_l0:0.017/1.9e-06, short_lstm.bias_hh_l0:0.017/1.9e-06, weight.original0:0.013/3.5e-07, 0.bias:0.012/2.7e-06, short2long.bias:0.010/2.2e-06, short_lstm.bias_ih_l0_reverse:0.010/1.1e-06, short_lstm.bias_hh_l0_reverse:0.010/1.1e-06, short_lstm.weight_hh_l0:0.009/1.7e-07, feature_proj.bias:0.007/1.3e-06, ln_flat.bias:0.006/1.4e-04, ln_proj.bias:0.006/1.1e-04, out_proj.bias:0.006/1.0e-04, ln_flat.weight:0.006/9.0e-08, ln_proj.weight:0.006/8.9e-08, norm1.weight:0.006/8.8e-08, norm2.bias:0.005/8.6e-05, norm1.bias:0.005/7.8e-05, norm2.weight:0.005/8.4e-08, linear2.bias:0.005/2.2e-06, ln_short.weight:0.004/6.4e-08, ln_short.bias:0.004/6.9e-05, self_attn.in_proj_bias:0.003/3.9e-05, short_lstm.weight_hh_l0_reverse:0.003/5.9e-08, linear1.bias:0.002/2.6e-07, weight.original0:0.002/4.9e-07

E03 | OPTS[1:1.6e-04|cnts=[36]] | GN[0.090,0.000,0.000,0.115] | GD[6.1e-03,3.1e-02,6.4e-02] | UR[1.0e-06,1.1e-04] | LR_MAIN=1.6e-04 | lr=1.6e-04 | TR[0.103,0.17,0.072] | VL[0.100,0.17,0.067] | SR=0.016 | SL=0.00,HR=0.000 |  | T=17.6s,TP=98531.5s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:2.128e-02/0.66,weight:4.841e-02/0.47,weight:3.082e-02/0.47] | 
TOP_K(G/U)=weight.original1:0.064/1.8e-05, weight.original1:0.058/2.0e-06, short2long.weight:0.048/1.7e-06, feature_proj.weight:0.031/1.1e-06, short_lstm.weight_ih_l0:0.021/6.6e-07, linear2.weight:0.020/7.0e-07, 2.bias:0.018/7.3e-05, out_proj.weight:0.013/4.5e-07, self_attn.in_proj_weight:0.013/2.1e-07, short_lstm.weight_ih_l0_reverse:0.012/3.6e-07, short_lstm.bias_ih_l0:0.011/1.6e-06, short_lstm.bias_hh_l0:0.011/1.6e-06, linear1.weight:0.011/1.9e-07, weight.original0:0.008/2.7e-07, 0.bias:0.007/2.1e-06, short2long.bias:0.006/1.7e-06, short_lstm.bias_ih_l0_reverse:0.006/8.5e-07, short_lstm.bias_hh_l0_reverse:0.006/8.6e-07, short_lstm.weight_hh_l0:0.006/1.4e-07, ln_flat.bias:0.004/1.1e-04, feature_proj.bias:0.004/1.0e-06, ln_proj.bias:0.004/8.5e-05, out_proj.bias:0.004/8.0e-05, ln_flat.weight:0.003/6.9e-08, ln_proj.weight:0.003/6.8e-08, norm2.bias:0.003/6.5e-05, norm1.weight:0.003/6.7e-08, norm1.bias:0.003/6.2e-05, norm2.weight:0.003/6.5e-08, linear2.bias:0.003/1.7e-06, ln_short.weight:0.003/5.1e-08, ln_short.bias:0.002/5.7e-05, self_attn.in_proj_bias:0.002/2.7e-05, weight.original0:0.002/5.6e-07, short_lstm.weight_hh_l0_reverse:0.002/4.5e-08, linear1.bias:0.001/2.0e-07

E04 | OPTS[1:2.1e-04|cnts=[36]] | GN[0.058,0.000,0.000,0.072] | GD[3.6e-03,1.8e-02,4.2e-02] | UR[7.1e-07,8.3e-05] | LR_MAIN=2.1e-04 | lr=2.1e-04 | TR[0.102,0.19,0.071] | VL[0.101,0.16,0.076] | SR=0.016 | SL=0.00,HR=0.000 |  | T=17.8s,TP=97461.3s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:1.068e-02/0.33,weight:2.884e-02/0.28,weight:1.753e-02/0.27] | 
TOP_K(G/U)=weight.original1:0.042/1.5e-05, weight.original1:0.038/1.7e-06, short2long.weight:0.029/1.3e-06, feature_proj.weight:0.018/7.7e-07, linear2.weight:0.012/5.2e-07, 2.bias:0.012/5.9e-05, short_lstm.weight_ih_l0:0.011/4.2e-07, out_proj.weight:0.007/3.3e-07, self_attn.in_proj_weight:0.007/1.5e-07, short_lstm.bias_ih_l0:0.007/1.2e-06, short_lstm.bias_hh_l0:0.007/1.2e-06, linear1.weight:0.006/1.4e-07, short_lstm.weight_ih_l0_reverse:0.006/2.3e-07, weight.original0:0.005/2.2e-07, 0.bias:0.005/1.7e-06, short_lstm.bias_ih_l0_reverse:0.004/6.4e-07, short_lstm.bias_hh_l0_reverse:0.004/6.5e-07, short2long.bias:0.004/1.2e-06, short_lstm.weight_hh_l0:0.003/1.0e-07, ln_flat.bias:0.002/8.3e-05, ln_proj.bias:0.002/6.2e-05, feature_proj.bias:0.002/7.1e-07, ln_flat.weight:0.002/5.5e-08, ln_proj.weight:0.002/5.4e-08, out_proj.bias:0.002/5.4e-05, norm1.weight:0.002/5.0e-08, norm2.bias:0.002/4.4e-05, norm2.weight:0.002/4.9e-08, norm1.bias:0.002/4.3e-05, linear2.bias:0.002/1.2e-06, ln_short.bias:0.001/4.0e-05, ln_short.weight:0.001/3.3e-08, self_attn.in_proj_bias:0.001/1.6e-05, short_lstm.weight_hh_l0_reverse:0.001/3.1e-08, linear1.bias:0.001/1.5e-07, weight.original0:0.000/7.9e-08

E05 | OPTS[1:2.6e-04|cnts=[36]] | GN[0.087,0.000,0.000,0.110] | GD[5.7e-03,2.7e-02,6.3e-02] | UR[1.4e-06,1.6e-04] | LR_MAIN=2.6e-04 | lr=2.6e-04 | TR[0.101,0.21,0.070] | VL[0.098,0.20,0.069] | SR=0.017 | SL=0.00,HR=0.000 |  | T=18.5s,TP=93506.1s/s | GPU=8.46GiB | LAYER_GN[weight_ih_l0:1.952e-02/0.61,weight:4.436e-02/0.43,weight:2.743e-02/0.42] | 
TOP_K(G/U)=weight.original1:0.063/2.8e-05, weight.original1:0.057/3.2e-06, short2long.weight:0.044/2.5e-06, feature_proj.weight:0.027/1.5e-06, short_lstm.weight_ih_l0:0.020/9.8e-07, linear2.weight:0.018/1.0e-06, 2.bias:0.018/1.1e-04, out_proj.weight:0.012/6.6e-07, self_attn.in_proj_weight:0.012/3.1e-07, short_lstm.bias_ih_l0:0.011/2.6e-06, short_lstm.bias_hh_l0:0.011/2.6e-06, linear1.weight:0.010/2.9e-07, short_lstm.weight_ih_l0_reverse:0.010/5.1e-07, weight.original0:0.008/4.3e-07, 0.bias:0.007/3.2e-06, short_lstm.bias_ih_l0_reverse:0.006/1.3e-06, short_lstm.bias_hh_l0_reverse:0.006/1.3e-06, short_lstm.weight_hh_l0:0.006/2.3e-07, short2long.bias:0.006/2.5e-06, ln_flat.bias:0.004/1.6e-04, ln_proj.bias:0.004/1.2e-04, feature_proj.bias:0.003/1.4e-06, out_proj.bias:0.003/1.1e-04, ln_flat.weight:0.003/1.1e-07, ln_proj.weight:0.003/1.0e-07, norm1.weight:0.003/1.0e-07, norm2.bias:0.003/8.2e-05, norm2.weight:0.003/9.8e-08, norm1.bias:0.003/8.2e-05, linear2.bias:0.003/2.4e-06, ln_short.bias:0.002/8.6e-05, ln_short.weight:0.002/7.1e-08, self_attn.in_proj_bias:0.002/2.7e-05, short_lstm.weight_hh_l0_reverse:0.002/6.8e-08, weight.original0:0.001/6.2e-07, linear1.bias:0.001/3.1e-07

E06 | OPTS[1:3.3e-04|cnts=[36]] | GN[0.053,0.000,0.000,0.068] | GD[3.6e-03,1.7e-02,3.8e-02] | UR[1.2e-06,1.2e-04] | LR_MAIN=3.3e-04 | lr=3.3e-04 | TR[0.100,0.22,0.069] | VL[0.097,0.22,0.067] | SR=0.018 | SL=0.00,HR=0.000 |  | T=18.1s,TP=95492.8s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:1.345e-02/0.42,weight:2.749e-02/0.27,weight:1.724e-02/0.26] | 
TOP_K(G/U)=weight.original1:0.038/2.2e-05, weight.original1:0.035/2.4e-06, short2long.weight:0.027/1.9e-06, feature_proj.weight:0.017/1.2e-06, short_lstm.weight_ih_l0:0.013/8.5e-07, linear2.weight:0.011/7.9e-07, 2.bias:0.011/8.9e-05, short_lstm.bias_ih_l0:0.007/2.1e-06, short_lstm.bias_hh_l0:0.007/2.1e-06, self_attn.in_proj_weight:0.007/2.4e-07, out_proj.weight:0.007/4.9e-07, short_lstm.weight_ih_l0_reverse:0.007/4.2e-07, linear1.weight:0.006/2.3e-07, weight.original0:0.005/3.2e-07, 0.bias:0.004/2.5e-06, short_lstm.weight_hh_l0:0.004/1.8e-07, short_lstm.bias_ih_l0_reverse:0.004/1.0e-06, short_lstm.bias_hh_l0_reverse:0.004/1.0e-06, short2long.bias:0.004/1.9e-06, ln_flat.bias:0.002/1.2e-04, ln_proj.bias:0.002/8.9e-05, feature_proj.bias:0.002/1.2e-06, out_proj.bias:0.002/8.3e-05, ln_flat.weight:0.002/8.1e-08, ln_proj.weight:0.002/8.0e-08, norm1.weight:0.002/7.9e-08, norm2.bias:0.002/6.4e-05, norm2.weight:0.002/7.8e-08, norm1.bias:0.002/6.3e-05, linear2.bias:0.002/2.0e-06, ln_short.weight:0.001/6.0e-08, ln_short.bias:0.001/7.1e-05, weight.original0:0.001/7.8e-07, self_attn.in_proj_bias:0.001/1.8e-05, short_lstm.weight_hh_l0_reverse:0.001/5.7e-08, linear1.bias:0.001/2.5e-07

E07 | OPTS[1:4.0e-04|cnts=[36]] | GN[0.138,0.000,0.000,0.173] | GD[8.8e-03,4.3e-02,1.0e-01] | UR[3.5e-06,3.4e-04] | LR_MAIN=4.0e-04 | lr=4.0e-04 | TR[0.100,0.22,0.069] | VL[0.098,0.21,0.065] | SR=0.017 | SL=0.00,HR=0.000 |  | T=18.7s,TP=92537.2s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:3.378e-02/1.06,weight:6.841e-02/0.67,weight:4.278e-02/0.65] | 
TOP_K(G/U)=weight.original1:0.100/6.8e-05, weight.original1:0.089/7.6e-06, short2long.weight:0.068/5.8e-06, feature_proj.weight:0.043/3.6e-06, short_lstm.weight_ih_l0:0.034/2.6e-06, 2.bias:0.028/2.8e-04, linear2.weight:0.028/2.3e-06, short_lstm.bias_ih_l0:0.019/6.4e-06, short_lstm.bias_hh_l0:0.019/6.6e-06, self_attn.in_proj_weight:0.018/7.3e-07, out_proj.weight:0.017/1.5e-06, linear1.weight:0.016/6.9e-07, short_lstm.weight_ih_l0_reverse:0.016/1.2e-06, weight.original0:0.012/1.0e-06, 0.bias:0.011/7.8e-06, short_lstm.weight_hh_l0:0.009/5.6e-07, short_lstm.bias_ih_l0_reverse:0.009/3.0e-06, short_lstm.bias_hh_l0_reverse:0.009/3.1e-06, short2long.bias:0.009/5.8e-06, ln_flat.bias:0.006/3.4e-04, ln_proj.bias:0.006/2.6e-04, feature_proj.bias:0.006/3.5e-06, out_proj.bias:0.005/2.4e-04, ln_flat.weight:0.005/2.5e-07, ln_proj.weight:0.005/2.5e-07, norm1.weight:0.005/2.4e-07, norm2.bias:0.005/1.8e-04, norm2.weight:0.005/2.3e-07, norm1.bias:0.004/1.7e-04, linear2.bias:0.004/5.8e-06, ln_short.weight:0.004/1.8e-07, ln_short.bias:0.004/2.0e-04, self_attn.in_proj_bias:0.003/4.2e-05, short_lstm.weight_hh_l0_reverse:0.003/1.8e-07, weight.original0:0.002/1.8e-06, linear1.bias:0.002/7.4e-07

E08 | OPTS[1:4.7e-04|cnts=[36]] | GN[0.019,0.000,0.000,0.024] | GD[1.2e-03,5.8e-03,1.4e-02] | UR[5.4e-07,5.0e-05] | LR_MAIN=4.7e-04 | lr=4.7e-04 | TR[0.100,0.23,0.069] | VL[0.096,0.23,0.068] | SR=0.018 | SL=0.00,HR=0.000 |  | T=18.4s,TP=94077.0s/s | GPU=8.46GiB | LAYER_GN[weight_ih_l0:4.756e-03/0.15,weight:9.218e-03/0.09,weight:5.807e-03/0.09] | 
TOP_K(G/U)=weight.original1:0.014/1.1e-05, weight.original1:0.012/1.3e-06, short2long.weight:0.009/9.4e-07, feature_proj.weight:0.006/5.9e-07, short_lstm.weight_ih_l0:0.005/4.3e-07, 2.bias:0.004/4.5e-05, linear2.weight:0.004/3.7e-07, short_lstm.bias_ih_l0:0.003/1.1e-06, short_lstm.bias_hh_l0:0.003/1.1e-06, self_attn.in_proj_weight:0.002/1.2e-07, out_proj.weight:0.002/2.5e-07, linear1.weight:0.002/1.2e-07, short_lstm.weight_ih_l0_reverse:0.002/2.1e-07, weight.original0:0.002/1.7e-07, 0.bias:0.002/1.3e-06, short_lstm.weight_hh_l0:0.001/9.6e-08, short_lstm.bias_ih_l0_reverse:0.001/5.1e-07, short_lstm.bias_hh_l0_reverse:0.001/5.2e-07, short2long.bias:0.001/9.1e-07, ln_flat.bias:0.001/5.0e-05, ln_proj.bias:0.001/4.0e-05, feature_proj.bias:0.001/5.4e-07, ln_flat.weight:0.001/4.1e-08, ln_proj.weight:0.001/4.1e-08, out_proj.bias:0.001/3.6e-05, norm1.weight:0.001/3.7e-08, norm2.bias:0.001/2.5e-05, norm2.weight:0.001/3.6e-08, norm1.bias:0.001/2.6e-05, linear2.bias:0.001/8.9e-07, ln_short.bias:0.000/3.1e-05, ln_short.weight:0.000/2.8e-08, short_lstm.weight_hh_l0_reverse:0.000/3.1e-08, self_attn.in_proj_bias:0.000/5.1e-06, linear1.bias:0.000/1.3e-07, weight.original0:0.000/1.5e-07

E09 | OPTS[1:5.5e-04|cnts=[36]] | GN[0.094,0.000,0.000,0.113] | GD[5.0e-03,2.5e-02,6.9e-02] | UR[2.8e-06,2.7e-04] | LR_MAIN=5.5e-04 | lr=5.5e-04 | TR[0.100,0.23,0.069] | VL[0.097,0.22,0.072] | SR=0.019 | SL=0.00,HR=0.000 |  | T=18.0s,TP=96236.8s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:2.146e-02/0.67,weight:4.185e-02/0.41,weight:2.509e-02/0.38] | 
TOP_K(G/U)=weight.original1:0.069/6.4e-05, weight.original1:0.060/7.1e-06, short2long.weight:0.042/5.0e-06, feature_proj.weight:0.025/2.9e-06, short_lstm.weight_ih_l0:0.021/2.3e-06, 2.bias:0.020/2.7e-04, linear2.weight:0.016/1.8e-06, short_lstm.bias_ih_l0:0.012/5.8e-06, short_lstm.bias_hh_l0:0.012/6.0e-06, self_attn.in_proj_weight:0.010/5.8e-07, out_proj.weight:0.010/1.2e-06, linear1.weight:0.010/5.7e-07, short_lstm.weight_ih_l0_reverse:0.009/9.6e-07, weight.original0:0.008/1.0e-06, 0.bias:0.008/7.2e-06, short_lstm.weight_hh_l0:0.006/5.0e-07, short2long.bias:0.005/4.9e-06, short_lstm.bias_ih_l0_reverse:0.005/2.4e-06, short_lstm.bias_hh_l0_reverse:0.005/2.4e-06, ln_flat.bias:0.004/2.4e-04, ln_proj.bias:0.004/2.0e-04, ln_flat.weight:0.003/2.3e-07, ln_proj.weight:0.003/2.2e-07, feature_proj.bias:0.003/2.8e-06, out_proj.bias:0.003/1.7e-04, norm2.bias:0.003/1.1e-04, norm1.weight:0.003/1.8e-07, norm2.weight:0.003/1.8e-07, linear2.bias:0.003/4.6e-06, norm1.bias:0.003/1.2e-04, ln_short.bias:0.002/1.5e-04, ln_short.weight:0.002/1.4e-07, self_attn.in_proj_bias:0.002/2.1e-05, short_lstm.weight_hh_l0_reverse:0.002/1.4e-07, weight.original0:0.002/1.6e-06, linear1.bias:0.001/6.1e-07

E10 | OPTS[1:6.3e-04|cnts=[36]] | GN[0.170,0.000,0.000,0.201] | GD[8.3e-03,4.1e-02,1.2e-01] | UR[5.2e-06,5.7e-04] | LR_MAIN=6.3e-04 | lr=6.3e-04 | TR[0.100,0.23,0.069] | VL[0.096,0.24,0.067] | SR=0.019 | SL=0.00,HR=0.000 |  | T=18.0s,TP=96127.0s/s | GPU=8.46GiB | LAYER_GN[weight_ih_l0:3.726e-02/1.16,weight:7.150e-02/0.70,weight:4.082e-02/0.62] | 
TOP_K(G/U)=weight.original1:0.125/1.3e-04, weight.original1:0.108/1.5e-05, short2long.weight:0.072/9.7e-06, feature_proj.weight:0.041/5.5e-06, short_lstm.weight_ih_l0:0.037/4.5e-06, 2.bias:0.036/5.7e-04, linear2.weight:0.026/3.4e-06, short_lstm.bias_ih_l0:0.021/1.2e-05, short_lstm.bias_hh_l0:0.021/1.2e-05, self_attn.in_proj_weight:0.017/1.1e-06, out_proj.weight:0.016/2.2e-06, linear1.weight:0.015/1.0e-06, weight.original0:0.015/2.1e-06, short_lstm.weight_ih_l0_reverse:0.015/1.8e-06, 0.bias:0.014/1.5e-05, short_lstm.weight_hh_l0:0.010/9.7e-07, short2long.bias:0.009/9.6e-06, short_lstm.bias_ih_l0_reverse:0.008/4.5e-06, short_lstm.bias_hh_l0_reverse:0.008/4.6e-06, ln_flat.bias:0.007/3.8e-04, ln_proj.bias:0.007/3.5e-04, ln_flat.weight:0.006/4.6e-07, ln_proj.weight:0.006/4.5e-07, feature_proj.bias:0.005/5.2e-06, out_proj.bias:0.005/2.9e-04, norm2.bias:0.005/1.9e-04, norm2.weight:0.004/3.5e-07, norm1.weight:0.004/3.5e-07, linear2.bias:0.004/8.8e-06, norm1.bias:0.004/2.1e-04, weight.original0:0.004/4.5e-06, ln_short.bias:0.003/2.6e-04, ln_short.weight:0.003/2.6e-07, self_attn.in_proj_bias:0.003/3.4e-05, short_lstm.weight_hh_l0_reverse:0.003/2.6e-07, linear1.bias:0.002/1.1e-06

E11 | OPTS[1:7.0e-04|cnts=[36]] | GN[0.010,0.000,0.000,0.013] | GD[5.8e-04,3.9e-03,7.2e-03] | UR[5.4e-07,2.8e-05] | LR_MAIN=7.0e-04 | lr=7.0e-04 | TR[0.099,0.23,0.069] | VL[0.096,0.24,0.064] | SR=0.019 | SL=0.00,HR=0.000 |  | T=18.1s,TP=95736.0s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:3.037e-03/0.09,weight:4.871e-03/0.05,weight:3.950e-03/0.06] | 
TOP_K(G/U)=weight.original1:0.007/1.1e-06, weight.original1:0.007/7.7e-06, short2long.weight:0.005/7.4e-07, feature_proj.weight:0.004/5.9e-07, short_lstm.weight_ih_l0:0.003/4.1e-07, linear1.weight:0.002/1.5e-07, linear2.weight:0.002/2.5e-07, 2.bias:0.002/2.8e-05, self_attn.in_proj_weight:0.002/1.1e-07, short_lstm.bias_ih_l0:0.002/9.4e-07, short_lstm.bias_hh_l0:0.002/9.7e-07, out_proj.weight:0.001/2.2e-07, short_lstm.weight_ih_l0_reverse:0.001/1.7e-07, weight.original0:0.001/1.3e-07, short_lstm.weight_hh_l0:0.001/9.1e-08, 0.bias:0.001/1.0e-06, short_lstm.bias_ih_l0_reverse:0.001/3.5e-07, short_lstm.bias_hh_l0_reverse:0.001/3.6e-07, short2long.bias:0.001/6.2e-07, feature_proj.bias:0.000/5.2e-07, weight.original0:0.000/5.4e-07, ln_flat.bias:0.000/2.2e-05, ln_proj.bias:0.000/2.2e-05, ln_proj.weight:0.000/3.6e-08, ln_flat.weight:0.000/3.5e-08, out_proj.bias:0.000/2.5e-05, norm1.bias:0.000/1.8e-05, ln_short.weight:0.000/2.8e-08, norm2.bias:0.000/1.2e-05, ln_short.bias:0.000/2.0e-05, linear2.bias:0.000/5.9e-07, self_attn.in_proj_bias:0.000/2.8e-06, norm1.weight:0.000/2.2e-08, norm2.weight:0.000/2.1e-08, linear1.bias:0.000/1.5e-07, short_lstm.weight_hh_l0_reverse:0.000/2.4e-08

E12 | OPTS[1:7.8e-04|cnts=[36]] | GN[0.007,0.000,0.000,0.012] | GD[6.1e-04,3.7e-03,6.1e-03] | UR[7.3e-07,3.2e-05] | LR_MAIN=7.8e-04 | lr=7.8e-04 | TR[0.099,0.24,0.069] | VL[0.096,0.24,0.064] | SR=0.020 | SL=0.00,HR=0.000 |  | T=17.8s,TP=97167.5s/s | GPU=8.46GiB | LAYER_GN[weight_ih_l0:3.744e-03/0.12,weight:5.227e-03/0.05,weight:4.399e-03/0.07] | 
TOP_K(G/U)=weight.original1:0.006/1.0e-06, short2long.weight:0.005/8.7e-07, feature_proj.weight:0.004/7.3e-07, short_lstm.weight_ih_l0:0.004/5.6e-07, weight.original1:0.004/4.4e-06, linear1.weight:0.002/1.8e-07, linear2.weight:0.002/3.2e-07, short_lstm.bias_ih_l0:0.002/1.3e-06, short_lstm.bias_hh_l0:0.002/1.3e-06, self_attn.in_proj_weight:0.002/1.4e-07, short_lstm.weight_ih_l0_reverse:0.002/2.6e-07, out_proj.weight:0.002/2.7e-07, short_lstm.weight_hh_l0:0.001/1.2e-07, 2.bias:0.001/1.8e-05, short_lstm.bias_ih_l0_reverse:0.001/5.5e-07, short_lstm.bias_hh_l0_reverse:0.001/5.6e-07, 0.bias:0.001/9.7e-07, short2long.bias:0.001/8.0e-07, feature_proj.bias:0.001/6.8e-07, weight.original0:0.001/7.7e-07, out_proj.bias:0.000/3.2e-05, weight.original0:0.000/8.0e-08, ln_flat.bias:0.000/2.1e-05, ln_proj.bias:0.000/2.1e-05, norm1.bias:0.000/2.2e-05, ln_short.weight:0.000/3.7e-08, ln_proj.weight:0.000/3.7e-08, ln_flat.weight:0.000/3.6e-08, ln_short.bias:0.000/2.5e-05, norm2.bias:0.000/1.5e-05, linear2.bias:0.000/8.7e-07, norm2.weight:0.000/3.0e-08, self_attn.in_proj_bias:0.000/3.2e-06, norm1.weight:0.000/2.7e-08, linear1.bias:0.000/1.9e-07, short_lstm.weight_hh_l0_reverse:0.000/3.1e-08

E13 | OPTS[1:8.4e-04|cnts=[36]] | GN[0.021,0.000,0.000,0.025] | GD[1.3e-03,5.6e-03,1.5e-02] | UR[1.0e-06,1.0e-04] | LR_MAIN=8.4e-04 | lr=8.4e-04 | TR[0.099,0.24,0.068] | VL[0.095,0.25,0.064] | SR=0.020 | SL=0.00,HR=0.000 |  | T=17.7s,TP=98110.5s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:5.489e-03/0.17,weight:9.024e-03/0.09,weight:5.624e-03/0.09] | 
TOP_K(G/U)=weight.original1:0.015/1.9e-05, weight.original1:0.014/2.5e-06, short2long.weight:0.009/1.6e-06, feature_proj.weight:0.006/1.0e-06, short_lstm.weight_ih_l0:0.005/8.8e-07, 2.bias:0.005/1.0e-04, linear2.weight:0.003/5.3e-07, short_lstm.bias_ih_l0:0.003/2.1e-06, short_lstm.bias_hh_l0:0.003/2.2e-06, linear1.weight:0.003/2.3e-07, short_lstm.weight_ih_l0_reverse:0.003/4.1e-07, self_attn.in_proj_weight:0.002/1.8e-07, out_proj.weight:0.002/3.8e-07, 0.bias:0.002/2.6e-06, weight.original0:0.002/3.2e-07, short_lstm.weight_hh_l0:0.001/1.8e-07, short_lstm.bias_ih_l0_reverse:0.001/9.6e-07, short_lstm.bias_hh_l0_reverse:0.001/9.8e-07, short2long.bias:0.001/1.7e-06, ln_flat.bias:0.001/3.8e-05, ln_proj.bias:0.001/4.0e-05, feature_proj.bias:0.001/9.9e-07, ln_flat.weight:0.001/7.8e-08, ln_proj.weight:0.001/7.3e-08, weight.original0:0.001/1.1e-06, out_proj.bias:0.001/4.5e-05, norm2.bias:0.001/2.5e-05, norm1.bias:0.001/3.2e-05, linear2.bias:0.001/1.6e-06, norm2.weight:0.001/5.5e-08, ln_short.bias:0.001/3.3e-05, ln_short.weight:0.001/5.3e-08, norm1.weight:0.000/5.1e-08, self_attn.in_proj_bias:0.000/3.9e-06, short_lstm.weight_hh_l0_reverse:0.000/4.5e-08, linear1.bias:0.000/2.6e-07

E14 | OPTS[1:9.0e-04|cnts=[36]] | GN[0.013,0.000,0.000,0.017] | GD[1.0e-03,4.2e-03,9.3e-03] | UR[7.9e-07,7.4e-05] | LR_MAIN=9.0e-04 | lr=9.0e-04 | TR[0.099,0.24,0.068] | VL[0.095,0.25,0.065] | SR=0.020 | SL=0.00,HR=0.000 |  | T=18.3s,TP=94405.1s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:3.989e-03/0.12,weight:6.130e-03/0.06,weight:4.156e-03/0.06] | 
TOP_K(G/U)=weight.original1:0.009/1.3e-05, weight.original1:0.009/1.7e-06, short2long.weight:0.006/1.2e-06, feature_proj.weight:0.004/7.9e-07, short_lstm.weight_ih_l0:0.004/6.8e-07, 2.bias:0.003/7.4e-05, linear2.weight:0.002/3.8e-07, short_lstm.bias_ih_l0:0.002/1.6e-06, short_lstm.bias_hh_l0:0.002/1.7e-06, linear1.weight:0.002/1.8e-07, short_lstm.weight_ih_l0_reverse:0.002/3.4e-07, self_attn.in_proj_weight:0.002/1.4e-07, out_proj.weight:0.002/3.0e-07, 0.bias:0.001/1.8e-06, weight.original0:0.001/2.2e-07, short_lstm.weight_hh_l0:0.001/1.4e-07, short_lstm.bias_ih_l0_reverse:0.001/7.7e-07, short_lstm.bias_hh_l0_reverse:0.001/7.9e-07, short2long.bias:0.001/1.2e-06, ln_flat.bias:0.001/2.3e-05, ln_proj.bias:0.001/2.5e-05, feature_proj.bias:0.001/7.7e-07, ln_flat.weight:0.001/5.6e-08, out_proj.bias:0.000/3.1e-05, weight.original0:0.000/7.9e-07, ln_proj.weight:0.000/5.3e-08, norm1.bias:0.000/2.2e-05, norm2.bias:0.000/1.6e-05, linear2.bias:0.000/1.1e-06, ln_short.bias:0.000/2.2e-05, ln_short.weight:0.000/4.1e-08, norm2.weight:0.000/3.9e-08, norm1.weight:0.000/3.5e-08, self_attn.in_proj_bias:0.000/2.6e-06, short_lstm.weight_hh_l0_reverse:0.000/3.7e-08, linear1.bias:0.000/2.0e-07

E15 | OPTS[1:9.4e-04|cnts=[36]] | GN[0.013,0.000,0.000,0.016] | GD[9.7e-04,4.0e-03,8.7e-03] | UR[8.0e-07,7.6e-05] | LR_MAIN=9.4e-04 | lr=9.4e-04 | TR[0.099,0.24,0.068] | VL[0.095,0.25,0.064] | SR=0.020 | SL=0.00,HR=0.000 |  | T=19.2s,TP=90390.9s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:3.832e-03/0.12,weight:5.780e-03/0.06,weight:4.011e-03/0.06] | 
TOP_K(G/U)=weight.original1:0.009/1.2e-05, weight.original1:0.009/1.7e-06, short2long.weight:0.006/1.2e-06, feature_proj.weight:0.004/8.0e-07, short_lstm.weight_ih_l0:0.004/6.9e-07, 2.bias:0.003/7.6e-05, linear2.weight:0.002/3.7e-07, short_lstm.bias_ih_l0:0.002/1.6e-06, short_lstm.bias_hh_l0:0.002/1.7e-06, short_lstm.weight_ih_l0_reverse:0.002/3.5e-07, linear1.weight:0.002/1.8e-07, self_attn.in_proj_weight:0.001/1.4e-07, out_proj.weight:0.001/3.0e-07, 0.bias:0.001/1.8e-06, weight.original0:0.001/2.2e-07, short_lstm.bias_ih_l0_reverse:0.001/8.0e-07, short_lstm.bias_hh_l0_reverse:0.001/8.2e-07, short_lstm.weight_hh_l0:0.001/1.4e-07, short2long.bias:0.001/1.2e-06, ln_flat.bias:0.001/1.9e-05, ln_proj.bias:0.001/2.2e-05, feature_proj.bias:0.001/7.7e-07, ln_flat.weight:0.000/5.8e-08, out_proj.bias:0.000/2.9e-05, ln_proj.weight:0.000/5.4e-08, weight.original0:0.000/7.4e-07, norm1.bias:0.000/2.1e-05, norm2.bias:0.000/1.5e-05, linear2.bias:0.000/1.1e-06, ln_short.weight:0.000/4.0e-08, ln_short.bias:0.000/1.9e-05, norm2.weight:0.000/3.7e-08, norm1.weight:0.000/3.4e-08, short_lstm.weight_hh_l0_reverse:0.000/4.0e-08, self_attn.in_proj_bias:0.000/2.4e-06, linear1.bias:0.000/2.0e-07

E16 | OPTS[1:9.7e-04|cnts=[36]] | GN[0.014,0.000,0.000,0.018] | GD[9.3e-04,5.7e-03,9.9e-03] | UR[9.1e-07,6.7e-05] | LR_MAIN=9.7e-04 | lr=9.7e-04 | TR[0.099,0.24,0.068] | VL[0.095,0.25,0.064] | SR=0.020 | SL=0.00,HR=0.000 |  | T=18.8s,TP=92350.9s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:6.285e-03/0.20,weight:5.709e-03/0.06,weight:4.540e-03/0.07] | 
TOP_K(G/U)=weight.original1:0.010/2.1e-06, weight.original1:0.009/1.3e-05, short_lstm.weight_ih_l0:0.006/1.2e-06, short2long.weight:0.006/1.2e-06, feature_proj.weight:0.005/9.4e-07, short_lstm.bias_ih_l0:0.003/2.8e-06, short_lstm.bias_hh_l0:0.003/2.9e-06, 2.bias:0.003/6.7e-05, linear2.weight:0.002/3.5e-07, short_lstm.weight_ih_l0_reverse:0.002/3.5e-07, linear1.weight:0.002/1.8e-07, self_attn.in_proj_weight:0.002/1.7e-07, out_proj.weight:0.002/3.3e-07, short_lstm.weight_hh_l0:0.002/2.3e-07, 0.bias:0.001/1.9e-06, weight.original0:0.001/2.4e-07, short_lstm.bias_ih_l0_reverse:0.001/7.8e-07, short_lstm.bias_hh_l0_reverse:0.001/8.0e-07, short2long.bias:0.001/9.9e-07, feature_proj.bias:0.001/8.4e-07, ln_flat.bias:0.001/1.6e-05, ln_proj.bias:0.001/2.0e-05, ln_proj.weight:0.000/6.1e-08, ln_flat.weight:0.000/5.9e-08, out_proj.bias:0.000/2.8e-05, ln_short.weight:0.000/4.9e-08, ln_short.bias:0.000/2.1e-05, short_lstm.weight_hh_l0_reverse:0.000/5.7e-08, norm1.bias:0.000/1.9e-05, norm1.weight:0.000/4.4e-08, norm2.weight:0.000/4.0e-08, norm2.bias:0.000/1.2e-05, self_attn.in_proj_bias:0.000/2.5e-06, linear2.bias:0.000/9.1e-07, weight.original0:0.000/5.2e-07, linear1.bias:0.000/1.9e-07

E17 | OPTS[1:9.9e-04|cnts=[36]] | GN[0.027,0.000,0.000,0.033] | GD[1.6e-03,9.4e-03,1.9e-02] | UR[1.5e-06,1.6e-04] | LR_MAIN=9.9e-04 | lr=9.9e-04 | TR[0.099,0.24,0.068] | VL[0.095,0.25,0.064] | SR=0.021 | SL=0.00,HR=0.000 |  | T=18.5s,TP=93807.0s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:9.848e-03/0.31,weight:9.434e-03/0.09,weight:6.464e-03/0.10] | 
TOP_K(G/U)=weight.original1:0.019/2.7e-05, weight.original1:0.018/3.8e-06, short_lstm.weight_ih_l0:0.010/1.9e-06, short2long.weight:0.009/2.0e-06, 2.bias:0.007/1.6e-04, feature_proj.weight:0.006/1.4e-06, short_lstm.bias_ih_l0:0.005/4.6e-06, short_lstm.bias_hh_l0:0.005/4.8e-06, short_lstm.weight_ih_l0_reverse:0.003/5.9e-07, linear2.weight:0.003/5.6e-07, self_attn.in_proj_weight:0.002/2.4e-07, short_lstm.weight_hh_l0:0.002/3.6e-07, linear1.weight:0.002/2.5e-07, weight.original0:0.002/5.0e-07, 0.bias:0.002/3.8e-06, out_proj.weight:0.002/4.8e-07, short_lstm.bias_ih_l0_reverse:0.002/1.4e-06, short_lstm.bias_hh_l0_reverse:0.002/1.4e-06, short2long.bias:0.001/1.8e-06, ln_flat.bias:0.001/2.8e-05, ln_proj.bias:0.001/3.4e-05, ln_proj.weight:0.001/1.0e-07, weight.original0:0.001/1.5e-06, ln_flat.weight:0.001/1.0e-07, feature_proj.bias:0.001/1.2e-06, out_proj.bias:0.001/4.0e-05, ln_short.bias:0.001/3.0e-05, ln_short.weight:0.001/7.5e-08, norm1.weight:0.001/7.2e-08, norm2.weight:0.001/7.0e-08, norm2.bias:0.001/2.0e-05, norm1.bias:0.001/2.9e-05, short_lstm.weight_hh_l0_reverse:0.001/8.3e-08, linear2.bias:0.000/1.6e-06, self_attn.in_proj_bias:0.000/3.3e-06, linear1.bias:0.000/2.6e-07

------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-10-26T18:08:12.998235Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=... groups=... seq_len_full=... feat=... : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : deterministic single-line dump of snapshot keys (sorted). Notable printed keys below reference exact snapshot field names and formats.
      -> B: number of batch samples used to build windows (snapshot.B)
      -> activation_mb: estimated activation footprint in MB computed from allocation delta (snapshot.activation_mb)
      -> backward_ms: placeholder for backward pass ms (None here; snapshot.backward_ms)
      -> collector_ms: total wall-clock ms spent by the collector (includes sampling, CPU/GPU syncs) (snapshot.collector_ms)
      -> cpu_copy_bytes: bytes copied to host for predictions, shown human-readable in log (snapshot.cpu_copy_bytes)
      -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
      -> device_syncs_count: count of explicit torch.cuda.synchronize() calls used for timing accuracy (snapshot.device_syncs_count)
      -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
      -> expected_segments: nominal B * groups (snapshot.expected_segments)
      -> feat_dim: feature dimension of inputs used to build windows (snapshot.feat_dim)
      -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
      -> gpu_allocated_bytes / gpu_reserved_bytes: raw GPU bytes allocated/reserved (snapshot.gpu_allocated_bytes, snapshot.gpu_reserved_bytes)
      -> gpu_peak_mb / gpu_reserved_mb: peak/reserved GPU memory in MB (snapshot.gpu_peak_mb, snapshot.gpu_reserved_mb)
      -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
      -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
      -> groups: number of logical groups used when flattening windows (snapshot.groups)
      -> mean_seg_len: average per-segment time-series length in timesteps (snapshot.mean_seg_len)
      -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
      -> out_bytes / out_dtype / out_numel / out_shape: model output bytes (human-readable in log), dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
      -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
      -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
      -> pred_extra_ms / preds_cpu_ms: placeholder for extra pred cost and ms to detach+copy preds to CPU (snapshot.pred_extra_ms, snapshot.preds_cpu_ms)
      -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
      -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
      -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
      -> step_block_ms: placeholder for step-block timing if measured (snapshot.step_block_ms)
      -> sum_seg_lens: sum of segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
      -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lrs}|cnts=[c1,c2,...]] : optimizer groups count, compact LR preview (first up to 3) and per-group parameter counts (from optimizer.param_groups)
  GN[reg,cls,ter,tot]      : gradient norms for name-buckets reg/cls/ter and total (sqrt of sum squares over matching named parameters; zero means no matching names found)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, 90th-percentile, and maximum (index-based p90)
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : primary LR token and explicit current lr printed in scientific notation
  TR[rmse,r2,mae]         : training metrics (RMSE, R^2, MAE) reported for the epoch (train_metrics)
  VL[rmse,r2,mae]         : validation metrics (RMSE, R^2, MAE) reported for the epoch (val_metrics)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults to 0.00/0.000 when missing)
  SCHED_PCT={pct:.1f}%     : optional scheduler percent-complete when scheduler exposes _total_steps and a step counter
  T={elapsed:.1f}s,TP={throughput:.1f}s/s : optional epoch elapsed and throughput if model stored _last_epoch_elapsed and _last_epoch_samples
  GPU={GiB:.2f}GiB         : optional high-water GPU memory in GiB when CUDA available (torch.cuda.max_memory_allocated)
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy
  LAYER_GN[...]           : optional small set of monitored layer norms and ratio-to-baseline printed as name_short:curr_norm/ratio
  TOP_K(G/U)=param:grad_norm/update_ratio,... : top-k parameter entries by gradient norm with their update ratios (short names use last two name segments)

BASELINES:
  TRAIN mean RMSE        = 0.04190
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.06583
  VAL   persistence RMSE = 0.01214

HYPERPARAMS:
  LOOK_BACK = 60
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  USE_SHORT_LSTM = True
  SHORT_UNITS = 64
  DROPOUT_SHORT = 0.0
  USE_TRANSFORMER = True
  TRANSFORMER_LAYERS = 1
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_LONG = 0.0
  USE_LONG_LSTM = False
  LONG_UNITS = 64
  FLATTEN_MODE = last
  PRED_HIDDEN = 64
  ALPHA_SMOOTH = 0.1
  MAX_EPOCHS = 90
  EARLY_STOP_PATIENCE = 9
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 5
  ONECYCLE_MAX_LR = 0.001
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 50
  ONECYCLE_PCT_START = 0.2
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 64
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  MICRO_SAMPLE_K = 16

BATCH_SHAPE B=64 groups=451 seq_len_full=60 feat=20
MICRODETAIL ms: B=64 activation_mb=4166 backward_ms=None collector_ms=981.68 cpu_copy_bytes=46KB dataloader_ms=721.65 device_syncs_count=35 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=28864 feat_dim=20 full_forward_ms=55.90 gpu_allocated_bytes=4932MB gpu_peak_mb=6611 gpu_reserved_bytes=13962MB gpu_reserved_mb=13962 grads={'backbone': True, 'head': True} group_nonzero_counts=[36] groups=451 mean_seg_len=2.53 num_segments=23903 out_bytes=46KB out_dtype=torch.float16 out_numel=23903 out_shape=(23903, 1, 1) param_bytes=300KB per_segment_p50_ms=4.28 per_segment_p90_ms=5.50 pred_extra_ms=None preds_cpu_ms=0.32 raw_reg_shape=(23903, 1, 1) segments_per_sec=427565.01 seq_len_full=60 step_block_ms=None sum_seg_lens=134 windows_bytes=109MB

E01 | OPTS[1:1.1e-04|cnts=[36]] | GN[0.141,0.000,0.000,0.185] | GD[8.3e-03,5.3e-02,9.7e-02] | UR[1.1e-06,8.6e-05] | LR_MAIN=1.1e-04 | lr=1.1e-04 | TR[0.133,-0.38,0.092] | VL[0.105,0.08,0.067] | SR=0.019 | SL=0.00,HR=0.000 |  | T=18.7s,TP=92640.4s/s | GPU=6.46GiB | LAYER_GN[weight_ih_l0:2.421e-02/1.00,weight:7.940e-02/1.00,weight:5.340e-02/1.00] | 
TOP_K(G/U)=weight.original1:0.097/1.7e-05, weight.original1:0.094/2.2e-06, short2long.weight:0.079/1.8e-06, feature_proj.weight:0.053/1.2e-06, linear2.weight:0.038/8.9e-07, 2.bias:0.034/3.5e-05, out_proj.weight:0.030/6.9e-07, self_attn.in_proj_weight:0.026/2.9e-07, short_lstm.weight_ih_l0:0.024/5.1e-07, linear1.weight:0.017/2.0e-07, short_lstm.weight_ih_l0_reverse:0.015/3.1e-07, weight.original0:0.015/3.4e-07, short_lstm.bias_ih_l0:0.012/1.1e-06, short_lstm.bias_hh_l0:0.012/1.1e-06, 0.bias:0.012/2.2e-06, weight.original0:0.011/1.9e-06, short2long.bias:0.010/1.8e-06, short_lstm.weight_hh_l0:0.008/1.4e-07, short_lstm.bias_ih_l0_reverse:0.008/7.5e-07, short_lstm.bias_hh_l0_reverse:0.008/6.9e-07, feature_proj.bias:0.007/1.3e-06, out_proj.bias:0.007/8.6e-05, ln_flat.weight:0.006/8.6e-08, ln_flat.bias:0.006/8.5e-05, ln_proj.bias:0.006/8.1e-05, ln_proj.weight:0.006/8.0e-08, norm2.bias:0.006/7.8e-05, norm1.bias:0.005/7.0e-05, linear2.bias:0.005/2.0e-06, norm2.weight:0.005/6.6e-08, norm1.weight:0.005/6.3e-08, self_attn.in_proj_bias:0.004/4.2e-05, ln_short.bias:0.004/4.2e-05, ln_short.weight:0.003/3.8e-08, short_lstm.weight_hh_l0_reverse:0.002/4.1e-08, linear1.bias:0.002/2.0e-07

------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-10-26T18:09:51.707761Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=... groups=... seq_len_full=... feat=... : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : deterministic single-line dump of snapshot keys (sorted). Notable printed keys below reference exact snapshot field names and formats.
      -> B: number of batch samples used to build windows (snapshot.B)
      -> activation_mb: estimated activation footprint in MB computed from allocation delta (snapshot.activation_mb)
      -> backward_ms: placeholder for backward pass ms (None here; snapshot.backward_ms)
      -> collector_ms: total wall-clock ms spent by the collector (includes sampling, CPU/GPU syncs) (snapshot.collector_ms)
      -> cpu_copy_bytes: bytes copied to host for predictions, shown human-readable in log (snapshot.cpu_copy_bytes)
      -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
      -> device_syncs_count: count of explicit torch.cuda.synchronize() calls used for timing accuracy (snapshot.device_syncs_count)
      -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
      -> expected_segments: nominal B * groups (snapshot.expected_segments)
      -> feat_dim: feature dimension of inputs used to build windows (snapshot.feat_dim)
      -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
      -> gpu_allocated_bytes / gpu_reserved_bytes: raw GPU bytes allocated/reserved (snapshot.gpu_allocated_bytes, snapshot.gpu_reserved_bytes)
      -> gpu_peak_mb / gpu_reserved_mb: peak/reserved GPU memory in MB (snapshot.gpu_peak_mb, snapshot.gpu_reserved_mb)
      -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
      -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
      -> groups: number of logical groups used when flattening windows (snapshot.groups)
      -> mean_seg_len: average per-segment time-series length in timesteps (snapshot.mean_seg_len)
      -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
      -> out_bytes / out_dtype / out_numel / out_shape: model output bytes (human-readable in log), dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
      -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
      -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
      -> pred_extra_ms / preds_cpu_ms: placeholder for extra pred cost and ms to detach+copy preds to CPU (snapshot.pred_extra_ms, snapshot.preds_cpu_ms)
      -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
      -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
      -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
      -> step_block_ms: placeholder for step-block timing if measured (snapshot.step_block_ms)
      -> sum_seg_lens: sum of segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
      -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lrs}|cnts=[c1,c2,...]] : optimizer groups count, compact LR preview (first up to 3) and per-group parameter counts (from optimizer.param_groups)
  GN[reg,cls,ter,tot]      : gradient norms for name-buckets reg/cls/ter and total (sqrt of sum squares over matching named parameters; zero means no matching names found)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, 90th-percentile, and maximum (index-based p90)
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : primary LR token and explicit current lr printed in scientific notation
  TR[rmse,r2,mae]         : training metrics (RMSE, R^2, MAE) reported for the epoch (train_metrics)
  VL[rmse,r2,mae]         : validation metrics (RMSE, R^2, MAE) reported for the epoch (val_metrics)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults to 0.00/0.000 when missing)
  SCHED_PCT={pct:.1f}%     : optional scheduler percent-complete when scheduler exposes _total_steps and a step counter
  T={elapsed:.1f}s,TP={throughput:.1f}s/s : optional epoch elapsed and throughput if model stored _last_epoch_elapsed and _last_epoch_samples
  GPU={GiB:.2f}GiB         : optional high-water GPU memory in GiB when CUDA available (torch.cuda.max_memory_allocated)
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy
  LAYER_GN[...]           : optional small set of monitored layer norms and ratio-to-baseline printed as name_short:curr_norm/ratio
  TOP_K(G/U)=param:grad_norm/update_ratio,... : top-k parameter entries by gradient norm with their update ratios (short names use last two name segments)

BASELINES:
  TRAIN mean RMSE        = 0.04190
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.06583
  VAL   persistence RMSE = 0.01214

HYPERPARAMS:
  LOOK_BACK = 60
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  USE_SHORT_LSTM = True
  SHORT_UNITS = 64
  DROPOUT_SHORT = 0.0
  USE_TRANSFORMER = True
  TRANSFORMER_LAYERS = 1
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_LONG = 0.0
  USE_LONG_LSTM = False
  LONG_UNITS = 64
  FLATTEN_MODE = last
  PRED_HIDDEN = 64
  ALPHA_SMOOTH = 0.1
  MAX_EPOCHS = 90
  EARLY_STOP_PATIENCE = 9
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 5
  ONECYCLE_MAX_LR = 0.001
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 50
  ONECYCLE_PCT_START = 0.2
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 64
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  MICRO_SAMPLE_K = 16

BATCH_SHAPE B=64 groups=451 seq_len_full=60 feat=20
MICRODETAIL ms: B=64 activation_mb=4166 backward_ms=None collector_ms=850.92 cpu_copy_bytes=46KB dataloader_ms=618.50 device_syncs_count=35 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=28864 feat_dim=20 full_forward_ms=56.77 gpu_allocated_bytes=4800MB gpu_peak_mb=6479 gpu_reserved_bytes=13828MB gpu_reserved_mb=13828 grads={'backbone': True, 'head': True} group_nonzero_counts=[36] groups=451 mean_seg_len=2.53 num_segments=23903 out_bytes=46KB out_dtype=torch.float16 out_numel=23903 out_shape=(23903, 1, 1) param_bytes=300KB per_segment_p50_ms=1.74 per_segment_p90_ms=2.31 pred_extra_ms=None preds_cpu_ms=0.29 raw_reg_shape=(23903, 1, 1) segments_per_sec=421054.72 seq_len_full=60 step_block_ms=None sum_seg_lens=134 windows_bytes=109MB

E01 | OPTS[1:1.1e-04|cnts=[36]] | GN[0.049,0.000,0.000,0.065] | GD[2.5e-03,1.7e-02,3.4e-02] | UR[3.9e-07,4.8e-05] | LR_MAIN=1.1e-04 | lr=1.1e-04 | TR[0.107,0.11,0.074] | VL[0.099,0.18,0.070] | SR=0.017 | SL=0.00,HR=0.000 |  | T=26.9s,TP=64369.6s/s | GPU=6.33GiB | LAYER_GN[weight_ih_l0:1.020e-02/1.00,weight:2.913e-02/1.00,weight:1.694e-02/1.00] | 
TOP_K(G/U)=weight.original1:0.034/7.8e-07, weight.original1:0.034/6.6e-06, short2long.weight:0.029/6.8e-07, feature_proj.weight:0.017/3.9e-07, linear2.weight:0.012/2.8e-07, 2.bias:0.011/3.5e-05, short_lstm.weight_ih_l0:0.010/2.1e-07, out_proj.weight:0.010/2.3e-07, self_attn.in_proj_weight:0.007/7.1e-08, short_lstm.bias_ih_l0:0.006/5.9e-07, short_lstm.bias_hh_l0:0.006/5.7e-07, linear1.weight:0.006/6.8e-08, 0.bias:0.004/7.9e-07, short_lstm.weight_ih_l0_reverse:0.004/8.3e-08, weight.original0:0.004/8.7e-08, short2long.bias:0.004/6.7e-07, short_lstm.weight_hh_l0:0.004/5.8e-08, short_lstm.bias_ih_l0_reverse:0.002/2.3e-07, short_lstm.bias_hh_l0_reverse:0.002/2.3e-07, feature_proj.bias:0.002/4.0e-07, ln_flat.bias:0.002/4.8e-05, ln_proj.bias:0.002/4.3e-05, out_proj.bias:0.002/3.6e-05, ln_flat.weight:0.002/2.7e-08, norm2.weight:0.002/2.7e-08, norm2.bias:0.002/3.5e-05, ln_proj.weight:0.002/2.6e-08, norm1.weight:0.002/2.5e-08, norm1.bias:0.002/3.3e-05, linear2.bias:0.002/6.7e-07, ln_short.weight:0.001/1.7e-08, ln_short.bias:0.001/2.3e-05, self_attn.in_proj_bias:0.001/1.4e-05, linear1.bias:0.001/6.5e-08, short_lstm.weight_hh_l0_reverse:0.001/1.0e-08, weight.original0:0.001/1.2e-07

E02 | OPTS[1:1.3e-04|cnts=[36]] | GN[0.005,0.000,0.000,0.008] | GD[3.6e-04,2.5e-03,4.5e-03] | UR[6.9e-08,7.5e-06] | LR_MAIN=1.3e-04 | lr=1.3e-04 | TR[0.102,0.19,0.071] | VL[0.098,0.19,0.068] | SR=0.017 | SL=0.00,HR=0.000 |  | T=23.1s,TP=74872.3s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:2.125e-03/0.21,weight:4.455e-03/0.15,weight:3.133e-03/0.18] | 
TOP_K(G/U)=short2long.weight:0.004/1.2e-07, weight.original1:0.004/1.2e-07, feature_proj.weight:0.003/8.6e-08, weight.original1:0.002/5.8e-07, short_lstm.weight_ih_l0:0.002/5.3e-08, linear2.weight:0.002/5.1e-08, out_proj.weight:0.001/3.9e-08, linear1.weight:0.001/1.7e-08, self_attn.in_proj_weight:0.001/1.4e-08, short_lstm.weight_ih_l0_reverse:0.001/2.7e-08, short_lstm.bias_ih_l0:0.001/8.8e-08, short_lstm.bias_hh_l0:0.001/8.5e-08, short_lstm.weight_hh_l0:0.001/1.1e-08, short2long.bias:0.001/1.1e-07, 0.bias:0.000/9.9e-08, 2.bias:0.000/1.5e-06, ln_proj.weight:0.000/5.8e-09, ln_flat.weight:0.000/5.6e-09, short_lstm.bias_ih_l0_reverse:0.000/3.9e-08, short_lstm.bias_hh_l0_reverse:0.000/4.0e-08, weight.original0:0.000/9.8e-09, norm1.weight:0.000/5.4e-09, feature_proj.bias:0.000/6.9e-08, norm2.weight:0.000/4.8e-09, ln_flat.bias:0.000/7.5e-06, ln_proj.bias:0.000/6.6e-06, out_proj.bias:0.000/6.0e-06, norm2.bias:0.000/5.4e-06, ln_short.weight:0.000/4.3e-09, norm1.bias:0.000/5.4e-06, linear2.bias:0.000/1.1e-07, weight.original0:0.000/5.0e-08, ln_short.bias:0.000/3.8e-06, self_attn.in_proj_bias:0.000/2.0e-06, linear1.bias:0.000/1.6e-08, short_lstm.weight_hh_l0_reverse:0.000/2.5e-09

E03 | OPTS[1:1.6e-04|cnts=[36]] | GN[0.163,0.000,0.000,0.208] | GD[7.3e-03,5.4e-02,1.1e-01] | UR[1.9e-06,1.9e-04] | LR_MAIN=1.6e-04 | lr=1.6e-04 | TR[0.102,0.19,0.071] | VL[0.098,0.20,0.066] | SR=0.016 | SL=0.00,HR=0.000 |  | T=22.4s,TP=77280.4s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:3.621e-02/3.55,weight:8.836e-02/3.03,weight:5.436e-02/3.21] | 
TOP_K(G/U)=weight.original1:0.112/3.3e-05, weight.original1:0.110/3.8e-06, short2long.weight:0.088/3.1e-06, feature_proj.weight:0.054/1.9e-06, 2.bias:0.040/1.8e-04, linear2.weight:0.037/1.3e-06, short_lstm.weight_ih_l0:0.036/1.1e-06, out_proj.weight:0.030/1.1e-06, self_attn.in_proj_weight:0.020/3.3e-07, short_lstm.bias_ih_l0:0.020/2.8e-06, short_lstm.bias_hh_l0:0.020/2.7e-06, linear1.weight:0.018/3.1e-07, 0.bias:0.014/3.9e-06, short_lstm.weight_ih_l0_reverse:0.013/4.1e-07, short_lstm.weight_hh_l0:0.012/2.9e-07, weight.original0:0.012/4.2e-07, short2long.bias:0.011/3.1e-06, short_lstm.bias_ih_l0_reverse:0.007/1.0e-06, short_lstm.bias_hh_l0_reverse:0.007/1.0e-06, feature_proj.bias:0.007/2.0e-06, ln_flat.bias:0.007/1.9e-04, ln_proj.bias:0.007/1.7e-04, out_proj.bias:0.007/1.6e-04, ln_flat.weight:0.006/1.3e-07, norm2.bias:0.006/1.4e-04, norm1.weight:0.006/1.2e-07, norm2.weight:0.006/1.2e-07, ln_proj.weight:0.006/1.2e-07, norm1.bias:0.006/1.4e-04, linear2.bias:0.006/3.1e-06, ln_short.weight:0.004/8.9e-08, ln_short.bias:0.004/9.3e-05, self_attn.in_proj_bias:0.003/3.0e-05, weight.original0:0.003/8.5e-07, linear1.bias:0.002/3.0e-07, short_lstm.weight_hh_l0_reverse:0.002/4.5e-08

------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-10-26T18:12:25.047426Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=... groups=... seq_len_full=... feat=... : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : deterministic single-line dump of snapshot keys (sorted). Notable printed keys below reference exact snapshot field names and formats.
      -> B: number of batch samples used to build windows (snapshot.B)
      -> activation_mb: estimated activation footprint in MB computed from allocation delta (snapshot.activation_mb)
      -> backward_ms: placeholder for backward pass ms (None here; snapshot.backward_ms)
      -> collector_ms: total wall-clock ms spent by the collector (includes sampling, CPU/GPU syncs) (snapshot.collector_ms)
      -> cpu_copy_bytes: bytes copied to host for predictions, shown human-readable in log (snapshot.cpu_copy_bytes)
      -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
      -> device_syncs_count: count of explicit torch.cuda.synchronize() calls used for timing accuracy (snapshot.device_syncs_count)
      -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
      -> expected_segments: nominal B * groups (snapshot.expected_segments)
      -> feat_dim: feature dimension of inputs used to build windows (snapshot.feat_dim)
      -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
      -> gpu_allocated_bytes / gpu_reserved_bytes: raw GPU bytes allocated/reserved (snapshot.gpu_allocated_bytes, snapshot.gpu_reserved_bytes)
      -> gpu_peak_mb / gpu_reserved_mb: peak/reserved GPU memory in MB (snapshot.gpu_peak_mb, snapshot.gpu_reserved_mb)
      -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
      -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
      -> groups: number of logical groups used when flattening windows (snapshot.groups)
      -> mean_seg_len: average per-segment time-series length in timesteps (snapshot.mean_seg_len)
      -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
      -> out_bytes / out_dtype / out_numel / out_shape: model output bytes (human-readable in log), dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
      -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
      -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
      -> pred_extra_ms / preds_cpu_ms: placeholder for extra pred cost and ms to detach+copy preds to CPU (snapshot.pred_extra_ms, snapshot.preds_cpu_ms)
      -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
      -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
      -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
      -> step_block_ms: placeholder for step-block timing if measured (snapshot.step_block_ms)
      -> sum_seg_lens: sum of segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
      -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lrs}|cnts=[c1,c2,...]] : optimizer groups count, compact LR preview (first up to 3) and per-group parameter counts (from optimizer.param_groups)
  GN[reg,cls,ter,tot]      : gradient norms for name-buckets reg/cls/ter and total (sqrt of sum squares over matching named parameters; zero means no matching names found)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, 90th-percentile, and maximum (index-based p90)
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : primary LR token and explicit current lr printed in scientific notation
  TR[rmse,r2,mae]         : training metrics (RMSE, R^2, MAE) reported for the epoch (train_metrics)
  VL[rmse,r2,mae]         : validation metrics (RMSE, R^2, MAE) reported for the epoch (val_metrics)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults to 0.00/0.000 when missing)
  SCHED_PCT={pct:.1f}%     : optional scheduler percent-complete when scheduler exposes _total_steps and a step counter
  T={elapsed:.1f}s,TP={throughput:.1f}s/s : optional epoch elapsed and throughput if model stored _last_epoch_elapsed and _last_epoch_samples
  GPU={GiB:.2f}GiB         : optional high-water GPU memory in GiB when CUDA available (torch.cuda.max_memory_allocated)
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy
  LAYER_GN[...]           : optional small set of monitored layer norms and ratio-to-baseline printed as name_short:curr_norm/ratio
  TOP_K(G/U)=param:grad_norm/update_ratio,... : top-k parameter entries by gradient norm with their update ratios (short names use last two name segments)

BASELINES:
  TRAIN mean RMSE        = 0.04190
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.06583
  VAL   persistence RMSE = 0.01214

HYPERPARAMS:
  LOOK_BACK = 60
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  USE_SHORT_LSTM = True
  SHORT_UNITS = 64
  DROPOUT_SHORT = 0.0
  USE_TRANSFORMER = True
  TRANSFORMER_LAYERS = 1
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_LONG = 0.0
  USE_LONG_LSTM = False
  LONG_UNITS = 64
  FLATTEN_MODE = last
  PRED_HIDDEN = 64
  ALPHA_SMOOTH = 0.1
  MAX_EPOCHS = 90
  EARLY_STOP_PATIENCE = 9
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 5
  ONECYCLE_MAX_LR = 0.001
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 50
  ONECYCLE_PCT_START = 0.2
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 64
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  MICRO_SAMPLE_K = 16

BATCH_SHAPE B=64 groups=451 seq_len_full=60 feat=20
MICRODETAIL ms: B=64 activation_mb=4166 backward_ms=None collector_ms=850.50 cpu_copy_bytes=46KB dataloader_ms=628.98 device_syncs_count=35 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=28864 feat_dim=20 full_forward_ms=55.78 gpu_allocated_bytes=4800MB gpu_peak_mb=6479 gpu_reserved_bytes=13828MB gpu_reserved_mb=13828 grads={'backbone': True, 'head': True} group_nonzero_counts=[36] groups=451 mean_seg_len=2.53 num_segments=23903 out_bytes=46KB out_dtype=torch.float16 out_numel=23903 out_shape=(23903, 1, 1) param_bytes=300KB per_segment_p50_ms=2.05 per_segment_p90_ms=3.02 pred_extra_ms=None preds_cpu_ms=0.22 raw_reg_shape=(23903, 1, 1) segments_per_sec=428518.46 seq_len_full=60 step_block_ms=None sum_seg_lens=134 windows_bytes=109MB

E01 | OPTS[1:1.1e-04|cnts=[36]] | GN[0.319,0.000,0.000,0.398] | GD[1.5e-02,9.1e-02,2.4e-01] | UR[1.8e-06,2.6e-04] | LR_MAIN=1.1e-04 | lr=1.1e-04 | TR[0.113,0.01,0.079] | VL[0.104,0.10,0.067] | SR=0.021 | SL=0.00,HR=0.000 |  | T=26.0s,TP=66718.6s/s | GPU=6.33GiB | LAYER_GN[weight_ih_l0:3.704e-02/1.00,weight:1.739e-01/1.00,weight:9.149e-02/1.00] | 
TOP_K(G/U)=weight.original1:0.240/4.4e-05, weight.original1:0.197/4.5e-06, short2long.weight:0.174/4.0e-06, feature_proj.weight:0.091/2.1e-06, linear2.weight:0.080/1.8e-06, 2.bias:0.065/9.8e-05, out_proj.weight:0.055/1.3e-06, self_attn.in_proj_weight:0.043/4.7e-07, short_lstm.weight_ih_l0:0.037/7.6e-07, linear1.weight:0.033/3.9e-07, weight.original0:0.029/6.8e-07, short_lstm.weight_ih_l0_reverse:0.027/5.6e-07, 0.bias:0.025/4.7e-06, short2long.bias:0.022/4.1e-06, short_lstm.bias_ih_l0:0.021/1.7e-06, short_lstm.bias_hh_l0:0.021/2.0e-06, short_lstm.bias_ih_l0_reverse:0.015/1.4e-06, short_lstm.bias_hh_l0_reverse:0.015/1.4e-06, ln_flat.bias:0.014/2.4e-04, ln_proj.bias:0.014/2.1e-04, ln_flat.weight:0.013/1.8e-07, ln_proj.weight:0.013/1.8e-07, feature_proj.bias:0.012/2.4e-06, norm2.bias:0.011/1.9e-04, out_proj.bias:0.011/2.6e-04, linear2.bias:0.011/4.0e-06, short_lstm.weight_hh_l0:0.011/1.8e-07, norm1.bias:0.011/2.5e-04, norm2.weight:0.009/1.3e-07, norm1.weight:0.009/1.2e-07, ln_short.bias:0.007/1.3e-04, ln_short.weight:0.006/8.5e-08, self_attn.in_proj_bias:0.006/6.2e-05, linear1.bias:0.004/3.8e-07, short_lstm.weight_hh_l0_reverse:0.004/6.2e-08, weight.original0:0.001/1.5e-07

E02 | OPTS[1:1.3e-04|cnts=[36]] | GN[0.235,0.000,0.000,0.291] | GD[1.2e-02,6.6e-02,1.8e-01] | UR[1.8e-06,1.9e-04] | LR_MAIN=1.3e-04 | lr=1.3e-04 | TR[0.107,0.12,0.075] | VL[0.101,0.15,0.066] | SR=0.022 | SL=0.00,HR=0.000 |  | T=22.6s,TP=76794.3s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:3.337e-02/0.90,weight:1.248e-01/0.72,weight:6.585e-02/0.72] | 
TOP_K(G/U)=weight.original1:0.176/3.8e-05, weight.original1:0.145/4.0e-06, short2long.weight:0.125/3.4e-06, feature_proj.weight:0.066/1.8e-06, linear2.weight:0.055/1.5e-06, 2.bias:0.048/8.7e-05, out_proj.weight:0.039/1.1e-06, short_lstm.weight_ih_l0:0.033/8.2e-07, self_attn.in_proj_weight:0.031/4.0e-07, linear1.weight:0.024/3.3e-07, short_lstm.weight_ih_l0_reverse:0.021/5.3e-07, weight.original0:0.021/5.9e-07, short_lstm.bias_ih_l0:0.019/1.9e-06, short_lstm.bias_hh_l0:0.019/2.1e-06, 0.bias:0.018/4.1e-06, short2long.bias:0.016/3.5e-06, short_lstm.bias_ih_l0_reverse:0.012/1.3e-06, short_lstm.bias_hh_l0_reverse:0.012/1.3e-06, ln_flat.bias:0.010/1.9e-04, ln_proj.bias:0.010/1.6e-04, ln_flat.weight:0.010/1.6e-07, ln_proj.weight:0.010/1.5e-07, short_lstm.weight_hh_l0:0.010/1.8e-07, feature_proj.bias:0.008/2.1e-06, norm2.bias:0.008/1.4e-04, out_proj.bias:0.008/1.9e-04, linear2.bias:0.008/3.3e-06, norm1.bias:0.008/1.8e-04, norm1.weight:0.007/1.1e-07, norm2.weight:0.007/1.1e-07, ln_short.bias:0.005/1.1e-04, ln_short.weight:0.004/7.0e-08, self_attn.in_proj_bias:0.004/4.5e-05, short_lstm.weight_hh_l0_reverse:0.003/6.6e-08, linear1.bias:0.003/3.3e-07, weight.original0:0.000/9.5e-08

E03 | OPTS[1:1.6e-04|cnts=[36]] | GN[0.026,0.000,0.000,0.034] | GD[1.7e-03,8.8e-03,1.9e-02] | UR[3.1e-07,3.1e-05] | LR_MAIN=1.6e-04 | lr=1.6e-04 | TR[0.103,0.18,0.071] | VL[0.099,0.19,0.071] | SR=0.020 | SL=0.00,HR=0.000 |  | T=22.6s,TP=76799.7s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:4.584e-03/0.12,weight:1.466e-02/0.08,weight:8.784e-03/0.10] | 
TOP_K(G/U)=weight.original1:0.019/5.2e-06, weight.original1:0.017/5.8e-07, short2long.weight:0.015/5.0e-07, feature_proj.weight:0.009/3.1e-07, linear2.weight:0.007/2.4e-07, 2.bias:0.005/1.2e-05, out_proj.weight:0.005/1.7e-07, short_lstm.weight_ih_l0:0.005/1.4e-07, self_attn.in_proj_weight:0.004/7.0e-08, linear1.weight:0.003/5.9e-08, short_lstm.weight_ih_l0_reverse:0.003/8.9e-08, short_lstm.bias_ih_l0:0.003/3.3e-07, short_lstm.bias_hh_l0:0.003/3.7e-07, weight.original0:0.002/8.0e-08, 0.bias:0.002/5.9e-07, short2long.bias:0.002/5.1e-07, short_lstm.bias_ih_l0_reverse:0.002/2.3e-07, short_lstm.bias_hh_l0_reverse:0.002/2.4e-07, short_lstm.weight_hh_l0:0.001/3.3e-08, ln_flat.weight:0.001/2.3e-08, ln_proj.weight:0.001/2.3e-08, ln_flat.bias:0.001/2.8e-05, ln_proj.bias:0.001/2.3e-05, feature_proj.bias:0.001/3.4e-07, out_proj.bias:0.001/3.1e-05, norm2.bias:0.001/2.1e-05, norm1.bias:0.001/2.9e-05, linear2.bias:0.001/5.1e-07, norm1.weight:0.001/1.6e-08, norm2.weight:0.001/1.6e-08, ln_short.bias:0.001/1.9e-05, ln_short.weight:0.001/1.3e-08, self_attn.in_proj_bias:0.001/7.1e-06, short_lstm.weight_hh_l0_reverse:0.000/1.1e-08, linear1.bias:0.000/5.7e-08, weight.original0:0.000/6.9e-08

E04 | OPTS[1:2.1e-04|cnts=[36]] | GN[0.137,0.000,0.000,0.169] | GD[7.3e-03,3.8e-02,1.0e-01] | UR[1.7e-06,1.8e-04] | LR_MAIN=2.1e-04 | lr=2.1e-04 | TR[0.102,0.20,0.070] | VL[0.098,0.20,0.068] | SR=0.020 | SL=0.00,HR=0.000 |  | T=23.0s,TP=75350.1s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:2.023e-02/0.55,weight:7.006e-02/0.40,weight:3.816e-02/0.42] | 
TOP_K(G/U)=weight.original1:0.103/3.6e-05, weight.original1:0.085/3.7e-06, short2long.weight:0.070/3.1e-06, feature_proj.weight:0.038/1.7e-06, linear2.weight:0.031/1.4e-06, 2.bias:0.028/8.2e-05, out_proj.weight:0.022/9.9e-07, short_lstm.weight_ih_l0:0.020/8.0e-07, self_attn.in_proj_weight:0.018/3.7e-07, linear1.weight:0.014/3.2e-07, short_lstm.weight_ih_l0_reverse:0.013/5.2e-07, weight.original0:0.012/5.5e-07, short_lstm.bias_ih_l0:0.012/1.9e-06, short_lstm.bias_hh_l0:0.012/2.1e-06, 0.bias:0.011/3.9e-06, short2long.bias:0.009/3.2e-06, short_lstm.bias_ih_l0_reverse:0.007/1.3e-06, short_lstm.bias_hh_l0_reverse:0.007/1.3e-06, ln_flat.weight:0.006/1.5e-07, short_lstm.weight_hh_l0:0.006/1.8e-07, ln_flat.bias:0.006/1.8e-04, ln_proj.bias:0.006/1.5e-04, ln_proj.weight:0.006/1.5e-07, feature_proj.bias:0.005/2.0e-06, out_proj.bias:0.005/1.7e-04, norm2.bias:0.005/1.2e-04, norm1.bias:0.004/1.7e-04, linear2.bias:0.004/3.1e-06, norm1.weight:0.004/1.0e-07, norm2.weight:0.004/1.0e-07, ln_short.bias:0.003/1.0e-04, ln_short.weight:0.003/6.7e-08, self_attn.in_proj_bias:0.002/3.3e-05, short_lstm.weight_hh_l0_reverse:0.002/6.0e-08, linear1.bias:0.002/3.2e-07, weight.original0:0.000/2.7e-08

E05 | OPTS[1:2.6e-04|cnts=[36]] | GN[0.121,0.000,0.000,0.149] | GD[6.7e-03,3.4e-02,9.1e-02] | UR[1.9e-06,2.0e-04] | LR_MAIN=2.6e-04 | lr=2.6e-04 | TR[0.101,0.21,0.070] | VL[0.098,0.20,0.072] | SR=0.018 | SL=0.00,HR=0.000 |  | T=23.7s,TP=72964.4s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:1.844e-02/0.50,weight:6.161e-02/0.35,weight:3.360e-02/0.37] | 
TOP_K(G/U)=weight.original1:0.091/3.9e-05, weight.original1:0.075/4.2e-06, short2long.weight:0.062/3.4e-06, feature_proj.weight:0.034/1.9e-06, linear2.weight:0.027/1.5e-06, 2.bias:0.025/9.4e-05, out_proj.weight:0.020/1.1e-06, short_lstm.weight_ih_l0:0.018/9.2e-07, self_attn.in_proj_weight:0.016/4.2e-07, linear1.weight:0.013/3.6e-07, short_lstm.weight_ih_l0_reverse:0.012/5.9e-07, weight.original0:0.011/6.2e-07, short_lstm.bias_ih_l0:0.010/2.2e-06, short_lstm.bias_hh_l0:0.010/2.4e-06, 0.bias:0.010/4.4e-06, short2long.bias:0.008/3.6e-06, short_lstm.bias_ih_l0_reverse:0.007/1.5e-06, short_lstm.bias_hh_l0_reverse:0.007/1.5e-06, short_lstm.weight_hh_l0:0.005/2.1e-07, ln_flat.weight:0.005/1.7e-07, ln_proj.weight:0.005/1.7e-07, ln_flat.bias:0.005/2.0e-04, ln_proj.bias:0.005/1.6e-04, feature_proj.bias:0.004/2.2e-06, out_proj.bias:0.004/1.8e-04, norm2.bias:0.004/1.2e-04, norm1.bias:0.004/1.7e-04, linear2.bias:0.004/3.4e-06, norm1.weight:0.003/1.1e-07, norm2.weight:0.003/1.1e-07, ln_short.bias:0.003/1.1e-04, ln_short.weight:0.002/7.8e-08, self_attn.in_proj_bias:0.002/3.0e-05, short_lstm.weight_hh_l0_reverse:0.002/6.9e-08, linear1.bias:0.002/3.6e-07, weight.original0:0.001/5.8e-07

E06 | OPTS[1:3.3e-04|cnts=[36]] | GN[0.024,0.000,0.000,0.030] | GD[1.3e-03,6.5e-03,1.8e-02] | UR[4.6e-07,5.0e-05] | LR_MAIN=3.3e-04 | lr=3.3e-04 | TR[0.100,0.22,0.069] | VL[0.097,0.22,0.067] | SR=0.018 | SL=0.00,HR=0.000 |  | T=25.9s,TP=66821.9s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:3.700e-03/0.10,weight:1.194e-02/0.07,weight:6.495e-03/0.07] | 
TOP_K(G/U)=weight.original1:0.018/1.0e-05, weight.original1:0.015/1.0e-06, short2long.weight:0.012/8.3e-07, feature_proj.weight:0.006/4.6e-07, 2.bias:0.005/2.4e-05, linear2.weight:0.005/3.6e-07, out_proj.weight:0.004/2.6e-07, short_lstm.weight_ih_l0:0.004/2.3e-07, self_attn.in_proj_weight:0.003/9.9e-08, linear1.weight:0.002/8.8e-08, short_lstm.weight_ih_l0_reverse:0.002/1.5e-07, weight.original0:0.002/1.6e-07, short_lstm.bias_ih_l0:0.002/5.2e-07, short_lstm.bias_hh_l0:0.002/5.9e-07, 0.bias:0.002/1.1e-06, short2long.bias:0.002/8.7e-07, short_lstm.bias_ih_l0_reverse:0.001/3.5e-07, short_lstm.bias_hh_l0_reverse:0.001/3.6e-07, short_lstm.weight_hh_l0:0.001/5.1e-08, ln_flat.bias:0.001/5.0e-05, ln_proj.bias:0.001/4.0e-05, ln_flat.weight:0.001/4.0e-08, ln_proj.weight:0.001/4.0e-08, feature_proj.bias:0.001/5.3e-07, out_proj.bias:0.001/4.6e-05, norm2.bias:0.001/3.0e-05, norm1.bias:0.001/4.4e-05, linear2.bias:0.001/8.2e-07, norm1.weight:0.001/2.9e-08, norm2.weight:0.001/2.7e-08, ln_short.bias:0.001/2.6e-05, ln_short.weight:0.000/1.8e-08, self_attn.in_proj_bias:0.000/5.9e-06, weight.original0:0.000/2.1e-07, short_lstm.weight_hh_l0_reverse:0.000/1.6e-08, linear1.bias:0.000/8.8e-08

------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-10-26T18:15:44.434160Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=... groups=... seq_len_full=... feat=... : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : deterministic single-line dump of snapshot keys (sorted). Notable printed keys below reference exact snapshot field names and formats.
      -> B: number of batch samples used to build windows (snapshot.B)
      -> activation_mb: estimated activation footprint in MB computed from allocation delta (snapshot.activation_mb)
      -> backward_ms: placeholder for backward pass ms (None here; snapshot.backward_ms)
      -> collector_ms: total wall-clock ms spent by the collector (includes sampling, CPU/GPU syncs) (snapshot.collector_ms)
      -> cpu_copy_bytes: bytes copied to host for predictions, shown human-readable in log (snapshot.cpu_copy_bytes)
      -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
      -> device_syncs_count: count of explicit torch.cuda.synchronize() calls used for timing accuracy (snapshot.device_syncs_count)
      -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
      -> expected_segments: nominal B * groups (snapshot.expected_segments)
      -> feat_dim: feature dimension of inputs used to build windows (snapshot.feat_dim)
      -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
      -> gpu_allocated_bytes / gpu_reserved_bytes: raw GPU bytes allocated/reserved (snapshot.gpu_allocated_bytes, snapshot.gpu_reserved_bytes)
      -> gpu_peak_mb / gpu_reserved_mb: peak/reserved GPU memory in MB (snapshot.gpu_peak_mb, snapshot.gpu_reserved_mb)
      -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
      -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
      -> groups: number of logical groups used when flattening windows (snapshot.groups)
      -> mean_seg_len: average per-segment time-series length in timesteps (snapshot.mean_seg_len)
      -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
      -> out_bytes / out_dtype / out_numel / out_shape: model output bytes (human-readable in log), dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
      -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
      -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
      -> pred_extra_ms / preds_cpu_ms: placeholder for extra pred cost and ms to detach+copy preds to CPU (snapshot.pred_extra_ms, snapshot.preds_cpu_ms)
      -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
      -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
      -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
      -> step_block_ms: placeholder for step-block timing if measured (snapshot.step_block_ms)
      -> sum_seg_lens: sum of segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
      -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lrs}|cnts=[c1,c2,...]] : optimizer groups count, compact LR preview (first up to 3) and per-group parameter counts (from optimizer.param_groups)
  GN[reg,cls,ter,tot]      : gradient norms for name-buckets reg/cls/ter and total (sqrt of sum squares over matching named parameters; zero means no matching names found)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, 90th-percentile, and maximum (index-based p90)
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : primary LR token and explicit current lr printed in scientific notation
  TR[rmse,r2,mae]         : training metrics (RMSE, R^2, MAE) reported for the epoch (train_metrics)
  VL[rmse,r2,mae]         : validation metrics (RMSE, R^2, MAE) reported for the epoch (val_metrics)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults to 0.00/0.000 when missing)
  SCHED_PCT={pct:.1f}%     : optional scheduler percent-complete when scheduler exposes _total_steps and a step counter
  T={elapsed:.1f}s,TP={throughput:.1f}s/s : optional epoch elapsed and throughput if model stored _last_epoch_elapsed and _last_epoch_samples
  GPU={GiB:.2f}GiB         : optional high-water GPU memory in GiB when CUDA available (torch.cuda.max_memory_allocated)
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy
  LAYER_GN[...]           : optional small set of monitored layer norms and ratio-to-baseline printed as name_short:curr_norm/ratio
  TOP_K(G/U)=param:grad_norm/update_ratio,... : top-k parameter entries by gradient norm with their update ratios (short names use last two name segments)

BASELINES:
  TRAIN mean RMSE        = 0.04190
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.06583
  VAL   persistence RMSE = 0.01214

HYPERPARAMS:
  LOOK_BACK = 60
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  USE_SHORT_LSTM = True
  SHORT_UNITS = 64
  DROPOUT_SHORT = 0.0
  USE_TRANSFORMER = True
  TRANSFORMER_LAYERS = 1
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_LONG = 0.0
  USE_LONG_LSTM = False
  LONG_UNITS = 64
  FLATTEN_MODE = last
  PRED_HIDDEN = 64
  ALPHA_SMOOTH = 0.1
  MAX_EPOCHS = 90
  EARLY_STOP_PATIENCE = 9
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 5
  ONECYCLE_MAX_LR = 0.001
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 50
  ONECYCLE_PCT_START = 0.2
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 64
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  MICRO_SAMPLE_K = 16

BATCH_SHAPE B=64 groups=451 seq_len_full=60 feat=20
MICRODETAIL ms: B=64 activation_mb=4166 backward_ms=None collector_ms=952.41 cpu_copy_bytes=46KB dataloader_ms=711.54 device_syncs_count=35 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=28864 feat_dim=20 full_forward_ms=55.43 gpu_allocated_bytes=4800MB gpu_peak_mb=6479 gpu_reserved_bytes=13828MB gpu_reserved_mb=13828 grads={'backbone': True, 'head': True} group_nonzero_counts=[36] groups=451 mean_seg_len=2.53 num_segments=23903 out_bytes=46KB out_dtype=torch.float16 out_numel=23903 out_shape=(23903, 1, 1) param_bytes=300KB per_segment_p50_ms=2.35 per_segment_p90_ms=3.50 pred_extra_ms=None preds_cpu_ms=0.34 raw_reg_shape=(23903, 1, 1) segments_per_sec=431237.43 seq_len_full=60 step_block_ms=None sum_seg_lens=134 windows_bytes=109MB

E01 | OPTS[1:1.1e-04|cnts=[36]] | GN[0.074,0.000,0.000,0.087] | GD[3.5e-03,1.9e-02,5.4e-02] | UR[4.4e-07,3.1e-05] | LR_MAIN=1.1e-04 | lr=1.1e-04 | TR[0.126,-0.23,0.089] | VL[0.106,0.07,0.069] | SR=0.016 | SL=0.00,HR=0.000 |  | T=27.3s,TP=63343.1s/s | GPU=6.33GiB | LAYER_GN[weight_ih_l0:1.035e-02/1.00,weight:3.424e-02/1.00,weight:1.742e-02/1.00] | 
TOP_K(G/U)=weight.original1:0.054/1.0e-05, weight.original1:0.045/1.0e-06, short2long.weight:0.034/7.9e-07, 2.bias:0.019/1.9e-05, feature_proj.weight:0.017/4.0e-07, linear2.weight:0.012/2.8e-07, out_proj.weight:0.011/2.4e-07, short_lstm.weight_ih_l0:0.010/2.1e-07, self_attn.in_proj_weight:0.007/8.1e-08, weight.original0:0.007/1.3e-06, weight.original0:0.007/1.5e-07, linear1.weight:0.006/7.0e-08, 0.bias:0.006/9.9e-07, short_lstm.bias_ih_l0:0.005/4.6e-07, short_lstm.bias_hh_l0:0.005/4.6e-07, short_lstm.weight_ih_l0_reverse:0.005/9.8e-08, short2long.bias:0.004/8.1e-07, ln_flat.weight:0.003/4.6e-08, ln_flat.bias:0.003/3.1e-05, ln_proj.weight:0.003/3.9e-08, short_lstm.weight_hh_l0:0.003/4.8e-08, ln_proj.bias:0.003/2.9e-05, feature_proj.bias:0.002/4.4e-07, short_lstm.bias_ih_l0_reverse:0.002/2.0e-07, short_lstm.bias_hh_l0_reverse:0.002/2.2e-07, out_proj.bias:0.002/2.3e-05, norm2.bias:0.002/2.0e-05, norm1.bias:0.002/2.1e-05, linear2.bias:0.002/6.6e-07, norm1.weight:0.002/2.5e-08, norm2.weight:0.002/2.4e-08, ln_short.bias:0.001/1.4e-05, ln_short.weight:0.001/1.6e-08, self_attn.in_proj_bias:0.001/8.2e-06, short_lstm.weight_hh_l0_reverse:0.001/1.5e-08, linear1.bias:0.001/7.7e-08

E02 | OPTS[1:1.3e-04|cnts=[36]] | GN[0.075,0.000,0.000,0.089] | GD[3.5e-03,2.0e-02,5.6e-02] | UR[5.6e-07,3.6e-05] | LR_MAIN=1.3e-04 | lr=1.3e-04 | TR[0.107,0.11,0.074] | VL[0.101,0.15,0.066] | SR=0.016 | SL=0.00,HR=0.000 |  | T=23.3s,TP=74274.1s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:1.245e-02/1.20,weight:3.465e-02/1.01,weight:1.860e-02/1.07] | 
TOP_K(G/U)=weight.original1:0.056/1.2e-05, weight.original1:0.044/1.2e-06, short2long.weight:0.035/9.5e-07, 2.bias:0.020/2.4e-05, feature_proj.weight:0.019/5.1e-07, short_lstm.weight_ih_l0:0.012/3.1e-07, linear2.weight:0.012/3.3e-07, out_proj.weight:0.011/3.0e-07, self_attn.in_proj_weight:0.008/1.0e-07, weight.original0:0.007/1.6e-06, weight.original0:0.007/1.9e-07, short_lstm.bias_ih_l0:0.006/7.1e-07, short_lstm.bias_hh_l0:0.006/7.1e-07, linear1.weight:0.006/8.5e-08, 0.bias:0.006/1.2e-06, short_lstm.weight_ih_l0_reverse:0.006/1.4e-07, short2long.bias:0.004/9.8e-07, short_lstm.weight_hh_l0:0.004/6.9e-08, ln_flat.weight:0.003/5.5e-08, ln_flat.bias:0.003/3.6e-05, ln_proj.weight:0.003/4.5e-08, ln_proj.bias:0.003/3.4e-05, short_lstm.bias_ih_l0_reverse:0.003/3.0e-07, short_lstm.bias_hh_l0_reverse:0.003/3.3e-07, feature_proj.bias:0.002/5.6e-07, out_proj.bias:0.002/2.8e-05, norm1.bias:0.002/2.6e-05, norm2.bias:0.002/2.5e-05, linear2.bias:0.002/8.0e-07, norm1.weight:0.002/2.9e-08, norm2.weight:0.002/2.9e-08, ln_short.bias:0.001/1.9e-05, ln_short.weight:0.001/2.2e-08, self_attn.in_proj_bias:0.001/9.8e-06, short_lstm.weight_hh_l0_reverse:0.001/1.6e-08, linear1.bias:0.001/9.4e-08

E03 | OPTS[1:1.6e-04|cnts=[36]] | GN[0.082,0.000,0.000,0.101] | GD[5.1e-03,2.4e-02,6.2e-02] | UR[9.1e-07,4.9e-05] | LR_MAIN=1.6e-04 | lr=1.6e-04 | TR[0.103,0.17,0.071] | VL[0.098,0.20,0.066] | SR=0.019 | SL=0.00,HR=0.000 |  | T=22.2s,TP=77931.0s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:1.720e-02/1.66,weight:4.003e-02/1.17,weight:2.402e-02/1.38] | 
TOP_K(G/U)=weight.original1:0.062/1.7e-05, weight.original1:0.048/1.7e-06, short2long.weight:0.040/1.4e-06, feature_proj.weight:0.024/8.4e-07, 2.bias:0.021/3.3e-05, short_lstm.weight_ih_l0:0.017/5.3e-07, linear2.weight:0.015/5.1e-07, out_proj.weight:0.014/4.8e-07, self_attn.in_proj_weight:0.010/1.7e-07, short_lstm.bias_ih_l0:0.009/1.4e-06, short_lstm.bias_hh_l0:0.009/1.4e-06, linear1.weight:0.008/1.4e-07, short_lstm.weight_ih_l0_reverse:0.008/2.4e-07, weight.original0:0.007/2.6e-07, weight.original0:0.007/2.0e-06, 0.bias:0.006/1.6e-06, short_lstm.weight_hh_l0:0.005/1.3e-07, short2long.bias:0.005/1.4e-06, short_lstm.bias_ih_l0_reverse:0.004/5.8e-07, short_lstm.bias_hh_l0_reverse:0.004/6.3e-07, ln_flat.weight:0.004/7.5e-08, ln_flat.bias:0.004/4.9e-05, ln_proj.bias:0.003/4.8e-05, ln_proj.weight:0.003/6.3e-08, feature_proj.bias:0.003/9.1e-07, out_proj.bias:0.003/4.6e-05, norm1.bias:0.003/4.3e-05, norm2.bias:0.002/3.9e-05, linear2.bias:0.002/1.2e-06, norm1.weight:0.002/4.4e-08, norm2.weight:0.002/4.2e-08, ln_short.bias:0.002/3.6e-05, ln_short.weight:0.002/4.0e-08, self_attn.in_proj_bias:0.002/1.6e-05, short_lstm.weight_hh_l0_reverse:0.001/2.6e-08, linear1.bias:0.001/1.5e-07

E04 | OPTS[1:2.1e-04|cnts=[36]] | GN[0.007,0.000,0.000,0.011] | GD[6.7e-04,2.7e-03,6.0e-03] | UR[1.8e-07,1.0e-05] | LR_MAIN=2.1e-04 | lr=2.1e-04 | TR[0.103,0.18,0.071] | VL[0.098,0.21,0.067] | SR=0.018 | SL=0.00,HR=0.000 |  | T=22.4s,TP=77264.2s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:2.256e-03/0.22,weight:5.816e-03/0.17,weight:4.066e-03/0.23] | 
TOP_K(G/U)=weight.original1:0.006/2.7e-07, short2long.weight:0.006/2.6e-07, feature_proj.weight:0.004/1.8e-07, linear2.weight:0.003/1.2e-07, weight.original1:0.003/9.1e-07, out_proj.weight:0.002/1.1e-07, short_lstm.weight_ih_l0:0.002/9.0e-08, self_attn.in_proj_weight:0.002/3.9e-08, short_lstm.weight_ih_l0_reverse:0.002/6.1e-08, linear1.weight:0.001/2.9e-08, short_lstm.bias_ih_l0:0.001/2.0e-07, short_lstm.bias_hh_l0:0.001/2.0e-07, 2.bias:0.001/1.5e-06, short_lstm.bias_ih_l0_reverse:0.001/1.3e-07, short_lstm.bias_hh_l0_reverse:0.001/1.4e-07, 0.bias:0.001/2.4e-07, short2long.bias:0.001/2.5e-07, short_lstm.weight_hh_l0:0.001/2.1e-08, weight.original0:0.001/2.0e-07, norm2.weight:0.000/1.3e-08, feature_proj.bias:0.000/1.8e-07, out_proj.bias:0.000/1.0e-05, ln_flat.bias:0.000/7.8e-06, norm1.weight:0.000/1.1e-08, ln_proj.bias:0.000/8.6e-06, norm2.bias:0.000/8.7e-06, norm1.bias:0.000/9.3e-06, linear2.bias:0.000/2.8e-07, ln_proj.weight:0.000/9.1e-09, ln_flat.weight:0.000/8.9e-09, weight.original0:0.000/1.5e-08, ln_short.bias:0.000/6.8e-06, self_attn.in_proj_bias:0.000/3.3e-06, ln_short.weight:0.000/7.0e-09, short_lstm.weight_hh_l0_reverse:0.000/5.8e-09, linear1.bias:0.000/3.1e-08

E05 | OPTS[1:2.6e-04|cnts=[36]] | GN[0.124,0.000,0.000,0.149] | GD[6.8e-03,3.2e-02,9.1e-02] | UR[2.0e-06,1.1e-04] | LR_MAIN=2.6e-04 | lr=2.6e-04 | TR[0.102,0.19,0.071] | VL[0.097,0.21,0.066] | SR=0.019 | SL=0.00,HR=0.000 |  | T=23.1s,TP=74818.5s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:2.293e-02/2.21,weight:5.768e-02/1.68,weight:3.201e-02/1.84] | 
TOP_K(G/U)=weight.original1:0.091/4.1e-05, weight.original1:0.076/4.3e-06, short2long.weight:0.058/3.2e-06, 2.bias:0.032/8.0e-05, feature_proj.weight:0.032/1.8e-06, short_lstm.weight_ih_l0:0.023/1.2e-06, linear2.weight:0.019/1.1e-06, out_proj.weight:0.018/1.0e-06, self_attn.in_proj_weight:0.014/3.8e-07, short_lstm.bias_ih_l0:0.013/3.0e-06, short_lstm.bias_hh_l0:0.013/3.0e-06, short_lstm.weight_ih_l0_reverse:0.011/5.7e-07, weight.original0:0.011/6.3e-07, linear1.weight:0.011/3.0e-07, weight.original0:0.010/4.5e-06, 0.bias:0.010/4.1e-06, short2long.bias:0.007/3.3e-06, short_lstm.weight_hh_l0:0.007/2.8e-07, short_lstm.bias_ih_l0_reverse:0.006/1.4e-06, short_lstm.bias_hh_l0_reverse:0.006/1.5e-06, ln_flat.weight:0.006/2.0e-07, ln_flat.bias:0.005/1.1e-04, ln_proj.weight:0.005/1.7e-07, ln_proj.bias:0.005/1.1e-04, feature_proj.bias:0.004/2.0e-06, out_proj.bias:0.004/9.8e-05, norm1.bias:0.003/9.2e-05, norm2.bias:0.003/8.6e-05, linear2.bias:0.003/2.6e-06, norm1.weight:0.003/9.6e-08, norm2.weight:0.003/9.5e-08, ln_short.weight:0.003/9.2e-08, ln_short.bias:0.003/7.6e-05, self_attn.in_proj_bias:0.002/3.0e-05, short_lstm.weight_hh_l0_reverse:0.002/8.1e-08, linear1.bias:0.001/3.3e-07

E06 | OPTS[1:3.3e-04|cnts=[36]] | GN[0.115,0.000,0.000,0.136] | GD[6.3e-03,3.0e-02,8.4e-02] | UR[2.2e-06,1.2e-04] | LR_MAIN=3.3e-04 | lr=3.3e-04 | TR[0.102,0.20,0.070] | VL[0.099,0.19,0.074] | SR=0.020 | SL=0.00,HR=0.000 |  | T=23.4s,TP=73902.3s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:2.049e-02/1.98,weight:5.066e-02/1.48,weight:2.893e-02/1.66] | 
TOP_K(G/U)=weight.original1:0.084/4.7e-05, weight.original1:0.070/4.9e-06, short2long.weight:0.051/3.6e-06, 2.bias:0.030/9.4e-05, feature_proj.weight:0.029/2.0e-06, short_lstm.weight_ih_l0:0.020/1.3e-06, linear2.weight:0.017/1.2e-06, out_proj.weight:0.016/1.1e-06, self_attn.in_proj_weight:0.012/4.0e-07, short_lstm.bias_ih_l0:0.012/3.4e-06, short_lstm.bias_hh_l0:0.012/3.4e-06, weight.original0:0.011/6.1e-06, short_lstm.weight_ih_l0_reverse:0.010/6.5e-07, weight.original0:0.010/7.3e-07, linear1.weight:0.010/3.4e-07, 0.bias:0.009/4.7e-06, short2long.bias:0.006/3.6e-06, short_lstm.weight_hh_l0:0.006/3.1e-07, short_lstm.bias_ih_l0_reverse:0.006/1.6e-06, short_lstm.bias_hh_l0_reverse:0.006/1.8e-06, ln_flat.weight:0.005/2.2e-07, ln_flat.bias:0.005/1.2e-04, ln_proj.weight:0.005/1.8e-07, ln_proj.bias:0.004/1.2e-04, feature_proj.bias:0.004/2.2e-06, out_proj.bias:0.003/1.1e-04, norm1.bias:0.003/1.0e-04, norm2.bias:0.003/9.2e-05, norm1.weight:0.003/1.1e-07, norm2.weight:0.003/1.1e-07, linear2.bias:0.003/2.9e-06, ln_short.weight:0.003/1.1e-07, ln_short.bias:0.002/8.6e-05, self_attn.in_proj_bias:0.002/3.0e-05, short_lstm.weight_hh_l0_reverse:0.002/8.7e-08, linear1.bias:0.001/3.8e-07

E07 | OPTS[1:4.0e-04|cnts=[36]] | GN[0.030,0.000,0.000,0.036] | GD[1.8e-03,8.0e-03,2.2e-02] | UR[7.4e-07,3.8e-05] | LR_MAIN=4.0e-04 | lr=4.0e-04 | TR[0.100,0.22,0.069] | VL[0.096,0.23,0.068] | SR=0.019 | SL=0.00,HR=0.000 |  | T=23.8s,TP=72759.3s/s | GPU=8.46GiB | LAYER_GN[weight_ih_l0:5.598e-03/0.54,weight:1.346e-02/0.39,weight:8.047e-03/0.46] | 
TOP_K(G/U)=weight.original1:0.022/1.5e-05, weight.original1:0.018/1.6e-06, short2long.weight:0.013/1.2e-06, feature_proj.weight:0.008/6.9e-07, 2.bias:0.008/2.9e-05, short_lstm.weight_ih_l0:0.006/4.3e-07, linear2.weight:0.005/3.9e-07, out_proj.weight:0.004/3.8e-07, self_attn.in_proj_weight:0.003/1.4e-07, short_lstm.bias_ih_l0:0.003/1.1e-06, short_lstm.bias_hh_l0:0.003/1.1e-06, short_lstm.weight_ih_l0_reverse:0.003/2.4e-07, linear1.weight:0.003/1.2e-07, weight.original0:0.003/2.3e-07, weight.original0:0.003/1.7e-06, 0.bias:0.002/1.5e-06, short_lstm.bias_ih_l0_reverse:0.002/5.9e-07, short_lstm.bias_hh_l0_reverse:0.002/6.4e-07, short_lstm.weight_hh_l0:0.002/1.1e-07, short2long.bias:0.002/1.2e-06, ln_flat.weight:0.001/7.4e-08, ln_flat.bias:0.001/3.8e-05, ln_proj.weight:0.001/6.1e-08, ln_proj.bias:0.001/3.8e-05, feature_proj.bias:0.001/7.4e-07, out_proj.bias:0.001/3.6e-05, norm1.bias:0.001/3.4e-05, norm2.bias:0.001/3.0e-05, norm1.weight:0.001/3.8e-08, norm2.weight:0.001/3.8e-08, ln_short.weight:0.001/3.7e-08, linear2.bias:0.001/9.4e-07, ln_short.bias:0.001/2.9e-05, short_lstm.weight_hh_l0_reverse:0.001/3.4e-08, self_attn.in_proj_bias:0.001/8.8e-06, linear1.bias:0.000/1.3e-07

E08 | OPTS[1:4.7e-04|cnts=[36]] | GN[0.022,0.000,0.000,0.027] | GD[1.5e-03,6.0e-03,1.6e-02] | UR[6.6e-07,3.5e-05] | LR_MAIN=4.7e-04 | lr=4.7e-04 | TR[0.100,0.22,0.069] | VL[0.096,0.24,0.066] | SR=0.019 | SL=0.00,HR=0.000 |  | T=24.1s,TP=71905.5s/s | GPU=8.46GiB *CHKPT | LAYER_GN[weight_ih_l0:4.126e-03/0.40,weight:1.044e-02/0.30,weight:5.996e-03/0.34] | 
TOP_K(G/U)=weight.original1:0.016/1.3e-05, weight.original1:0.013/1.3e-06, short2long.weight:0.010/1.1e-06, feature_proj.weight:0.006/6.1e-07, 2.bias:0.006/2.6e-05, short_lstm.weight_ih_l0:0.004/3.8e-07, linear2.weight:0.003/3.4e-07, out_proj.weight:0.003/3.5e-07, self_attn.in_proj_weight:0.003/1.3e-07, short_lstm.weight_ih_l0_reverse:0.003/2.4e-07, short_lstm.bias_ih_l0:0.002/9.6e-07, short_lstm.bias_hh_l0:0.002/9.5e-07, weight.original0:0.002/1.8e-06, weight.original0:0.002/2.1e-07, linear1.weight:0.002/9.6e-08, 0.bias:0.002/1.3e-06, short_lstm.bias_ih_l0_reverse:0.001/5.9e-07, short_lstm.bias_hh_l0_reverse:0.001/6.4e-07, short2long.bias:0.001/1.1e-06, short_lstm.weight_hh_l0:0.001/8.5e-08, ln_flat.weight:0.001/6.1e-08, ln_flat.bias:0.001/3.5e-05, ln_proj.weight:0.001/5.1e-08, ln_proj.bias:0.001/3.4e-05, feature_proj.bias:0.001/6.6e-07, out_proj.bias:0.001/3.3e-05, norm1.bias:0.001/3.0e-05, norm2.bias:0.001/2.8e-05, short_lstm.weight_hh_l0_reverse:0.001/4.0e-08, linear2.bias:0.001/8.6e-07, norm1.weight:0.001/3.2e-08, norm2.weight:0.001/3.2e-08, ln_short.weight:0.001/3.2e-08, ln_short.bias:0.001/2.8e-05, self_attn.in_proj_bias:0.000/7.1e-06, linear1.bias:0.000/1.1e-07

------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-10-26T18:27:29.166310Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=... groups=... seq_len_full=... feat=... : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : deterministic single-line dump of snapshot keys (sorted). Notable printed keys below reference exact snapshot field names and formats.
      -> B: number of batch samples used to build windows (snapshot.B)
      -> activation_mb: estimated activation footprint in MB computed from allocation delta (snapshot.activation_mb)
      -> backward_ms: placeholder for backward pass ms (None here; snapshot.backward_ms)
      -> collector_ms: total wall-clock ms spent by the collector (includes sampling, CPU/GPU syncs) (snapshot.collector_ms)
      -> cpu_copy_bytes: bytes copied to host for predictions, shown human-readable in log (snapshot.cpu_copy_bytes)
      -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
      -> device_syncs_count: count of explicit torch.cuda.synchronize() calls used for timing accuracy (snapshot.device_syncs_count)
      -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
      -> expected_segments: nominal B * groups (snapshot.expected_segments)
      -> feat_dim: feature dimension of inputs used to build windows (snapshot.feat_dim)
      -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
      -> gpu_allocated_bytes / gpu_reserved_bytes: raw GPU bytes allocated/reserved (snapshot.gpu_allocated_bytes, snapshot.gpu_reserved_bytes)
      -> gpu_peak_mb / gpu_reserved_mb: peak/reserved GPU memory in MB (snapshot.gpu_peak_mb, snapshot.gpu_reserved_mb)
      -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
      -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
      -> groups: number of logical groups used when flattening windows (snapshot.groups)
      -> mean_seg_len: average per-segment time-series length in timesteps (snapshot.mean_seg_len)
      -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
      -> out_bytes / out_dtype / out_numel / out_shape: model output bytes (human-readable in log), dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
      -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
      -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
      -> pred_extra_ms / preds_cpu_ms: placeholder for extra pred cost and ms to detach+copy preds to CPU (snapshot.pred_extra_ms, snapshot.preds_cpu_ms)
      -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
      -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
      -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
      -> step_block_ms: placeholder for step-block timing if measured (snapshot.step_block_ms)
      -> sum_seg_lens: sum of segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
      -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lrs}|cnts=[c1,c2,...]] : optimizer groups count, compact LR preview (first up to 3) and per-group parameter counts (from optimizer.param_groups)
  GN[reg,cls,ter,tot]      : gradient norms for name-buckets reg/cls/ter and total (sqrt of sum squares over matching named parameters; zero means no matching names found)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, 90th-percentile, and maximum (index-based p90)
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : primary LR token and explicit current lr printed in scientific notation
  TR[rmse,r2,mae]         : training metrics (RMSE, R^2, MAE) reported for the epoch (train_metrics)
  VL[rmse,r2,mae]         : validation metrics (RMSE, R^2, MAE) reported for the epoch (val_metrics)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults to 0.00/0.000 when missing)
  SCHED_PCT={pct:.1f}%     : optional scheduler percent-complete when scheduler exposes _total_steps and a step counter
  T={elapsed:.1f}s,TP={throughput:.1f}s/s : optional epoch elapsed and throughput if model stored _last_epoch_elapsed and _last_epoch_samples
  GPU={GiB:.2f}GiB         : optional high-water GPU memory in GiB when CUDA available (torch.cuda.max_memory_allocated)
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy
  LAYER_GN[...]           : optional small set of monitored layer norms and ratio-to-baseline printed as name_short:curr_norm/ratio
  TOP_K(G/U)=param:grad_norm/update_ratio,... : top-k parameter entries by gradient norm with their update ratios (short names use last two name segments)

BASELINES:
  TRAIN mean RMSE        = 0.04190
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.06583
  VAL   persistence RMSE = 0.01214

HYPERPARAMS:
  LOOK_BACK = 60
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  USE_SHORT_LSTM = True
  SHORT_UNITS = 64
  DROPOUT_SHORT = 0.0
  USE_TRANSFORMER = True
  TRANSFORMER_LAYERS = 1
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_LONG = 0.0
  USE_LONG_LSTM = False
  LONG_UNITS = 64
  FLATTEN_MODE = last
  PRED_HIDDEN = 64
  ALPHA_SMOOTH = 0.1
  MAX_EPOCHS = 90
  EARLY_STOP_PATIENCE = 9
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 5
  ONECYCLE_MAX_LR = 0.001
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 50
  ONECYCLE_PCT_START = 0.2
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 64
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  MICRO_SAMPLE_K = 16

BATCH_SHAPE B=64 groups=451 seq_len_full=60 feat=20
MICRODETAIL ms: B=64 activation_mb=4167 backward_ms=None collector_ms=640.75 cpu_copy_bytes=46KB dataloader_ms=319.94 device_syncs_count=35 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=28864 feat_dim=20 full_forward_ms=57.07 gpu_allocated_bytes=5596MB gpu_peak_mb=7275 gpu_reserved_bytes=13194MB gpu_reserved_mb=13194 grads={'backbone': True, 'head': True} group_nonzero_counts=[36] groups=451 mean_seg_len=2.53 num_segments=23903 out_bytes=46KB out_dtype=torch.float16 out_numel=23903 out_shape=(23903, 1, 1) param_bytes=300KB per_segment_p50_ms=3.94 per_segment_p90_ms=8.51 pred_extra_ms=None preds_cpu_ms=0.39 raw_reg_shape=(23903, 1, 1) segments_per_sec=418846.62 seq_len_full=60 step_block_ms=None sum_seg_lens=134 windows_bytes=109MB

E01 | OPTS[1:1.1e-04|cnts=[36]] | GN[0.128,0.000,0.000,0.155] | GD[7.4e-03,3.5e-02,8.8e-02] | UR[8.1e-07,7.4e-05] | LR_MAIN=1.1e-04 | lr=1.1e-04 | TR[0.113,0.01,0.079] | VL[0.104,0.11,0.070] | SR=0.015 | SL=0.00,HR=0.000 |  | T=16.9s,TP=102624.2s/s | GPU=7.10GiB | LAYER_GN[weight_ih_l0:2.528e-02/1.00,weight:5.926e-02/1.00,weight:3.531e-02/1.00] | 
TOP_K(G/U)=weight.original1:0.088/1.7e-05, weight.original1:0.086/2.0e-06, short2long.weight:0.059/1.4e-06, feature_proj.weight:0.035/8.1e-07, 2.bias:0.032/3.1e-05, short_lstm.weight_ih_l0:0.025/5.3e-07, linear2.weight:0.022/5.2e-07, out_proj.weight:0.018/4.2e-07, self_attn.in_proj_weight:0.014/1.5e-07, short_lstm.bias_ih_l0:0.013/1.2e-06, short_lstm.bias_hh_l0:0.013/1.2e-06, linear1.weight:0.012/1.4e-07, weight.original0:0.012/2.3e-06, 0.bias:0.011/2.1e-06, short_lstm.weight_ih_l0_reverse:0.011/2.2e-07, weight.original0:0.010/2.4e-07, short2long.bias:0.007/1.4e-06, short_lstm.weight_hh_l0:0.007/1.2e-07, ln_flat.weight:0.006/7.9e-08, ln_proj.weight:0.006/7.6e-08, short_lstm.bias_ih_l0_reverse:0.005/4.6e-07, short_lstm.bias_hh_l0_reverse:0.005/5.0e-07, ln_flat.bias:0.005/7.4e-05, ln_proj.bias:0.005/6.2e-05, feature_proj.bias:0.005/8.0e-07, out_proj.bias:0.004/6.0e-05, norm2.bias:0.004/5.7e-05, norm1.bias:0.004/5.3e-05, linear2.bias:0.004/1.3e-06, norm2.weight:0.004/4.8e-08, norm1.weight:0.003/4.5e-08, ln_short.bias:0.003/3.9e-05, ln_short.weight:0.003/3.4e-08, self_attn.in_proj_bias:0.002/1.6e-05, linear1.bias:0.002/1.4e-07, short_lstm.weight_hh_l0_reverse:0.002/2.5e-08

------------------------------------------------------------------------------------------------------------------------------------------------------
RUN START: 2025-10-26T18:28:42.135757Z

SINGLE RUN DIAGNOSTIC FORMAT (explanatory)
    BATCH_SHAPE B=... groups=... seq_len_full=... feat=... : canonical input geometry used to build forwarded windows (snapshot.B, snapshot.groups, snapshot.seq_len_full, snapshot.feat_dim)
    MICRODETAIL ms: <k=v ...> : deterministic single-line dump of snapshot keys (sorted). Notable printed keys below reference exact snapshot field names and formats.
      -> B: number of batch samples used to build windows (snapshot.B)
      -> activation_mb: estimated activation footprint in MB computed from allocation delta (snapshot.activation_mb)
      -> backward_ms: placeholder for backward pass ms (None here; snapshot.backward_ms)
      -> collector_ms: total wall-clock ms spent by the collector (includes sampling, CPU/GPU syncs) (snapshot.collector_ms)
      -> cpu_copy_bytes: bytes copied to host for predictions, shown human-readable in log (snapshot.cpu_copy_bytes)
      -> dataloader_ms: ms spent fetching the sampled batch from the dataloader (snapshot.dataloader_ms)
      -> device_syncs_count: count of explicit torch.cuda.synchronize() calls used for timing accuracy (snapshot.device_syncs_count)
      -> env: small dict with python/torch/cuda/device_name strings (snapshot.env)
      -> expected_segments: nominal B * groups (snapshot.expected_segments)
      -> feat_dim: feature dimension of inputs used to build windows (snapshot.feat_dim)
      -> full_forward_ms: wall-clock ms for the sampled forward over prepared windows (snapshot.full_forward_ms)
      -> gpu_allocated_bytes / gpu_reserved_bytes: raw GPU bytes allocated/reserved (snapshot.gpu_allocated_bytes, snapshot.gpu_reserved_bytes)
      -> gpu_peak_mb / gpu_reserved_mb: peak/reserved GPU memory in MB (snapshot.gpu_peak_mb, snapshot.gpu_reserved_mb)
      -> grads: dict {'backbone': bool, 'head': bool} indicating gradient presence by name-bucket (snapshot.grads)
      -> group_nonzero_counts: per-optimizer-group counts of parameters with non-None .grad (snapshot.group_nonzero_counts)
      -> groups: number of logical groups used when flattening windows (snapshot.groups)
      -> mean_seg_len: average per-segment time-series length in timesteps (snapshot.mean_seg_len)
      -> num_segments: actual number of flattened segments forwarded (snapshot.num_segments)
      -> out_bytes / out_dtype / out_numel / out_shape: model output bytes (human-readable in log), dtype string, element count, and tuple shape (snapshot.out_bytes, snapshot.out_dtype, snapshot.out_numel, snapshot.out_shape)
      -> param_bytes: total parameter memory in bytes (human-readable in log; raw int in snapshot.param_bytes)
      -> per_segment_p50_ms / per_segment_p90_ms: empirical per-segment forward-ms percentiles when sampling enabled (snapshot.per_segment_p50_ms, snapshot.per_segment_p90_ms)
      -> pred_extra_ms / preds_cpu_ms: placeholder for extra pred cost and ms to detach+copy preds to CPU (snapshot.pred_extra_ms, snapshot.preds_cpu_ms)
      -> raw_reg_shape: the raw detached regression output shape (snapshot.raw_reg_shape)
      -> segments_per_sec: inferred throughput = num_segments / (full_forward_ms/1000.0) (snapshot.segments_per_sec)
      -> seq_len_full: nominal full sequence length used when padding/truncating windows (snapshot.seq_len_full)
      -> step_block_ms: placeholder for step-block timing if measured (snapshot.step_block_ms)
      -> sum_seg_lens: sum of segment lengths used to compute mean_seg_len (snapshot.sum_seg_lens)
      -> windows_bytes: total bytes for the windows tensor (human-readable in log; raw int in snapshot.windows_bytes)

PER-EPOCH LOG FORMAT (explanatory):
  E{ep:02d}                : epoch number formatted with two digits
  OPTS[{groups}:{lrs}|cnts=[c1,c2,...]] : optimizer groups count, compact LR preview (first up to 3) and per-group parameter counts (from optimizer.param_groups)
  GN[reg,cls,ter,tot]      : gradient norms for name-buckets reg/cls/ter and total (sqrt of sum squares over matching named parameters; zero means no matching names found)
  GD[med,p90,max]         : gradient-norm distribution statistics printed as median, 90th-percentile, and maximum (index-based p90)
  UR[med,max]             : update-ratio statistics (median,max) where update_ratio = lr * grad_norm / max(weight_norm,1e-8)
  LR_MAIN={lr:.1e} | lr={lr:.1e} : primary LR token and explicit current lr printed in scientific notation
  TR[rmse,r2,mae]         : training metrics (RMSE, R^2, MAE) reported for the epoch (train_metrics)
  VL[rmse,r2,mae]         : validation metrics (RMSE, R^2, MAE) reported for the epoch (val_metrics)
  SR={slope_rmse:.3f}     : slope RMSE computed on model.last_val_preds/model.last_val_targs (trend calibration)
  SL={slip:.2f},HR={hub_max:.3f} : slip fraction and hub max indicators derived from model.last_hub (defaults to 0.00/0.000 when missing)
  SCHED_PCT={pct:.1f}%     : optional scheduler percent-complete when scheduler exposes _total_steps and a step counter
  T={elapsed:.1f}s,TP={throughput:.1f}s/s : optional epoch elapsed and throughput if model stored _last_epoch_elapsed and _last_epoch_samples
  GPU={GiB:.2f}GiB         : optional high-water GPU memory in GiB when CUDA available (torch.cuda.max_memory_allocated)
  *CHKPT                  : optional marker when model._last_epoch_checkpoint is truthy
  LAYER_GN[...]           : optional small set of monitored layer norms and ratio-to-baseline printed as name_short:curr_norm/ratio
  TOP_K(G/U)=param:grad_norm/update_ratio,... : top-k parameter entries by gradient norm with their update ratios (short names use last two name segments)

BASELINES:
  TRAIN mean RMSE        = 0.04190
  TRAIN persistence RMSE = 0.00941
  VAL   mean RMSE        = 0.06583
  VAL   persistence RMSE = 0.01214

HYPERPARAMS:
  LOOK_BACK = 60
  USE_CONV = False
  CONV_K = 3
  CONV_DILATION = 1
  USE_TCN = False
  TCN_LAYERS = 2
  TCN_KERNEL = 3
  USE_SHORT_LSTM = True
  SHORT_UNITS = 64
  DROPOUT_SHORT = 0.0
  USE_TRANSFORMER = True
  TRANSFORMER_LAYERS = 1
  TRANSFORMER_HEADS = 4
  TRANSFORMER_FF_MULT = 4
  DROPOUT_LONG = 0.0
  USE_LONG_LSTM = False
  LONG_UNITS = 64
  FLATTEN_MODE = last
  PRED_HIDDEN = 64
  ALPHA_SMOOTH = 0.1
  MAX_EPOCHS = 90
  EARLY_STOP_PATIENCE = 9
  WEIGHT_DECAY = 1e-05
  CLIPNORM = 5
  ONECYCLE_MAX_LR = 0.001
  ONECYCLE_DIV_FACTOR = 10
  ONECYCLE_FINAL_DIV = 50
  ONECYCLE_PCT_START = 0.2
  ONECYCLE_STRATEGY = cos
  TRAIN_BATCH = 64
  VAL_BATCH = 1
  TRAIN_WORKERS = 8
  TRAIN_PREFETCH_FACTOR = 4
  MICRO_SAMPLE_K = 16

BATCH_SHAPE B=64 groups=451 seq_len_full=60 feat=20
MICRODETAIL ms: B=64 activation_mb=4166 backward_ms=None collector_ms=965.25 cpu_copy_bytes=46KB dataloader_ms=675.48 device_syncs_count=35 env={'python': '3.12.3', 'torch': '2.7.0a0+ecf3bae40a.nv25.02', 'cuda': '12.8', 'device_name': 'NVIDIA GeForce RTX 5080 Laptop GPU'} expected_segments=28864 feat_dim=20 full_forward_ms=56.95 gpu_allocated_bytes=4800MB gpu_peak_mb=6479 gpu_reserved_bytes=13828MB gpu_reserved_mb=13828 grads={'backbone': True, 'head': True} group_nonzero_counts=[36] groups=451 mean_seg_len=2.53 num_segments=23903 out_bytes=46KB out_dtype=torch.float16 out_numel=23903 out_shape=(23903, 1, 1) param_bytes=300KB per_segment_p50_ms=2.36 per_segment_p90_ms=3.25 pred_extra_ms=None preds_cpu_ms=0.27 raw_reg_shape=(23903, 1, 1) segments_per_sec=419700.71 seq_len_full=60 step_block_ms=None sum_seg_lens=134 windows_bytes=109MB

E01 | OPTS[1:1.1e-04|cnts=[36]] | GN[0.053,0.000,0.000,0.070] | GD[2.5e-03,2.0e-02,3.6e-02] | UR[4.8e-07,6.4e-05] | LR_MAIN=1.1e-04 | lr=1.1e-04 | TR[0.108,0.09,0.075] | VL[0.100,0.17,0.072] | SR=0.014 | SL=0.00,HR=0.000 |  | T=22.5s,TP=77030.4s/s | GPU=6.33GiB | LAYER_GN[weight_ih_l0:9.707e-03/1.00,weight:2.950e-02/1.00,weight:2.041e-02/1.00] | 
TOP_K(G/U)=weight.original1:0.036/8.4e-07, weight.original1:0.036/6.6e-06, short2long.weight:0.030/6.8e-07, feature_proj.weight:0.020/4.8e-07, linear2.weight:0.014/3.1e-07, 2.bias:0.013/6.4e-05, out_proj.weight:0.011/2.5e-07, short_lstm.weight_ih_l0:0.010/2.0e-07, self_attn.in_proj_weight:0.009/9.8e-08, linear1.weight:0.007/8.4e-08, short_lstm.bias_ih_l0:0.006/5.5e-07, short_lstm.bias_hh_l0:0.006/5.6e-07, 0.bias:0.005/9.6e-07, short_lstm.weight_hh_l0:0.004/6.9e-08, short_lstm.weight_ih_l0_reverse:0.004/7.7e-08, short2long.bias:0.004/6.5e-07, weight.original0:0.003/7.9e-08, feature_proj.bias:0.003/4.9e-07, out_proj.bias:0.002/5.9e-05, short_lstm.bias_ih_l0_reverse:0.002/2.1e-07, short_lstm.bias_hh_l0_reverse:0.002/2.2e-07, norm2.bias:0.002/6.0e-05, norm1.bias:0.002/5.3e-05, ln_flat.bias:0.002/5.3e-05, ln_proj.bias:0.002/5.2e-05, linear2.bias:0.002/7.5e-07, norm2.weight:0.002/2.7e-08, ln_flat.weight:0.002/2.7e-08, ln_proj.weight:0.002/2.7e-08, norm1.weight:0.002/2.5e-08, weight.original0:0.002/3.0e-07, self_attn.in_proj_bias:0.001/1.6e-05, ln_short.bias:0.001/3.6e-05, ln_short.weight:0.001/1.7e-08, short_lstm.weight_hh_l0_reverse:0.001/1.6e-08, linear1.bias:0.001/8.4e-08
