{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457f3994-6d3b-4a52-9d2e-35e0e29924f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'libs.models.dual_lstm' from '/workspace/my_models/Trading/_Stock_Analysis_/libs/models/dual_lstm.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 1) Wipe out your namespace\n",
    "%reset -f\n",
    "\n",
    "# 2) Clear Jupyter’s stored outputs (and inputs if you like)\n",
    "try:\n",
    "    Out.clear()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    In.clear()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# 3) Force Python GC\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# 4) Free any GPU buffers\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "import importlib\n",
    "from libs import params, trades, feats, plots, models_core\n",
    "from libs.models import dual_lstm\n",
    "importlib.reload(params)\n",
    "importlib.reload(trades)\n",
    "importlib.reload(feats)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(models_core)\n",
    "importlib.reload(dual_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2366b422-dfac-4830-8f50-db7b522f2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off interactive plotting globally (we’ll manage our own display)\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # safe, headless-friendly\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.exceptions import TrialPruned\n",
    "from optuna.importance import get_param_importances\n",
    "\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9498b30-9abb-4123-87f1-0ed191478e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_sel = pd.read_csv(params.feat_all_csv, index_col=0, parse_dates=True)[params.features_cols_tick + ['bid','ask'] + [params.label_col]]\n",
    "    \n",
    "df_feat_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2e58b-3140-4a76-9473-1fab56c18d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate look_backs under half the interval between the day’s first and sess_start\n",
    "\n",
    "first_time = (\n",
    "    df_feat_sel.index\n",
    "        .to_series()\n",
    "        .groupby(df_feat_sel.index.normalize())\n",
    "        .min()\n",
    "        .dt.time\n",
    "        .mode()[0]\n",
    ")\n",
    "\n",
    "# convert both times to minutes since midnight\n",
    "fm = first_time.hour * 60 + first_time.minute\n",
    "sm = params.sess_start.hour * 60 + params.sess_start.minute\n",
    "\n",
    "# half the difference, count full 30-min slots, and build multiples\n",
    "n_steps    = int(((sm - fm) / 2) // 30)      # e.g. floor(165/30) = 5\n",
    "look_backs = [30 * i for i in range(1, n_steps + 1)]\n",
    "look_backs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4612b-f5bb-4e4a-8784-6d5689de67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Optuna objective definition\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# look_backs = [30, 45, 60, 75, 90] ################################\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    hp = {\n",
    "    # ── Architecture ────────────────────────────────────────────────\n",
    "    \"look_back\"    : trial.suggest_categorical(\"look_back\", look_backs),\n",
    "    \"DROPOUT_SHORT\": trial.suggest_float(\"DROPOUT_SHORT\", 0.05, 0.35),\n",
    "    \"DROPOUT_LONG\":  trial.suggest_float(\"DROPOUT_LONG\",  0.05, 0.35),\n",
    "    \"ATT_DROPOUT\":   trial.suggest_float(\"ATT_DROPOUT\",   0.05, 0.35),\n",
    "    \n",
    "    # ── Optimizer & Scheduler ──────────────────────────────────────\n",
    "    \"INITIAL_LR\":    trial.suggest_float(\"INITIAL_LR\",    1e-5, 1e-3,   log=True),\n",
    "    \"ETA_MIN\":       trial.suggest_float(\"ETA_MIN\",       1e-6, 1e-5,   log=True),\n",
    "    \"WEIGHT_DECAY\":  trial.suggest_float(\"WEIGHT_DECAY\",  1e-5, 1e-2,  log=True),\n",
    "    \"CLIPNORM\":      trial.suggest_float(\"CLIPNORM\",      0.1, 10),\n",
    "    }\n",
    "\n",
    "    print(f\"\\n▶ Trial {trial.number} starting with:\\n{hp}\\n\")\n",
    "\n",
    "    sess_start_pred = dt.time(*divmod((params.sess_start.hour * 60 + params.sess_start.minute) - hp[\"look_back\"], 60))\n",
    "    \n",
    "    print('Build LSTM input tensors (disk-backed memmaps)...')\n",
    "    X, y_sig, y_ret, raw_close, raw_bid, raw_ask, end_times = models_core.build_tensors(\n",
    "        df            = df_feat_sel,\n",
    "        sess_start    = sess_start_pred \n",
    "    )\n",
    "    \n",
    "    print('Split into train/val/test by calendar day...')\n",
    "    (\n",
    "    (X_tr,  y_sig_tr,  y_ret_tr),\n",
    "    (X_val, y_sig_val, y_ret_val),\n",
    "    (X_te,  y_sig_te,  y_ret_te,  raw_close_te, raw_bid_te, raw_ask_te),\n",
    "    samples_per_day,\n",
    "    day_id_tr, day_id_val, day_id_te\n",
    "    ) = models_core.chronological_split(\n",
    "        X, y_sig, y_ret,\n",
    "        raw_close, raw_bid, raw_ask,\n",
    "        end_times   = end_times,\n",
    "        train_prop  = params.train_prop,\n",
    "        val_prop    = params.val_prop,\n",
    "        train_batch = params.hparams['TRAIN_BATCH']\n",
    "    )\n",
    "\n",
    "    print('Carve `end_times` into the same three splits...')\n",
    "    n_tr  = day_id_tr .shape[0] \n",
    "    n_val = day_id_val.shape[0]\n",
    "    i_tr  = n_tr\n",
    "    i_val = n_tr + n_val\n",
    "    \n",
    "    end_times_tr  = end_times[:i_tr]\n",
    "    end_times_val = end_times[i_tr:i_val]\n",
    "    end_times_te  = end_times[i_val:]\n",
    "    \n",
    "    print('Build DataLoaders over calendar‐days...')\n",
    "    train_loader, val_loader, test_loader = models_core.split_to_day_datasets(\n",
    "        # train split:   \n",
    "        X_tr,            y_sig_tr,     y_ret_tr,   end_times_tr,\n",
    "        # val split:\n",
    "        X_val,           y_sig_val,    y_ret_val,  end_times_val,\n",
    "        # test split + raw‐prices\n",
    "        X_te,            y_sig_te,     y_ret_te,   end_times_te,\n",
    "        raw_close_te, raw_bid_te, raw_ask_te,\n",
    "        \n",
    "        sess_start_time       = sess_start_pred,\n",
    "        signal_thresh         = params.best_optuna_params[\"buy_threshold\"],\n",
    "        return_thresh         = 0.01,  # flat‐zone threshold for returns (to tune)\n",
    "        train_batch           = params.hparams[\"TRAIN_BATCH\"],\n",
    "        train_workers         = params.hparams[\"NUM_WORKERS\"],\n",
    "        train_prefetch_factor = params.hparams[\"TRAIN_PREFETCH_FACTOR\"]\n",
    "    )\n",
    "\n",
    "    print('Instantiate the stateful DualMemoryLSTM...')\n",
    "    model = dual_lstm.DualMemoryLSTM(\n",
    "        n_feats        = X.shape[-1],                          \n",
    "        short_units    = params.hparams['SHORT_UNITS'],    \n",
    "        long_units     = params.hparams['LONG_UNITS'],     \n",
    "        dropout_short  = hp[\"DROPOUT_SHORT\"],  \n",
    "        dropout_long   = hp[\"DROPOUT_LONG\"],   \n",
    "        att_heads      = params.hparams['ATT_HEADS'],\n",
    "        att_drop       = hp['ATT_DROPOUT']\n",
    "    )\n",
    "    model.to(params.device)  \n",
    "\n",
    "    print('Build optimizer, LR scheduler, AMP scaler, and gradient‐clip norm...')\n",
    "    optimizer, plateau_sched, _ , scaler, clipnorm = \\\n",
    "        models_core.make_optimizer_and_scheduler(\n",
    "            model            = model,\n",
    "            initial_lr       = hp[\"INITIAL_LR\"],\n",
    "            weight_decay     = hp[\"WEIGHT_DECAY\"],\n",
    "            clipnorm         = hp[\"CLIPNORM\"]\n",
    "        )\n",
    "    cosine_sched = CosineAnnealingWarmRestarts(\n",
    "        optimizer, \n",
    "        T_0=params.hparams['T_0'], \n",
    "        T_mult=params.hparams['T_MULT'], \n",
    "        eta_min=hp['ETA_MIN']\n",
    "    )\n",
    "    \n",
    "    print('Run the custom stateful training loop...')\n",
    "    best_val_rmse  = dual_lstm.lstm_training_loop(\n",
    "        model               = model,\n",
    "        optimizer           = optimizer,\n",
    "        cosine_sched        = cosine_sched,\n",
    "        plateau_sched       = plateau_sched,\n",
    "        scaler              = scaler,\n",
    "        train_loader        = train_loader,\n",
    "        val_loader          = val_loader,\n",
    "        max_epochs          = params.hparams['MAX_EPOCHS'],\n",
    "        early_stop_patience = params.hparams['EARLY_STOP_PATIENCE'],\n",
    "        clipnorm            = hp[\"CLIPNORM\"],\n",
    "        device              = params.device\n",
    "    )\n",
    "\n",
    "    print('Delete variables to free memory...')\n",
    "    del model, optimizer, plateau_sched, cosine_sched, scaler\n",
    "    del X, y_sig, y_ret, raw_close, raw_bid, raw_ask\n",
    "    del X_tr,  y_sig_tr,  y_ret_tr, X_val, y_sig_val, y_ret_val, X_te,  y_sig_te,  y_ret_te\n",
    "    del raw_close_te, raw_bid_te, raw_ask_te\n",
    "    del train_loader, val_loader, test_loader\n",
    "\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return best_val_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce185de-1d62-49f9-9a96-00385e813521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build blank figure & line\n",
    "fig, ax = plt.subplots(figsize=(7,3))\n",
    "line, = ax.plot([], [], \"bo-\")\n",
    "ax.set(xlabel=\"Trial #\", ylabel=\"Objective\",\n",
    "       title=\"Optuna optimization progress\")\n",
    "ax.grid(True)\n",
    "\n",
    "# display once and grab the handle\n",
    "handle = display(fig, display_id=True)\n",
    "plt.close(fig)\n",
    "\n",
    "# ask plots.py for a callback bound to these objects\n",
    "live_cb = plots.make_live_plot_callback(fig, ax, line, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7658050b-a604-4331-ac64-72b2c7fd3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  Create Optuna study and run optimization\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "study = optuna.create_study(\n",
    "    storage=\"sqlite:///optuna_study.db\",    # Point it at an SQLite file so it writes out each result immediately instead of buffering in RAM\n",
    "    load_if_exists=True,\n",
    "    direction=\"minimize\",\n",
    "    pruner=MedianPruner(n_startup_trials=6, n_warmup_steps=12),\n",
    ")\n",
    "\n",
    "        \n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials = 100,\n",
    "    n_jobs   = 1,\n",
    "    callbacks=[live_cb, plots.cleanup_callback],\n",
    ")\n",
    "\n",
    "plt.close('all')   # safe here; the final image remains displayed in the notebook output\n",
    "gc.collect()       # optional extra sweep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312366c-7f12-4c10-9f34-0647d6be022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  Print out the best hyperparameters & result\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation RMSE:\", study.best_value)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  Compute and print parameter importances\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "imps = get_param_importances(study)\n",
    "print(\"\\nHyperparameter importances (higher ⇒ more impact on RMSE):\")\n",
    "for name, score in sorted(imps.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {name:20s} : {score:.3f}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  Dump study results to JSON\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Build your session‐only DataFrame once\n",
    "session_df = df.between_time(params.regular_start,\n",
    "                             params.regular_end)\n",
    "\n",
    "# 2) Derive the trading‐day boundaries\n",
    "first_day = session_df.index.normalize().min()\n",
    "last_day  = session_df.index.normalize().max()\n",
    "\n",
    "# 3) Format your file name\n",
    "start_date = first_day.strftime(\"%Y%m%d\")\n",
    "end_date   = last_day.strftime(\"%Y%m%d\")\n",
    "file_name  = f\"{params.ticker}_{start_date}-{end_date}_optuna_model_hpars.json\"\n",
    "file_path  = os.path.join(results_folder, file_name)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Dump study results (including importances)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params\": study.best_params,\n",
    "            \"best_value\" : study.best_value,\n",
    "            \"importances\": imps,\n",
    "            \"trials\": [\n",
    "                {\"number\": t.number, \"value\": t.value, \"params\": t.params, \n",
    "                 \"state\": t.state.name}\n",
    "                for t in study.trials\n",
    "            ],\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )\n",
    "\n",
    "print(f\"\\nOptuna results (and importances) saved to: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97c435-e800-483e-b2ab-f9412ef6954e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865782e-fc07-4354-a5b9-2cdeed1ebad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa9fb2-411b-4d9f-9a33-e6f6c59de7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
