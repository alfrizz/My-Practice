{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35445790-eaab-428e-9fb9-1d07594ee3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from pandas import Timestamp\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "import optuna\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126b826b-72fe-4766-88ea-910e010d6fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>gmtoffset</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-02 09:00:00</th>\n",
       "      <td>1735808400</td>\n",
       "      <td>0</td>\n",
       "      <td>251.9000</td>\n",
       "      <td>251.90</td>\n",
       "      <td>250.6000</td>\n",
       "      <td>251.3600</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 09:01:00</th>\n",
       "      <td>1735808460</td>\n",
       "      <td>0</td>\n",
       "      <td>251.3700</td>\n",
       "      <td>251.54</td>\n",
       "      <td>251.2600</td>\n",
       "      <td>251.3200</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 09:02:00</th>\n",
       "      <td>1735808520</td>\n",
       "      <td>0</td>\n",
       "      <td>251.3700</td>\n",
       "      <td>251.43</td>\n",
       "      <td>251.2100</td>\n",
       "      <td>251.2100</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 09:03:00</th>\n",
       "      <td>1735808580</td>\n",
       "      <td>0</td>\n",
       "      <td>251.3000</td>\n",
       "      <td>251.30</td>\n",
       "      <td>250.9800</td>\n",
       "      <td>250.9800</td>\n",
       "      <td>1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 09:04:00</th>\n",
       "      <td>1735808640</td>\n",
       "      <td>0</td>\n",
       "      <td>250.9600</td>\n",
       "      <td>251.15</td>\n",
       "      <td>250.9400</td>\n",
       "      <td>251.0300</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 23:55:00</th>\n",
       "      <td>1748994900</td>\n",
       "      <td>0</td>\n",
       "      <td>203.0000</td>\n",
       "      <td>203.00</td>\n",
       "      <td>202.8635</td>\n",
       "      <td>202.9900</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 23:56:00</th>\n",
       "      <td>1748994960</td>\n",
       "      <td>0</td>\n",
       "      <td>202.9725</td>\n",
       "      <td>202.99</td>\n",
       "      <td>202.9201</td>\n",
       "      <td>202.9201</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 23:57:00</th>\n",
       "      <td>1748995020</td>\n",
       "      <td>0</td>\n",
       "      <td>202.9700</td>\n",
       "      <td>202.97</td>\n",
       "      <td>202.9300</td>\n",
       "      <td>202.9699</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 23:58:00</th>\n",
       "      <td>1748995080</td>\n",
       "      <td>0</td>\n",
       "      <td>202.9200</td>\n",
       "      <td>202.96</td>\n",
       "      <td>202.9200</td>\n",
       "      <td>202.9600</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03 23:59:00</th>\n",
       "      <td>1748995140</td>\n",
       "      <td>0</td>\n",
       "      <td>202.9600</td>\n",
       "      <td>203.05</td>\n",
       "      <td>202.9000</td>\n",
       "      <td>203.0000</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99597 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp  gmtoffset      open    high       low  \\\n",
       "datetime                                                                 \n",
       "2025-01-02 09:00:00  1735808400          0  251.9000  251.90  250.6000   \n",
       "2025-01-02 09:01:00  1735808460          0  251.3700  251.54  251.2600   \n",
       "2025-01-02 09:02:00  1735808520          0  251.3700  251.43  251.2100   \n",
       "2025-01-02 09:03:00  1735808580          0  251.3000  251.30  250.9800   \n",
       "2025-01-02 09:04:00  1735808640          0  250.9600  251.15  250.9400   \n",
       "...                         ...        ...       ...     ...       ...   \n",
       "2025-06-03 23:55:00  1748994900          0  203.0000  203.00  202.8635   \n",
       "2025-06-03 23:56:00  1748994960          0  202.9725  202.99  202.9201   \n",
       "2025-06-03 23:57:00  1748995020          0  202.9700  202.97  202.9300   \n",
       "2025-06-03 23:58:00  1748995080          0  202.9200  202.96  202.9200   \n",
       "2025-06-03 23:59:00  1748995140          0  202.9600  203.05  202.9000   \n",
       "\n",
       "                        close  volume  \n",
       "datetime                               \n",
       "2025-01-02 09:00:00  251.3600     834  \n",
       "2025-01-02 09:01:00  251.3200    1175  \n",
       "2025-01-02 09:02:00  251.2100     847  \n",
       "2025-01-02 09:03:00  250.9800    1692  \n",
       "2025-01-02 09:04:00  251.0300     633  \n",
       "...                       ...     ...  \n",
       "2025-06-03 23:55:00  202.9900     755  \n",
       "2025-06-03 23:56:00  202.9201     531  \n",
       "2025-06-03 23:57:00  202.9699     222  \n",
       "2025-06-03 23:58:00  202.9600     865  \n",
       "2025-06-03 23:59:00  203.0000     300  \n",
       "\n",
       "[99597 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"AAPL\"\n",
    "folder = \"Intraday stocks\" \n",
    "\n",
    "pattern = os.path.join(folder, f\"{ticker}_*.csv\")\n",
    "files = glob.glob(pattern)\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No files found for ticker {ticker} in {folder}\")\n",
    "\n",
    "# If there are multiple files, you might sort them or choose the first one.\n",
    "files.sort()  # sorts alphabetically\n",
    "file_to_read = files[0]\n",
    "\n",
    "df = pd.read_csv(file_to_read, index_col=0, parse_dates=[\"datetime\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d4288f-76d6-47f0-94a0-ca5be2791396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_prepost_trading_data(df, regular_start, regular_end):\n",
    "    \"\"\"\n",
    "    Modifies the input DataFrame in place by shifting entire days that begin in the 8:00 hour\n",
    "    by +1 hour so that the trading times become aligned (solar times), and then smoothing\n",
    "    all data outside the regular trading session continuously across day boundaries.\n",
    "    \n",
    "    The smoothing window (in minutes) is computed from the ratio of average volumes in the \n",
    "    regular and non-regular sessions.\n",
    "    \n",
    "    All columns (open, high, low, close, volume, ask, bid) are then smoothed using a moving\n",
    "    average over the non-regular rows (i.e. those outside the session defined by regular_start \n",
    "    and regular_end). The original columns are preserved with an \"_orig\" suffix.\n",
    "    \n",
    "    Within the smoothing loop:\n",
    "      - Price columns (open, high, low, close, ask, bid) are rounded to 4 decimals.\n",
    "      - The volume column is rounded to the nearest integer.\n",
    "    \n",
    "    Additionally, the DataFrame's index is updated to reflect the shifted (solar) times.\n",
    "    \n",
    "    Parameters:\n",
    "      df : pd.DataFrame\n",
    "          DataFrame with columns: open, high, low, close, volume, ask, bid and a DatetimeIndex.\n",
    "      regular_start : The start time of the regular session.\n",
    "      regular_end :  The end time of the regular session.\n",
    "    \n",
    "    Returns:\n",
    "      df : pd.DataFrame\n",
    "          The same DataFrame (modified in place) with updated columns and index.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df[['open', 'high', 'low', 'close', 'volume']]\n",
    "    \n",
    "    ask_bid_spread = 0.03 / 100.0 # setting a fixed spread (to replace with real ask bid price values)\n",
    "    # Create 'ask' as close price plus the spread fraction and 'bid' as close price minus the spread fraction.\n",
    "    df=df.copy()\n",
    "    df['ask'] = round(df['close'] * (1 + ask_bid_spread),4)\n",
    "    df['bid'] = round(df['close'] * (1 - ask_bid_spread),4)\n",
    "    \n",
    "    # Create a copy of the original columns by renaming them with an \"_orig\" suffix,\n",
    "    # and re-create working columns.\n",
    "    for col in list(df.columns):\n",
    "        df.rename(columns={col: f\"{col}_orig\"}, inplace=True)\n",
    "        df[col] = df[f\"{col}_orig\"]\n",
    "\n",
    "    # Identify the working columns (those not ending with \"_orig\") and convert them to float.\n",
    "    working_cols = [col for col in df.columns if not col.endswith(\"_orig\")]\n",
    "    df[working_cols] = df[working_cols].astype(np.float64)\n",
    "\n",
    "    # Compute adjusted times (temporary Series) by shifting days with an 8:00 hour start.\n",
    "    adj_times = df.index.to_series().copy()\n",
    "    for day, group in df.groupby(df.index.normalize()):\n",
    "        if group.index.min().hour == 8:  # if first timestamp is anywhere between 08:00 and 08:59\n",
    "            adj_times.loc[group.index] = group.index + pd.Timedelta(hours=1)\n",
    "        else:\n",
    "            adj_times.loc[group.index] = group.index\n",
    "\n",
    "    # Create masks for regular vs. non-regular rows using the adjusted times.\n",
    "    regular_mask = (adj_times.dt.time >= regular_start) & (adj_times.dt.time <= regular_end)\n",
    "    nonregular_mask = ~regular_mask\n",
    "\n",
    "    # Compute the smoothing window size based on the ratio of average volumes.\n",
    "    avg_vol_regular = df.loc[regular_mask, \"volume_orig\"].mean()\n",
    "    avg_vol_nonregular = df.loc[nonregular_mask, \"volume_orig\"].mean()\n",
    "    ratio = avg_vol_regular / (avg_vol_nonregular if avg_vol_nonregular != 0 else 1)\n",
    "    window_nonregular = max(int(round(ratio)), 1)\n",
    "    \n",
    "    # Loop only through the working columns\n",
    "    for col in working_cols:\n",
    "        # Extract non‑regular rows (resetting the index to get a continuous Series).\n",
    "        series_nr = df.loc[nonregular_mask, col].reset_index(drop=True)\n",
    "        smoothed = series_nr.rolling(window=window_nonregular, min_periods=1).mean().values.astype(np.float64)\n",
    "        if col != \"volume\":\n",
    "            df.loc[nonregular_mask, col] = np.round(smoothed, 4).astype(np.float64)\n",
    "        else:\n",
    "            df.loc[nonregular_mask, col] = np.rint(smoothed).astype(np.int64)\n",
    "\n",
    "    # Update the DataFrame's index to the adjusted times.\n",
    "    df.index = adj_times\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c97398c-c1f7-4fde-876c-48b3a52afde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_trades(df, min_prof_thr, max_down_prop):\n",
    "    \"\"\"\n",
    "    Identifies trades from a one-minute bars DataFrame with an added retracement rule.\n",
    "    \n",
    "    Criteria:\n",
    "      - A buy candidate is a local minimum (price lower than its immediate neighbors).\n",
    "      - From that buy, the algorithm scans forward updating the highest price seen (candidate sell).\n",
    "      - If the price later retraces by more than max_down_prop (as a fraction of the overall gain \n",
    "        from buy to the highest price), the trade is \"closed\" immediately and recorded using \n",
    "        the previously recorded maximum as its sell point.\n",
    "      - The trade is recorded only if the profit percentage exceeds the min_gain_thr.\n",
    "    \n",
    "    Parameters:\n",
    "      df : pd.DataFrame\n",
    "         DataFrame with a datetime index and a 'close' column.\n",
    "      min_prof_thr : float\n",
    "         Minimum profit percentage required (e.g., 1.5 for 1.5%).\n",
    "      max_down_prop : float\n",
    "         Maximum allowed retracement (as a fraction of the gain). For example, 0.5 means that if\n",
    "         the price falls more than 50% of (max_so_far - buy_price) after the buy, then the trade is closed.\n",
    "    \n",
    "    Returns:\n",
    "      trades : list\n",
    "         A list of tuples, each trade represented as:\n",
    "           ((buy_date, sell_date), (buy_price, sell_price), profit_pc)\n",
    "    \"\"\"\n",
    "    trades = []\n",
    "    closes = df['close'].values\n",
    "    dates = df.index\n",
    "    n = len(df)\n",
    "    i = 1  # start from the second element\n",
    "\n",
    "    while i < n - 1:\n",
    "        # Look for a local minimum as the candidate buy point.\n",
    "        if closes[i] < closes[i - 1] and closes[i] < closes[i + 1]:\n",
    "            buy_index = i\n",
    "            buy_date = dates[buy_index]\n",
    "            buy_price = closes[buy_index]\n",
    "            \n",
    "            # Initialize the candidate sell data.\n",
    "            max_so_far = buy_price\n",
    "            candidate_sell_index = None\n",
    "            \n",
    "            # Scan forward to find the candidate sell (local maximum) while monitoring retracement.\n",
    "            j = i + 1\n",
    "            while j < n:\n",
    "                current_price = closes[j]\n",
    "                if current_price > max_so_far:\n",
    "                    max_so_far = current_price\n",
    "                    candidate_sell_index = j\n",
    "                else:\n",
    "                    # Only check retracement if we've seen an increase.\n",
    "                    if max_so_far > buy_price:\n",
    "                        retracement = (max_so_far - current_price) / (max_so_far - buy_price)\n",
    "                        # Instead of invalidating the trade, break out to \"close\" it.\n",
    "                        if retracement > max_down_prop:\n",
    "                            break\n",
    "                j += 1\n",
    "\n",
    "            # If we found any candidate sell, record the trade.\n",
    "            if candidate_sell_index is not None:\n",
    "                sell_index = candidate_sell_index\n",
    "                sell_date = dates[sell_index]\n",
    "                sell_price = closes[sell_index]\n",
    "                profit_pc = ((sell_price - buy_price) / buy_price) * 100\n",
    "                if profit_pc >= min_prof_thr:\n",
    "                    trades.append(((buy_date, sell_date), (buy_price, sell_price), profit_pc))\n",
    "                # Jump past the sell point to avoid overlapping trades.\n",
    "                i = sell_index + 1\n",
    "            else:\n",
    "                i = buy_index + 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return trades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0450622-861e-459f-b525-15a37668a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_trades_daily(df, min_prof_thr, max_down_prop, regular_start_shifted, regular_end, day_to_check=None):\n",
    "    \"\"\"\n",
    "    Identifies all trades for each trading day in a multi-day DataFrame and returns,\n",
    "    for each day, a DataFrame reindexed to exactly cover the trading hours (at one-minute intervals)\n",
    "    along with the list of identified trades for that day.\n",
    "\n",
    "    Process:\n",
    "      1. Ensure the DataFrame index is a DatetimeIndex.\n",
    "      2. Group the DataFrame by day (using the normalized date).\n",
    "      3. For each day:\n",
    "           a. Build a fixed date_range from regular_start_shifted to regular_end.\n",
    "           b. Filter the day’s data to these trading hours using between_time().\n",
    "           c. Reindex the filtered data to the fixed minute index and forward-fill missing values.\n",
    "           d. Identify trades using identify_trades(day_df, min_prof_thr, max_down_prop).\n",
    "      4. Only store days where at least one trade is found.\n",
    "\n",
    "    Parameters:\n",
    "      df : pd.DataFrame\n",
    "          A DataFrame with a datetime index (or a column convertible to datetime) and at least a 'close' column.\n",
    "      min_prof_thr : float\n",
    "          The minimum profit percentage required to record a trade.\n",
    "      max_down_prop : float\n",
    "          The maximum allowed retracement in each trade.\n",
    "      regular_start_shifted: datetime\n",
    "          The start time for the trading session (e.g., '13:00' for shifted timestamps).\n",
    "      regular_end : datetime\n",
    "          The end time for the trading session (e.g., '20:00').\n",
    "      day_to_check : str, optional\n",
    "          A specific day (in 'YYYY-MM-DD' format) to process. Only that day will be processed\n",
    "          if provided. Default is None (process all days).\n",
    "\n",
    "    Returns:\n",
    "      results_by_day : dict\n",
    "          A dictionary mapping each trading day (Timestamp) to a tuple:\n",
    "              (day_df, trades)\n",
    "          where day_df is the DataFrame strictly covering the trading hours (with one-minute frequency)\n",
    "          and trades is a list of identified trade tuples.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the index is a DatetimeIndex:\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    results_by_day = {}\n",
    "\n",
    "    # Group the DataFrame by day\n",
    "    for day, group in df.groupby(df.index.normalize()):\n",
    "        if day_to_check is not None and day.strftime('%Y-%m-%d') != day_to_check:\n",
    "            continue # If not the specific selected day, skip.\n",
    "\n",
    "        # Build the fixed trading session index for the day.\n",
    "        day_str = day.strftime('%Y-%m-%d')\n",
    "        day_start = pd.Timestamp(f\"{day_str} {regular_start_shifted}\")\n",
    "        day_end = pd.Timestamp(f\"{day_str} {regular_end}\")\n",
    "        trading_index = pd.date_range(start=day_start, end=day_end, freq='min')\n",
    "\n",
    "        # Filter the day's data to the defined trading hours.\n",
    "        day_filtered = group.between_time(regular_start_shifted, regular_end)\n",
    "        # Reindex using the fixed trading session index (forward fill missing minutes).\n",
    "        day_df = day_filtered.reindex(trading_index).ffill()\n",
    "\n",
    "        if day_df.empty:\n",
    "            continue # If no valid data is present, skip this day.\n",
    "\n",
    "        # Call the helper function using the day's filtered data.\n",
    "        trades = identify_trades(day_df, min_prof_thr, max_down_prop)\n",
    "\n",
    "        # Only store days that contain at least one identified trade.\n",
    "        if trades:\n",
    "            results_by_day[day] = (day_df, trades)\n",
    "\n",
    "    return results_by_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df37145e-9e12-4074-8156-98499aa942cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_continuous_signal(day_df, trades, min_prof_thr, smooth_win_sig, pre_entry_decay):\n",
    "    \"\"\"\n",
    "    Computes the continuous trading signal for a single trading day based on the provided trades.\n",
    "    \n",
    "    For each trade, assume:\n",
    "      - t_min = buy_date (optimal entry)\n",
    "      - P_max = sell_price (assumed maximum price reached during the trade)\n",
    "      \n",
    "    The raw signal at time t is defined as:\n",
    "         raw_value = (P_max - close(t)) - min_prof_thr.\n",
    "         \n",
    "    For raw_value <= 0, the signal is 0.\n",
    "    For t < t_min, an exponential penalty is applied:\n",
    "         signal(t) = exp(-pre_entry_decay * delta_minutes) * raw_value,\n",
    "    where delta_minutes is the minutes between t and t_min.\n",
    "    For t >= t_min (up to sell_date), no penalty is applied.\n",
    "    For overlapping trades the maximum signal is used.\n",
    "    \n",
    "    After calculating the continuous signal (stored in \"signal\"), a smoothed version is computed,\n",
    "    stored in \"signal_smooth\" using a rolling window.\n",
    "    \n",
    "    Parameters:\n",
    "      day_df : pd.DataFrame\n",
    "          DataFrame for the day (must include a \"close\" column and a datetime index).\n",
    "      trades : list\n",
    "          List of trades for the day. Each trade is expected to be a tuple:\n",
    "          ((buy_date, sell_date), (buy_price, sell_price), profit_pc)\n",
    "      min_prof_thr : float\n",
    "          Minimum profit threshold above which potential profit is counted.\n",
    "      smooth_win_sig : int\n",
    "          Rolling window size (in minutes) for smoothing the continuous signal.\n",
    "      pre_entry_decay : float\n",
    "          Decay rate for applying an exponential penalty to points before the trade entry.\n",
    "    \n",
    "    Returns:\n",
    "      df : pd.DataFrame\n",
    "          The input DataFrame updated with:\n",
    "             \"signal\"         -- raw continuous trading signal.\n",
    "             \"signal_smooth\"  -- smoothed continuous trading signal.\n",
    "    \"\"\"\n",
    "    df = day_df.copy()\n",
    "    df[\"signal\"] = 0.0  # initialize continuous signal column\n",
    "\n",
    "    # Process each trade and update the signal accordingly.\n",
    "    for trade in trades:\n",
    "        (buy_date, sell_date), (buy_price, sell_price), profit_pc = trade\n",
    "        P_max = sell_price  # assumed maximum reached in trade\n",
    "        t_min = buy_date    # optimal entry time\n",
    "        \n",
    "        # Only calculate signal for time points up to the sell_date.\n",
    "        mask = df.index <= sell_date\n",
    "        for t in df.index[mask]:\n",
    "            price = df.at[t, \"close\"]\n",
    "            raw_value = (P_max - price) - min_prof_thr\n",
    "            if raw_value <= 0:\n",
    "                signal_value = 0.0\n",
    "            else:\n",
    "                # For times before the trade entry, apply exponential penalty.\n",
    "                if t < t_min:\n",
    "                    delta_minutes = (t_min - t).total_seconds() / 60.0\n",
    "                    penalty = math.exp(-pre_entry_decay * delta_minutes)\n",
    "                    signal_value = penalty * raw_value\n",
    "                else:\n",
    "                    signal_value = raw_value\n",
    "            # If there are overlapping trades, store the maximum signal.\n",
    "            df.at[t, \"signal\"] = max(df.at[t, \"signal\"], signal_value)\n",
    "    \n",
    "    # Smooth the continuous signal with a rolling window.\n",
    "    df[\"signal_smooth\"] = df[\"signal\"].rolling(window=smooth_win_sig, center=False).mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a451370c-8602-4e37-b0d1-6b17cfca3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trade_actions(df, smooth_win_sig, buy_threshold, trailing_stop_thresh, regular_start):\n",
    "    \"\"\"\n",
    "    Generates discrete trade actions for a single day based on a simplified rule:\n",
    "      - Normalize the pre-computed \"signal\" column using min–max normalization.\n",
    "      - Smooth \"signal_norm\" via a centered rolling window to obtain \"signal_smooth_norm\".\n",
    "      - Trigger a buy the first time when \"signal_smooth_norm\" crosses above (or equals) the buy_threshold.\n",
    "        A buy is only triggered if the current time is at/after the specified regular_start.\n",
    "        (If the buy condition was met before the start, it will be held and then triggered at market open.)\n",
    "      - Once in a trade, track the maximum raw close reached since entry. Compute the trailing stop level as:\n",
    "              trailing_stop_level = trade_max_price * (1 - (trailing_stop_thresh * (1 + entry_signal))/100)\n",
    "        When the current price falls below this trailing_stop_level, trigger a sell.\n",
    "    \n",
    "      The discrete trade action is stored in \"trade_action\":\n",
    "         +1 for buy, \n",
    "          0 for hold (or no action), \n",
    "         -1 for sell.\n",
    "    \n",
    "    Parameters:\n",
    "      df : pd.DataFrame\n",
    "          DataFrame that already includes a continuous \"signal\" and the \"close\" price column.\n",
    "      smooth_win_sig : int\n",
    "          Rolling window size for smoothing the normalized signal.\n",
    "      buy_threshold : float\n",
    "          The signal threshold which, when crossed by the smoothed normalized signal,\n",
    "          triggers a buy.\n",
    "      trailing_stop_thresh : float\n",
    "          Trailing stop loss percentage.\n",
    "      regular_start : datetime.time or str, optional\n",
    "          The time of day from which buy signals are allowed (e.g. '13:30' or datetime.time(13,30)).\n",
    "    \n",
    "    Returns:\n",
    "      df : pd.DataFrame\n",
    "          The input DataFrame updated with additional columns:\n",
    "             \"signal_norm\"         -- normalized continuous signal.\n",
    "             \"signal_smooth_norm\"  -- smoothed normalized signal.\n",
    "             \"trade_action\"        -- discrete trade action: +1 (buy), 0 (hold), -1 (sell).\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(df)\n",
    "    \n",
    "    # --- Step 1: Normalize the continuous \"signal\" ---\n",
    "    sig_min = df[\"signal\"].min()\n",
    "    sig_max = df[\"signal\"].max()\n",
    "    if sig_max == sig_min:\n",
    "        df[\"signal_norm\"] = 0.0\n",
    "    else:\n",
    "        df[\"signal_norm\"] = (df[\"signal\"] - sig_min) / (sig_max - sig_min)\n",
    "    \n",
    "    # --- Step 2: Smooth the normalized signal ---\n",
    "    df[\"signal_smooth_norm\"] = df[\"signal_norm\"].rolling(window=smooth_win_sig, center=True).mean()\n",
    "    \n",
    "    # --- Initialize trade action column and trade state variables ---\n",
    "    df[\"trade_action\"] = 0  # default: hold/no action\n",
    "    in_trade = False\n",
    "    trade_buy_price = None   # raw close price at entry\n",
    "    trade_max_price = None   # maximum raw close price reached since entry\n",
    "    entry_signal = 0.0       # capture the entry signal for scaling the trailing stop\n",
    "    \n",
    "    pending_buy = False      # flag to indicate that buy condition has occurred (even if before regular_start)\n",
    "    pending_buy_signal = 0.0 # stores the signal value when the condition was met\n",
    "    \n",
    "    # Retrieve the smoothed normalized signal as a NumPy array for faster access.\n",
    "    smooth_signal = df[\"signal_smooth_norm\"].values\n",
    "    \n",
    "    # Iterate over all time points.\n",
    "    for i in range(n):\n",
    "        # Get the current time from the index; assuming df.index is a DatetimeIndex.\n",
    "        current_time = df.iloc[i].name.time()\n",
    "        \n",
    "        if not in_trade:\n",
    "            # Check if the buy condition is crossed\n",
    "            if smooth_signal[i] >= buy_threshold and ((df[\"trade_action\"] == 1).any() == False # this is the first buy\n",
    "                                                      or smooth_signal[i-1] < buy_threshold):\n",
    "                # Set the pending buy flag regardless of trading hours\n",
    "                pending_buy = True\n",
    "                pending_buy_signal = smooth_signal[i]\n",
    "            \n",
    "            # If we have a pending buy and the current time is at/after regular_start, trigger the buy.\n",
    "            if pending_buy and current_time >= regular_start:\n",
    "                df.iloc[i, df.columns.get_loc(\"trade_action\")] = 1  # Trigger buy signal.\n",
    "                trade_buy_price = df[\"close\"].iloc[i]\n",
    "                trade_max_price = trade_buy_price\n",
    "                entry_signal = pending_buy_signal  # Use the signal value recorded when condition was met.\n",
    "                in_trade = True\n",
    "                pending_buy = False  # Reset pending flag after entering the trade.\n",
    "                \n",
    "        else:\n",
    "            # We are in a trade; update the maximum observed price.\n",
    "            current_price = df[\"close\"].iloc[i]\n",
    "            if current_price > trade_max_price:\n",
    "                trade_max_price = current_price\n",
    "            # Compute the trailing stop level.\n",
    "            dynamic_trailing_thresh = trailing_stop_thresh * (1 + smooth_signal[i])\n",
    "            trailing_stop_level = trade_max_price * (1 - dynamic_trailing_thresh / 100)\n",
    "            if current_price < trailing_stop_level and smooth_signal[i] < buy_threshold:\n",
    "                df.iloc[i, df.columns.get_loc(\"trade_action\")] = -1  # Trigger sell signal.\n",
    "                in_trade = False\n",
    "            else:\n",
    "                df.iloc[i, df.columns.get_loc(\"trade_action\")] = 0  # Hold.\n",
    "    \n",
    "    # Optionally force a sell at the end of the day if still in trade.\n",
    "    if in_trade:\n",
    "        df.iloc[-1, df.columns.get_loc(\"trade_action\")] = -1\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe907f40-916f-4371-80de-4e00a0aca4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trade_signal_to_results(results_by_day, min_prof_thr, regular_start,\n",
    "                                smooth_win_sig=5, pre_entry_decay=0.05,\n",
    "                                buy_threshold=0.6, trailing_stop_thresh=0.5):\n",
    "    \"\"\"\n",
    "    Updates the input dictionary (results_by_day) by applying two steps:\n",
    "    \n",
    "       (A) Compute the continuous trading signal for each day (using compute_continuous_signal).\n",
    "       (B) Generate discrete trade actions based on the continuous signal and a trailing stop loss \n",
    "           mechanism (using generate_trade_actions).\n",
    "    \n",
    "    The continuous signal uses the formula:\n",
    "         raw_value = (P_max - close(t)) - min_prof_thr,\n",
    "    with exponential decay applied prior to the optimal entry time. The signal is later smoothed.\n",
    "    \n",
    "    The discrete trade actions use the normalized continuous signal to identify candidate peaks.\n",
    "    A candidate peak (shifted by half the smoothing window) is taken as the entry (buy signal) if the\n",
    "    raw close is a local minimum. Then, while in a trade, a trailing stop loss is applied: when\n",
    "         (max_price - current_close) / (max_price - buy_price) * 100 >= trailing_stop_thresh,\n",
    "    a sell signal is issued.\n",
    "    \n",
    "    Parameters:\n",
    "      results_by_day : dict\n",
    "          Dictionary mapping each trading day (Timestamp) to a tuple (day_df, trades).\n",
    "      min_prof_thr : float\n",
    "          Minimum profit threshold used in continuous signal calculation.\n",
    "      smooth_win_sig : int, default 5\n",
    "          Rolling window size for smoothing signals.\n",
    "      pre_entry_decay : float, default 0.05\n",
    "          Decay rate applied before the trade entry for signal calculation.\n",
    "      buy_threshold : float, default 0.6\n",
    "          Minimum level in the smoothed normalized signal to consider a candidate peak for a trade.\n",
    "      trailing_stop_thresh : float, default 0.5 percent of max stock price\n",
    "          Trailing stop loss threshold. A sell signal is triggered when the retracement in raw close\n",
    "          prices meets/exceeds this value.\n",
    "    \n",
    "    Returns:\n",
    "      updated_results : dict\n",
    "          The results_by_day dictionary updated so that each day's DataFrame now includes:\n",
    "              \"signal\", \"signal_smooth\", \"signal_norm\", \"signal_smooth_norm\", and \"trade_action\".\n",
    "    \"\"\"\n",
    "    updated_results = {}\n",
    "    \n",
    "    for day, (day_df, trades) in results_by_day.items():\n",
    "        # Step (A): Compute the continuous trading signal.\n",
    "        df = compute_continuous_signal(day_df, trades, min_prof_thr, smooth_win_sig, pre_entry_decay)\n",
    "        \n",
    "        # Step (B): Generate discrete trade actions (using trailing stop loss logic).\n",
    "        df = generate_trade_actions(df, smooth_win_sig, buy_threshold, trailing_stop_thresh, regular_start)\n",
    "        \n",
    "        updated_results[day] = (df, trades)\n",
    "    \n",
    "    return updated_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06bf51ee-15e9-4953-8603-6caca3da3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_trading(results_by_day, regular_start, regular_end):\n",
    "    \"\"\"\n",
    "    Processes the results_by_day dictionary (produced by identify_trades_daily) by simulating \n",
    "    trading for each day's DataFrame. It uses the precomputed \"trade_action\" column to drive \n",
    "    the simulation. The updated DataFrame is augmented with the following new columns:\n",
    "      - \"Position\": cumulative number of shares held.\n",
    "      - \"Cash\": evolving cash balance.\n",
    "      - \"NetValue\": mark-to-market net asset value (cash + position * bid price).\n",
    "      - \"Action\": a string describing the action (\"Buy\", \"Sell\", \"Hold\", \"No trade\").\n",
    "      - \"TradedAmount\": the number of shares traded (+1 for buy, -1 for sell, 0 otherwise).\n",
    "      - \"StrategyEarning\": the current net value during the session (0 before regular start).\n",
    "      - \"BuyHoldEarning\": profit (or loss) if one had bought at the session’s start ask and sold at the current bid (0 before regular start).\n",
    "      - \"EarningDiff\": the difference between StrategyEarning and BuyHoldEarning.\n",
    "      \n",
    "    Additionally, it computes two lists:\n",
    "      - \"Trade Gains ($)\": a list of dollar gains for each completed trade.\n",
    "      - \"Trade Gains (%)\": a list of percentage gains for each completed trade.\n",
    "      \n",
    "    All preexisting columns in the input DataFrame are preserved.\n",
    "    \n",
    "    Parameters:\n",
    "      results_by_day : dict\n",
    "          A dictionary mapping each trading day (Timestamp) to a tuple. The tuple can be either:\n",
    "              (day_df, trades)\n",
    "          or\n",
    "              (day_df, trades, performance_stats)\n",
    "          where day_df is the DataFrame covering the trading hours (with one-minute frequency)\n",
    "          and trades is a list of identified trade tuples.\n",
    "      regular_start : datetime.time \n",
    "          Starting time of the trading session (e.g. '13:00').\n",
    "      regular_end : datetime.time \n",
    "          Ending time of the trading session (e.g. '20:00').\n",
    "    \n",
    "    Returns:\n",
    "      updated_results_by_day : dict\n",
    "          A dictionary mapping each trading day (Timestamp) to a tuple:\n",
    "              (df_sim, trades, performance_stats)\n",
    "          where df_sim is the updated simulation DataFrame for that day.\n",
    "    \"\"\"\n",
    "    \n",
    "    updated_results = {}\n",
    "    \n",
    "    # Process each day. Unpack values depending on their length.\n",
    "    for day, value in results_by_day.items():\n",
    "        if len(value) == 2:\n",
    "            day_df, trades = value\n",
    "        elif len(value) == 3:\n",
    "            day_df, trades, _ = value   # Ignore existing performance_stats if present.\n",
    "        else:\n",
    "            raise ValueError(f\"Expected tuple of length 2 or 3 for key {day}, got {len(value)}\")\n",
    "        \n",
    "        session_df = day_df.copy()  # Work with a copy.\n",
    "        \n",
    "        # Initialize simulation variables.\n",
    "        position = 0   # shares held\n",
    "        cash = 0       # starting cash\n",
    "        \n",
    "        positions = []      # cumulative position per minute\n",
    "        cash_balances = []  # cash balance per minute\n",
    "        net_values = []     # net asset value: cash + position * bid\n",
    "        actions = []        # descriptive action: \"Buy\", \"Sell\", \"Hold\", \"No trade\"\n",
    "        traded_amounts = [] # numeric traded amount: +1, -1, or 0\n",
    "        \n",
    "        # Lists for the earnings:\n",
    "        buy_hold_earnings = []     # Earning without the strategy (buy-and-hold)\n",
    "        strategy_earnings = []     # Earning with the strategy (actual simulation net value)\n",
    "        \n",
    "        session_initial_trade_price = None  # Will be set at the first row with time >= regular_start\n",
    "        \n",
    "        # Loop over each minute (row) in the session.\n",
    "        for timestamp, row in session_df.iterrows():\n",
    "            bid_price = row['bid']\n",
    "            ask_price = row['ask']\n",
    "            action_num = row['trade_action']   # Precomputed signal: +1 (buy), -1 (sell), 0 (hold)\n",
    "            current_time = timestamp.time()\n",
    "            \n",
    "            # Only execute trades if within session hours.\n",
    "            if regular_start <= current_time < regular_end:\n",
    "                if action_num == 1:\n",
    "                    position += 1\n",
    "                    cash -= ask_price  # buy at ask price\n",
    "                    action = \"Buy\"\n",
    "                    traded_amt = 1\n",
    "                elif action_num == -1:\n",
    "                    if position > 0:\n",
    "                        position -= 1\n",
    "                        cash += bid_price  # sell at bid price\n",
    "                        action = \"Sell\"\n",
    "                        traded_amt = -1\n",
    "                    else:\n",
    "                        action = \"Hold\"\n",
    "                        traded_amt = 0\n",
    "                else:\n",
    "                    action = \"Hold\"\n",
    "                    traded_amt = 0\n",
    "            else:\n",
    "                action = \"No trade\"\n",
    "                traded_amt = 0\n",
    "            \n",
    "            positions.append(position)\n",
    "            cash_balances.append(np.round(cash, 3))\n",
    "            net_val = np.round(cash + position * bid_price, 3)\n",
    "            net_values.append(net_val)\n",
    "            actions.append(action)\n",
    "            traded_amounts.append(traded_amt)\n",
    "            \n",
    "            # Compute earnings only if current_time >= regular_start.\n",
    "            if current_time >= regular_start:\n",
    "                if session_initial_trade_price is None:\n",
    "                    # Set the reference (buy-and-hold) price at the first row of the session.\n",
    "                    session_initial_trade_price = ask_price\n",
    "                current_bh = bid_price - session_initial_trade_price\n",
    "                current_strat = net_val  # Strategy net value.\n",
    "            else:\n",
    "                current_bh = 0\n",
    "                current_strat = 0\n",
    "            buy_hold_earnings.append(np.round(current_bh, 3))\n",
    "            strategy_earnings.append(np.round(current_strat, 3))\n",
    "        \n",
    "        # Build the simulation DataFrame (preserving all preexisting columns).\n",
    "        df_sim = session_df.copy()\n",
    "        df_sim['Position'] = positions\n",
    "        df_sim['Cash'] = cash_balances\n",
    "        df_sim['NetValue'] = net_values\n",
    "        df_sim['Action'] = actions\n",
    "        df_sim['TradedAmount'] = traded_amounts\n",
    "        \n",
    "        # Append the new earnings columns.\n",
    "        df_sim['StrategyEarning'] = strategy_earnings\n",
    "        df_sim['BuyHoldEarning'] = buy_hold_earnings\n",
    "        df_sim['EarningDiff'] = df_sim['StrategyEarning'] - df_sim['BuyHoldEarning']\n",
    "        \n",
    "        # --------------------------------------------------------------------\n",
    "        # NEW: Compute separate gains (in $ and in %) for each trade using the \"Action\" column.\n",
    "        # A trade is defined as a \"Buy\" (recorded from the Ask price) followed by the next \"Sell\" (using the Bid).\n",
    "        trade_gains = []\n",
    "        trade_gains_perc = []\n",
    "        buy_price = None  # Reference price for the current trade.\n",
    "        for timestamp, row in df_sim.iterrows():\n",
    "            if row['Action'] == \"Buy\":\n",
    "                buy_price = row['ask']\n",
    "            elif row['Action'] == \"Sell\" and buy_price is not None:\n",
    "                gain = row['bid'] - buy_price\n",
    "                perc_gain = (gain / buy_price) * 100\n",
    "                trade_gains.append(np.round(gain, 3))\n",
    "                trade_gains_perc.append(np.round(perc_gain, 3))\n",
    "                buy_price = None\n",
    "        # NEW: If there's an open trade at the end, simulate a sale using the final bid price.\n",
    "        if buy_price is not None:\n",
    "            final_bid = df_sim.iloc[-1]['bid']\n",
    "            gain = final_bid - buy_price\n",
    "            perc_gain = (gain / buy_price) * 100\n",
    "            trade_gains.append(np.round(gain, 3))\n",
    "            trade_gains_perc.append(np.round(perc_gain, 3))\n",
    "        # --------------------------------------------------------------------\n",
    "        \n",
    "        # --- Compute performance statistics using realistic prices ---\n",
    "        idx_start = df_sim.index.get_loc(next(ts for ts in df_sim.index if ts.time() >= regular_start))\n",
    "        baseline_price = session_df.iloc[idx_start]['ask']\n",
    "        if len(session_df) > 1:\n",
    "            final_liquidation_price = session_df.iloc[-2]['bid']  # penultimate row's bid.\n",
    "            buy_hold_gain = final_liquidation_price - baseline_price\n",
    "            final_net_value = net_values[-2]\n",
    "        else:\n",
    "            final_liquidation_price = session_df.iloc[-1]['bid']\n",
    "            buy_hold_gain = final_liquidation_price - baseline_price\n",
    "            final_net_value = net_values[-1]\n",
    "        \n",
    "        profit_diff = final_net_value - buy_hold_gain\n",
    "        final_net_return_pct = (final_net_value / baseline_price) * 100\n",
    "        buy_hold_return_pct = (buy_hold_gain / baseline_price) * 100\n",
    "        \n",
    "        strategy_improve_pct = final_net_return_pct - buy_hold_return_pct\n",
    "        \n",
    "        performance_stats = {\n",
    "            'Final Net Value ($)': np.round(final_net_value, 3),\n",
    "            'Buy & Hold Gain ($)': np.round(buy_hold_gain, 3),\n",
    "            'Strategy Profit Difference ($)': np.round(profit_diff, 3),\n",
    "            'Final Net Return (%)': np.round(final_net_return_pct, 3),\n",
    "            'Buy & Hold Return (%)': np.round(buy_hold_return_pct, 3),\n",
    "            'Strategy Improvement (%)': np.round(strategy_improve_pct, 3),\n",
    "            'Trade Gains ($)': trade_gains,            # List of individual trade gains (in dollars).\n",
    "            'Trade Gains (%)': trade_gains_perc          # List of individual trade gain percentages.\n",
    "        }\n",
    "        \n",
    "        updated_results[day] = (df_sim, trades, performance_stats)\n",
    "    \n",
    "    return updated_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c12f6e5-f25a-4bd0-a251-4068e0ab15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiz_function(df,\n",
    "                     min_prof_thr=0.3,       # percent of minimum profit to define a potential trade\n",
    "                     max_down_prop=0.6,      # float (percent/100) of maximum allowed drop of a potential trade\n",
    "                     smooth_win_sig=15,      # smoothing window of the signal used for the identification of the final trades \n",
    "                     pre_entry_decay=0.9,    # pre-trade decay of the final trades' smoothed signal\n",
    "                     buy_threshold=0.05,     # float (percent/100) threshold of the smoothed signal to trigger the final trade\n",
    "                     trailing_stop_thresh=0.2  # percent of the trailing stop loss of the final trade\n",
    "                     ):\n",
    "    import datetime\n",
    "    \n",
    "    # Define your trading session boundaries.\n",
    "    regular_start  = datetime.datetime.strptime('14:30', '%H:%M').time()   \n",
    "    regular_start_shifted = datetime.datetime.strptime('13:30', '%H:%M').time()   \n",
    "    regular_end = datetime.datetime.strptime('21:00', '%H:%M').time()  \n",
    "    \n",
    "    # First, adjust the input DataFrame's timestamps.\n",
    "    df = smooth_prepost_trading_data(df, regular_start, regular_end)\n",
    "\n",
    "    # Identify potential trades day-by-day.\n",
    "    results_by_day = identify_trades_daily(df=df,\n",
    "                                           min_prof_thr=min_prof_thr, \n",
    "                                           max_down_prop=max_down_prop,\n",
    "                                           regular_start_shifted=regular_start_shifted,\n",
    "                                           regular_end=regular_end)\n",
    "\n",
    "    # Add trade signals to the daily results (using the unshifted regular_start).\n",
    "    results_by_day = add_trade_signal_to_results(results_by_day=results_by_day, \n",
    "                                                 min_prof_thr=min_prof_thr, \n",
    "                                                 regular_start=regular_start,\n",
    "                                                 smooth_win_sig=smooth_win_sig, \n",
    "                                                 pre_entry_decay=pre_entry_decay,\n",
    "                                                 buy_threshold=buy_threshold, \n",
    "                                                 trailing_stop_thresh=trailing_stop_thresh)\n",
    "\n",
    "    # Simulate trading across the days.\n",
    "    results_by_day = simulate_trading(results_by_day=results_by_day, \n",
    "                                      regular_start=regular_start, \n",
    "                                      regular_end=regular_end)\n",
    "    \n",
    "    # Build a dictionary mapping each day to its strategy improvement.\n",
    "    improvements = {}\n",
    "    for day_key, day_result in results_by_day.items():\n",
    "        improvements[day_key.strftime('%Y-%m-%d')] = day_result[2]['Strategy Improvement (%)']\n",
    "\n",
    "    avg_improvement = sum(improvements.values()) / len(improvements) \n",
    "\n",
    "    # Return the average improvement and the dictionary with day-specific improvements.\n",
    "    return avg_improvement, improvements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74fbc73f-77dc-41ee-bd75-f05a069d7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_improvement, improvements = optimiz_function(df=df,\n",
    "#                                                  min_prof_thr=0.3,         # percent of minimum profit to define a potential trade\n",
    "#                                                  max_down_prop=0.4,        # float (percent/100) of maximum allowed drop of a potential trade\n",
    "#                                                  smooth_win_sig=15,        # smoothing window of the signal used for the identification of the final trades \n",
    "#                                                  pre_entry_decay=0.9,      # pre-trade decay of the final trades' smoothed signal\n",
    "#                                                  buy_threshold=0.1,       # float (percent/100) threshold of the smoothed signal to trigger the final trade\n",
    "#                                                  trailing_stop_thresh=0.2  # percent of the trailing stop loss of the final trade\n",
    "#                                                  )\n",
    "\n",
    "# print(avg_improvement)\n",
    "# improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05989e1a-6afb-47f9-9f9e-2d60e9ebc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Objective Function ===\n",
    "def objective(trial):\n",
    "    # Suggest parameters to test.\n",
    "    params = {\n",
    "        \"min_prof_thr\": trial.suggest_float(\"min_prof_thr\", 0.1, 0.5),\n",
    "        \"max_down_prop\": trial.suggest_float(\"max_down_prop\", 0.1, 0.5),\n",
    "        \"smooth_win_sig\": trial.suggest_int(\"smooth_win_sig\", 10, 40),\n",
    "        \"pre_entry_decay\": trial.suggest_float(\"pre_entry_decay\", 0.5, 1.0),\n",
    "        \"buy_threshold\": trial.suggest_float(\"buy_threshold\", 0.05, 0.5),\n",
    "        \"trailing_stop_thresh\": trial.suggest_float(\"trailing_stop_thresh\", 0.1, 0.5),\n",
    "    }\n",
    "\n",
    "    # Run your strategy simulation with the current set of parameters.\n",
    "    avg_improvement, improvements_dict = optimiz_function(\n",
    "        df=df,\n",
    "        min_prof_thr=params[\"min_prof_thr\"],\n",
    "        max_down_prop=params[\"max_down_prop\"],\n",
    "        smooth_win_sig=params[\"smooth_win_sig\"],\n",
    "        pre_entry_decay=params[\"pre_entry_decay\"],\n",
    "        buy_threshold=params[\"buy_threshold\"],\n",
    "        trailing_stop_thresh=params[\"trailing_stop_thresh\"]\n",
    "    )\n",
    "    \n",
    "    # Detailed print inside the objective: (Useful for debugging and logging)\n",
    "    trial_number = trial.number + 1\n",
    "    # print(\"\\n\" + \"=\"*80)\n",
    "    # print(f\"Trial {trial_number}\")\n",
    "    # print(\"Parameters:\")\n",
    "    # for k, v in params.items():\n",
    "    #     print(f\"   {k}: {v}\")\n",
    "    # print(\"Daily Improvements:\")\n",
    "    # for day, improv in improvements_dict.items():\n",
    "    #     print(f\"   {day}: {improv}\")\n",
    "    # print(f\"Average Improvement: {avg_improvement}\")\n",
    "    # print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # It might also be useful to record raw params into the trial's user attributes.\n",
    "    trial.set_user_attr(\"params\", params)\n",
    "    trial.set_user_attr(\"improvements\", improvements_dict)\n",
    "    \n",
    "    return avg_improvement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034220a3-f9e4-46ed-9fa1-0ee9f6a35f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Callback for Progress Monitoring ===\n",
    "def save_progress(study, trial):\n",
    "    # This callback prints summary information after each trial.\n",
    "    trial_count = len(study.trials)\n",
    "    best_value = study.best_value\n",
    "    current_trial = trial.number + 1\n",
    "    # print(f\"========== Summary After Trial {current_trial} of {study.best_trial.number + trial_count} ==========\")\n",
    "    # print(f\"Current trial value: {trial.value}\")\n",
    "    # print(f\"Best value so far: {best_value}\")\n",
    "    # print(\"Best parameters so far:\")\n",
    "    # print(study.best_params)\n",
    "    # Optionally, you can also save the study information to a file:\n",
    "    with open(\"optuna_progress_log.txt\", \"a\") as f:\n",
    "        log = {\n",
    "            \"trial\": current_trial,\n",
    "            \"trial_value\": trial.value,\n",
    "            \"best_value\": best_value,\n",
    "            \"best_params\": study.best_params,\n",
    "            \"trial_params\": trial.user_attrs.get(\"params\", {})\n",
    "        }\n",
    "        f.write(json.dumps(log) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf2b85f-ec8f-45db-8ff5-a3beb73b4945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 19:45:29,450] A new study created in memory with name: no-name-4eb88762-03d9-4efd-80da-9b4575f4d2e3\n",
      "[I 2025-06-10 19:46:13,829] Trial 0 finished with value: 0.37902884615384635 and parameters: {'min_prof_thr': 0.23066728669296255, 'max_down_prop': 0.21280865404151586, 'smooth_win_sig': 26, 'pre_entry_decay': 0.9194386727938012, 'buy_threshold': 0.309527685345971, 'trailing_stop_thresh': 0.24675644078600373}. Best is trial 0 with value: 0.37902884615384635.\n",
      "[I 2025-06-10 19:46:47,183] Trial 1 finished with value: 0.48156730769230766 and parameters: {'min_prof_thr': 0.28120559833101555, 'max_down_prop': 0.4614157696299791, 'smooth_win_sig': 40, 'pre_entry_decay': 0.7935030136028927, 'buy_threshold': 0.47241917032079744, 'trailing_stop_thresh': 0.21604243116680497}. Best is trial 1 with value: 0.48156730769230766.\n",
      "[I 2025-06-10 19:47:11,774] Trial 2 finished with value: 0.3052574257425743 and parameters: {'min_prof_thr': 0.3901430558993191, 'max_down_prop': 0.16367896840430196, 'smooth_win_sig': 17, 'pre_entry_decay': 0.8321901848250319, 'buy_threshold': 0.3196880613216308, 'trailing_stop_thresh': 0.19902337403396683}. Best is trial 1 with value: 0.48156730769230766.\n",
      "[I 2025-06-10 19:48:30,950] Trial 3 finished with value: 0.5022596153846157 and parameters: {'min_prof_thr': 0.12228463199322288, 'max_down_prop': 0.29262389161657715, 'smooth_win_sig': 25, 'pre_entry_decay': 0.8216381454875176, 'buy_threshold': 0.41416426945163015, 'trailing_stop_thresh': 0.31389473936508905}. Best is trial 3 with value: 0.5022596153846157.\n"
     ]
    }
   ],
   "source": [
    "# === Create and Run the Study ===\n",
    "# You can use an RDB storage backend if you want to persist results:\n",
    "# storage = optuna.storages.RDBStorage(url=\"sqlite:///optuna_study.db\")\n",
    "# study = optuna.create_study(direction=\"maximize\", storage=storage, study_name=\"my_study\", load_if_exists=True)\n",
    "# For this example, we'll create an in-memory study.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Run the optimization with the callback\n",
    "n_trials = 100  # Adjust this number as needed.\n",
    "study.optimize(objective, n_trials=n_trials, callbacks=[save_progress])\n",
    "\n",
    "# === Print Final Results ===\n",
    "print(\"Best Parameters:\", study.best_params)\n",
    "print(\"Best Average Improvement:\", study.best_value)\n",
    "\n",
    "# Optionally, saving the study to a JSON file might be useful.\n",
    "with open(\"optuna_final_results.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"best_params\": study.best_params,\n",
    "        \"best_value\": study.best_value,\n",
    "        \"trials\": [trial.user_attrs for trial in study.trials]\n",
    "    }, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5682870-1819-4573-9b81-d11808e5ecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2300f-5d09-488b-b3ab-66f60b2812c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6cc7b-4728-4e81-8e81-bbc7fc61e787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
