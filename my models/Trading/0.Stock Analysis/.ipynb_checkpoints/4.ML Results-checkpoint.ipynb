{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db53f869-3ce8-4b85-9c38-ba83b86b51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Wipe out all Python variables\n",
    "%reset -f\n",
    "# 2) Force Python’s garbage collector to run\n",
    "import gc\n",
    "gc.collect()\n",
    "# 3) If you’re using PyTorch + CUDA, free any lingering GPU memory\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import importlib\n",
    "from libs import models, plots, trades, params\n",
    "importlib.reload(models)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(params)\n",
    "importlib.reload(trades)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt   \n",
    "from pprint import pprint\n",
    "\n",
    "import torch.nn.functional as Funct\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.serialization.add_safe_globals([models.DayWindowDataset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9b44fb-0cf5-4b31-8cdf-39d8d587234e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('dfs training/GOOGL_0.2691.pth')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device               = params.device\n",
    "ticker               = params.ticker\n",
    "save_path            = params.save_path\n",
    "pred_threshold       = params.pred_threshold_man\n",
    "regular_start        = params.regular_start\n",
    "regular_start_pred   = params.regular_start_pred\n",
    "regular_end          = params.regular_end\n",
    "look_back            = params.look_back\n",
    "trailing_stop_thresh = params.trailing_stop_thresh_man\n",
    "\n",
    "# month to inspect (YYYY-MM)\n",
    "date_to_check = params.date_to_check\n",
    "\n",
    "# model path\n",
    "val_rmse_str = \"0.2691\"   # same rmse in the filename\n",
    "\n",
    "csv_dir: str = \"./dfs training\"\n",
    "path_csv_load = f\"{csv_dir}/{ticker}_final.csv\"\n",
    "path_csv_save = f\"{csv_dir}/{ticker}_test_DF.csv\"\n",
    "\n",
    "model_path = save_path / f\"{ticker}_{val_rmse_str}.pth\"\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fcfa66-3fa8-4cb4-a040-4e0b5b1804fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>r_1</th>\n",
       "      <th>r_5</th>\n",
       "      <th>r_15</th>\n",
       "      <th>vol_15</th>\n",
       "      <th>volume_spike</th>\n",
       "      <th>vwap_dev</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>signal_smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:06:00</th>\n",
       "      <td>28.644845</td>\n",
       "      <td>28.644845</td>\n",
       "      <td>28.644845</td>\n",
       "      <td>28.644845</td>\n",
       "      <td>4580.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.568641</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.636251</td>\n",
       "      <td>28.653438</td>\n",
       "      <td>0.327384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:07:00</th>\n",
       "      <td>28.639690</td>\n",
       "      <td>28.639690</td>\n",
       "      <td>28.639690</td>\n",
       "      <td>28.639690</td>\n",
       "      <td>4540.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.570338</td>\n",
       "      <td>-0.000352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.631098</td>\n",
       "      <td>28.648282</td>\n",
       "      <td>0.328556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:08:00</th>\n",
       "      <td>28.634534</td>\n",
       "      <td>28.634534</td>\n",
       "      <td>28.634534</td>\n",
       "      <td>28.634534</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.574408</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.625944</td>\n",
       "      <td>28.643125</td>\n",
       "      <td>0.329833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:09:00</th>\n",
       "      <td>28.629379</td>\n",
       "      <td>28.629379</td>\n",
       "      <td>28.629379</td>\n",
       "      <td>28.629379</td>\n",
       "      <td>4460.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.581017</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.620791</td>\n",
       "      <td>28.637968</td>\n",
       "      <td>0.331213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:10:00</th>\n",
       "      <td>28.624224</td>\n",
       "      <td>28.624224</td>\n",
       "      <td>28.624224</td>\n",
       "      <td>28.624224</td>\n",
       "      <td>4420.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.590413</td>\n",
       "      <td>-0.000862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.615637</td>\n",
       "      <td>28.632811</td>\n",
       "      <td>0.332697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:56:00</th>\n",
       "      <td>173.375000</td>\n",
       "      <td>173.677100</td>\n",
       "      <td>173.215000</td>\n",
       "      <td>173.565000</td>\n",
       "      <td>621199.0</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>-0.004226</td>\n",
       "      <td>-0.009661</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>2.462713</td>\n",
       "      <td>1.248428</td>\n",
       "      <td>17.019768</td>\n",
       "      <td>173.512900</td>\n",
       "      <td>173.617100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:57:00</th>\n",
       "      <td>173.565000</td>\n",
       "      <td>173.590000</td>\n",
       "      <td>173.240000</td>\n",
       "      <td>173.380000</td>\n",
       "      <td>624198.0</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>-0.005063</td>\n",
       "      <td>-0.010671</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>2.154838</td>\n",
       "      <td>1.246015</td>\n",
       "      <td>11.648165</td>\n",
       "      <td>173.328000</td>\n",
       "      <td>173.432000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:58:00</th>\n",
       "      <td>173.390000</td>\n",
       "      <td>173.410000</td>\n",
       "      <td>173.200000</td>\n",
       "      <td>173.310000</td>\n",
       "      <td>454542.0</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>-0.005811</td>\n",
       "      <td>-0.011816</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>1.439161</td>\n",
       "      <td>1.245096</td>\n",
       "      <td>11.384870</td>\n",
       "      <td>173.258000</td>\n",
       "      <td>173.362000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 20:59:00</th>\n",
       "      <td>173.315000</td>\n",
       "      <td>173.400000</td>\n",
       "      <td>173.230000</td>\n",
       "      <td>173.280000</td>\n",
       "      <td>1094746.0</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.004434</td>\n",
       "      <td>-0.011932</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>2.836382</td>\n",
       "      <td>1.244678</td>\n",
       "      <td>11.830567</td>\n",
       "      <td>173.228000</td>\n",
       "      <td>173.332000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 21:00:00</th>\n",
       "      <td>173.300000</td>\n",
       "      <td>174.050000</td>\n",
       "      <td>173.170000</td>\n",
       "      <td>173.609700</td>\n",
       "      <td>7649838.0</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>-0.009290</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>8.568493</td>\n",
       "      <td>1.248745</td>\n",
       "      <td>22.962317</td>\n",
       "      <td>173.557600</td>\n",
       "      <td>173.661800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1651679 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           open        high         low       close  \\\n",
       "2014-04-03 12:06:00   28.644845   28.644845   28.644845   28.644845   \n",
       "2014-04-03 12:07:00   28.639690   28.639690   28.639690   28.639690   \n",
       "2014-04-03 12:08:00   28.634534   28.634534   28.634534   28.634534   \n",
       "2014-04-03 12:09:00   28.629379   28.629379   28.629379   28.629379   \n",
       "2014-04-03 12:10:00   28.624224   28.624224   28.624224   28.624224   \n",
       "...                         ...         ...         ...         ...   \n",
       "2025-06-18 20:56:00  173.375000  173.677100  173.215000  173.565000   \n",
       "2025-06-18 20:57:00  173.565000  173.590000  173.240000  173.380000   \n",
       "2025-06-18 20:58:00  173.390000  173.410000  173.200000  173.310000   \n",
       "2025-06-18 20:59:00  173.315000  173.400000  173.230000  173.280000   \n",
       "2025-06-18 21:00:00  173.300000  174.050000  173.170000  173.609700   \n",
       "\n",
       "                        volume       r_1       r_5      r_15    vol_15  \\\n",
       "2014-04-03 12:06:00     4580.0 -0.000180 -0.000180 -0.000180  0.000046   \n",
       "2014-04-03 12:07:00     4540.0 -0.000180 -0.000360 -0.000360  0.000063   \n",
       "2014-04-03 12:08:00     4500.0 -0.000180 -0.000540 -0.000540  0.000075   \n",
       "2014-04-03 12:09:00     4460.0 -0.000180 -0.000720 -0.000720  0.000082   \n",
       "2014-04-03 12:10:00     4420.0 -0.000180 -0.000900 -0.000900  0.000088   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "2025-06-18 20:56:00   621199.0  0.001124 -0.004226 -0.009661  0.001493   \n",
       "2025-06-18 20:57:00   624198.0 -0.001066 -0.005063 -0.010671  0.001487   \n",
       "2025-06-18 20:58:00   454542.0 -0.000404 -0.005811 -0.011816  0.001436   \n",
       "2025-06-18 20:59:00  1094746.0 -0.000173 -0.004434 -0.011932  0.001432   \n",
       "2025-06-18 21:00:00  7649838.0  0.001901  0.001382 -0.009290  0.001592   \n",
       "\n",
       "                     volume_spike  vwap_dev     rsi_14         bid  \\\n",
       "2014-04-03 12:06:00      0.568641 -0.000177   0.000000   28.636251   \n",
       "2014-04-03 12:07:00      0.570338 -0.000352   0.000000   28.631098   \n",
       "2014-04-03 12:08:00      0.574408 -0.000524   0.000000   28.625944   \n",
       "2014-04-03 12:09:00      0.581017 -0.000694   0.000000   28.620791   \n",
       "2014-04-03 12:10:00      0.590413 -0.000862   0.000000   28.615637   \n",
       "...                           ...       ...        ...         ...   \n",
       "2025-06-18 20:56:00      2.462713  1.248428  17.019768  173.512900   \n",
       "2025-06-18 20:57:00      2.154838  1.246015  11.648165  173.328000   \n",
       "2025-06-18 20:58:00      1.439161  1.245096  11.384870  173.258000   \n",
       "2025-06-18 20:59:00      2.836382  1.244678  11.830567  173.228000   \n",
       "2025-06-18 21:00:00      8.568493  1.248745  22.962317  173.557600   \n",
       "\n",
       "                            ask  signal_smooth  \n",
       "2014-04-03 12:06:00   28.653438       0.327384  \n",
       "2014-04-03 12:07:00   28.648282       0.328556  \n",
       "2014-04-03 12:08:00   28.643125       0.329833  \n",
       "2014-04-03 12:09:00   28.637968       0.331213  \n",
       "2014-04-03 12:10:00   28.632811       0.332697  \n",
       "...                         ...            ...  \n",
       "2025-06-18 20:56:00  173.617100       0.000000  \n",
       "2025-06-18 20:57:00  173.432000       0.000000  \n",
       "2025-06-18 20:58:00  173.362000       0.000000  \n",
       "2025-06-18 20:59:00  173.332000       0.000000  \n",
       "2025-06-18 21:00:00  173.661800       0.000000  \n",
       "\n",
       "[1651679 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_csv_load, index_col=0, parse_dates=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93385fa-870a-4259-ad0c-05d68180afcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing <build_lstm_tensors>...\n",
      "executing <chronological_split>...\n",
      "Shapes:\n",
      "  X_tr        = torch.Size([750156, 12, 120])\n",
      "  y_tr        = torch.Size([750156])\n",
      "  raw_close_te= torch.Size([164998])\n",
      "  raw_bid_te  = torch.Size([164998])\n",
      "  raw_ask_te  = torch.Size([164998])\n",
      "\n",
      "Days: train=1984, val=410, test=422\n",
      "Windows: train=750156, val=160069, test=164998\n",
      "\n",
      "First 5 window‐end times: [Timestamp('2014-04-03 14:30:00'), Timestamp('2014-04-03 14:31:00'), Timestamp('2014-04-03 14:32:00'), Timestamp('2014-04-03 14:33:00'), Timestamp('2014-04-03 14:34:00')]\n",
      "\n",
      "X_tr[0] covers bars from 2014-04-03 12:30:00 to 2014-04-03 14:29:00\n",
      "Those timestamps:\n",
      "DatetimeIndex(['2014-04-03 12:30:00', '2014-04-03 12:31:00',\n",
      "               '2014-04-03 12:32:00', '2014-04-03 12:33:00',\n",
      "               '2014-04-03 12:34:00', '2014-04-03 12:35:00',\n",
      "               '2014-04-03 12:36:00', '2014-04-03 12:37:00',\n",
      "               '2014-04-03 12:38:00', '2014-04-03 12:39:00',\n",
      "               ...\n",
      "               '2014-04-03 14:20:00', '2014-04-03 14:21:00',\n",
      "               '2014-04-03 14:22:00', '2014-04-03 14:23:00',\n",
      "               '2014-04-03 14:24:00', '2014-04-03 14:25:00',\n",
      "               '2014-04-03 14:26:00', '2014-04-03 14:27:00',\n",
      "               '2014-04-03 14:28:00', '2014-04-03 14:29:00'],\n",
      "              dtype='datetime64[ns]', length=120, freq='min')\n",
      "y_tr[0] (and raw_close_te[0]) is the bar at 2014-04-03 14:30:00\n"
     ]
    }
   ],
   "source": [
    "print('executing <build_lstm_tensors>...')\n",
    "X, y, raw_close, raw_bid, raw_ask = models.build_lstm_tensors(\n",
    "    df=df,\n",
    "    look_back=look_back,\n",
    "    features_cols=params.features_cols,\n",
    "    label_col=params.label_col,\n",
    "    regular_start=regular_start_pred\n",
    ")\n",
    "\n",
    "print('executing <chronological_split>...')\n",
    "(X_tr, y_tr), \\\n",
    "(X_val, y_val), \\\n",
    "(X_te, y_te, raw_close_te, raw_bid_te, raw_ask_te), \\\n",
    "samples_per_day, day_id_tr, day_id_val, day_id_te = models.chronological_split(\n",
    "    X, y, raw_close, raw_bid, raw_ask, df,\n",
    "    look_back   = look_back,\n",
    "    regular_start   = regular_start_pred,\n",
    "    train_prop  = params.train_prop,\n",
    "    val_prop    = params.val_prop,\n",
    "    train_batch = params.train_batch\n",
    ")\n",
    "\n",
    "print('executing <split_to_day_datasets>...')\n",
    "train_loader, val_loader, test_loader = models.split_to_day_datasets(\n",
    "    # Training split arrays (from chronological_split)\n",
    "    X_tr, y_tr, day_id_tr,\n",
    "    # Validation split arrays\n",
    "    X_val, y_val, day_id_val,\n",
    "    # Test split arrays + raw prices for post‐tracking\n",
    "    X_te, y_te, day_id_te, raw_close_te, raw_bid_te, raw_ask_te,\n",
    "    # Original minute‐bar DataFrame for weekday mapping\n",
    "    df=df,\n",
    "    train_batch=params.train_batch,\n",
    "    train_workers=params.num_workers\n",
    ")\n",
    "\n",
    "print('dataloaders generated!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3e3272-5c5c-4fe4-b889-48529376f6c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1933637684.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    .\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daba10b-3212-4a06-b607-748995bdc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire model object (architecture + weights)\n",
    "model_best = torch.load(model_path, map_location=device, weights_only=False)\n",
    "model_best.to(device).eval()\n",
    "model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3bb61-a03f-466d-9fde-ed65753fc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero‐forecast baseline on val vs test\n",
    "# √( mean( (yᵢ – 0)² ) )\n",
    "\n",
    "val_baseline  = models.naive_rmse(val_loader)\n",
    "test_baseline = models.naive_rmse(test_loader)\n",
    "\n",
    "print(f\"Val zero‐forecast baseline RMSE  = {val_baseline:.5f}\")\n",
    "print(f\"Test zero‐forecast baseline RMSE = {test_baseline:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce154412-6773-4774-bc9f-7bc5f74f981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to confirm the baseline proportions, calculate the STD\n",
    "# σ = √( mean( (yᵢ – ȳ)² ) )\n",
    "\n",
    "y_vals = np.concatenate([batch[1].view(-1).numpy()\n",
    "                         for batch in val_loader])\n",
    "y_tes  = np.concatenate([batch[1].view(-1).numpy()\n",
    "                         for batch in test_loader])\n",
    "print(\"std val:\", np.std(y_vals))\n",
    "print(\"std test:\", np.std(y_tes))\n",
    "\n",
    "plt.hist(y_vals, bins=100, alpha=0.5, label=\"val\")\n",
    "plt.hist(y_tes,  bins=100, alpha=0.5, label=\"test\")\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fd008-4a5d-44fd-9bb4-c4e70e4c8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(\n",
    "    model: torch.nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    "    split_name: str = \"Test\",\n",
    "    compute_rmse: bool = True,\n",
    "    collect_preds: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Run your LSTM over every day in `loader`, with the same reset logic\n",
    "    you use in rmse_over_windows and collect_predictions, but controlled by flags:\n",
    "      - compute_rmse: if True, accumulates MSE and returns RMSE\n",
    "      - collect_preds: if True, gathers every window's prediction into a flat array\n",
    "\n",
    "    Returns:\n",
    "      (rmse, preds) where:\n",
    "        • rmse is a float if compute_rmse else None\n",
    "        • preds is a 1D np.ndarray if collect_preds else None\n",
    "\n",
    "    You can call:\n",
    "      rmse, _     = evaluate_model(model, loader, device, split_name, True, False)\n",
    "      _, preds    = evaluate_model(model, loader, device, split_name, False, True)\n",
    "      rmse, preds = evaluate_model(model, loader, device, split_name, True, True)\n",
    "    \"\"\"\n",
    "    # Move model & reset its internal state\n",
    "    model.to(device).eval()\n",
    "    model.h_short = model.h_long = None\n",
    "\n",
    "    prev_wd        = None\n",
    "    total_sq_error = 0.0     # for RMSE\n",
    "    total_windows  = 0       # counter for windows\n",
    "    all_preds      = []      # list to store per-day preds\n",
    "\n",
    "    # Iterate exactly as in two original functions\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=f\"{split_name}\", unit=\"day\"):\n",
    "            # Unpack: xb_day, yb_day, optional raw_*, wd\n",
    "            xb_day, yb_day, *_, wd = batch\n",
    "            wd_val = int(wd.item())\n",
    "\n",
    "            # reset per-day LSTM\n",
    "            model.reset_short()\n",
    "            # reset per-week LSTM on weekday wrap\n",
    "            if prev_wd is not None and wd_val < prev_wd:\n",
    "                model.reset_long()\n",
    "            prev_wd = wd_val\n",
    "\n",
    "            # pull input windows and true targets\n",
    "            x    = xb_day[0].to(device)        # shape: (W, look_back, F)\n",
    "            y    = yb_day.view(-1).to(device)  # shape: (W,)\n",
    "\n",
    "            # forward pass → get last-step prediction\n",
    "            out  = model(x)                    # (W, look_back, 1)\n",
    "            pred = out[:, -1, 0]               # (W,)\n",
    "\n",
    "            # accumulate RMSE stats if requested\n",
    "            if compute_rmse:\n",
    "                total_sq_error += (pred - y).pow(2).sum().item()\n",
    "                total_windows  += y.numel()\n",
    "\n",
    "            # collect raw preds if requested\n",
    "            if collect_preds:\n",
    "                all_preds.append(pred.cpu().numpy())\n",
    "\n",
    "    # compute final RMSE\n",
    "    rmse = None\n",
    "    if compute_rmse:\n",
    "        rmse = math.sqrt(total_sq_error / total_windows)\n",
    "        print(f\"\\n{split_name} RMSE over {total_windows} windows = {rmse:.5f}\")\n",
    "\n",
    "    # flatten collected predictions\n",
    "    preds = None\n",
    "    if collect_preds:\n",
    "        preds = np.concatenate(all_preds, axis=0)\n",
    "\n",
    "    return rmse, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557c7f6-8653-4b5c-afc2-e16ba8daf319",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rmse, _     = evaluate_model(model_best, val_loader, device, split_name=\"Validation\")\n",
    "test_rmse, _     = evaluate_model(model_best, test_loader, device, split_name=\"Test\")\n",
    "\n",
    "_, preds = evaluate_model(model_best, test_loader, device,\n",
    "                          split_name=\"Test\",\n",
    "                          compute_rmse=False, collect_preds=True)\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fee7f2-78d5-4ceb-b830-a3d92e88069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_pred_actions(df: pd.DataFrame, preds: np.ndarray) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Stamp preds on the exact minute-bars your model saw.\n",
    "    2) Take only those rows (the “test split”) and\n",
    "       generate trade actions on them.\n",
    "    3) Return the smaller DF.\n",
    "    \"\"\"\n",
    "    # 0) copy & init\n",
    "    df = df.copy()\n",
    "    df[\"pred_signal\"] = np.nan\n",
    "\n",
    "    # 1) build valid_idx exactly as before\n",
    "    valid_ts = []\n",
    "    days = sorted(df.index.normalize().unique())\n",
    "    # replay the test-day logic via day_id_te:\n",
    "    test_global_ids = np.unique(day_id_te)\n",
    "    for gid in test_global_ids:\n",
    "        day = days[int(gid)]\n",
    "        day_df = df[df.index.normalize() == day].sort_index()\n",
    "\n",
    "        # drop first LOOK_BACK bars, then mask times >= regular_start\n",
    "        ends = day_df.index[look_back:]\n",
    "        mask = ends.time >= regular_start\n",
    "        valid_ts.append(ends[mask])\n",
    "\n",
    "    valid_idx = pd.DatetimeIndex(np.concatenate([ts.values for ts in valid_ts]))\n",
    "\n",
    "    if len(valid_idx) != len(preds):\n",
    "        raise ValueError(f\"{len(valid_idx)} slots vs {len(preds)} preds\")\n",
    "\n",
    "    df.loc[valid_idx, \"pred_signal\"] = preds\n",
    "\n",
    "    # 2) slice to only test-rows\n",
    "    df_test = df.loc[valid_idx]\n",
    "\n",
    "    # 3) generate trade actions per test-day only\n",
    "    outs = []\n",
    "    for _, day_df in df_test.groupby(df_test.index.normalize(), sort=False):\n",
    "        outs.append(\n",
    "            trades.generate_trade_actions(\n",
    "                df                   = day_df,\n",
    "                col_signal           = \"pred_signal\",\n",
    "                col_action           = \"pred_action\",\n",
    "                buy_threshold        = pred_threshold,\n",
    "                trailing_stop_thresh = trailing_stop_thresh,\n",
    "                regular_start        = regular_start\n",
    "            )\n",
    "        )\n",
    "\n",
    "    df_out = pd.concat(outs).sort_index()\n",
    "    df_out.to_csv(path_csv_save)\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc219b44-696e-41dc-97ae-d5c5a5403d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_preds = add_pred_actions(\n",
    "    df, preds\n",
    ")\n",
    "\n",
    "df_with_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b957c-f93a-41b6-bce1-08806c2b0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('generating sim_results as a dict: { date → (df_sim, trades_list, perf_stats) } ...')\n",
    "\n",
    "# Run the simulator on your DataFrame of predictions/actions\n",
    "sim_results = trades.simulate_trading(\n",
    "    results_by_day_sign = df_with_preds,              # full DF with pred_action\n",
    "    col_action          = \"pred_action\",              # name of the discrete action column\n",
    "    regular_start       = params.regular_start,       \n",
    "    regular_end         = params.regular_end,         \n",
    "    ticker              = params.ticker\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08efbd70-ae18-4653-a023-aa7f2cc81b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "year, month = map(int, date_to_check.split(\"-\"))\n",
    "\n",
    "# 1) Build lists of days in that month + accumulate ALL days\n",
    "days_in_month = []\n",
    "performance_month = []\n",
    "performance_all   = []\n",
    "\n",
    "for day, (df_sim, trades_list, perf_stats) in sim_results.items():\n",
    "    # always collect for the global summary\n",
    "    performance_all.append(perf_stats)\n",
    "\n",
    "    # pick out this month for plotting\n",
    "    if day.year == year and day.month == month:\n",
    "        days_in_month.append(day)\n",
    "        performance_month.append(perf_stats)\n",
    "\n",
    "# 2) Plot & print per-day stats for the month\n",
    "if not days_in_month:\n",
    "    print(f\"No simulation data for {date_to_check}\")\n",
    "else:\n",
    "    print(f\"\\nPlotting days in {date_to_check}:\")\n",
    "    for day in days_in_month:\n",
    "        df_sim, trades_list, perf_stats = sim_results[day]\n",
    "        plots.plot_trades(\n",
    "            df                = df_sim,\n",
    "            col_signal1       = \"pred_signal\",\n",
    "            col_signal2       = \"signal_smooth\",\n",
    "            col_action        = \"pred_action\",\n",
    "            trades            = trades_list,\n",
    "            buy_threshold     = params.pred_threshold_man,\n",
    "            performance_stats = perf_stats\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n=== Performance for {day} ===\")\n",
    "        for k, v in perf_stats.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "# 3) Monthly summary\n",
    "df_month = df_with_preds[df_with_preds.index.to_period(\"M\") == date_to_check]\n",
    "monthly_summary = plots.aggregate_performance(performance_month, df_month)\n",
    "pprint(monthly_summary)\n",
    "\n",
    "# 4) Overall summary across ALL days, with date range\n",
    "overall_summary = plots.aggregate_performance(performance_all, df_with_preds)\n",
    "pprint(overall_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a6f11-54e4-4778-ac70-903606897ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cee26d-0227-49cc-8d3d-6da977a39753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
