{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f06a4f-691a-4a84-a305-e7212eb879bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c868158-e6bb-4d56-bbdd-8e8103f0b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Wipe out all Python variables\n",
    "%reset -f\n",
    "# 2) Force Python’s garbage collector to run\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import importlib\n",
    "from libs import trades, plots, params, models\n",
    "importlib.reload(trades)\n",
    "importlib.reload(plots)\n",
    "importlib.reload(params)\n",
    "importlib.reload(models)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import math\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "from typing import Sequence, List, Tuple, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Funct\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b98406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>r_1</th>\n",
       "      <th>r_5</th>\n",
       "      <th>r_15</th>\n",
       "      <th>vol_15</th>\n",
       "      <th>volume_spike</th>\n",
       "      <th>vwap_dev</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>signal_smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:06:00</th>\n",
       "      <td>28.644845</td>\n",
       "      <td>28.644845</td>\n",
       "      <td>28.644845</td>\n",
       "      <td>28.644845</td>\n",
       "      <td>4580.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.568641</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.636251</td>\n",
       "      <td>28.653438</td>\n",
       "      <td>0.162925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:07:00</th>\n",
       "      <td>28.639690</td>\n",
       "      <td>28.639690</td>\n",
       "      <td>28.639690</td>\n",
       "      <td>28.639690</td>\n",
       "      <td>4540.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.570338</td>\n",
       "      <td>-0.000352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.631098</td>\n",
       "      <td>28.648282</td>\n",
       "      <td>0.164530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:08:00</th>\n",
       "      <td>28.634534</td>\n",
       "      <td>28.634534</td>\n",
       "      <td>28.634534</td>\n",
       "      <td>28.634534</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.574408</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.625944</td>\n",
       "      <td>28.643125</td>\n",
       "      <td>0.166141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:09:00</th>\n",
       "      <td>28.629379</td>\n",
       "      <td>28.629379</td>\n",
       "      <td>28.629379</td>\n",
       "      <td>28.629379</td>\n",
       "      <td>4460.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.581017</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.620791</td>\n",
       "      <td>28.637968</td>\n",
       "      <td>0.167757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-03 12:10:00</th>\n",
       "      <td>28.624224</td>\n",
       "      <td>28.624224</td>\n",
       "      <td>28.624224</td>\n",
       "      <td>28.624224</td>\n",
       "      <td>4420.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.590413</td>\n",
       "      <td>-0.000862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.615637</td>\n",
       "      <td>28.632811</td>\n",
       "      <td>0.169381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-17 20:56:00</th>\n",
       "      <td>176.090000</td>\n",
       "      <td>176.160000</td>\n",
       "      <td>176.010000</td>\n",
       "      <td>176.050000</td>\n",
       "      <td>126589.0</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>1.610125</td>\n",
       "      <td>1.217786</td>\n",
       "      <td>39.325843</td>\n",
       "      <td>175.997200</td>\n",
       "      <td>176.102800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-17 20:57:00</th>\n",
       "      <td>176.050000</td>\n",
       "      <td>176.080000</td>\n",
       "      <td>175.890000</td>\n",
       "      <td>175.930000</td>\n",
       "      <td>125176.0</td>\n",
       "      <td>-0.000682</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>1.478464</td>\n",
       "      <td>1.216271</td>\n",
       "      <td>34.328358</td>\n",
       "      <td>175.877200</td>\n",
       "      <td>175.982800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-17 20:58:00</th>\n",
       "      <td>175.930000</td>\n",
       "      <td>175.975000</td>\n",
       "      <td>175.860000</td>\n",
       "      <td>175.890000</td>\n",
       "      <td>200235.0</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>2.096227</td>\n",
       "      <td>1.215761</td>\n",
       "      <td>29.648241</td>\n",
       "      <td>175.837200</td>\n",
       "      <td>175.942800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-17 20:59:00</th>\n",
       "      <td>175.900000</td>\n",
       "      <td>175.970000</td>\n",
       "      <td>175.800000</td>\n",
       "      <td>175.930000</td>\n",
       "      <td>393414.0</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>-0.001136</td>\n",
       "      <td>-0.002073</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>3.295458</td>\n",
       "      <td>1.216254</td>\n",
       "      <td>25.925926</td>\n",
       "      <td>175.877200</td>\n",
       "      <td>175.982800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-17 21:00:00</th>\n",
       "      <td>175.930000</td>\n",
       "      <td>176.040000</td>\n",
       "      <td>175.800000</td>\n",
       "      <td>175.950000</td>\n",
       "      <td>5670184.0</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>-0.002469</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>11.461178</td>\n",
       "      <td>1.216344</td>\n",
       "      <td>27.748691</td>\n",
       "      <td>175.897200</td>\n",
       "      <td>176.002800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1473635 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           open        high         low       close  \\\n",
       "2014-04-03 12:06:00   28.644845   28.644845   28.644845   28.644845   \n",
       "2014-04-03 12:07:00   28.639690   28.639690   28.639690   28.639690   \n",
       "2014-04-03 12:08:00   28.634534   28.634534   28.634534   28.634534   \n",
       "2014-04-03 12:09:00   28.629379   28.629379   28.629379   28.629379   \n",
       "2014-04-03 12:10:00   28.624224   28.624224   28.624224   28.624224   \n",
       "...                         ...         ...         ...         ...   \n",
       "2025-06-17 20:56:00  176.090000  176.160000  176.010000  176.050000   \n",
       "2025-06-17 20:57:00  176.050000  176.080000  175.890000  175.930000   \n",
       "2025-06-17 20:58:00  175.930000  175.975000  175.860000  175.890000   \n",
       "2025-06-17 20:59:00  175.900000  175.970000  175.800000  175.930000   \n",
       "2025-06-17 21:00:00  175.930000  176.040000  175.800000  175.950000   \n",
       "\n",
       "                        volume       r_1       r_5      r_15    vol_15  \\\n",
       "2014-04-03 12:06:00     4580.0 -0.000180 -0.000180 -0.000180  0.000046   \n",
       "2014-04-03 12:07:00     4540.0 -0.000180 -0.000360 -0.000360  0.000063   \n",
       "2014-04-03 12:08:00     4500.0 -0.000180 -0.000540 -0.000540  0.000075   \n",
       "2014-04-03 12:09:00     4460.0 -0.000180 -0.000720 -0.000720  0.000082   \n",
       "2014-04-03 12:10:00     4420.0 -0.000180 -0.000900 -0.000900  0.000088   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "2025-06-17 20:56:00   126589.0 -0.000284 -0.000681 -0.001297  0.000443   \n",
       "2025-06-17 20:57:00   125176.0 -0.000682 -0.000398 -0.001761  0.000469   \n",
       "2025-06-17 20:58:00   200235.0 -0.000227 -0.001023 -0.002016  0.000468   \n",
       "2025-06-17 20:59:00   393414.0  0.000227 -0.001136 -0.002073  0.000464   \n",
       "2025-06-17 21:00:00  5670184.0  0.000114 -0.000852 -0.002469  0.000435   \n",
       "\n",
       "                     volume_spike  vwap_dev     rsi_14         bid  \\\n",
       "2014-04-03 12:06:00      0.568641 -0.000177   0.000000   28.636251   \n",
       "2014-04-03 12:07:00      0.570338 -0.000352   0.000000   28.631098   \n",
       "2014-04-03 12:08:00      0.574408 -0.000524   0.000000   28.625944   \n",
       "2014-04-03 12:09:00      0.581017 -0.000694   0.000000   28.620791   \n",
       "2014-04-03 12:10:00      0.590413 -0.000862   0.000000   28.615637   \n",
       "...                           ...       ...        ...         ...   \n",
       "2025-06-17 20:56:00      1.610125  1.217786  39.325843  175.997200   \n",
       "2025-06-17 20:57:00      1.478464  1.216271  34.328358  175.877200   \n",
       "2025-06-17 20:58:00      2.096227  1.215761  29.648241  175.837200   \n",
       "2025-06-17 20:59:00      3.295458  1.216254  25.925926  175.877200   \n",
       "2025-06-17 21:00:00     11.461178  1.216344  27.748691  175.897200   \n",
       "\n",
       "                            ask  signal_smooth  \n",
       "2014-04-03 12:06:00   28.653438       0.162925  \n",
       "2014-04-03 12:07:00   28.648282       0.164530  \n",
       "2014-04-03 12:08:00   28.643125       0.166141  \n",
       "2014-04-03 12:09:00   28.637968       0.167757  \n",
       "2014-04-03 12:10:00   28.632811       0.169381  \n",
       "...                         ...            ...  \n",
       "2025-06-17 20:56:00  176.102800       0.000000  \n",
       "2025-06-17 20:57:00  175.982800       0.000000  \n",
       "2025-06-17 20:58:00  175.942800       0.000000  \n",
       "2025-06-17 20:59:00  175.982800       0.000000  \n",
       "2025-06-17 21:00:00  176.002800       0.000000  \n",
       "\n",
       "[1473635 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ticker         = params.ticker\n",
    "look_back      = params.look_back \n",
    "features_cols  = params.features_cols\n",
    "label_col      = params.label_col\n",
    "save_path      = params.save_path\n",
    "\n",
    "date = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "regular_start_pred  = params.regular_start_pred\n",
    "\n",
    "# USE GPU if available, otherwise fallback to CPU\n",
    "device = params.device\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "fin_csv_path  = save_path / f\"{ticker}_final.csv\"\n",
    "df = pd.read_csv(fin_csv_path, index_col=0, parse_dates=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b805fa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1174595, 120, 12])\n",
      "torch.Size([1174595])\n",
      "Shapes:\n",
      "  X         = torch.Size([1174595, 120, 12]) (samples, features, look_back)\n",
      "  y         = torch.Size([1174595]) (samples,)\n",
      "  raw_close = torch.Size([1174595])\n",
      "  raw_bid   = torch.Size([1174595])\n",
      "  raw_ask   = torch.Size([1174595])\n",
      "\n",
      "First 5 window‐end timestamps:\n",
      "  2014-04-03 14:06:00\n",
      "  2014-04-03 14:07:00\n",
      "  2014-04-03 14:08:00\n",
      "  2014-04-03 14:09:00\n",
      "  2014-04-03 14:10:00\n",
      "\n",
      "First window covers 120 bars from\n",
      "  2014-04-03 12:06:00  →  2014-04-03 14:05:00\n",
      "and predicts the bar at 2014-04-03 14:06:00\n",
      "\n",
      "Those bars (timestamps):\n",
      "DatetimeIndex(['2014-04-03 12:06:00', '2014-04-03 12:07:00',\n",
      "               '2014-04-03 12:08:00', '2014-04-03 12:09:00',\n",
      "               '2014-04-03 12:10:00', '2014-04-03 12:11:00',\n",
      "               '2014-04-03 12:12:00', '2014-04-03 12:13:00',\n",
      "               '2014-04-03 12:14:00', '2014-04-03 12:15:00',\n",
      "               ...\n",
      "               '2014-04-03 13:56:00', '2014-04-03 13:57:00',\n",
      "               '2014-04-03 13:58:00', '2014-04-03 13:59:00',\n",
      "               '2014-04-03 14:00:00', '2014-04-03 14:01:00',\n",
      "               '2014-04-03 14:02:00', '2014-04-03 14:03:00',\n",
      "               '2014-04-03 14:04:00', '2014-04-03 14:05:00'],\n",
      "              dtype='datetime64[ns]', length=120, freq='min')\n",
      "First 5 values y: [0.28795275 0.28954306 0.29157925 0.2940605  0.29507098]\n",
      "First 5 signal_smooth values, on regular trade time:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2014-04-03 14:06:00    0.287953\n",
       "2014-04-03 14:07:00    0.289543\n",
       "2014-04-03 14:08:00    0.291579\n",
       "2014-04-03 14:09:00    0.294060\n",
       "2014-04-03 14:10:00    0.295071\n",
       "Name: signal_smooth, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, raw_close, raw_bid, raw_ask = models.build_lstm_tensors(\n",
    "    df=df,\n",
    "    look_back=look_back,\n",
    "    features_cols=features_cols,\n",
    "    label_col=label_col,\n",
    "    regular_start=regular_start_pred\n",
    ")\n",
    "\n",
    "# 1)\n",
    "print(X.shape) # we use 'm' features and 'n' previous look back values to predict each 1 label\n",
    "print(y.shape) \n",
    "\n",
    "\n",
    "# 2) quick shapes\n",
    "print(\"Shapes:\")\n",
    "print(\"  X         =\", X.shape,    \"(samples, features, look_back)\")\n",
    "print(\"  y         =\", y.shape,    \"(samples,)\")\n",
    "print(\"  raw_close =\", raw_close.shape)\n",
    "print(\"  raw_bid   =\", raw_bid.shape)\n",
    "print(\"  raw_ask   =\", raw_ask.shape)\n",
    "\n",
    "# # 3) rebuild the list of label‐timestamps (window‐ends)\n",
    "# ends = []\n",
    "# for day, day_df in df.groupby(df.index.normalize(), sort=False):\n",
    "#     day_df = day_df.sort_index()\n",
    "#     # candidate ends at positions look_back .. end\n",
    "#     idxs = day_df.index[look_back:]\n",
    "#     # only keep those at/after regular_start_pred\n",
    "#     mask = [t >= regular_start_pred for t in idxs.time]\n",
    "#     ends.extend(idxs[mask])\n",
    "\n",
    "# # 4) show first few ends\n",
    "# print(\"\\nFirst 5 window‐end timestamps:\")\n",
    "# for ts in ends[:5]:\n",
    "#     print(\" \", ts)\n",
    "\n",
    "# # 5) show exactly which minutes X[0] contains\n",
    "# first_end   = ends[0]\n",
    "# first_start = first_end - pd.Timedelta(minutes=look_back)\n",
    "# print(f\"\\nFirst window covers {look_back} bars from\")\n",
    "# print(f\"  {first_start}  →  {first_end - pd.Timedelta(minutes=1)}\")\n",
    "# print(f\"and predicts the bar at {first_end}\")\n",
    "\n",
    "# print(\"\\nThose bars (timestamps):\")\n",
    "# print(pd.date_range(first_start, first_end - pd.Timedelta(minutes=1), freq=\"1min\"))\n",
    "# # -------------------------------------------------------------------\n",
    "\n",
    "# y_np         = y.cpu().numpy()\n",
    "# print(\"First 5 values y:\",         y_np[:5])\n",
    "# print(\"First 5 signal_smooth values, on regular trade time:\")\n",
    "# df.signal_smooth.iloc[look_back:look_back+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b4f1ac4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Split into train/val/test by calendar day\u001b[39;00m\n\u001b[1;32m      2\u001b[0m (X_tr, y_tr), \\\n\u001b[1;32m      3\u001b[0m (X_val, y_val), \\\n\u001b[1;32m      4\u001b[0m (X_te, y_te, raw_close_te, raw_bid_te, raw_ask_te), \\\n\u001b[0;32m----> 5\u001b[0m samples_per_day, day_id_tr, day_id_val, day_id_te \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchronological_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_close\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_bid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_ask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlook_back\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlook_back\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregular_start\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mregular_start_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_prop\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_prop\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTRAIN_BATCH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 1) Print shapes of all tensors\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/my models/Trading/0.Stock Analysis/libs/models.py:257\u001b[0m, in \u001b[0;36mchronological_split\u001b[0;34m(X, y, raw_close, raw_bid, raw_ask, df, look_back, regular_start, train_prop, val_prop, train_batch, device)\u001b[0m\n\u001b[1;32m    255\u001b[0m test_days \u001b[38;5;241m=\u001b[39m [all_days[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(D) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m cut_val]\n\u001b[1;32m    256\u001b[0m df_test   \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnormalize()\u001b[38;5;241m.\u001b[39misin(test_days)]\n\u001b[0;32m--> 257\u001b[0m \u001b[43mdf_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdfs training/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mticker\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_test_DF.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# 8) Return splits + metadata\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    261\u001b[0m     (X_tr, y_tr),\n\u001b[1;32m    262\u001b[0m     (X_val, y_val),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m     day_id_tr, day_id_val, day_id_te\n\u001b[1;32m    266\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/csvs.py:324\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[1;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 324\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mwriters.pyx:56\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Split into train/val/test by calendar day\n",
    "(X_tr, y_tr), \\\n",
    "(X_val, y_val), \\\n",
    "(X_te, y_te, raw_close_te, raw_bid_te, raw_ask_te), \\\n",
    "samples_per_day, day_id_tr, day_id_val, day_id_te = models.chronological_split(\n",
    "    X, y, raw_close, raw_bid, raw_ask, df,\n",
    "    look_back   = look_back,\n",
    "    regular_start   = regular_start_pred,\n",
    "    train_prop  = params.train_prop,\n",
    "    val_prop    = params.val_prop,\n",
    "    train_batch = params.hparams['TRAIN_BATCH']\n",
    ")\n",
    "\n",
    "# 1) Print shapes of all tensors\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_tr        =\", X_tr.shape)\n",
    "print(\"  y_tr        =\", y_tr.shape)\n",
    "print(\"  raw_close_te=\", raw_close_te.shape)\n",
    "print(\"  raw_bid_te  =\", raw_bid_te.shape)\n",
    "print(\"  raw_ask_te  =\", raw_ask_te.shape)\n",
    "\n",
    "# # 2) Print number of days in each split\n",
    "# n_tr_days = torch.unique(day_id_tr).numel()\n",
    "# n_val_days= torch.unique(day_id_val).numel()\n",
    "# n_te_days = torch.unique(day_id_te).numel()\n",
    "# print(f\"\\nDays: train={n_tr_days}, val={n_val_days}, test={n_te_days}\")\n",
    "\n",
    "# # 3) Print number of windows in each split\n",
    "# print(f\"Windows: train={X_tr.shape[0]}, val={X_val.shape[0]}, test={X_te.shape[0]}\")\n",
    "\n",
    "# # 4) List the first few window‐end timestamps\n",
    "# ends = []\n",
    "# for day, day_df in df.groupby(df.index.normalize(), sort=False):\n",
    "#     ts = day_df.index[look_back:]\n",
    "#     ends.extend(ts[ts.time >= regular_start_pred])\n",
    "# first_ends = ends[:5]\n",
    "# print(\"\\nFirst 5 window‐end times:\", first_ends)\n",
    "\n",
    "# # 5) Show exactly which minutes X_tr[0] covers, and where y_tr[0] sits\n",
    "# first_end   = first_ends[0]\n",
    "# first_start = first_end - pd.Timedelta(minutes=look_back)\n",
    "# # input bars = [first_start … first_end − 1min]\n",
    "# print(f\"\\nX_tr[0] covers bars from {first_start} to {first_end - pd.Timedelta(minutes=1)}\")\n",
    "# print(\"Those timestamps:\")\n",
    "# print(pd.date_range(first_start, first_end - pd.Timedelta(minutes=1), freq=\"1min\"))\n",
    "# print(f\"y_tr[0] (and raw_close_te[0]) is the bar at {first_end}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9b6c4-3d79-45c0-b2c0-c4f46f1ad866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "#  Build DataLoaders over calendar‐days\n",
    "# -----------------------------------------------------------------------------\n",
    "train_loader, val_loader, test_loader = models.split_to_day_datasets(\n",
    "    # Training split arrays (from chronological_split)\n",
    "    X_tr, y_tr, day_id_tr,\n",
    "    # Validation split arrays\n",
    "    X_val, y_val, day_id_val,\n",
    "    # Test split arrays + raw prices for post‐tracking\n",
    "    X_te, y_te, day_id_te, raw_close_te, raw_bid_te, raw_ask_te,\n",
    "    # Original minute‐bar DataFrame for weekday mapping\n",
    "    df=df,\n",
    "    train_batch=params.hparams['TRAIN_BATCH'],\n",
    "    train_workers=params.hparams['NUM_WORKERS']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec031f-6c8f-455f-9c72-ae411e03ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Instantiate the stateful DualMemoryLSTM & move to device\n",
    "# -----------------------------------------------------------------------------\n",
    "model = models.DualMemoryLSTM(\n",
    "    n_feats        = len(features_cols),                          \n",
    "    short_units    = params.hparams['SHORT_UNITS'],    \n",
    "    long_units     = params.hparams['LONG_UNITS'],     \n",
    "    dropout_short  = params.hparams['DROPOUT_SHORT'],  \n",
    "    dropout_long   = params.hparams['DROPOUT_LONG'],   \n",
    "    att_heads      = params.hparams['ATT_HEADS'],\n",
    "    att_drop       = params.hparams['ATT_DROPOUT']\n",
    ")\n",
    "model.to(device)   # place model parameters on GPU or CPU as specified\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512a0dd-d2c8-418e-bfca-4580fb4be995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Compute plateau_sched timing parameters\n",
    "# -----------------------------------------------------------------------------\n",
    "# Total training samples = total windows in X_tr (one window per row)\n",
    "n_train_samples = X_tr.shape[0]\n",
    "\n",
    "# How many optimizer steps (day‐bundles) constitute one epoch?\n",
    "steps_per_epoch = len(train_loader)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build optimizer, LR scheduler, AMP scaler, and gradient‐clip norm\n",
    "# -----------------------------------------------------------------------------\n",
    "optimizer, plateau_sched, cosine_sched, scaler, clipnorm = models.make_optimizer_and_scheduler(\n",
    "    model,\n",
    "    initial_lr        = params.hparams['INITIAL_LR'],       \n",
    "    weight_decay      = params.hparams['WEIGHT_DECAY'],     \n",
    "    clipnorm          = params.hparams['CLIPNORM']   \n",
    ")\n",
    "\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70105f-bbe5-4ce0-aabe-acf9193ef401",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# function to find the optimal learning rate\n",
    "############################################\n",
    "\n",
    "# # 1) Move model to CPU and build a fresh optimizer (no scheduler metadata)\n",
    "# model_cpu = model.cpu()\n",
    "# optimizer_cpu = torch.optim.AdamW(\n",
    "#     model_cpu.parameters(),\n",
    "#     lr=1e-3,        # placeholder; the finder will override this\n",
    "#     weight_decay=5e-4\n",
    "# )\n",
    "\n",
    "# # 2) Create a tiny DataLoader (batch_size=1) to save memory\n",
    "# small_loader = DataLoader(\n",
    "#     train_loader.dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0\n",
    "# )\n",
    "\n",
    "# # 3) Define an aligned MSE that permutes/expands your [1,1,D] or [D,1,1]\n",
    "# #    target → [D, T, 1] to match output shape exactly.\n",
    "# def aligned_mse(output, target):\n",
    "#     # output: [D, T, 1]\n",
    "#     # target might come in as [D,1,1] or [1,1,D]\n",
    "#     tgt = target\n",
    "\n",
    "#     # Case A: target == [D, 1, 1] → expand middle dim to T\n",
    "#     if tgt.dim() == 3 and tgt.shape[0] == output.shape[0] \\\n",
    "#        and tgt.shape[1] == 1 and tgt.shape[2] == 1:\n",
    "#         tgt = tgt.expand(-1, output.size(1), -1)\n",
    "\n",
    "#     # Case B: target == [1, 1, D] → permute to [D,1,1] then expand\n",
    "#     elif tgt.dim() == 3 and tgt.shape[0] == 1 \\\n",
    "#          and tgt.shape[1] == 1 and tgt.shape[2] == output.shape[0]:\n",
    "#         # permute (0,1,2) → (2,1,0) to get [D,1,1]\n",
    "#         tgt = tgt.permute(2, 1, 0)\n",
    "#         tgt = tgt.expand(-1, output.size(1), -1)\n",
    "\n",
    "#     else:\n",
    "#         # fallback: broadcast to exactly output.shape\n",
    "#         tgt = tgt.expand(output.shape)\n",
    "\n",
    "#     return Funct.mse_loss(output, tgt)\n",
    "\n",
    "# # 4) Free any lingering GPU memory\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # 5) Run the LR‐Finder on CPU for just 30 mini‐batches\n",
    "# lr_finder = LRFinder(\n",
    "#     model_cpu,\n",
    "#     optimizer_cpu,\n",
    "#     aligned_mse,\n",
    "#     device=\"cpu\"\n",
    "# )\n",
    "# lr_finder.range_test(\n",
    "#     small_loader,\n",
    "#     end_lr=1,     # maximum LR to try\n",
    "#     num_iter=30   # number of batches\n",
    "# )\n",
    "# lr_finder.plot()   # examine loss vs. LR curve\n",
    "# lr_finder.reset()  # restore original model & optimizer states\n",
    "\n",
    "# # 6) Move model back to GPU for your main training\n",
    "# model = model_cpu.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf94780-a876-4bf4-ad27-6abc2da1fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Count how many calendar days we see each epoch and Compute baseline RMSE on validation (zero forecast)\n",
    "# -----------------------------------------------------------------------------\n",
    "n_train_days = len(train_loader.dataset)  # dataset length = # unique days\n",
    "print(f\"Training sees {n_train_days} calendar days per epoch\\n\")\n",
    "\n",
    "baseline_val_rmse = models.naive_rmse(val_loader)\n",
    "print(f\"Baseline (zero‐forecast) RMSE on validation = {baseline_val_rmse:.6f}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run the custom stateful training loop\n",
    "# -----------------------------------------------------------------------------\n",
    "best_val_rmse  = models.custom_stateful_training_loop(\n",
    "    model               = model,\n",
    "    optimizer           = optimizer,\n",
    "    cosine_sched        = cosine_sched,\n",
    "    plateau_sched       = plateau_sched,\n",
    "    scaler              = scaler,\n",
    "    train_loader        = train_loader,\n",
    "    val_loader          = val_loader,\n",
    "    max_epochs          = params.hparams['MAX_EPOCHS'],\n",
    "    early_stop_patience = params.hparams['EARLY_STOP_PATIENCE'],\n",
    "    baseline_val_rmse   = baseline_val_rmse,\n",
    "    clipnorm            = clipnorm,\n",
    "    device              = device\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Final reporting: best RMSE and relative improvement\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\nChampion validation RMSE = {best_val_rmse:.6f}\")\n",
    "\n",
    "improvement = 100.0 * (1.0 - best_val_rmse / baseline_val_rmse)\n",
    "print(f\"Improvement over zero‐baseline = {improvement:5.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e0cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8660dd-d2db-434a-aa59-17814d343fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
