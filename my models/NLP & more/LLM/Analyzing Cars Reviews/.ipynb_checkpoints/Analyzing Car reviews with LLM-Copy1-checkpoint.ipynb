{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ccf226-acc1-4477-9c7b-06f1dda11a73",
   "metadata": {},
   "source": [
    "Car-ing is sharing, an auto dealership company for car sales and rental, is taking their services to the next level thanks to Large Language Models (LLMs).\n",
    "\n",
    "As their newly recruited AI and NLP developer, you've been asked to prototype a chatbot app with multiple functionalities that not only assist customers but also provide support to human agents in the company.\n",
    "\n",
    "The solution should receive textual prompts and use a variety of pre-trained Hugging Face LLMs to respond to a series of tasks, e.g. classifying the sentiment in a carâ€™s text review, answering a customer question, summarizing or translating text, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b59218-7904-44f1-ac79-20f6ed80b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install evaluate\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87abf218-c94e-44fb-999d-1a12899fb155",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "Use a pre-trained LLM to classify the sentiment of the five car reviews in the car_reviews.csv dataset, and evaluate the classification accuracy and F1 score of predictions.\n",
    "Store the model outputs in predicted_labels, then extract the labels and map them onto a list of {0,1} integer binary labels called predictions.\n",
    "Store the calculated metrics in accuracy_result and f1_result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69740e7-158d-49bd-878b-167651ade10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\Ingegneria\\Data Science GD\\My-Practice\\my models\\NLP & more\\LLM\n"
     ]
    }
   ],
   "source": [
    "# car_reviews = pd.read_csv('data/car_reviews.csv')\n",
    "# car_reviews\n",
    "\n",
    "\n",
    "\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded15563-29d5-4769-b417-23355adc6969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8a7ea-5a12-4a3f-bf0f-3e4f3462fcde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "309c2078-2d15-4867-9e86-89c88b792258",
   "metadata": {},
   "source": [
    "2.\n",
    "\n",
    "The company is recently attracting customers from Spain. Extract and pass the first two sentences of the first review in the dataset to an English-to-Spanish translation LLM. Calculate the BLEU score to assess translation quality, using the content in reference_translations.txt as references.\n",
    "Store the translated text generated by the LLM in translated_review.\n",
    "Store the BLEU score metric result in bleu_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22187dd9-b1cd-48d7-9542-7c559bee53bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb78c6-1257-4528-8699-d3c59ce9e8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd4e60-7598-459f-8b2d-a29bdbd4e1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16154702-44f2-4a2b-b4d0-424ffc2eb3ad",
   "metadata": {},
   "source": [
    "3.\n",
    "\n",
    "The 2nd review in the dataset emphasizes brand aspects. Load an extractive QA LLM such as \"deepset/minilm-uncased-squad2\" to formulate the question \"What did he like about the brand?\" and obtain an answer.\n",
    "Use question and context for the two variables containing the LLM inputs: question and context.\n",
    "Store the actual text answer in answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b45fa1-8b3e-44c9-9d6f-813cd34d5a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f99ded-faf0-438d-8f4c-df8e5e174116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94ea3a-f2e9-4366-88ff-d1c7605d0974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604a7df1-0d23-46ac-8754-92beb6eead0d",
   "metadata": {},
   "source": [
    "4.\n",
    "\n",
    "Summarize the last review in the dataset, into approximately 50-55 tokens long. Store it in the variable summarized_text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b6f06-4e31-4867-b01e-cf46e47060e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfcd369-7ad6-4938-9cba-41c0ca6e53eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d00ecc-4976-4f2e-80e7-1f332527e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load the car reviews dataset\n",
    "file_path = \"data/car_reviews.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "# Put the car reviews and their associated sentiment labels in two lists\n",
    "reviews = df['Review'].tolist()\n",
    "real_labels = df['Class'].tolist()\n",
    "\n",
    "\n",
    "# Instruction 1: sentiment classification\n",
    "\n",
    "# Load a sentiment analysis LLM into a pipeline\n",
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# Perform inference on the car reviews and display prediction results\n",
    "predicted_labels = classifier(reviews)\n",
    "for review, prediction, label in zip(reviews, predicted_labels, real_labels):\n",
    "    print(f\"Review: {review}\\nActual Sentiment: {label}\\nPredicted Sentiment: {prediction['label']} (Confidence: {prediction['score']:.4f})\\n\")\n",
    "\n",
    "# Load accuracy and F1 score metrics    \n",
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "# Map categorical sentiment labels into integer labels\n",
    "references = [1 if label == \"POSITIVE\" else 0 for label in real_labels]\n",
    "predictions = [1 if label['label'] == \"POSITIVE\" else 0 for label in predicted_labels]\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy_result_dict = accuracy.compute(references=references, predictions=predictions)\n",
    "accuracy_result = accuracy_result_dict['accuracy']\n",
    "f1_result_dict = f1.compute(references=references, predictions=predictions)\n",
    "f1_result = f1_result_dict['f1']\n",
    "print(f\"Accuracy: {accuracy_result}\")\n",
    "print(f\"F1 result: {f1_result}\")\n",
    "\n",
    "\n",
    "# Instruction 2: Translation\n",
    "\n",
    "# Load translation LLM into a pipeline and translate car review\n",
    "first_review = reviews[0]\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "translated_review = translator(first_review, max_length=27)[0]['translation_text']\n",
    "print(f\"Model translation:\\n{translated_review}\")\n",
    "\n",
    "# Load reference translations from file\n",
    "with open(\"data/reference_translations.txt\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "references = [line.strip() for line in lines]\n",
    "print(f\"Spanish translation references:\\n{references}\")\n",
    "\n",
    "# Load and calculate BLEU score metric\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "bleu_score = bleu.compute(predictions=[translated_review], references=[references])\n",
    "print(bleu_score['bleu'])\n",
    "\n",
    "\n",
    "# Instruction 3: extractive QA\n",
    "\n",
    "# Import auto classes (optional: can be solved via pipelines too)\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "# Instantiate model and tokenizer\n",
    "model_ckp = \"deepset/minilm-uncased-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckp)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckp)\n",
    "\n",
    "# Define context and question, and tokenize them\n",
    "context = reviews[1]\n",
    "print(f\"Context:\\n{context}\")\n",
    "question = \"What did he like about the brand?\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "\n",
    "# Perform inference and extract answer from raw outputs\n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "start_idx = torch.argmax(outputs.start_logits)\n",
    "end_idx = torch.argmax(outputs.end_logits) + 1\n",
    "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "\n",
    "# Decode and show answer\n",
    "answer = tokenizer.decode(answer_span)\n",
    "print(\"Answer: \", answer)\n",
    "\n",
    "\n",
    "# Instruction 4\n",
    "\n",
    "# Get original text to summarize upon car review\n",
    "text_to_summarize = reviews[-1]\n",
    "print(f\"Original text:\\n{text_to_summarize}\")\n",
    "\n",
    "# Load summarization pipeline and perform inference\n",
    "model_name = \"cnicu/t5-small-booksum\"\n",
    "summarizer = pipeline(\"summarization\", model=model_name)\n",
    "outputs = summarizer(text_to_summarize, max_length=53)\n",
    "summarized_text = outputs[0]['summary_text']\n",
    "print(f\"Summarized text:\\n{summarized_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
