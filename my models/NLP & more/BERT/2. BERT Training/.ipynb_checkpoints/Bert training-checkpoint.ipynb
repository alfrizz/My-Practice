{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1f58e2f8-afd2-4814-9a50-3b3812fb3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'\n",
    "\n",
    "# # to avoid OutOfMemoryError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec2086a5-35b3-4c78-99c2-78c239da52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know how fine-tuning with NSP and MLM works, but how exactly do we apply that in code?\n",
    "\n",
    "from transformers import BertTokenizer, BertForPreTraining, BertModel, DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "\n",
    "with open('clean.txt', 'r') as fp:\n",
    "    text = fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "66064306-8b11-4339-9634-b2f4f138629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['From my grandfather Verus I learned good morals and the government of my temper.',\n",
       " 'From the reputation and remembrance of my father, modesty and a manly character.',\n",
       " 'From my mother, piety and beneficence, and abstinence, not only from evil deeds, but even from evil thoughts; and further, simplicity in my way of living, far removed from the habits of the rich.']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(text))\n",
    "text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7575571b-c206-42f1-8960-b9829ac07042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1372"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "To prepare our data for NSP, we need to create a mix of non-random sentences (where the two sentences were originally together) — and random sentences.\n",
    "For this, we’ll create a bag of sentences extracted from text which we can then randomly select a sentence from when creating a random NotNextSentence pair.\n",
    "'''\n",
    "bag = [item for sentence in text for item in sentence.split('.') if item != '']\n",
    "bag_size = len(bag)\n",
    "bag_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "876b16f1-5d9b-437b-b612-c04473964dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From Maximus I learned self-government, and not to be led aside by anything; and cheerfulness in all circumstances, as well as in illness; and a just admixture in the moral character of sweetness and dignity, and to do what was set before me without complaining'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag[14] # just the first sentence (before the \".\") in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "15276224-1607-4ffc-a186-c3a5001d5283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From Maximus I learned self-government, and not to be led aside by anything; and cheerfulness in all circumstances, as well as in illness; and a just admixture in the moral character of sweetness and dignity, and to do what was set before me without complaining. I observed that everybody believed that he thought as he spoke, and that in all that he did he never had any bad intention; and he never showed amazement and surprise, and was never in a hurry, and never put off doing a thing, nor was perplexed nor dejected, nor did he ever laugh to disguise his vexation, nor, on the other hand, was he ever passionate or suspicious. He was accustomed to do acts of beneficence, and was ready to forgive, and was free from all falsehood; and he presented the appearance of a man who could not be diverted from right rather than of a man who had been improved. I observed, too, that no man could ever think that he was despised by Maximus, or ever venture to think himself a better man. He had also the art of being humorous in an agreeable way.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b54ed7fc-928f-4664-9256-ff770159c72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From Maximus I learned self-government, and not to be led aside by anything; and cheerfulness in all circumstances, as well as in illness; and a just admixture in the moral character of sweetness and dignity, and to do what was set before me without complaining',\n",
       " ' I observed that everybody believed that he thought as he spoke, and that in all that he did he never had any bad intention; and he never showed amazement and surprise, and was never in a hurry, and never put off doing a thing, nor was perplexed nor dejected, nor did he ever laugh to disguise his vexation, nor, on the other hand, was he ever passionate or suspicious',\n",
       " ' He was accustomed to do acts of beneficence, and was ready to forgive, and was free from all falsehood; and he presented the appearance of a man who could not be diverted from right rather than of a man who had been improved',\n",
       " ' I observed, too, that no man could ever think that he was despised by Maximus, or ever venture to think himself a better man',\n",
       " ' He had also the art of being humorous in an agreeable way']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag[14:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "162f33f4-1a19-468f-8144-05eb1c898813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAfter creating our bag we can go ahead and create our 50/50 random/non-random NSP training data. For this, we will create a list of sentence As, sentence Bs, and their respective IsNextSentence or NotNextSentence labels.\\n'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "After creating our bag we can go ahead and create our 50/50 random/non-random NSP training data. For this, we will create a list of sentence As, sentence Bs, and their respective IsNextSentence or NotNextSentence labels.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d803176e-8b2e-417b-b63d-e0431ad3730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentence_a = []\n",
    "sentence_b = []\n",
    "label = []\n",
    "\n",
    "for paragraph in text:\n",
    "    sentences = [\n",
    "        sentence for sentence in paragraph.split('.') if sentence != ''\n",
    "    ]\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 1:\n",
    "        start = random.randint(0, num_sentences-2)\n",
    "        # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "        if random.random() >= 0.5:\n",
    "            # this is IsNextSentence (sentence_b consecutive to sentence_a)\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(sentences[start+1])\n",
    "            label.append(0)\n",
    "        else:\n",
    "            index = random.randint(0, bag_size-1)\n",
    "            # this is NotNextSentence (sentence_b random)\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(bag[index])\n",
    "            label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3ba93ee8-d1a0-49ba-a72b-e0f8f4b74f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 317, 317)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_a), len(sentence_b), len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1e20518f-1aff-4b1c-96eb-3981e0f3b21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I observed that everybody believed that he thought as he spoke, and that in all that he did he never had any bad intention; and he never showed amazement and surprise, and was never in a hurry, and never put off doing a thing, nor was perplexed nor dejected, nor did he ever laugh to disguise his vexation, nor, on the other hand, was he ever passionate or suspicious\n",
      "---\n",
      " He was accustomed to do acts of beneficence, and was ready to forgive, and was free from all falsehood; and he presented the appearance of a man who could not be diverted from right rather than of a man who had been improved\n",
      "---\n",
      "0\n",
      "////////////////////\n",
      " There was in him nothing harsh, nor implacable, nor violent, nor, as one may say, anything carried to the sweating point; but he examined all things severally, as if he had abundance of time, and without confusion, in an orderly way, vigorously and consistently\n",
      "---\n",
      " But this is altogether a mark of the most common sort of men, for it is in thy power whenever thou shalt choose to retire into thyself\n",
      "---\n",
      "1\n",
      "////////////////////\n",
      " Further, I am thankful to the gods that I was not longer brought up with my grandfather's concubine, and that I preserved the flower of my youth, and that I did not make proof of my virility before the proper season, but even deferred the time; that I was subjected to a ruler and a father who was able to take away all pride from me, and to bring me to the knowledge that it is possible for a man to live in a palace without wanting either guards or embroidered dresses, or torches and statues, and such-like show; but that it is in such a man's power to bring himself very near to the fashion of a private person, without being for this reason either meaner in thought, or more remiss in action, with respect to the things which must be done for the public interest in a manner that befits a ruler\n",
      "---\n",
      " I thank the gods for giving me such a brother, who was able by his moral character to rouse me to vigilance over myself, and who, at the same time, pleased me by his respect and affection; that my children have not been stupid nor deformed in body; that I did not make more proficiency in rhetoric, poetry, and the other studies, in which I should perhaps have been completely engaged, if I had seen that I was making progress in them; that I made haste to place those who brought me up in the station of honour, which they seemed to desire, without putting them off with hope of my doing it some time after, because they were then still young; that I knew Apollonius, Rusticus, Maximus; that I received clear and frequent impressions about living according to nature, and what kind of a life that is, so that, so far as depended on the gods, and their gifts, and help, and inspirations, nothing hindered me from forthwith living according to nature, though I still fall short of it through my own fault, and through not observing the admonitions of the gods, and, I may almost say, their direct instructions; that my body has held out so long in such a kind of life; that I never touched either Benedicta or Theodotus, and that, after having fallen into amatory passions, I was cured; and, though I was often out of humour with Rusticus, I never did anything of which I had occasion to repent; that, though it was my mother's fate to die young, she spent the last years of her life with me; that, whenever I wished to help any man in his need, or on any other occasion, I was never told that I had not the means of doing it; and that to myself the same necessity never happened, to receive anything from another; that I have such a wife, so obedient, and so affectionate, and so simple; that I had abundance of good masters for my children; and that remedies have been shown to me by dreams, both others, and against bloodspitting and giddiness\n",
      "---\n",
      "0\n",
      "////////////////////\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(sentence_a[i] + '\\n---')\n",
    "    print(sentence_b[i] + '\\n---')\n",
    "    print(label[i])\n",
    "    print('////////////////////')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a899ac3-0fcf-4f01-ba95-c1db425a17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now tokenize our data. As is typical with BERT models, we truncate/pad our sequences to a length of 512 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2c7e35de-9d61-406b-abe1-96767370fd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', #PyTorch tensors\n",
    "                   max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2627b0f9-563f-4529-be20-94111fb05292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "85a6d71a-f63b-479a-bafa-521fadb1557b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  5159,  ...,     0,     0,     0],\n",
       "        [  101,  2045,  2001,  ...,     0,     0,     0],\n",
       "        [  101,  2582,  1010,  ...,  2402,  1010,   102],\n",
       "        ...,\n",
       "        [  101,  3459,  2185,  ...,     0,     0,     0],\n",
       "        [  101,  2043, 15223,  ...,     0,     0,     0],\n",
       "        [  101,  7887,  3288,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    " Because we tokenized two sentences, our tokenizer automatically applied 0 values to sentence A and 1 values to sentence B in the token_type_ids tensor\n",
    " In the input_ids tensor, the tokenizer automatically placed a SEP token (102) between these two sentences — marking the boundary between them both.\n",
    "'''\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d7f03626-bede-48b3-9cf2-57a8995c5eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our NSP labels must be placed within a tensor called next_sentence_label\n",
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T\n",
    "inputs.next_sentence_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ce0b4d16-b7d6-45fa-927c-9bd812f11ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  5159,  ...,     0,     0,     0],\n",
       "         [  101,  2045,  2001,  ...,     0,     0,     0],\n",
       "         [  101,  2582,  1010,  ...,  2402,  1010,   102],\n",
       "         ...,\n",
       "         [  101,  1998, 15223,  ...,     0,     0,     0],\n",
       "         [  101,  2296,  2158,  ...,     0,     0,     0],\n",
       "         [  101,  2021,  2059,  ...,     0,     0,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'next_sentence_label': tensor([[0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]])}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0c1d9e29-445d-4fbe-a960-f2bbf33cb195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For MLM we need to clone our current input_ids tensor to create a MLM labels tensor — then we move onto masking ~15% of tokens in the input_ids tensor.\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0713023a-04e9-4105-87da-ff97e42ad306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045, 5159,  ...,    0,    0,    0],\n",
       "         [ 101, 2045, 2001,  ...,    0,    0,    0],\n",
       "         [ 101, 2582, 1010,  ..., 2402, 1010,  102],\n",
       "         [ 101, 4088, 1996,  ...,    0,    0,    0],\n",
       "         [ 101, 2156, 1996,  ...,    0,    0,    0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'next_sentence_label': tensor([[0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]),\n",
       " 'labels': tensor([[ 101, 1045, 5159,  ...,    0,    0,    0],\n",
       "         [ 101, 2045, 2001,  ...,    0,    0,    0],\n",
       "         [ 101, 2582, 1010,  ..., 2402, 1010,  102],\n",
       "         [ 101, 4088, 1996,  ...,    0,    0,    0],\n",
       "         [ 101, 2156, 1996,  ...,    0,    0,    0]])}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7b8b5ec1-6b7b-447a-830f-3f1b4fe95a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7189, 0.8634, 0.1762,  ..., 0.8440, 0.0596, 0.7085],\n",
       "        [0.4003, 0.0113, 0.5288,  ..., 0.5583, 0.0384, 0.9262],\n",
       "        [0.3399, 0.5835, 0.7057,  ..., 0.2381, 0.4659, 0.6749],\n",
       "        ...,\n",
       "        [0.4027, 0.5887, 0.5198,  ..., 0.6664, 0.5911, 0.7619],\n",
       "        [0.0421, 0.7242, 0.0786,  ..., 0.8145, 0.8941, 0.3929],\n",
       "        [0.7927, 0.1855, 0.8645,  ..., 0.7465, 0.0325, 0.3125]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cdf0b2fc-5c7b-48b4-ab6a-e997a36d3502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([317, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False,  True, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False,  True,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mask array\n",
    "# we are ensuring that we don’t mask any special tokens — such as CLS (101), SEP (102), and PAD (0) tokens.\n",
    "\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "print(mask_arr.shape)\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eace7bca-ed24-451d-92c3-60ea16206872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([317, 512])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The inputs.input_ids is a 2D tensor that contains the tokenized versions of your input sentences. Each row corresponds to a sentence, and each column corresponds to a token in that sentence.\n",
    "\n",
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8e92d966-ea2e-4905-8ddc-612379f218a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  4],\n",
       "        [  9],\n",
       "        [ 18],\n",
       "        [ 22],\n",
       "        [ 28],\n",
       "        [ 35],\n",
       "        [ 45],\n",
       "        [ 48],\n",
       "        [ 51],\n",
       "        [ 57],\n",
       "        [ 59],\n",
       "        [ 60],\n",
       "        [ 61],\n",
       "        [ 62],\n",
       "        [ 75],\n",
       "        [ 82],\n",
       "        [ 84],\n",
       "        [ 89],\n",
       "        [ 95],\n",
       "        [109],\n",
       "        [119],\n",
       "        [121],\n",
       "        [123],\n",
       "        [126],\n",
       "        [127],\n",
       "        [138],\n",
       "        [143],\n",
       "        [167],\n",
       "        [176],\n",
       "        [190],\n",
       "        [191],\n",
       "        [192],\n",
       "        [205],\n",
       "        [221],\n",
       "        [226],\n",
       "        [230],\n",
       "        [232],\n",
       "        [241],\n",
       "        [243],\n",
       "        [246],\n",
       "        [248],\n",
       "        [260],\n",
       "        [262],\n",
       "        [276],\n",
       "        [283],\n",
       "        [286],\n",
       "        [288],\n",
       "        [301],\n",
       "        [317],\n",
       "        [318],\n",
       "        [319],\n",
       "        [327],\n",
       "        [328],\n",
       "        [329],\n",
       "        [344],\n",
       "        [347],\n",
       "        [354],\n",
       "        [355],\n",
       "        [356],\n",
       "        [366],\n",
       "        [373],\n",
       "        [374],\n",
       "        [383],\n",
       "        [392],\n",
       "        [393],\n",
       "        [394],\n",
       "        [396],\n",
       "        [397],\n",
       "        [400],\n",
       "        [402],\n",
       "        [403],\n",
       "        [431],\n",
       "        [436],\n",
       "        [438],\n",
       "        [441],\n",
       "        [445],\n",
       "        [446],\n",
       "        [448],\n",
       "        [465],\n",
       "        [466],\n",
       "        [493],\n",
       "        [499]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(mask_arr[0].nonzero()))\n",
    "mask_arr[2].nonzero() # non zero == true == masked indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "17413b8f-65a9-43a9-8ba2-1228d2416de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4,   9,  18,  22,  28,  35,  45,  48,  51,  57,  59,  60,  61,  62,\n",
       "         75,  82,  84,  89,  95, 109, 119, 121, 123, 126, 127, 138, 143, 167,\n",
       "        176, 190, 191, 192, 205, 221, 226, 230, 232, 241, 243, 246, 248, 260,\n",
       "        262, 276, 283, 286, 288, 301, 317, 318, 319, 327, 328, 329, 344, 347,\n",
       "        354, 355, 356, 366, 373, 374, 383, 392, 393, 394, 396, 397, 400, 402,\n",
       "        403, 431, 436, 438, 441, 445, 446, 448, 465, 466, 493, 499])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(mask_arr[2].nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a638ce2a-851a-4084-a06f-f2d5641de7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4, 9, 18, 22, 28, 35, 45, 48, 51, 57]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now take the indices of each True value within each vector.\n",
    "# Flattening the tensor with torch.flatten() turns it into a 1D tensor, and then .tolist() converts this tensor to a Python list.\n",
    "\n",
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )\n",
    "    \n",
    "print(len(selection))\n",
    "selection[2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "77021694-8153-4ae0-a861-36290231f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then apply these indices to each row in input_ids, assigning each value at these indices a value of 103.\n",
    "# The number 103 corresponds to the special [MASK] token in BERT and some other transformer-based models. \n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d92dfe17-2ad8-43bb-a45b-c70b8931fba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2d97ff7f-2b9b-4424-bff1-1f764fee34a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  2582,  1010,  1045,   103, 18836,  2000,  1996,  5932,   103,\n",
       "         1045,  2001,  2025,  2936,  2716,  2039,  2007,  2026,   103,  1005,\n",
       "         1055,  9530,   103, 16765,  1010,  1998,  2008,  1045,   103,  1996,\n",
       "         6546,  1997,  2026,  3360,  1010,   103,  2008,  1045,  2106,  2025,\n",
       "         2191,  6947,  1997,  2026,  6819,   103,  3012,  2077,   103,  5372,\n",
       "         2161,   103,  2021,  2130, 13366, 28849,  2094,   103,  2051,   103,\n",
       "          103,   103,   103, 13532,  2000,  1037,  7786,  1998,  1037,  2269,\n",
       "         2040,  2001,  2583,  2000,  2202,   103,  2035,  6620,  2013,  2033,\n",
       "         1010,  1998,   103,  3288,   103,  2000,  1996,  3716,  2008,   103,\n",
       "         2003,  2825,  2005,  1037,  2158,   103,  2444,  1999,  1037,  4186,\n",
       "         2302,  5782,  2593,  4932,  2030, 23590, 14464,  1010,  2030,   103,\n",
       "         1998, 11342,  1010,  1998,  2107,  1011,  2066,  2265,  1025,   103,\n",
       "         2008,   103,  2003,   103,  2107,  1037,   103,   103,  1055,  2373,\n",
       "         2000,  3288,  2370,  2200,  2379,  2000,  1996,  4827,   103,  1037,\n",
       "         2797,  2711,  1010,   103,  2108,  2005,  2023,  3114,  2593,  2812,\n",
       "         2121,  1999,  2245,  1010,  2030,  2062,  2128, 15630,  2015,  1999,\n",
       "         2895,  1010,  2007,  4847,  2000,  1996,  2477,   103,  2442,  2022,\n",
       "         2589,  2005,  1996,  2270,  3037,  1999,   103,  5450,  2008,  2022,\n",
       "         8873,  3215,  1037,  7786,   102,  1045,  4067,  1996,  5932,  2005,\n",
       "          103,   103,   103,  1037,  2567,  1010,  2040,  2001,  2583,  2011,\n",
       "         2010,  7191,  2839,  2000, 27384,   103,  2000,  6819, 20142,  6651,\n",
       "         2058,  2870,  1010,  1998,  2040,  1010,  2012,  1996,  2168,  2051,\n",
       "         1010,   103,  2033,  2011,  2010,  4847,   103, 12242,  1025,  2008,\n",
       "          103,  2336,   103,  2025,  2042,  5236,  4496, 13366,  2953,  7583,\n",
       "         1999,   103,  1025,   103,  1045,  2106,   103,  2191,   103, 26293,\n",
       "         1999, 17871,  1010,  4623,  1010,  1998,  1996,  2060,  2913,  1010,\n",
       "          103,  2029,   103,  2323,  3383,  2031,  2042,  3294,  5117,  1010,\n",
       "         2065,  1045,  2018,  2464,  2008,  1045,   103,  2437,  5082,  1999,\n",
       "         2068,  1025,  2008,   103,  2081, 24748,   103,  2173,   103,  2040,\n",
       "         2716,  2033,  2039,  1999,  1996,  2276,  1997,  6225,  1010,  2029,\n",
       "         2027,   103,  2000,  4792,  1010,  2302,  5128,  2068,  2125,  2007,\n",
       "         3246,  1997,  2026,  2725,  2009,  2070,  2051,   103,   103,   103,\n",
       "         2027,  2020,  2059,  2145,  2402,  1025,  2008,   103,   103,   103,\n",
       "        20447,  1010, 27471,  2271,  1010, 21692,  1025,  2008,  1045,  2363,\n",
       "         3154,  1998,  6976, 19221,   103,  2542,  2429,   103,  3267,  1010,\n",
       "         1998,  2054,  2785,  1997,   103,   103,   103,  2003,  1010,  2061,\n",
       "         2008,  1010,  2061,  2521,  2004, 17292,   103,  1996,  5932,  1010,\n",
       "         1998,  2037,  9604,   103,   103,  2393,  1010,  1998,  7780,  2015,\n",
       "         1010,  2498, 17666,   103,  2033,  2013,  5743, 24415,  2542,  2429,\n",
       "         2000,  3267,   103,   103,   103,  2145,   103,   103,  1997,  2009,\n",
       "          103,  2026,   103,   103,  1010,  1998,  2083,  2025, 14158,  1996,\n",
       "         4748,  8202, 22753,  2015,  1997,  1996,  5932,  1010,  1998,  1010,\n",
       "         1045,  2089,  2471,  2360,  1010,  2037,  3622,  8128,  1025,  2008,\n",
       "         2026,   103,  2038,  2218,  2041,  2061,   103,  1999,   103,  1037,\n",
       "         2785,   103,  2166,  1025,  2008,   103,   103,  5028,   103, 12122,\n",
       "         2050,  2030, 14833, 27364,  2271,  1010,  1998,  2008,  1010,  2044,\n",
       "         2383,  5357,  2046, 25933,  7062,   103,   103,  1045,  2001, 21391,\n",
       "         1025,  1998,  1010,  2295,  1045,  2001,  2411,  2041,  1997, 17211,\n",
       "         2007, 27471,  2271,  1010,  1045,  2196,  2106,  2505,  1997,  2029,\n",
       "         1045,  2018,  6686,   103, 16360,  4765,  1025,  2008,  1010,   103,\n",
       "         2009,  2001,  2026,  2388,  1005,  1055,  6580,  2000,  3280,  2402,\n",
       "         1010,   102])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63da170c-a3b8-4ffa-b6c5-32cf8f17e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDataloader\\nAll of our input and label tensors are ready — all we need to do now is format them into a PyTorch dataset object so that it can be loaded into a PyTorch Dataloader — which will feed batches of data into our model during training.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Dataloader\n",
    "All of our input and label tensors are ready — all we need to do now is format them into a PyTorch dataset object so that it can be loaded into a PyTorch Dataloader — which will feed batches of data into our model during training.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bf020934-2187-4c86-8946-7a38fb15d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a PyTorch dataset from our data.\n",
    "\n",
    "'''\n",
    "This is a custom PyTorch Dataset class named OurDataset. It’s designed to handle the encodings (or preprocessed input data) for a language model like BERT. Here’s a brief explanation of its methods:\n",
    "\n",
    "__init__(self, encodings): This is the initializer method that’s called when you create a new instance of OurDataset. It takes one argument, encodings, which should be a dictionary containing the preprocessed input data. This dictionary is stored in the instance variable self.encodings.\n",
    "\n",
    "__getitem__(self, idx): This method is used to get the item at a specific index, idx. It returns a dictionary where each value is a tensor containing the data for one input feature (like input IDs, attention mask, etc.) at the given index. This method is called when you access an item in the dataset like this: dataset[i].\n",
    "\n",
    "__len__(self): This method returns the number of items in the dataset. It’s implemented by returning the length of the input_ids in self.encodings, assuming that all input features have the same length. This method is called when you use the len() function on the dataset: len(dataset).\n",
    "\n",
    "This class allows PyTorch to handle the dataset in a way that’s optimized for machine learning tasks. You can use it with a DataLoader to easily generate batches of data for training or evaluation.\n",
    "'''\n",
    "\n",
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eba12134-4216-44a5-852e-5cb68e1d72f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7a422e06-30d3-4001-b371-c03b4ffd01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our data using the OurDataset class.\n",
    "\n",
    "dataset = OurDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd858890-ffc9-4bb5-aae7-ead150f30440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif you have a simple use case and don’t want to create a custom subclass, you might consider using torch.utils.data.TensorDataset. This is a utility class that wraps tensors into a dataset. For example, if inputs is a tensor of input features and labels is a tensor of labels, you can create a dataset like this:\\n\\ndataset = torch.utils.data.TensorDataset(inputs, labels)\\n\\nIn the custom case above, the dataloader expects the __len__ method for checking the total number of samples within our dataset, and the __getitem__ method for extracting samples.\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if you have a simple use case and don’t want to create a custom subclass, you might consider using torch.utils.data.TensorDataset. This is a utility class that wraps tensors into a dataset. For example, if inputs is a tensor of input features and labels is a tensor of labels, you can create a dataset like this:\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(inputs, labels)\n",
    "\n",
    "In the custom case above, the dataloader expects the __len__ method for checking the total number of samples within our dataset, and the __getitem__ method for extracting samples.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "15b478a7-08da-4aff-a96f-91b23b62416d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "380d6aa3-5e05-4841-b5de-6a493df994f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5a041221-aa67-4328-a87f-767cd9101cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up GPU memory: Make sure you’re freeing up GPU memory whenever possible. You can do this by calling torch.cuda.empty_cache() to release cache that PyTorch is holding onto.\n",
    "\n",
    "torch.cuda.empty_cache() # batch size reduced as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b4b5a334-108e-411c-bd28-d45e471703ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/40 [00:00<?, ?it/s]C:\\Users\\Alienware\\AppData\\Local\\Temp\\ipykernel_25736\\264689798.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0:   2%|█▌                                                             | 1/40 [00:09<06:20,  9.76s/it, loss=7.82]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[1996, 1996, 1996,  ..., 1996, 1996, 1996],\n",
      "        [1996, 1996, 1996,  ..., 1996, 1996, 1996],\n",
      "        [1996, 1996, 1996,  ..., 1996, 1996, 1996],\n",
      "        ...,\n",
      "        [1996, 1996, 1996,  ..., 1996, 1996, 1996],\n",
      "        [1996, 1996, 1996,  ..., 1996, 1996, 1996],\n",
      "        [1996, 1996, 1996,  ..., 1996, 1996, 1996]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 7.815109729766846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   5%|███▏                                                           | 2/40 [00:16<05:11,  8.21s/it, loss=15.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[18738, 18738, 18738,  ..., 18738, 18738, 18738],\n",
      "        [18738, 18738, 18738,  ..., 18738, 18738, 18738],\n",
      "        [18738, 18738, 18738,  ..., 18738, 18738, 18738],\n",
      "        ...,\n",
      "        [18738, 18738, 18738,  ..., 18738, 18738, 18738],\n",
      "        [18738, 18738, 18738,  ..., 18738, 18738, 18738],\n",
      "        [18738, 18738, 18738,  ..., 18738, 18738, 18738]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 15.434216499328613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   8%|████▋                                                          | 3/40 [00:23<04:44,  7.70s/it, loss=2.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.667572021484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|██████▎                                                        | 4/40 [00:31<04:29,  7.48s/it, loss=2.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.425849437713623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  12%|███████▉                                                       | 5/40 [00:38<04:18,  7.39s/it, loss=2.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.3294835090637207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  15%|█████████▍                                                     | 6/40 [00:45<04:09,  7.35s/it, loss=2.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.92909574508667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18%|███████████                                                    | 7/40 [00:53<04:03,  7.38s/it, loss=2.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.633181571960449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  20%|████████████▌                                                  | 8/40 [01:00<03:54,  7.34s/it, loss=2.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.2549805641174316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  22%|██████████████▍                                                 | 9/40 [01:07<03:46,  7.32s/it, loss=2.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.800774574279785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  25%|███████████████▌                                              | 10/40 [01:14<03:38,  7.28s/it, loss=3.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 3.7215635776519775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  28%|█████████████████                                             | 11/40 [01:22<03:31,  7.28s/it, loss=2.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.7436749935150146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  30%|██████████████████▌                                           | 12/40 [01:29<03:22,  7.25s/it, loss=1.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 1.9624648094177246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  32%|████████████████████▏                                         | 13/40 [01:36<03:15,  7.22s/it, loss=2.85]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.8547191619873047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  35%|█████████████████████▋                                        | 14/40 [01:43<03:07,  7.21s/it, loss=2.65]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.6545639038085938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  38%|███████████████████████▎                                      | 15/40 [01:50<02:59,  7.20s/it, loss=2.45]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.4531941413879395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  40%|████████████████████████▊                                     | 16/40 [01:58<02:53,  7.23s/it, loss=2.88]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.8757522106170654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  42%|██████████████████████████▊                                    | 17/40 [02:05<02:45,  7.21s/it, loss=4.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 4.400176048278809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  45%|███████████████████████████▉                                  | 18/40 [02:12<02:38,  7.20s/it, loss=2.98]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.9819884300231934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  48%|█████████████████████████████▍                                | 19/40 [02:19<02:30,  7.19s/it, loss=2.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.259904146194458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|███████████████████████████████                               | 20/40 [02:26<02:24,  7.22s/it, loss=2.19]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.1859617233276367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  52%|████████████████████████████████▌                             | 21/40 [02:34<02:19,  7.33s/it, loss=2.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.2663822174072266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  55%|██████████████████████████████████                            | 22/40 [02:42<02:13,  7.43s/it, loss=2.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.722405433654785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  57%|███████████████████████████████████▋                          | 23/40 [02:49<02:05,  7.41s/it, loss=2.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.339925765991211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  60%|█████████████████████████████████████▏                        | 24/40 [02:56<01:58,  7.40s/it, loss=2.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.305657386779785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  62%|██████████████████████████████████████▊                       | 25/40 [03:04<01:50,  7.35s/it, loss=2.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.7423248291015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  65%|████████████████████████████████████████▎                     | 26/40 [03:11<01:42,  7.30s/it, loss=2.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.0201072692871094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  68%|█████████████████████████████████████████▊                    | 27/40 [03:18<01:34,  7.27s/it, loss=1.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 1.9632925987243652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70%|███████████████████████████████████████████▍                  | 28/40 [03:25<01:26,  7.24s/it, loss=2.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.333892822265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  72%|█████████████████████████████████████████████▋                 | 29/40 [03:32<01:19,  7.22s/it, loss=1.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 1.8013050556182861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  75%|██████████████████████████████████████████████▌               | 30/40 [03:39<01:12,  7.20s/it, loss=2.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.1063594818115234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|████████████████████████████████████████████████              | 31/40 [03:47<01:04,  7.19s/it, loss=2.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.061734199523926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|█████████████████████████████████████████████████▌            | 32/40 [03:54<00:57,  7.21s/it, loss=1.98]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 1.976759433746338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  82%|███████████████████████████████████████████████████▏          | 33/40 [04:01<00:50,  7.19s/it, loss=2.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.9387779235839844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|████████████████████████████████████████████████████▋         | 34/40 [04:08<00:43,  7.20s/it, loss=2.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.2708487510681152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  88%|██████████████████████████████████████████████████████▎       | 35/40 [04:16<00:36,  7.23s/it, loss=2.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.6831271648406982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90%|███████████████████████████████████████████████████████▊      | 36/40 [04:23<00:28,  7.22s/it, loss=2.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 2.038661003112793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  92%|█████████████████████████████████████████████████████████▎    | 37/40 [04:30<00:21,  7.20s/it, loss=2.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 2.0434813499450684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  95%|██████████████████████████████████████████████████████████▉   | 38/40 [04:37<00:14,  7.20s/it, loss=1.86]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 1.857365369796753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  98%|████████████████████████████████████████████████████████████▍ | 39/40 [04:44<00:07,  7.18s/it, loss=1.99]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "Loss: 1.9866505861282349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████| 40/40 [04:52<00:00,  7.31s/it, loss=1.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Predictions: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "NSP Predictions: tensor([0, 0, 0, 0, 0], device='cuda:0')\n",
      "Real Labels (NSP): tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Loss: 1.6349890232086182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # for our progress bar\n",
    "import torch.optim as optim\n",
    "\n",
    "# And initialize the dataloader, which we'll be using to load our data into the model during training.\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop: # The inner loop iterates over the DataLoader object (loader), which yields batches of data.\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optimizer.zero_grad() # For each batch, it first zeros out any previously calculated gradients.\n",
    "        # pull all tensor batches required for training\n",
    "        # It then moves all the tensor batches to the device where the computations will be performed (usually a GPU if available).\n",
    "        input_ids = batch['input_ids'].to(device) # original sentence with some token masked\n",
    "        token_type_ids = batch['token_type_ids'].to(device) # 0:tokens in sentence_a , 1:tokens in sentence_b\n",
    "        attention_mask = batch['attention_mask'].to(device) # 1:real tokens , 0:padding tokens\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device) # 0:consecutive sentence , 1:random sentence\n",
    "        labels = batch['labels'].to(device) # clone of input_ids: contains the correct labels (words) that were masked. Helps the model learn to predict masked tokens.\n",
    "        # process\n",
    "        # Forward Pass: The model processes the inputs and returns the training outputs (the evaluation outputs are in the next section)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids, \n",
    "                        next_sentence_label=next_sentence_label, \n",
    "                        labels=labels)\n",
    "        # extract loss from the outputs\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update (backward propagation)\n",
    "        loss.backward()\n",
    "        # update parameters, based on the calculated gradients\n",
    "        optimizer.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        # Extract MLM predictions at training\n",
    "\n",
    "        prediction_logits = outputs.prediction_logits\n",
    "        mlm_predictions = torch.argmax(prediction_logits, dim=-1)\n",
    "\n",
    "        # Extract NSP predictions\n",
    "        seq_relationship_logits = outputs.seq_relationship_logits\n",
    "        nsp_predictions = torch.argmax(seq_relationship_logits, dim=1)\n",
    "\n",
    "        print(f\"MLM Predictions: {mlm_predictions}\")\n",
    "        print(f\"NSP Predictions: {nsp_predictions}\")\n",
    "        print(f\"Real Labels (NSP): {next_sentence_label}\")\n",
    "        print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f8005b7b-b324-4416-9810-ebb184f80144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence A: 'The sun is shining.'\n",
      "Sentence B: 'It's a beautiful day.'\n",
      "Predicted Next Sentence Label: 0\n",
      "\n",
      "Sentence A: 'Random text here.'\n",
      "Sentence B: 'More random text.'\n",
      "Predicted Next Sentence Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = BertForPreTraining.from_pretrained('path_to_save_trained_model')\n",
    "model.eval()\n",
    "\n",
    "# Prepare your test data\n",
    "test_sentences = [\n",
    "    (\"The sun is shining.\", \"It's a beautiful day.\"),\n",
    "    (\"Random text here.\", \"More random text.\")\n",
    "]\n",
    "\n",
    "for sentence_a, sentence_b in test_sentences:\n",
    "    encoding = tokenizer(sentence_a, sentence_b, return_tensors='pt', max_length=128, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    token_type_ids = encoding['token_type_ids'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "    \n",
    "    seq_relationship_logits = outputs.seq_relationship_logits\n",
    "    predicted_next_sentence_label = torch.argmax(seq_relationship_logits, dim=1)\n",
    "    print(f\"Sentence A: '{sentence_a}'\")\n",
    "    print(f\"Sentence B: '{sentence_b}'\")\n",
    "    print(\"Predicted Next Sentence Label:\", predicted_next_sentence_label.item())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ac719c-8546-4709-b225-00cbc243ef84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ae44e-7d74-4a5c-8f1e-97a6e173901c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
