{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Work with environments\n",
    "\n",
    "\n",
    "When you run a script as an Azure Machine Learning job, you need to define the execution context for the job run. One key configuration is the compute target on which the script will be run. This could be the local workstation (in this case the compute instance), or a remote compute target such as the Azure Machine Learning managed compute cluster that is provisioned on-demand.\n",
    "\n",
    "In this notebook, you'll create a compute cluster and explore compute targets for jobs.\n",
    "\n",
    "## Before you start\n",
    "\n",
    "You'll need the latest version of the  **azure-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
    "\n",
    "> **Note**:\n",
    "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1665745893251
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azure-ai-ml\n",
      "Version: 1.22.4\n",
      "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
      "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
      "Author: Microsoft Corporation\n",
      "Author-email: azuresdkengsysadmins@microsoft.com\n",
      "License: MIT License\n",
      "Location: c:\\users\\alienware\\miniconda3\\envs\\py310\\lib\\site-packages\n",
      "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, opencensus-ext-logging, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\alienware\\miniconda3\\envs\\py310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip show azure-ai-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "\n",
    "# Load environment variables from config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Use an absolute path to avoid path issues\n",
    "config_file_path = \"G:/My Drive/Ingegneria/Data Science GD/My-Practice/my models/Azure ML/config.ini\"\n",
    "config.read(config_file_path)\n",
    "\n",
    "# all following IDs to be retrieved, to login correctly\n",
    "os.environ['AZURE_CLIENT_ID'] = config['azure']['client_id']\n",
    "os.environ['AZURE_CLIENT_SECRET'] = config['azure']['client_secret']\n",
    "os.environ['AZURE_TENANT_ID'] = config['azure']['tenant_id']\n",
    "os.environ['AZURE_SUBSCRIPTION_ID'] = config['azure']['subscription_id']\n",
    "os.environ['AZURE_STORAGE_KEY'] = config['azure']['storage_key']\n",
    "\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "# Initialize MLClient with the obtained credential\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=os.environ['AZURE_SUBSCRIPTION_ID'],\n",
    "    resource_group_name=\"rg-dp100-labs\",\n",
    "    workspace_name=\"mlw-dp100-labs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a script as a job\n",
    "\n",
    "To train a model, you'll first create the **diabetes_training.py** script in the **src** folder. The script uses the **diabetes.csv** file in the same folder as the training data.\n",
    "\n",
    "Note that you import libraries at the beginning of the script. Functions from these libraries are used to process the data and train the model. Whatever compute you use to run the script must have these libraries installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/diabetes-training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/diabetes-training.py\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you create the script, you can run the script as a job. The script uses common libraries. So you can use a curated environment that includes pandas, numpy, and scikit-learn, among others.\n",
    "\n",
    "The job uses the latest version of the curated environment: `AzureML-sklearn-0.24-ubuntu18.04-py37-cpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/zen_cup_mw8zwptm5b?wsid=/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=8bfc37bf-8e21-4420-841d-49303c72ec1a\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\", # Specifies the directory containing your source code files.\n",
    "    command=\"python diabetes-training.py\", # Defines the command to be executed when the job runs\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\", # Specifies the environment in which the job will run, including all dependencies and configurations (curated environment from Azure ML that includes scikit-learn 0.24, Ubuntu 18.04, Python 3.7, and CPU support)\n",
    "    compute=\"aml-cluster\", # Identifies the compute target where the job will be executed.\n",
    "    display_name=\"diabetes-train-curated-env\", # Provides a human-readable name for the job.\n",
    "    experiment_name=\"diabetes-training\" # This groups the job under the diabetes-training experiment, allowing you to organize and track related jobs (any name can be used)\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the job is running, you can already run the next cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List environments\n",
    "\n",
    "Let's explore the environments within the workspace. \n",
    "\n",
    "In the previous job, you used one of the curated environments. To explore all environments that already exist in the workspace, you can list the environments: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\n"
     ]
    }
   ],
   "source": [
    "envs = ml_client.environments.list()\n",
    "for env in envs:\n",
    "    print(env.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all curated environments have names that begin **AzureML-** (you can't use this prefix for your own environments).\n",
    "\n",
    "To review a specific environment, you can retrieve an environment by its name and version. For example, you can retrieve the *description* and *tags* of the curated environment you used for the previous job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An environment for tasks such as regression, clustering, and classification with Scikit-learn. Contains the Azure ML SDK and additional python packages. {'Scikit-learn': '0.24.1', 'OS': 'Ubuntu18.04', 'Training': ''}\n"
     ]
    }
   ],
   "source": [
    "env = ml_client.environments.get(\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\", version=44)\n",
    "print(env. description, env.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and use a custom environment\n",
    "\n",
    "If a curated environment doesn't include all the Python packages you need to run your script, you can create your own custom environment. By listing all necessary packages in an environment, you can easily re-run your scripts. All the dependencies are stored in the environment which you can then specify in the job configuration, independent of the compute you use.\n",
    "\n",
    "For example, you can create an environment simply from a Docker image. Certain frameworks like PyTorch will have a public Docker image that already includes everything you need. \n",
    "\n",
    "Let's create an environment from a Docker image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'docker-image-example', 'description': 'Environment created from a Docker image.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs/environments/docker-image-example/versions/1', 'Resource__source_path': '', 'base_path': 'G:\\\\My Drive\\\\Ingegneria\\\\Data Science GD\\\\My-Practice\\\\my models\\\\Azure ML\\\\azure-ml-labs\\\\Labs\\\\04', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x00000285C3F932B0>, 'serialize': <msrest.serialization.Serializer object at 0x00000285C3F92CB0>, 'version': '1', 'conda_file': None, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_image = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    name=\"docker-image-example\",\n",
    "    description=\"Environment created from a Docker image.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is now registered in your workspace and you can reference it when you run a script as a job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/wheat_whistle_887dry6fnj?wsid=/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=8bfc37bf-8e21-4420-841d-49303c72ec1a\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python diabetes-training.py\",\n",
    "    environment=\"docker-image-example:1\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-custom-env\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> The job will quickly fail! Review the error message. </p>\n",
    "\n",
    "The error message will tell you that there is no module named pandas. There are two possible causes for such an error:\n",
    "\n",
    "- The script uses pandas but didn't import the library (`import pandas as pd`). \n",
    "- The script does import the library at the top of the script but the compute didn't have the library installed (`pip install pandas`).\n",
    "\n",
    "After reviewing the `diabetes-training.py` script you can observe the script is correct, which means the library wasn't installed. In other words, the environment didn't include the necessary packages.\n",
    "\n",
    "Let's create a new environment, using the base Docker image used in the previous job. Now, you'll add a conda specification to ensure the necessary packages will be installed. First, run the following cell to create the conda specification file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/conda-env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/conda-env.yml\n",
    "name: basic-env-cpu\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.11\n",
    "  - scikit-learn\n",
    "  - pandas\n",
    "  - numpy\n",
    "  - matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all necessary dependencies are included in the conda specification file for the script to run successfully.\n",
    "\n",
    "Create a new environment using the base Docker image **and** the conda specification file to add the necessary dependencies. Azure Machine Learning will build the conda environment on top of the Docker image you provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'docker-image-plus-conda-example', 'description': 'Environment created from a Docker image plus Conda environment.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs/environments/docker-image-plus-conda-example/versions/1', 'Resource__source_path': '', 'base_path': 'G:\\\\My Drive\\\\Ingegneria\\\\Data Science GD\\\\My-Practice\\\\my models\\\\Azure ML\\\\azure-ml-labs\\\\Labs\\\\04', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x00000285C38BB0D0>, 'serialize': <msrest.serialization.Serializer object at 0x00000285C3F134C0>, 'version': '1', 'conda_file': {'channels': ['conda-forge'], 'dependencies': ['python=3.11', 'scikit-learn', 'pandas', 'numpy', 'matplotlib'], 'name': 'basic-env-cpu'}, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"conda-forge\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.11\",\\n    \"scikit-learn\",\\n    \"pandas\",\\n    \"numpy\",\\n    \"matplotlib\"\\n  ],\\n  \"name\": \"basic-env-cpu\"\\n}'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    conda_file=\"./src/conda-env.yml\",\n",
    "    name=\"docker-image-plus-conda-example\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can submit a job with the new environment to run the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading src (0.53 MBs): 100%|############################################| 529705/529705 [00:00<00:00, 843343.84it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/magenta_spring_lycgxh8y6p?wsid=/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=8bfc37bf-8e21-4420-841d-49303c72ec1a\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python diabetes-training.py\",\n",
    "    environment=\"docker-image-plus-conda-example:1\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-custom-env\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting the job with the new custom environment triggers the build of the environment. The first time you use a newly created environment, it can take 10-15 minutes to build the environment, which also means your job will take longer to complete. \n",
    "\n",
    "You can also choose to manually trigger the build of the environment before you submit a job. The environment only needs to be built the first time you use it. \n",
    "\n",
    "When the job triggers the build of a new environment, you can review the logs of the build in the **Outputs + logs** tab of the job. Open **azureml-logs/20_image_build_log.txt** to inspect the logs of the environment build. \n",
    "\n",
    "![Screenshot build logs](./images/screenshot-logs.png)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
