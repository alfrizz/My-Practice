{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log models with MLflow\n",
    "\n",
    "You can use MLflow in Azure Machine Learning to log models. When you log a model as a model instead of an artifact, a MLmodel is created in the output directory. The MLmodel file contains all the model's metadata. You can customize the model's signature when logging the model.\n",
    "\n",
    "## Before you start\n",
    "\n",
    "You'll need the latest version of the **azure-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
    "\n",
    "> **Note**:\n",
    "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azure-ai-ml\n",
      "Version: 1.22.4\n",
      "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
      "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
      "Author: Microsoft Corporation\n",
      "Author-email: azuresdkengsysadmins@microsoft.com\n",
      "License: MIT License\n",
      "Location: c:\\users\\alienware\\miniconda3\\envs\\py310\\lib\\site-packages\n",
      "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, opencensus-ext-logging, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\alienware\\miniconda3\\envs\\py310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip show azure-ai-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1663753569264
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "\n",
    "# Load environment variables from config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Use an absolute path to avoid path issues\n",
    "config_file_path = \"G:/My Drive/Ingegneria/Data Science GD/My-Practice/my models/Azure ML/config.ini\"\n",
    "config.read(config_file_path)\n",
    "\n",
    "# all following IDs to be retrieved, to login correctly\n",
    "os.environ['AZURE_CLIENT_ID'] = config['azure']['client_id']\n",
    "os.environ['AZURE_CLIENT_SECRET'] = config['azure']['client_secret']\n",
    "os.environ['AZURE_TENANT_ID'] = config['azure']['tenant_id']\n",
    "os.environ['AZURE_SUBSCRIPTION_ID'] = config['azure']['subscription_id']\n",
    "os.environ['AZURE_STORAGE_KEY'] = config['azure']['storage_key']\n",
    "\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "# Initialize MLClient with the obtained credential\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=os.environ['AZURE_SUBSCRIPTION_ID'],\n",
    "    resource_group_name=\"rg-dp100-labs\",\n",
    "    workspace_name=\"mlw-dp100-labs\"\n",
    ")\n",
    "# ml_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autologging with MLflow\n",
    "\n",
    "When you use autologging, your model is automatically logged. The model flavor and schema is inferred. \n",
    "\n",
    "Run the following cell to create the **train-model-autolog.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create a folder for the script files\n",
    "script_folder = 'src'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train-model-autolog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train-model-autolog.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main(args):\n",
    "    # enable autologging\n",
    "    mlflow.autolog()\n",
    "\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    eval_model(model, X_test, y_test)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can submit the script as a command job.\n",
    "\n",
    "Run the cell below to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading src (0.45 MBs): 100%|###########################################| 450294/450294 [00:00<00:00, 1104089.54it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/crimson_sponge_nddnh63m4v?wsid=/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=8bfc37bf-8e21-4420-841d-49303c72ec1a\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train-model-autolog.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-autolog\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Studio, navigate to the **diabetes-train-autolog** job to explore the overview of the command job you ran. Find the logged artifacts in the **Outputs + logs** tab. Select the `model` folder to find the `MLmodel` file and explore its contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the flavor with autologging\n",
    "\n",
    "You can use autologging, but still specify the flavor of the model. In the example, the model's flavor is scikit-learn.\n",
    "\n",
    "Run the following cell to create the **train-model-sklearn.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train-model-sklearn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train-model-sklearn.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main(args):\n",
    "    # enable autologging\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    eval_model(model, X_test, y_test)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    "\n",
    "    # calculate AUC\n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "    print('AUC: ' + str(auc))\n",
    "\n",
    "    # plot ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    # Plot the diagonal 50% line\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # Plot the FPR and TPR achieved by our model\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.savefig(\"ROC-Curve.png\") \n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can submit the script as a command job.\n",
    "\n",
    "Run the cell below to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading src (0.45 MBs): 100%|############################################| 453162/453162 [00:00<00:00, 904649.85it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/tender_machine_v4h8pfvx3g?wsid=/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=8bfc37bf-8e21-4420-841d-49303c72ec1a\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train-model-sklearn.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-sklearn\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Studio, navigate to the **diabetes-train-sklearn** job to explore the overview of the command job you ran. Find the logged artifacts in the **Outputs + logs** tab. Select the `model` folder to find the `MLmodel` file and explore its contents.\n",
    "\n",
    "Compare the `MLmodel` files of the previous two runs. You'll notice that they're the same, indicating that MLflow's autolog feature correctly inferred the model's flavor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize the model with an inferred signature\n",
    "\n",
    "You can manually log the model using `mlflow.sklearn.log_model` instead of autologging. You'll create a signature by inferring it from the training dataset and predicted results. And finally, you'll log the scikit-learn model.\n",
    "\n",
    "Run the following cell to create the **train-model-infer.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train-model-infer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train-model-infer.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature # The infer_signature function in MLflow is used to capture the input and output schema of a machine learning model. This schema helps validate that the model is being used correctly during deployment and ensures that the inputs to the model and the expected outputs are consistent with the data it was trained on\n",
    "\n",
    "def main(args):\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # evaluate model\n",
    "    y_hat = eval_model(model, X_test, y_test)\n",
    "\n",
    "    # create the signature by inferring it from the datasets\n",
    "    signature = infer_signature(X_train, y_hat)\n",
    "\n",
    "    # manually log the model\n",
    "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    " \n",
    "    return y_hat\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can submit the script as a command job.\n",
    "\n",
    "Run the cell below to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading src (0.46 MBs): 100%|############################################| 455758/455758 [00:00<00:00, 832933.96it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/jolly_chain_6d0jh46bl0?wsid=/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=8bfc37bf-8e21-4420-841d-49303c72ec1a\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train-model-infer.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-infer\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Studio, navigate to the **diabetes-train-infer** job to explore the overview of the command job you ran. Find the logged artifacts in the **Outputs + logs** tab. Select the `model` folder to find the `MLmodel` file and explore its contents.\n",
    "\n",
    "Compare the `MLmodel` files with the previous two runs. You'll notice that they're all the same, indicating that MLflow's autolog feature correctly inferred the model's signature too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize the model with a defined signature\n",
    "\n",
    "You can manually log the model using `mlflow.sklearn.log_model`. You'll also create a signature manually. And finally, you'll log the scikit-learn model.\n",
    "\n",
    "Run the following cell to create the **train-model-signature.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train-model-signature.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train-model-signature.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import ModelSignature # another way to create a model signature that explicitly defines the input and output schema. This is part of MLflow's functionality to help ensure that the model receives and outputs data in the expected format during deployment.\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "def main(args):\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # evaluate model\n",
    "    y_hat = eval_model(model, X_test, y_test)\n",
    "\n",
    "    # create the signature manually\n",
    "    input_schema = Schema([\n",
    "    ColSpec(\"integer\", \"Pregnancies\"),\n",
    "    ColSpec(\"integer\", \"PlasmaGlucose\"),\n",
    "    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n",
    "    ColSpec(\"integer\", \"TricepsThickness\"),\n",
    "    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n",
    "    ColSpec(\"integer\", \"SerumInsulin\"),\n",
    "    ColSpec(\"double\", \"BMI\"),\n",
    "    ColSpec(\"double\", \"DiabetesPedigree\"),\n",
    "    ColSpec(\"integer\", \"Age\"),\n",
    "    ])\n",
    "\n",
    "    output_schema = Schema([ColSpec(\"boolean\")])\n",
    "\n",
    "    # Create the signature object\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "    # manually log the model\n",
    "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    " \n",
    "    return y_hat\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can submit the script as a command job.\n",
    "\n",
    "Run the cell below to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading src (0.46 MBs): 100%|############################################| 458907/458907 [00:00<00:00, 826406.37it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/mighty_soca_b8vsfmldyr?wsid=/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=8bfc37bf-8e21-4420-841d-49303c72ec1a\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train-model-signature.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-signature\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Studio, navigate to the **diabetes-train-signature** job to explore the overview of the command job you ran. Find the logged artifacts in the **Outputs + logs** tab. Select the `model` folder to find the `MLmodel` file and explore its contents.\n",
    "\n",
    "Compare the `MLmodel` files with the previous runs. You'll notice that the signature is different from the previous runs. Previous runs used tensor-based signatures, whereas the latest run used a column-based signature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model\n",
    "\n",
    "When you choose a model you want to deploy, you can first register the model. \n",
    "\n",
    "To register the latest model, you'll refer to the name of the job run. By registering the model as an MLflow model, you can easily deploy it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mighty_soca_b8vsfmldyr'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = returned_job.name\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model({'job_name': 'mighty_soca_b8vsfmldyr', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'mlflow-diabetes', 'description': 'Model created from run.', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs/models/mlflow-diabetes/versions/1', 'Resource__source_path': '', 'base_path': 'G:\\\\My Drive\\\\Ingegneria\\\\Data Science GD\\\\My-Practice\\\\my models\\\\Azure ML\\\\azure-ml-labs\\\\Labs\\\\10', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000018FDBBFBDF0>, 'serialize': <msrest.serialization.Serializer object at 0x0000018FDBBF9270>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourceGroups/rg-dp100-labs/workspaces/mlw-dp100-labs/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.mighty_soca_b8vsfmldyr/model', 'datastore': None, 'utc_time_created': None, 'flavors': {'python_function': {'env': 'conda.yaml', 'loader_module': 'mlflow.sklearn', 'model_path': 'model.pkl', 'predict_fn': 'predict', 'python_version': '3.7.16'}, 'sklearn': {'code': '', 'pickled_model': 'model.pkl', 'serialization_format': 'cloudpickle', 'sklearn_version': '0.24.1'}}, 'arm_type': 'model_version', 'type': 'mlflow_model', 'stage': 'Development'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "run_model = Model(\n",
    "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n",
    "    name=\"mlflow-diabetes\",\n",
    "    description=\"Model created from run.\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    ")\n",
    "# Uncomment after adding required details above\n",
    "ml_client.models.create_or_update(run_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Studio, navigate to the **Models** page. In the model list, find the `mlflow-diabetes` model and select it to explore it further.\n",
    "\n",
    "- In the **Details** tab of the `mlflow-diabetes` model, you can review that it's a `MLFLOW` type model and the job that trained the model.\n",
    "- In the **Artifacts** tab you can find the directory with the `MLmodel` file.\n",
    "\n",
    "If you want to explore the model's behavior further, you can **optionally** choose to deploy the model to a real-time endpoint."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
