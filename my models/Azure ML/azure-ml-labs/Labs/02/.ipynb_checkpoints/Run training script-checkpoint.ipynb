{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a training script with the Python SDK\n",
    "\n",
    "You can use the Python SDK for Azure Machine Learning to submit scripts as jobs. By using jobs, you can easily keep track of the input parameters and outputs when training a machine learning model.\n",
    "\n",
    "## Before you start\n",
    "\n",
    "You'll need the latest version of the **azure-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
    "\n",
    "> **Note**:\n",
    "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azure-ai-ml\n",
      "Version: 1.22.4\n",
      "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
      "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
      "Author: Microsoft Corporation\n",
      "Author-email: azuresdkengsysadmins@microsoft.com\n",
      "License: MIT License\n",
      "Location: c:\\users\\alienware\\miniconda3\\envs\\py310\\lib\\site-packages\n",
      "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, opencensus-ext-logging, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\alienware\\miniconda3\\envs\\py310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip show azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### imports here ####\n",
    "\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, AzureCliCredential\n",
    "from azure.ai.ml import MLClient, command, Input\n",
    "\n",
    "import configparser\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlw-dp100-labs\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Use an absolute path to avoid path issues\n",
    "config_file_path = \"G:/My Drive/Ingegneria/Data Science GD/My-Practice/my models/Azure ML/config.ini\"\n",
    "config.read(config_file_path)\n",
    "\n",
    "# Check if the 'azure' section exists\n",
    "if 'azure' in config:\n",
    "    os.environ['AZURE_CLIENT_ID'] = config['azure']['client_id']\n",
    "    os.environ['AZURE_CLIENT_SECRET'] = config['azure']['client_secret']\n",
    "    os.environ['AZURE_TENANT_ID'] = config['azure']['tenant_id']\n",
    "    os.environ['AZURE_SUBSCRIPTION_ID'] = config['azure']['subscription_id']\n",
    "\n",
    "    # Attempt to use DefaultAzureCredential\n",
    "    try:\n",
    "        credential = DefaultAzureCredential()\n",
    "        credential.get_token(\"https://management.azure.com/.default\")\n",
    "    except Exception as ex:\n",
    "        print(\"DefaultAzureCredential failed, falling back to InteractiveBrowserCredential.\")\n",
    "        credential = InteractiveBrowserCredential()\n",
    "\n",
    "    # Initialize MLClient with the obtained credential\n",
    "    ml_client = MLClient(\n",
    "        credential=credential,\n",
    "        subscription_id=os.environ['AZURE_SUBSCRIPTION_ID'],\n",
    "        resource_group_name=\"rg-dp100-labs\",\n",
    "        workspace_name=\"mlw-dp100-labs\"\n",
    "    )\n",
    "\n",
    "    # List workspaces to verify the connection\n",
    "    try:\n",
    "        workspaces = ml_client.workspaces.list()\n",
    "        for ws in workspaces:\n",
    "            print(ws.name)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to list workspaces: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"The 'azure' section is missing in the config.ini file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Python SDK to train a model\n",
    "\n",
    "To train a model, you'll first create the **diabetes_training.py** script in the **src** folder. The script uses the **diabetes.csv** file in the same folder as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/diabetes-training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/diabetes-training.py\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('src\\diabetes.csv')\n",
    "\n",
    "# separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to submit the job that trains a classification model to predict diabetes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Training a logistic regression model with regularization rate of 0.01\n",
      "Accuracy: 0.774\n",
      "AUC: 0.8484909696999852\n"
     ]
    }
   ],
   "source": [
    "# Run the script using %run\n",
    "%run src/diabetes-training.py # modify the path of the diabetes.cvs in the py file, before uploading them to azure: diabetes = pd.read_csv('src/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data({'path': 'azureml://subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs/datastores/workspaceblobstore/paths/LocalUpload/262cdbadf171d4037c6e97e879d03619/src/', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_folder', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'src-folder-dataset', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs/data/src-folder-dataset/versions/2', 'Resource__source_path': '', 'base_path': 'G:\\\\My Drive\\\\Ingegneria\\\\Data Science GD\\\\My-Practice\\\\my models\\\\Azure ML\\\\azure-ml-labs\\\\Labs\\\\02', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000013A6EC32C50>, 'serialize': <msrest.serialization.Serializer object at 0x0000013A6EC32830>, 'version': '2', 'latest_version': None, 'datastore': None})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Data asset for the entire src directory\n",
    "data_asset = Data(\n",
    "    path=\"./src\",  # Local path to your src directory\n",
    "    type=\"uri_folder\",  # Type of data asset as a folder\n",
    "    name=\"src-folder-dataset\",\n",
    "    version=\"2\"  # Ensure version is a string\n",
    ")\n",
    "\n",
    "# Upload the Data asset\n",
    "ml_client.data.create_or_update(data_asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: azureml://subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs/datastores/workspaceblobstore/paths/LocalUpload/262cdbadf171d4037c6e97e879d03619/src/\n"
     ]
    }
   ],
   "source": [
    "# Verify the dataset exists and retrieve the path\n",
    "dataset = ml_client.data.get(name=\"src-folder-dataset\", version=\"2\")\n",
    "print(\"Dataset path:\", dataset.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading src (0.53 MBs): 100%|###########################################| 530617/530617 [00:00<00:00, 1230123.53it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/bubbly_bucket_xvxz2m8xml?wsid=/subscriptions/a90ed0cd-b0b9-4e3a-bd85-67272a44de15/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=8bfc37bf-8e21-4420-841d-49303c72ec1a\n"
     ]
    }
   ],
   "source": [
    "# Define the job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python diabetes-training.py --data ${{inputs.diabetes_data}}\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-pythonv2-train\",\n",
    "    experiment_name=\"diabetes-training\",\n",
    "    inputs={\n",
    "        \"diabetes_data\": Input(type=\"uri_file\", path=dataset.path)  # Use the verified dataset path\n",
    "    }\n",
    ")\n",
    "\n",
    "#then submit the job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)\n",
    "\n",
    "# then check the job and the logs"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
