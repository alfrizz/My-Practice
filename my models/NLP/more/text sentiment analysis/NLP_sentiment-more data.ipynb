{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eed7d786-0cbb-450f-8fb7-d114b1174a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a635d38-3899-475e-8819-ec102550b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1')\n",
    "\n",
    "#removing @username from the text column\n",
    "\n",
    "df[6] = df.iloc[:, 5].apply(lambda text: re.sub(r'@\\w+\\s*', '', text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8c9d6a7-7e10-4cc7-b094-0febe7fb9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the new text column to two txt files (one for positive sentences and one for negative sentences)\n",
    "\n",
    "df[df.iloc[:, 0]==4].iloc[:, 6].to_csv('pos1.txt', index=False, header=False)\n",
    "df[df.iloc[:, 0]==0].iloc[:, 6].to_csv('neg1.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddf6a29e-bd4f-4407-b8fb-827a48080448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the old pos.txt and the new pos1.txt\n",
    "\n",
    "with open('pos.txt', 'r', encoding='utf-8') as file1:\n",
    "    file1_contents = file1.read()\n",
    "\n",
    "with open('pos1.txt', 'r', encoding='utf-8') as file2:\n",
    "    file2_contents = file2.read()\n",
    "\n",
    "combined_contents = file1_contents + file2_contents\n",
    "# Open the output file in write mode (creates the file if it doesn't exist)\n",
    "with open('pos_all.txt', 'w', encoding='utf-8') as combined_file:\n",
    "    combined_file.write(combined_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41e9aa4c-86d6-4472-9c2d-4f8a34c49238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the old neg.txt and the new neg1.txt\n",
    "\n",
    "with open('neg.txt', 'r', encoding='utf-8') as file1:\n",
    "    file1_contents = file1.read()\n",
    "\n",
    "with open('neg1.txt', 'r', encoding='utf-8') as file2:\n",
    "    file2_contents = file2.read()\n",
    "\n",
    "combined_contents = file1_contents + file2_contents\n",
    "# Open the output file in write mode (creates the file if it doesn't exist)\n",
    "with open('neg_all.txt', 'w', encoding='utf-8') as combined_file:\n",
    "    combined_file.write(combined_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da620f91-26ce-4c3c-9917-c5167e409239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lexicon (directory=os.getcwd(), max_quant=0.998, min_quant=0.972, visualize=False):\n",
    "    \n",
    "    all_words = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('_all.txt'):\n",
    "            with open(filename, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    words_in_line = word_tokenize(line)\n",
    "                    all_words += words_in_line\n",
    "        \n",
    "    all_words_lem = [lemmatizer.lemmatize(word) for word in all_words]\n",
    "    all_words_cnt = Counter(all_words_lem)\n",
    "    \n",
    "    freq_list = [freq for _ , freq in all_words_cnt.items()]\n",
    "    max_freq = np.quantile(freq_list, max_quant)\n",
    "    min_freq = np.quantile(freq_list, min_quant)\n",
    "\n",
    "    all_words_filt = {word : freq for word, freq in all_words_cnt.items() if  min_freq < freq < max_freq}\n",
    "    freq_list_filt = [freq for _ , freq in all_words_filt.items()]\n",
    "    words_list_filt = [word for word , _ in all_words_filt.items()]\n",
    "    \n",
    "    if visualize:\n",
    "        print ('number of words in the filtered dictionary:', len(freq_list_filt))\n",
    "        print ('max repetitions considered:', max_freq)\n",
    "        print ('min repetitions considered:', min_freq)\n",
    "        plt.hist(freq_list_filt, bins = len(freq_list_filt))\n",
    "        plt.show()\n",
    "    \n",
    "    return words_list_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2275137-24ff-4d78-87a4-b9a824bd985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words in the filtered dictionary: 13677\n",
      "max repetitions considered: 1928.0\n",
      "min repetitions considered: 50.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['destined',\n",
       " '21st',\n",
       " 'century',\n",
       " 'conan',\n",
       " 'splash',\n",
       " 'greater',\n",
       " 'van',\n",
       " 'steven',\n",
       " 'lord',\n",
       " 'ring',\n",
       " 'column',\n",
       " 'describe',\n",
       " 'peter',\n",
       " 'jackson',\n",
       " 'vision',\n",
       " 'j',\n",
       " 'effective',\n",
       " 'rare',\n",
       " 'honest',\n",
       " 'provides',\n",
       " 'insight',\n",
       " 'comic',\n",
       " 'reached',\n",
       " 'absolute',\n",
       " 'offer',\n",
       " 'combination',\n",
       " 'entertainment',\n",
       " 'education',\n",
       " 'perhaps',\n",
       " 'literally',\n",
       " 'showed',\n",
       " 'intention',\n",
       " 'screenplay',\n",
       " 'curl',\n",
       " 'edge',\n",
       " 'clever',\n",
       " 'somehow',\n",
       " 'pull',\n",
       " 'slice',\n",
       " 'asian',\n",
       " 'cinema',\n",
       " 'singing',\n",
       " 'surprise',\n",
       " 'quality',\n",
       " 'genuine',\n",
       " 'fed',\n",
       " 'greatest',\n",
       " 'ultimately',\n",
       " 'utterly',\n",
       " 'compelling',\n",
       " 'wrote',\n",
       " 'reputation',\n",
       " 'famous',\n",
       " 'author',\n",
       " 'lived',\n",
       " 'overly',\n",
       " 'documentary',\n",
       " 'masterpiece',\n",
       " 'four',\n",
       " 'beauty',\n",
       " 'willing',\n",
       " 'mystery',\n",
       " 'breath',\n",
       " 'fresh',\n",
       " 'thoughtful',\n",
       " 'cast',\n",
       " 'includes',\n",
       " 'actor',\n",
       " 'independent',\n",
       " 'involves',\n",
       " 'amusing',\n",
       " 'disturbing',\n",
       " 'assembly',\n",
       " 'whom',\n",
       " 'connect',\n",
       " 'departure',\n",
       " 'standard',\n",
       " 'fare',\n",
       " 'score',\n",
       " 'dedicated',\n",
       " 'occasionally',\n",
       " 'extremely',\n",
       " 'brings',\n",
       " 'romantic',\n",
       " '95',\n",
       " 'treasure',\n",
       " 'planet',\n",
       " 'pace',\n",
       " 'race',\n",
       " 'familiar',\n",
       " 'however',\n",
       " 'lack',\n",
       " 'epic',\n",
       " 'often',\n",
       " 'tale',\n",
       " 'disney',\n",
       " 'effort',\n",
       " 'bow',\n",
       " 'tone',\n",
       " 'act',\n",
       " 'guaranteed',\n",
       " 'shook',\n",
       " 'rolled',\n",
       " 'master',\n",
       " 'filmmaker',\n",
       " 'unique',\n",
       " 'teach',\n",
       " 'danger',\n",
       " 'drug',\n",
       " 'paid',\n",
       " 'crush',\n",
       " 'title',\n",
       " 'funeral',\n",
       " 'hugh',\n",
       " 'grant',\n",
       " 'smart',\n",
       " 'seemed',\n",
       " 'static',\n",
       " 'perfectly',\n",
       " 'capture',\n",
       " 'hotel',\n",
       " 'lobby',\n",
       " 'highway',\n",
       " 'cafe',\n",
       " 'spooky',\n",
       " 'fascinating',\n",
       " 'reward',\n",
       " 'bond',\n",
       " 'outing',\n",
       " 'recent',\n",
       " 'stunt',\n",
       " 'border',\n",
       " 'heavy',\n",
       " 'technology',\n",
       " 'beginning',\n",
       " 'creep',\n",
       " 'series',\n",
       " 'draw',\n",
       " 'attention',\n",
       " 'magnet',\n",
       " 'circle',\n",
       " 'known',\n",
       " 'mark',\n",
       " 'loses',\n",
       " 'bite',\n",
       " 'ending',\n",
       " 'novel',\n",
       " 'surely',\n",
       " 'yarn',\n",
       " 'e',\n",
       " 'el',\n",
       " 'de',\n",
       " 'uno',\n",
       " 'que',\n",
       " 'la',\n",
       " 'ver',\n",
       " 'por',\n",
       " 'su',\n",
       " 'strong',\n",
       " 'musician',\n",
       " 'creating',\n",
       " 'rhythm',\n",
       " 'itself',\n",
       " 'lip',\n",
       " 'wipe',\n",
       " 'bead',\n",
       " 'sweat',\n",
       " 'performance',\n",
       " 'glimpse',\n",
       " 'culture',\n",
       " 'tender',\n",
       " 'target',\n",
       " 'giant',\n",
       " 'creature',\n",
       " 'feature',\n",
       " 'kick',\n",
       " 'engaging',\n",
       " 'johnson',\n",
       " 'career',\n",
       " 'cheap',\n",
       " 'beautifully',\n",
       " 'chilly',\n",
       " 'begin',\n",
       " 'snow',\n",
       " 'plus',\n",
       " 'sheep',\n",
       " 'host',\n",
       " 'dose',\n",
       " 'everytime',\n",
       " 'steam',\n",
       " 'amuse',\n",
       " 'manages',\n",
       " 'original',\n",
       " 'rip',\n",
       " 'bryan',\n",
       " 'adam',\n",
       " 'potential',\n",
       " 'simply',\n",
       " 'package',\n",
       " 'certainly',\n",
       " 'intended',\n",
       " 'er',\n",
       " 'spirit',\n",
       " 'piece',\n",
       " 'america',\n",
       " 'british',\n",
       " 'gold',\n",
       " 'charming',\n",
       " 'whether',\n",
       " 'lecture',\n",
       " 'self',\n",
       " 'fellow',\n",
       " 'pleasant',\n",
       " 'held',\n",
       " 'american',\n",
       " 'teen',\n",
       " 'whatever',\n",
       " 'bringing',\n",
       " 'beloved',\n",
       " 'screen',\n",
       " 'tuck',\n",
       " 'labour',\n",
       " 'involved',\n",
       " 'madness',\n",
       " 'animated',\n",
       " 'inner',\n",
       " 'struggle',\n",
       " 'hero',\n",
       " 'insecure',\n",
       " 'intense',\n",
       " 'alive',\n",
       " 'actress',\n",
       " 'complex',\n",
       " 'character',\n",
       " 'grows',\n",
       " 'shocking',\n",
       " 'charm',\n",
       " 'obvious',\n",
       " 'humour',\n",
       " 'bride',\n",
       " 'sense',\n",
       " 'psychological',\n",
       " 'drama',\n",
       " 'burst',\n",
       " 'sudden',\n",
       " 'violence',\n",
       " 'intelligent',\n",
       " 'journey',\n",
       " 'sensitive',\n",
       " 'young',\n",
       " 'foster',\n",
       " 'fierce',\n",
       " 'dangerous',\n",
       " 'hold',\n",
       " 'truly',\n",
       " 'experience',\n",
       " 'example',\n",
       " 'art',\n",
       " 'heal',\n",
       " 'clarify',\n",
       " 'comfort',\n",
       " 'deeply',\n",
       " 'director',\n",
       " 'suspense',\n",
       " 'whose',\n",
       " 'coloring',\n",
       " 'substance',\n",
       " 'appearance',\n",
       " 'role',\n",
       " 'rolling',\n",
       " 'incredible',\n",
       " 'challenge',\n",
       " 'reality',\n",
       " 'sexual',\n",
       " 'originally',\n",
       " 'against',\n",
       " 'painful',\n",
       " 'viewer',\n",
       " 'accomplished',\n",
       " 'albeit',\n",
       " 'depressing',\n",
       " 'view',\n",
       " 'iranian',\n",
       " 'aside',\n",
       " 'isle',\n",
       " 'thoroughly',\n",
       " 'vista',\n",
       " 'incredibly',\n",
       " 'death',\n",
       " 'process',\n",
       " 'hong',\n",
       " 'kong',\n",
       " 'landscape',\n",
       " 'adventure',\n",
       " 'blast',\n",
       " 'energy',\n",
       " 'bouncy',\n",
       " 'animation',\n",
       " 'catchy',\n",
       " 'entire',\n",
       " '85',\n",
       " 'sport',\n",
       " 'action',\n",
       " 'field',\n",
       " 'doug',\n",
       " 'traffic',\n",
       " 'location',\n",
       " 'us',\n",
       " 'ability',\n",
       " 'focused',\n",
       " 'sincere',\n",
       " 'footage',\n",
       " 'document',\n",
       " 'photograph',\n",
       " 'recording',\n",
       " 'entertaining',\n",
       " 'child',\n",
       " 'create',\n",
       " 'history',\n",
       " 'powerful',\n",
       " 'detailed',\n",
       " 'realization',\n",
       " 'significant',\n",
       " 'lift',\n",
       " 'above',\n",
       " 'level',\n",
       " 'promising',\n",
       " 'unusual',\n",
       " 'horror',\n",
       " 'normal',\n",
       " 'barely',\n",
       " 'program',\n",
       " 'discovery',\n",
       " 'channel',\n",
       " 'disappear',\n",
       " 'perspective',\n",
       " 'opened',\n",
       " 'photography',\n",
       " 'burger',\n",
       " 'national',\n",
       " 'grief',\n",
       " 'curiosity',\n",
       " 'chronic',\n",
       " 'fear',\n",
       " 'enjoyed',\n",
       " 'favor',\n",
       " 'surprised',\n",
       " 'quickly',\n",
       " 'faded',\n",
       " 'memory',\n",
       " 'chicago',\n",
       " 'completely',\n",
       " 'steve',\n",
       " 'method',\n",
       " 'speed',\n",
       " 'volume',\n",
       " 'refreshing',\n",
       " 'korean',\n",
       " 'five',\n",
       " 'female',\n",
       " 'battle',\n",
       " 'relationship',\n",
       " 'deeper',\n",
       " 'surface',\n",
       " 'crime',\n",
       " 'flick',\n",
       " 'common',\n",
       " 'double',\n",
       " 'value',\n",
       " 'crew',\n",
       " 'previous',\n",
       " 'patience',\n",
       " 'pressure',\n",
       " 'possible',\n",
       " 'sequel',\n",
       " 'comedy',\n",
       " 'rule',\n",
       " 'universe',\n",
       " '2000',\n",
       " 'mile',\n",
       " 'ribbon',\n",
       " 'ultimate',\n",
       " 'filled',\n",
       " 'pure',\n",
       " 'excitement',\n",
       " 'du',\n",
       " 'sarcasm',\n",
       " 'tempting',\n",
       " 'regard',\n",
       " 'mr',\n",
       " 'andrew',\n",
       " 'allows',\n",
       " 'artist',\n",
       " 'term',\n",
       " 'edited',\n",
       " 'style',\n",
       " 'subject',\n",
       " 'pray',\n",
       " 'lacking',\n",
       " 'mtv',\n",
       " 'mostly',\n",
       " 'secret',\n",
       " 'indeed',\n",
       " 'metaphor',\n",
       " 'accomplishment',\n",
       " 'dramatic',\n",
       " 'impact',\n",
       " 'mainly',\n",
       " 'between',\n",
       " 'cube',\n",
       " 'personal',\n",
       " 'revelation',\n",
       " 'regarding',\n",
       " 'result',\n",
       " 'gentle',\n",
       " 'healing',\n",
       " 'somewhere',\n",
       " 'modern',\n",
       " 'neither',\n",
       " 'nor',\n",
       " 'comedian',\n",
       " 'unlike',\n",
       " 'swimming',\n",
       " 'performer',\n",
       " 'key',\n",
       " 'intriguing',\n",
       " 'constantly',\n",
       " 'desire',\n",
       " 'format',\n",
       " 'manner',\n",
       " 'blessing',\n",
       " 'extreme',\n",
       " 'ops',\n",
       " 'expectation',\n",
       " 'acting',\n",
       " 'dialogue',\n",
       " 'nine',\n",
       " 'buck',\n",
       " 'suffering',\n",
       " 'human',\n",
       " 'quiet',\n",
       " 'otherwise',\n",
       " 'excellent',\n",
       " 'sequence',\n",
       " 'obviously',\n",
       " 'struck',\n",
       " 'chord',\n",
       " 'south',\n",
       " 'magic',\n",
       " 'classy',\n",
       " 'item',\n",
       " 'legend',\n",
       " 'prove',\n",
       " 'chop',\n",
       " 'nature',\n",
       " 'progress',\n",
       " 'theme',\n",
       " 'proved',\n",
       " 'important',\n",
       " 'finale',\n",
       " 'exactly',\n",
       " 'meal',\n",
       " 'strap',\n",
       " 'pair',\n",
       " 'shut',\n",
       " 'space',\n",
       " 'merely',\n",
       " 'technical',\n",
       " 'feat',\n",
       " 'russian',\n",
       " 'cinematic',\n",
       " 'milestone',\n",
       " 'talented',\n",
       " 'terribly',\n",
       " 'essential',\n",
       " 'social',\n",
       " 'deal',\n",
       " 'steak',\n",
       " 'spectacular',\n",
       " 'gem',\n",
       " 'obsession',\n",
       " 'delight',\n",
       " 'goofy',\n",
       " 'midnight',\n",
       " 'regular',\n",
       " 'cliche',\n",
       " 'honesty',\n",
       " 'sens',\n",
       " 'minor',\n",
       " 'balance',\n",
       " 'sweetness',\n",
       " 'paint',\n",
       " 'single',\n",
       " 'scene',\n",
       " 'effect',\n",
       " 'folk',\n",
       " 'indulge',\n",
       " 'force',\n",
       " 'humanity',\n",
       " 'hardware',\n",
       " 'george',\n",
       " 'lucas',\n",
       " 'forgotten',\n",
       " 'mike',\n",
       " 'succeed',\n",
       " 'formula',\n",
       " 'winning',\n",
       " 'offering',\n",
       " 'audience',\n",
       " 'urban',\n",
       " 'model',\n",
       " 'hoot',\n",
       " 'candidate',\n",
       " 'giving',\n",
       " 'speech',\n",
       " 'innocent',\n",
       " 'superior',\n",
       " 'factor',\n",
       " 'smack',\n",
       " 'tim',\n",
       " 'allen',\n",
       " 'hog',\n",
       " 'plenty',\n",
       " 'enjoyable',\n",
       " 'soul',\n",
       " 'mummy',\n",
       " 'represent',\n",
       " 'partly',\n",
       " 'aware',\n",
       " 'determined',\n",
       " 'entertain',\n",
       " 'script',\n",
       " 'sharp',\n",
       " 'partially',\n",
       " 'kiss',\n",
       " 'believed',\n",
       " 'ray',\n",
       " 'jason',\n",
       " 'fooled',\n",
       " 'nobody',\n",
       " 'deserves',\n",
       " 'prize',\n",
       " 'charlotte',\n",
       " 'husband',\n",
       " 'harmless',\n",
       " 'happiest',\n",
       " 'surprising',\n",
       " 'irish',\n",
       " 'general',\n",
       " 'slowly',\n",
       " 'thriller',\n",
       " 'recommending',\n",
       " 'marvelous',\n",
       " 'michael',\n",
       " 'faithful',\n",
       " 'twin',\n",
       " 'premise',\n",
       " 'become',\n",
       " 'precious',\n",
       " 'stephen',\n",
       " 'posse',\n",
       " 'trailer',\n",
       " 'aspect',\n",
       " 'harsh',\n",
       " 'visual',\n",
       " 'likely',\n",
       " 'anywhere',\n",
       " 'humor',\n",
       " 'behavior',\n",
       " 'return',\n",
       " 'root',\n",
       " 'genre',\n",
       " 'depend',\n",
       " 'certain',\n",
       " 'intelligence',\n",
       " 'science',\n",
       " 'count',\n",
       " 'remains',\n",
       " 'solid',\n",
       " 'somewhat',\n",
       " 'howard',\n",
       " 'steady',\n",
       " 'follows',\n",
       " 'realistic',\n",
       " 'path',\n",
       " 'existence',\n",
       " 'iran',\n",
       " 'chunk',\n",
       " 'trapped',\n",
       " 'pinch',\n",
       " 'trial',\n",
       " 'seaside',\n",
       " 'shallow',\n",
       " 'attempt',\n",
       " 'indie',\n",
       " 'rank',\n",
       " 'among',\n",
       " 'flow',\n",
       " 'friendship',\n",
       " 'buried',\n",
       " 'environment',\n",
       " 'traditional',\n",
       " 'careful',\n",
       " 'period',\n",
       " 'release',\n",
       " 'decade',\n",
       " 'honestly',\n",
       " 'unexpected',\n",
       " 'deposit',\n",
       " 'punishment',\n",
       " 'tearing',\n",
       " 'cop',\n",
       " 'understands',\n",
       " 'medium',\n",
       " 'amazingly',\n",
       " 'jack',\n",
       " 'britney',\n",
       " 'delivered',\n",
       " 'superstar',\n",
       " 'travel',\n",
       " 'fame',\n",
       " 'freeway',\n",
       " 'business',\n",
       " 'nervous',\n",
       " 'mild',\n",
       " 'gang',\n",
       " 'spare',\n",
       " 'borrowed',\n",
       " 'material',\n",
       " 'himself',\n",
       " 'delighted',\n",
       " 'treat',\n",
       " 'slight',\n",
       " 'pleasure',\n",
       " 'insightful',\n",
       " 'conflict',\n",
       " 'parental',\n",
       " 'peace',\n",
       " 'moved',\n",
       " 'frustrated',\n",
       " 'heartbreaking',\n",
       " 'glued',\n",
       " 'goodness',\n",
       " 'queen',\n",
       " 'natural',\n",
       " 'gift',\n",
       " 'australian',\n",
       " 'john',\n",
       " 'english',\n",
       " 'terrific',\n",
       " 'dong',\n",
       " 'sticking',\n",
       " 'wallet',\n",
       " 'sting',\n",
       " 'bust',\n",
       " 'gut',\n",
       " 'examination',\n",
       " 'joke',\n",
       " 'becomes',\n",
       " 'enemy',\n",
       " 'jean',\n",
       " 'nocturnal',\n",
       " 'badge',\n",
       " 'honor',\n",
       " 'realizes',\n",
       " 'fully',\n",
       " 'clash',\n",
       " 'incident',\n",
       " 'headline',\n",
       " 'mixed',\n",
       " 'emotion',\n",
       " 'combined',\n",
       " 'understanding',\n",
       " 'purely',\n",
       " 'worship',\n",
       " 'nonetheless',\n",
       " 'reminder',\n",
       " 'foreign',\n",
       " 'policy',\n",
       " 'rise',\n",
       " 'trimmed',\n",
       " 'production',\n",
       " 'scale',\n",
       " 'satisfy',\n",
       " 'hollywood',\n",
       " 'possibly',\n",
       " 'clumsy',\n",
       " 'equally',\n",
       " 'painfully',\n",
       " 'moore',\n",
       " 'impress',\n",
       " 'territory',\n",
       " 'brought',\n",
       " 'guessing',\n",
       " 'frame',\n",
       " 'touch',\n",
       " 'nerve',\n",
       " 'updated',\n",
       " 'source',\n",
       " 'hilarious',\n",
       " 'poem',\n",
       " 'labor',\n",
       " 'workplace',\n",
       " 'delightful',\n",
       " 'despite',\n",
       " 'flaw',\n",
       " 'amy',\n",
       " 'personality',\n",
       " 'typical',\n",
       " 'per',\n",
       " 'christian',\n",
       " 'slightly',\n",
       " 'nearly',\n",
       " 'lead',\n",
       " 'motivation',\n",
       " 'stress',\n",
       " 'keen',\n",
       " 'particularly',\n",
       " 'downer',\n",
       " 'passion',\n",
       " 'strange',\n",
       " 'desert',\n",
       " 'filmed',\n",
       " 'taste',\n",
       " 'accessible',\n",
       " 'affecting',\n",
       " 'throughout',\n",
       " 'impressive',\n",
       " 'direction',\n",
       " 'narrative',\n",
       " 'spin',\n",
       " 'appreciate',\n",
       " 'greatly',\n",
       " 'large',\n",
       " 'grow',\n",
       " 'attached',\n",
       " 'strength',\n",
       " 'warmth',\n",
       " 'immensely',\n",
       " 'david',\n",
       " 'additional',\n",
       " 'storyline',\n",
       " 'magical',\n",
       " 'mama',\n",
       " 'plot',\n",
       " 'development',\n",
       " 'touching',\n",
       " 'nostalgia',\n",
       " 'search',\n",
       " 'jim',\n",
       " 't-shirt',\n",
       " 'imagination',\n",
       " 'analysis',\n",
       " 'todd',\n",
       " 'invite',\n",
       " 'apart',\n",
       " 'fault',\n",
       " 'admit',\n",
       " 'present',\n",
       " 'middle',\n",
       " 'musical',\n",
       " 'desperate',\n",
       " 'escape',\n",
       " 'difficult',\n",
       " 'horrid',\n",
       " 'benefit',\n",
       " 'detail',\n",
       " 'speaks',\n",
       " 'event',\n",
       " 'easily',\n",
       " 'focusing',\n",
       " 'quirky',\n",
       " 'individual',\n",
       " 'stand',\n",
       " 'forth',\n",
       " 'abuse',\n",
       " 'latin',\n",
       " 'soft',\n",
       " 'ship',\n",
       " 'dock',\n",
       " 'continues',\n",
       " 'ahead',\n",
       " 'generation',\n",
       " 'dumb',\n",
       " 'witness',\n",
       " 'several',\n",
       " 'happily',\n",
       " 'victim',\n",
       " 'none',\n",
       " 'williams',\n",
       " 'presenting',\n",
       " 'impossible',\n",
       " 'romance',\n",
       " 'pumpkin',\n",
       " 'dare',\n",
       " 'debut',\n",
       " 'considering',\n",
       " 'background',\n",
       " 'increasingly',\n",
       " 'frightening',\n",
       " 'notch',\n",
       " 'accent',\n",
       " 'emotional',\n",
       " 'positive',\n",
       " 'sit',\n",
       " 'success',\n",
       " 'element',\n",
       " 'direct',\n",
       " 'praise',\n",
       " 'absolutely',\n",
       " 'meaning',\n",
       " 'occasional',\n",
       " 'thankfully',\n",
       " 'skirt',\n",
       " 'rapidly',\n",
       " 'fantasy',\n",
       " 'attitude',\n",
       " 'push',\n",
       " 'hunter',\n",
       " 'agenda',\n",
       " 'trouble',\n",
       " 'sucker',\n",
       " 'fashion',\n",
       " 'ingredient',\n",
       " 'appetite',\n",
       " 'stab',\n",
       " 'messy',\n",
       " 'fat',\n",
       " 'greek',\n",
       " 'sacrifice',\n",
       " 'image',\n",
       " 'balanced',\n",
       " 'reasonable',\n",
       " 'necessary',\n",
       " 'discussion',\n",
       " 'politics',\n",
       " 'understandable',\n",
       " 'energetic',\n",
       " 'ikea',\n",
       " 'trooper',\n",
       " 'gross',\n",
       " 'razor',\n",
       " 'reject',\n",
       " 'temptation',\n",
       " 'remembers',\n",
       " 'interested',\n",
       " 'response',\n",
       " 'stroke',\n",
       " 'ram',\n",
       " 'grace',\n",
       " 'seeking',\n",
       " 'disappointed',\n",
       " 'brain',\n",
       " 'savvy',\n",
       " 'legendary',\n",
       " 'writer',\n",
       " 'given',\n",
       " 'asset',\n",
       " 'twist',\n",
       " 'worthy',\n",
       " 'enormous',\n",
       " 'saddest',\n",
       " 'uplifting',\n",
       " 'sentimental',\n",
       " 'usual',\n",
       " 'brilliant',\n",
       " 'rough',\n",
       " 'safely',\n",
       " 'insomnia',\n",
       " 'precisely',\n",
       " 'war',\n",
       " 'china',\n",
       " 'crash',\n",
       " 'surreal',\n",
       " 'french',\n",
       " 'simple',\n",
       " 'risk',\n",
       " 'choose',\n",
       " 'bump',\n",
       " 'depth',\n",
       " 'betty',\n",
       " 'predictable',\n",
       " 'asia',\n",
       " 'herself',\n",
       " 'anna',\n",
       " 'italian',\n",
       " 'heck',\n",
       " 'based',\n",
       " 'keeping',\n",
       " 'campaign',\n",
       " 'trail',\n",
       " 'melodrama',\n",
       " 'emotionally',\n",
       " 'delivers',\n",
       " 'theater',\n",
       " 'wallpaper',\n",
       " 'chosen',\n",
       " 'freedom',\n",
       " 'hu',\n",
       " 'sorrow',\n",
       " 'bold',\n",
       " 'pat',\n",
       " 'easier',\n",
       " 'respect',\n",
       " 'wild',\n",
       " 'civil',\n",
       " 'allowed',\n",
       " 'build',\n",
       " 'complete',\n",
       " 'satisfying',\n",
       " 'sort',\n",
       " 'brutal',\n",
       " 'strangely',\n",
       " 'fiction',\n",
       " 'learning',\n",
       " 'cultural',\n",
       " 'grab',\n",
       " 'amaze',\n",
       " 'remarkable',\n",
       " 'meditation',\n",
       " 'revolution',\n",
       " 'creepy',\n",
       " 'committed',\n",
       " 'involving',\n",
       " 'chinese',\n",
       " 'wind',\n",
       " 'acted',\n",
       " 'actual',\n",
       " 'price',\n",
       " 'marching',\n",
       " 'weak',\n",
       " 'revenge',\n",
       " 'leading',\n",
       " 'subtle',\n",
       " 'supportive',\n",
       " 'foul',\n",
       " 'freaky',\n",
       " 'mix',\n",
       " 'serious',\n",
       " 'ego',\n",
       " 'jealousy',\n",
       " 'within',\n",
       " 'seemingly',\n",
       " 'marriage',\n",
       " 'diversity',\n",
       " 'brief',\n",
       " 'bargain',\n",
       " 'nail',\n",
       " 'tight',\n",
       " 'pronounce',\n",
       " 'correctly',\n",
       " 'successfully',\n",
       " 'foil',\n",
       " 'cheated',\n",
       " 'tart',\n",
       " 'appeal',\n",
       " 'tough',\n",
       " 'shake',\n",
       " 'introduction',\n",
       " 'expected',\n",
       " 'gender',\n",
       " 'preference',\n",
       " 'political',\n",
       " 'rebel',\n",
       " 'unbelievably',\n",
       " 'perfection',\n",
       " 'nicely',\n",
       " 'serf',\n",
       " 'society',\n",
       " 'transition',\n",
       " 'quest',\n",
       " 'origin',\n",
       " 'acceptance',\n",
       " 'sexy',\n",
       " 'gorgeous',\n",
       " 'pushed',\n",
       " 'pulled',\n",
       " 'sex',\n",
       " 'celebrated',\n",
       " 'expect',\n",
       " 'bunch',\n",
       " 'and/or',\n",
       " 'poetry',\n",
       " 'particular',\n",
       " 'interest',\n",
       " 'student',\n",
       " 'international',\n",
       " 'designed',\n",
       " 'major',\n",
       " 'minority',\n",
       " 'report',\n",
       " 'truth',\n",
       " 'amount',\n",
       " 'swim',\n",
       " 'written',\n",
       " 'produced',\n",
       " 'directed',\n",
       " 'charles',\n",
       " 'authentic',\n",
       " 'monster',\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create_lexicon(visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d87d354-67ba-42b2-87c1-5427d6743ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe (lexicon, sample, is_positive):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    dataset = []\n",
    "    label = 1 if is_positive else 0\n",
    "    \n",
    "    with open(sample, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line_tokenized = word_tokenize(line)\n",
    "            line_lemmatized = [lemmatizer.lemmatize(line_tokenized) for line_tokenized in line_tokenized]\n",
    "            feature = np.zeros(len(lexicon))\n",
    "            \n",
    "            for word in line_lemmatized:\n",
    "                if word in lexicon:\n",
    "                    feature[lexicon.index(word)] += 1\n",
    "                    \n",
    "            dataset.append([feature, label])\n",
    "        \n",
    "        dataframe = pd.DataFrame(dataset, columns=['text_encod', 'label']) # .reset_index(drop = True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a956577-49a0-4882-afb3-aa59381790c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_n_split_df(pos_file, neg_file):\n",
    "    \n",
    "    lexicon = create_lexicon()\n",
    "    print('lexicon created')\n",
    "    \n",
    "    pos_df = create_dataframe(lexicon, pos_file, is_positive = True)\n",
    "    print('positive dataframe created')\n",
    "    neg_df = create_dataframe(lexicon, neg_file, is_positive = False)\n",
    "    print('negative dataframe created')\n",
    "    full_dataframe = pd.concat([pos_df, neg_df]) #, ignore_index = True\n",
    "    print('full dataframe created')    \n",
    "    \n",
    "    train_x, test_x, train_y, test_y  = train_test_split(full_dataframe['text_encod'], full_dataframe['label'], \n",
    "                                                        test_size=0.1, shuffle=True)\n",
    "    print('train test split created')    \n",
    "\n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c4b08-851d-4625-a3ee-a4ff032892eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lexicon created\n",
      "positive dataframe created\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "\n",
    "train_x, test_x, train_y, test_y = merge_n_split_df(pos_file = 'pos_all.txt', neg_file = 'neg_all.txt')\n",
    "with open('sentiment_set.pickle','wb') as file:\n",
    "    pickle.dump([train_x,test_x,train_y,test_y],file)\n",
    "    print('sentiment_set pickle created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d617852c-42a8-461c-bb52-e81f7a5123e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481,)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 2000)              964000    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4000)              8004000   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8000)              32008000  \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16000)             128016000 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 32002     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,024,002\n",
      "Trainable params: 169,024,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=2000, \n",
    "                                activation='relu', \n",
    "                                input_shape=(train_x.iloc[0].shape), # number of words in the lexicon (to reshape accordingly)\n",
    "                                kernel_initializer='glorot_uniform')) #uniform distribution weights initialization\n",
    "print(train_x[0].shape)\n",
    "model.add(tf.keras.layers.Dense(4000))\n",
    "# model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(8000))\n",
    "# model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(16000))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax')) # 2 (pos or neg) output (to one-hot encode accordingly)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2f39192-8ede-4d69-9a76-360400f4b516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 5s 46ms/step - loss: 5.0243 - accuracy: 0.5265 - precision_1: 0.5266 - recall_1: 0.5264\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: 0.5731 - accuracy: 0.7013 - precision_1: 0.7013 - recall_1: 0.7013\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: 0.3738 - accuracy: 0.8286 - precision_1: 0.8286 - recall_1: 0.8286\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: 0.1943 - accuracy: 0.9187 - precision_1: 0.9187 - recall_1: 0.9187\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: 0.1345 - accuracy: 0.9450 - precision_1: 0.9450 - recall_1: 0.9450\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: 0.1061 - accuracy: 0.9537 - precision_1: 0.9537 - recall_1: 0.9537\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: 0.1006 - accuracy: 0.9571 - precision_1: 0.9571 - recall_1: 0.9571\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: 0.0898 - accuracy: 0.9588 - precision_1: 0.9588 - recall_1: 0.9588\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: 0.0852 - accuracy: 0.9611 - precision_1: 0.9611 - recall_1: 0.9611\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: 0.0791 - accuracy: 0.9603 - precision_1: 0.9603 - recall_1: 0.9603\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.0808 - accuracy: 0.9581 - precision_1: 0.9581 - recall_1: 0.9581\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.0781 - accuracy: 0.9603 - precision_1: 0.9603 - recall_1: 0.9603\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), \n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(monitor='accuracy', patience=3)\n",
    "\n",
    "x_train_resh = np.vstack(train_x)\n",
    "y_train_resh = to_categorical(train_y, num_classes=2)\n",
    "\n",
    "history = model.fit(x_train_resh,\n",
    "                    y_train_resh,\n",
    "                    epochs=50,\n",
    "                    batch_size = 100,\n",
    "                    callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32dd306-39c0-43ad-b8a2-f149150599f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5276476101218369"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_perc = model(np.vstack(test_x))\n",
    "y_pred = tf.argmax(y_pred_perc, axis = 1)\n",
    "y_test = [1 if y == [0, 1] else 0 for y in test_y]\n",
    "test_acc = np.mean(y_pred==y_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "763b8b85-3b32-407c-a313-35d0a4cc8f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10000)             4820000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10000)             100010000 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10000)             100010000 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 20002     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 204,860,002\n",
      "Trainable params: 204,860,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.models.Sequential()\n",
    "model1.add(tf.keras.layers.Dense(units=10000, \n",
    "                                activation='relu', \n",
    "                                input_shape=(train_x.iloc[0].shape), # number of words in the lexicon (to reshape accordingly)\n",
    "                                kernel_initializer='glorot_uniform')) #uniform distribution weights initialization\n",
    "print(train_x[0].shape)\n",
    "model1.add(tf.keras.layers.Dense(10000))\n",
    "model1.add(tf.keras.layers.Dense(10000))\n",
    "model1.add(tf.keras.layers.Dense(2, activation='softmax')) # 2 (pos or neg) output (to one-hot encode accordingly)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b5356c3-ebf7-4557-9ae4-daf9e3d97fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 4s 263ms/step - loss: 11.3279 - accuracy: 0.5046 - precision: 0.5045 - recall: 0.5029\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.9423 - accuracy: 0.5002 - precision: 0.5002 - recall: 0.5002\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 0.7073 - accuracy: 0.5213 - precision: 0.5213 - recall: 0.5213\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.7021 - accuracy: 0.5301 - precision: 0.5301 - recall: 0.5301\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.6545 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.6041 - accuracy: 0.7234 - precision: 0.7234 - recall: 0.7234\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.5294 - accuracy: 0.7594 - precision: 0.7594 - recall: 0.7594\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.4323 - accuracy: 0.8144 - precision: 0.8144 - recall: 0.8144\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.3077 - accuracy: 0.8871 - precision: 0.8871 - recall: 0.8871\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.1762 - accuracy: 0.9398 - precision: 0.9398 - recall: 0.9398\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.1011 - accuracy: 0.9609 - precision: 0.9609 - recall: 0.9609\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.0786 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.0756 - accuracy: 0.9630 - precision: 0.9630 - recall: 0.9630\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.0765 - accuracy: 0.9629 - precision: 0.9629 - recall: 0.9629\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.0729 - accuracy: 0.9631 - precision: 0.9631 - recall: 0.9631\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.0735 - accuracy: 0.9641 - precision: 0.9641 - recall: 0.9641\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.0694 - accuracy: 0.9646 - precision: 0.9646 - recall: 0.9646\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0681 - accuracy: 0.9635 - precision: 0.9635 - recall: 0.9635\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0680 - accuracy: 0.9637 - precision: 0.9637 - recall: 0.9637\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0679 - accuracy: 0.9632 - precision: 0.9632 - recall: 0.9632\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(), \n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(monitor='accuracy', patience=3)\n",
    "\n",
    "x_train_resh = np.vstack(train_x)\n",
    "y_train_resh = to_categorical(train_y, num_classes=2)\n",
    "\n",
    "history = model1.fit(x_train_resh,\n",
    "                    y_train_resh,\n",
    "                    epochs=50,\n",
    "                    batch_size = 1000,\n",
    "                    callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34a9c0d0-2dcc-42f4-a2da-bc65be881638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5135895032802249"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_perc1 = model1(np.vstack(test_x))\n",
    "y_pred1 = tf.argmax(y_pred_perc1, axis = 1)\n",
    "y_test1 = [1 if y == [0, 1] else 0 for y in test_y]\n",
    "test_acc1 = np.mean(y_pred1==y_test1)\n",
    "test_acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26c91b19-6d50-42bd-a4d7-e1839af52868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481,)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 1000)              482000    \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,488,002\n",
      "Trainable params: 4,488,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Dense(units=1000, \n",
    "                                activation='relu', \n",
    "                                input_shape=(train_x.iloc[0].shape), # number of words in the lexicon (to reshape accordingly)\n",
    "                                kernel_initializer='glorot_uniform')) #uniform distribution weights initialization\n",
    "print(train_x[0].shape)\n",
    "model2.add(tf.keras.layers.Dense(1000))\n",
    "model2.add(tf.keras.layers.Dense(1000))\n",
    "model2.add(tf.keras.layers.Dense(1000))\n",
    "model2.add(tf.keras.layers.Dense(1000))\n",
    "model2.add(tf.keras.layers.Dense(2, activation='softmax')) # 2 (pos or neg) output (to one-hot encode accordingly)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abc38bb8-e675-416b-887c-1fbf29274892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6556 - accuracy: 0.6323 - precision_2: 0.6323 - recall_2: 0.6323\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.7316 - precision_2: 0.7316 - recall_2: 0.7316\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.4215 - accuracy: 0.7992 - precision_2: 0.7992 - recall_2: 0.7992\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2392 - accuracy: 0.8903 - precision_2: 0.8903 - recall_2: 0.8903\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1470 - accuracy: 0.9322 - precision_2: 0.9322 - recall_2: 0.9322\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1135 - accuracy: 0.9490 - precision_2: 0.9490 - recall_2: 0.9490\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0906 - accuracy: 0.9549 - precision_2: 0.9549 - recall_2: 0.9549\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0800 - accuracy: 0.9595 - precision_2: 0.9595 - recall_2: 0.9595\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0741 - accuracy: 0.9605 - precision_2: 0.9605 - recall_2: 0.9605\n",
      "Epoch 10/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0706 - accuracy: 0.9614 - precision_2: 0.9614 - recall_2: 0.9614\n",
      "Epoch 11/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0715 - accuracy: 0.9599 - precision_2: 0.9599 - recall_2: 0.9599\n",
      "Epoch 12/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.0725 - accuracy: 0.9620 - precision_2: 0.9620 - recall_2: 0.9620\n",
      "Epoch 13/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0696 - accuracy: 0.9607 - precision_2: 0.9607 - recall_2: 0.9607\n",
      "Epoch 14/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0722 - accuracy: 0.9597 - precision_2: 0.9597 - recall_2: 0.9597\n",
      "Epoch 15/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.0708 - accuracy: 0.9619 - precision_2: 0.9619 - recall_2: 0.9619\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(), \n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(monitor='accuracy', patience=3)\n",
    "\n",
    "x_train_resh = np.vstack(train_x)\n",
    "y_train_resh = to_categorical(train_y, num_classes=2)\n",
    "\n",
    "history = model2.fit(x_train_resh,\n",
    "                    y_train_resh,\n",
    "                    epochs=50,\n",
    "                    # batch_size = 1000,\n",
    "                    callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44e58c19-9cd4-487d-89bd-0ef82f61fd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5567010309278351"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_perc2 = model2(np.vstack(test_x))\n",
    "y_pred2 = tf.argmax(y_pred_perc2, axis = 1)\n",
    "y_test2 = [0 if y == [0, 1] else 1 for y in test_y]\n",
    "test_acc2 = np.mean(y_pred2==y_test2)\n",
    "test_acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e32985ac-7e66-4b87-b396-44d3c33c65c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4924"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py309",
   "language": "python",
   "name": "py309"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
