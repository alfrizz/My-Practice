{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8853d093-045f-4c1d-8e24-8a34f113d493",
   "metadata": {},
   "source": [
    "SpaCy NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360ec9d0-8e1b-407d-b551-bf59583c0e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Barack Obama was the 44th president of the United States."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with kernel py310\n",
    "\n",
    "import spacy # Load the English language model \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "# Define a sample text \n",
    "text = \"Barack Obama was the 44th president of the United States.\" \n",
    "\n",
    "# Parse the text with the loaded NER model \n",
    "doc = nlp(text)\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c74879f-10ed-45c7-8a4d-2e096576a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama --> PERSON\n",
      "44th --> ORDINAL\n",
      "the United States --> GPE\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the entities in the document and print their labels \n",
    "for ent in doc.ents: \n",
    "  print(ent,'-->', ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0ec0a-dd64-4599-9496-cb8dfcd7320a",
   "metadata": {},
   "source": [
    "BERT NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46eabce3-8f99-4efc-bb90-a25fa3c126ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████| 59.0/59.0 [00:00<00:00, 14.9kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 829/829 [00:00<00:00, 276kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████████████████████████████████████████████████| 213k/213k [00:00<00:00, 970kB/s]\n",
      "Downloading (…)in/added_tokens.json: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2.00/2.00 [00:00<00:00, 776B/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 22.4kB/s]\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='dslim/bert-base-NER', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('dslim/bert-base-NER')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aa41c8a-0df5-4284-adb5-b29f0836861f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 433M/433M [00:12<00:00, 34.3MB/s]\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained('dslim/bert-base-NER')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2893a70-1468-4506-8840-306d2a2429f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.token_classification.TokenClassificationPipeline at 0x235d852a820>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e432f6b4-35cf-4b83-961a-cdce3aef6730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.99954945,\n",
       "  'index': 1,\n",
       "  'word': 'Barack',\n",
       "  'start': 0,\n",
       "  'end': 6},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99952054,\n",
       "  'index': 2,\n",
       "  'word': 'Obama',\n",
       "  'start': 7,\n",
       "  'end': 12},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.99972564,\n",
       "  'index': 10,\n",
       "  'word': 'United',\n",
       "  'start': 43,\n",
       "  'end': 49},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9993253,\n",
       "  'index': 11,\n",
       "  'word': 'States',\n",
       "  'start': 50,\n",
       "  'end': 56}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a sample text\n",
    "text = \"Barack Obama was the 44th president of the United States.\"\n",
    "\n",
    "# Use the pipeline to predict named entities\n",
    "ner_predictions = nlp(text)\n",
    "\n",
    "ner_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ef4b2d9-eb00-474e-8340-bd3e251635c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'B-PER', 'score': 0.99954945, 'index': 1, 'word': 'Barack', 'start': 0, 'end': 6}\n",
      "{'entity': 'I-PER', 'score': 0.99952054, 'index': 2, 'word': 'Obama', 'start': 7, 'end': 12}\n",
      "{'entity': 'B-LOC', 'score': 0.99972564, 'index': 10, 'word': 'United', 'start': 43, 'end': 49}\n",
      "{'entity': 'I-LOC', 'score': 0.9993253, 'index': 11, 'word': 'States', 'start': 50, 'end': 56}\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the predicted named entities and print their labels\n",
    "for ner_prediction in ner_predictions:\n",
    "    print(ner_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3daa9-f865-425b-9fef-b195607125b5",
   "metadata": {},
   "source": [
    "NLTK NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b266f36c-3d2c-49db-bb7d-e3fe505c5e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Barack',\n",
       " 'Obama',\n",
       " 'was',\n",
       " 'the',\n",
       " '44th',\n",
       " 'president',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "# Define a sample text \n",
    "text = \"Barack Obama was the 44th president of the United States.\" \n",
    "\n",
    "# Tokenize the text \n",
    "tokens = nltk.word_tokenize(text) \n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58484fbb-d566-469a-a2d9-28c95c0fb51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Barack', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('44th', 'JJ'),\n",
       " ('president', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part-of-speech tag the tokens \n",
    "tagged = nltk.pos_tag(tokens) \n",
    "\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb71cf2e-1f61-404a-8220-41db02e9c5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Alienware\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Alienware\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,568.0,168.0\" width=\"568px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"11.2676%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Barack</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.6338%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"11.2676%\" x=\"11.2676%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Obama</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.9014%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"7.04225%\" x=\"22.5352%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">was</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"26.0563%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"7.04225%\" x=\"29.5775%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"33.0986%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.4507%\" x=\"36.6197%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">44th</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40.8451%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"15.493%\" x=\"45.0704%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">president</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"52.8169%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.6338%\" x=\"60.5634%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">of</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.3803%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"7.04225%\" x=\"66.1972%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.7183%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"22.5352%\" x=\"73.2394%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GPE</text></svg><svg width=\"50%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">United</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"50%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">States</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNPS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.507%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"4.22535%\" x=\"95.7746%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97.8873%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Barack', 'NNP')]), Tree('PERSON', [('Obama', 'NNP')]), ('was', 'VBD'), ('the', 'DT'), ('44th', 'JJ'), ('president', 'NN'), ('of', 'IN'), ('the', 'DT'), Tree('GPE', [('United', 'NNP'), ('States', 'NNPS')]), ('.', '.')])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "# Use the NLTK NER classifier to identify named entities \n",
    "named_entities = nltk.ne_chunk(tagged) \n",
    "\n",
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3800ed36-ffc5-4d34-9790-6afad708c788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON\n",
      "PERSON\n",
      "GPE\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the named entities and print their labels \n",
    "for entity in named_entities: \n",
    "  if hasattr(entity, \"label\"): \n",
    "    print(entity.label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ac25f-6671-4da6-9c29-d0f2dfe5cf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc6f87-c535-4ceb-8617-908a4b06e45b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1a387-2568-4def-88de-cdefb6b0c075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1574a6f-3240-45e9-9ae2-4fbe59779d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py309",
   "language": "python",
   "name": "py309"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
