{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333ac498-c76c-49a4-a36e-0453f258a0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 13:18:12.782917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750072692.805326   14164 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750072692.813312   14164 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750072692.832460   14164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750072692.832484   14164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750072692.832486   14164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750072692.832488   14164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/tmp/ipykernel_14164/1617902310.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python        3.10.18\n",
      "TensorFlow    2.19.0\n",
      "Visible GPUs  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750072704.251393   14164 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182a1d7b988a433dba6f1551c73ef965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?batch/s] – "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750072707.681321   14226 service.cc:152] XLA service 0x7283b8020a50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750072707.681369   14226 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1750072708.159009   14226 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU             → 203.39 s\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a07bc8476a47eb989608bc7ff86bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?batch/s] – "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750072932.534680   14230 service.cc:152] XLA service 0x7283a404c590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750072932.534750   14230 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 with Max-Q Design, Compute Capability 7.5\n",
      "I0000 00:00:1750072932.684313   14230 cuda_dnn.cc:529] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU FP32        →  10.35 s\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6be517ed7714119a04c27fed6e2ec72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?batch/s] – "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU mixed-FP16  →  14.73 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "One-cell benchmark\n",
    "──────────────────\n",
    "• Builds a tiny CNN\n",
    "• Trains it once on CPU, once on GPU FP32, once on GPU mixed-FP16\n",
    "• Shows a live tqdm bar that also prints *samples / second*,\n",
    "  running loss, and running accuracy.\n",
    "\"\"\"\n",
    "\n",
    "# ─────────────────────────  Imports  ──────────────────────────\n",
    "import os, time, platform, tensorflow as tf, numpy as np\n",
    "from tensorflow.keras import layers, mixed_precision\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# ─────────────────────  Environment report  ───────────────────\n",
    "print(f\"Python        {platform.python_version()}\")\n",
    "print(f\"TensorFlow    {tf.__version__}\")\n",
    "print(f\"Visible GPUs  {tf.config.list_physical_devices('GPU')}\")\n",
    "print()\n",
    "\n",
    "# ───────────────────────  Synthetic data  ─────────────────────\n",
    "BATCH = 512\n",
    "N_SAMPLES = 60_000\n",
    "\n",
    "x = np.random.rand(N_SAMPLES, 32, 32, 3).astype(\"float32\")\n",
    "y = np.random.randint(10, size=N_SAMPLES).astype(\"int32\")\n",
    "\n",
    "ds = (tf.data.Dataset\n",
    "        .from_tensor_slices((x, y))\n",
    "        .shuffle(4_096)\n",
    "        .batch(BATCH)\n",
    "        .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "# ───────────────────────  Build model  ────────────────────────\n",
    "def build_model(fp16=False):\n",
    "    if fp16:\n",
    "        mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    else:\n",
    "        mixed_precision.set_global_policy(\"float32\")\n",
    "\n",
    "    inp = layers.Input((32, 32, 3))\n",
    "    x   = layers.Conv2D(64, 3, activation=\"relu\")(inp)\n",
    "    x   = layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
    "    x   = layers.GlobalAveragePooling2D()(x)\n",
    "    out = layers.Dense(10)(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# ───────────────  Callback: tqdm + throughput  ────────────────\n",
    "class TqdmSpeed(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_steps):\n",
    "        super().__init__()\n",
    "        self.total_steps = total_steps\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.t0    = time.time()\n",
    "        self.bar   = tqdm(total=self.total_steps, unit=\"batch\",\n",
    "                          bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} \"\n",
    "                                     \"[{elapsed}<{remaining}, \"\n",
    "                                     \"{rate_fmt}] – {postfix}\")\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.bar.update(1)\n",
    "        seen = (batch + 1) * BATCH\n",
    "        samples_per_sec = seen / (time.time() - self.t0)\n",
    "        self.bar.set_postfix(\n",
    "            loss=f\"{logs['loss']:.3f}\",\n",
    "            acc=f\"{logs['accuracy']:.3f}\",\n",
    "            sps=f\"{samples_per_sec:,.0f}\"\n",
    "        )\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.bar.close()\n",
    "\n",
    "\n",
    "# ──────────────────────  Timing helper  ───────────────────────\n",
    "def time_one_epoch(device, *, fp16=False, label=\"\"):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    with tf.device(device):\n",
    "        model = build_model(fp16)\n",
    "        steps = int(np.ceil(N_SAMPLES / BATCH))\n",
    "        cb    = TqdmSpeed(steps)\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        model.fit(ds, epochs=1, verbose=0, callbacks=[cb])\n",
    "        secs  = time.perf_counter() - start\n",
    "\n",
    "    print(f\"{label:<15} → {secs:6.2f} s\\n\")\n",
    "\n",
    "\n",
    "# ─────────────────────────  Runs  ─────────────────────────────\n",
    "time_one_epoch(\"/CPU:0\",            label=\"CPU\")\n",
    "time_one_epoch(\"/GPU:0\",            label=\"GPU FP32\")\n",
    "time_one_epoch(\"/GPU:0\", fp16=True, label=\"GPU mixed-FP16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934cfc9-1822-455d-bfe2-0c1b387b2f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9481c-df48-4dc2-9d28-6f345e2dbbea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
