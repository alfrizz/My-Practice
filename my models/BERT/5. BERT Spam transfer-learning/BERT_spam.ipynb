{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933d5b39-984f-4197-8f4c-95287da2c961",
   "metadata": {},
   "source": [
    "Import Required Libraries & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d87192d-c99f-4a7f-9b65-9effa5c8cc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast, BertConfig, BertTokenizer, BertModel\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f6ee13-c551-4216-a054-1409bb721898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spamdata_v2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d56465-b9a7-404d-99bd-841614dea82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5572 non-null   int64 \n",
      " 1   text    5572 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d609f3-0f28-44a8-be75-9de3fe6d8ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.865937\n",
       "1    0.134063\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee60259-7fca-4805-be14-53482cff5a50",
   "metadata": {},
   "source": [
    "Split the Dataset into train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "523ff530-a8c6-4c87-a81b-21092d7904fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900,)\n",
      "(1672,)\n",
      "(836,)\n",
      "(836,)\n"
     ]
    }
   ],
   "source": [
    "# split train dataset into train, validation and test sets\n",
    "\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)\n",
    "\n",
    "print(train_text.shape)\n",
    "print(temp_text.shape)\n",
    "print(val_text.shape)\n",
    "print(test_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56922227-46e4-4652-92b6-1f01e00e2f46",
   "metadata": {},
   "source": [
    "Import Bert - base- uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e794b5ab-dd78-46be-b8f4-3d5093a9f262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6caa702a-f4f1-48ec-baa1-f4588f25375e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4661ae1-de3c-4b06-802b-f2a51ca78260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGdCAYAAAAIbpn/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtsUlEQVR4nO3dfXRU1aH+8WcCkwkgkxgoSaYGjNYqyqtQYnyrlZCAVFG51WhujS0XWkysmFYx/QFCfAkEixSkUO9S0CWodV1FRYoZQYlKDBDMVRApeql4C5PcGkOAlGRIzu+PWTlxDEJeJkx2+H7WYpU5Z589+zycxKdnMhOHZVmWAAAADBQR7gUAAAC0F0UGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGCsnuFeQGdpbGzUgQMH1LdvXzkcjnAvBwAAtIJlWTp8+LA8Ho8iIk59v6XbFpkDBw4oMTEx3MsAAADt8OWXX+qcc8455bhuW2T69u0rKRCE2+3u8Hx+v19FRUVKS0uT0+ns8HymIocAcmhGFgHkEEAOzcgioK051NTUKDEx0f7v+Kl02yLT9HKS2+0OWZHp3bu33G73GX9BkgM5fBNZBJBDADk0I4uA9ubQ2h8L4Yd9AQCAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIzVM9wLONOc+8Ab7T727/MnhnAlAACYjzsyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACM1eYiU1xcrOuvv14ej0cOh0Nr16619/n9fs2cOVNDhw5Vnz595PF4dMcdd+jAgQNBc1RVVSkzM1Nut1sxMTGaMmWKjhw5EjTmo48+0lVXXaWoqCglJiaqsLCwfWcIAAC6rTYXmaNHj2r48OFatmxZi321tbXasWOHZs+erR07dujll1/Wnj17dMMNNwSNy8zM1K5du+T1erVu3ToVFxdr2rRp9v6amhqlpaVp0KBBKisr08KFCzV37lw9+eST7ThFAADQXbX5c2QmTJigCRMmnHBfdHS0vF5v0LYnnnhCY8aM0f79+zVw4EDt3r1bGzZs0LZt2zR69GhJ0tKlS3Xdddfpsccek8fj0erVq1VfX6+nn35akZGRuuSSS1ReXq5FixYFFR4AAHBm6/QPxDt06JAcDodiYmIkSSUlJYqJibFLjCSlpqYqIiJCpaWluummm1RSUqKrr75akZGR9pj09HQtWLBAX3/9tc4+++wWz1NXV6e6ujr7cU1NjaTAy11+v7/D59E0R0fncvWwOryGcApVDqYjh2ZkEUAOAeTQjCwC2ppDW/Pq1CJz7NgxzZw5U7fddpvcbrckyefzacCAAcGL6NlTsbGx8vl89pikpKSgMXFxcfa+ExWZgoICzZs3r8X2oqIi9e7dOyTnI6nFHae2KhzT/mPXr1/foecOpY7m0F2QQzOyCCCHAHJoRhYBrc2htra2TfN2WpHx+/265ZZbZFmWli9f3llPY8vLy1Nubq79uKamRomJiUpLS7NLVEf4/X55vV6NGzdOTqez3fMMmftmu4/dOTe93ceGSqhyMB05NCOLAHIIIIdmZBHQ1hyaXlFprU4pMk0l5osvvtCmTZuCikR8fLwqKyuDxh8/flxVVVWKj4+3x1RUVASNaXrcNObbXC6XXC5Xi+1OpzOkF1BH56trcHToubuKUOdqKnJoRhYB5BBADs3IIqC1ObQ1q5B/jkxTidm7d6/eeust9evXL2h/SkqKqqurVVZWZm/btGmTGhsblZycbI8pLi4Oep3M6/XqwgsvPOHLSgAA4MzU5iJz5MgRlZeXq7y8XJK0b98+lZeXa//+/fL7/fq3f/s3bd++XatXr1ZDQ4N8Pp98Pp/q6+slSYMHD9b48eM1depUbd26Ve+//75ycnKUkZEhj8cjSbr99tsVGRmpKVOmaNeuXXrxxRf1xz/+MeilIwAAgDa/tLR9+3b95Cc/sR83lYusrCzNnTtXr732miRpxIgRQce9/fbbuuaaayRJq1evVk5OjsaOHauIiAhNnjxZS5YsscdGR0erqKhI2dnZGjVqlPr37685c+bw1msAABCkzUXmmmuukWV991uIT7avSWxsrNasWXPSMcOGDdO7777b1uUBAIAzCL9rCQAAGIsiAwAAjEWRAQAAxqLIAAAAY1FkAACAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYCyKDAAAMBZFBgAAGIsiAwAAjEWRAQAAxqLIAAAAY1FkAACAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFhtLjLFxcW6/vrr5fF45HA4tHbt2qD9lmVpzpw5SkhIUK9evZSamqq9e/cGjamqqlJmZqbcbrdiYmI0ZcoUHTlyJGjMRx99pKuuukpRUVFKTExUYWFh288OAAB0a20uMkePHtXw4cO1bNmyE+4vLCzUkiVLtGLFCpWWlqpPnz5KT0/XsWPH7DGZmZnatWuXvF6v1q1bp+LiYk2bNs3eX1NTo7S0NA0aNEhlZWVauHCh5s6dqyeffLIdpwgAALqrnm09YMKECZowYcIJ91mWpcWLF2vWrFmaNGmSJOnZZ59VXFyc1q5dq4yMDO3evVsbNmzQtm3bNHr0aEnS0qVLdd111+mxxx6Tx+PR6tWrVV9fr6efflqRkZG65JJLVF5erkWLFgUVHgAAcGZrc5E5mX379snn8yk1NdXeFh0dreTkZJWUlCgjI0MlJSWKiYmxS4wkpaamKiIiQqWlpbrppptUUlKiq6++WpGRkfaY9PR0LViwQF9//bXOPvvsFs9dV1enuro6+3FNTY0kye/3y+/3d/jcmubo6FyuHlaH1xBOocrBdOTQjCwCyCGAHJqRRUBbc2hrXiEtMj6fT5IUFxcXtD0uLs7e5/P5NGDAgOBF9Oyp2NjYoDFJSUkt5mjad6IiU1BQoHnz5rXYXlRUpN69e7fzjFryer0dOr5wTPuPXb9+fYeeO5Q6mkN3QQ7NyCKAHALIoRlZBLQ2h9ra2jbNG9IiE055eXnKzc21H9fU1CgxMVFpaWlyu90dnt/v98vr9WrcuHFyOp3tnmfI3DfbfezOuentPjZUQpWD6cihGVkEkEMAOTQji4C25tD0ikprhbTIxMfHS5IqKiqUkJBgb6+oqNCIESPsMZWVlUHHHT9+XFVVVfbx8fHxqqioCBrT9LhpzLe5XC65XK4W251OZ0gvoI7OV9fg6NBzdxWhztVU5NCMLALIIYAcmpFFQGtzaGtWIf0cmaSkJMXHx2vjxo32tpqaGpWWliolJUWSlJKSourqapWVldljNm3apMbGRiUnJ9tjiouLg14n83q9uvDCC0/4shIAADgztbnIHDlyROXl5SovL5cU+AHf8vJy7d+/Xw6HQzNmzNDDDz+s1157TR9//LHuuOMOeTwe3XjjjZKkwYMHa/z48Zo6daq2bt2q999/Xzk5OcrIyJDH45Ek3X777YqMjNSUKVO0a9cuvfjii/rjH/8Y9NIRAABAm19a2r59u37yk5/Yj5vKRVZWllatWqX7779fR48e1bRp01RdXa0rr7xSGzZsUFRUlH3M6tWrlZOTo7FjxyoiIkKTJ0/WkiVL7P3R0dEqKipSdna2Ro0apf79+2vOnDm89RoAAARpc5G55pprZFnf/RZih8Oh/Px85efnf+eY2NhYrVmz5qTPM2zYML377rttXR4AADiD8LuWAACAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYCyKDAAAMBZFBgAAGIsiAwAAjEWRAQAAxqLIAAAAY1FkAACAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYCyKDAAAMBZFBgAAGIsiAwAAjBXyItPQ0KDZs2crKSlJvXr10vnnn6+HHnpIlmXZYyzL0pw5c5SQkKBevXopNTVVe/fuDZqnqqpKmZmZcrvdiomJ0ZQpU3TkyJFQLxcAABgs5EVmwYIFWr58uZ544gnt3r1bCxYsUGFhoZYuXWqPKSws1JIlS7RixQqVlpaqT58+Sk9P17Fjx+wxmZmZ2rVrl7xer9atW6fi4mJNmzYt1MsFAAAG6xnqCbds2aJJkyZp4sSJkqRzzz1Xzz//vLZu3SopcDdm8eLFmjVrliZNmiRJevbZZxUXF6e1a9cqIyNDu3fv1oYNG7Rt2zaNHj1akrR06VJdd911euyxx+TxeEK9bAAAYKCQF5nLL79cTz75pP72t7/phz/8of77v/9b7733nhYtWiRJ2rdvn3w+n1JTU+1joqOjlZycrJKSEmVkZKikpEQxMTF2iZGk1NRURUREqLS0VDfddFOL562rq1NdXZ39uKamRpLk9/vl9/s7fF5Nc3R0LlcP69SDTrGGcApVDqYjh2ZkEUAOAeTQjCwC2ppDW/MKeZF54IEHVFNTo4suukg9evRQQ0ODHnnkEWVmZkqSfD6fJCkuLi7ouLi4OHufz+fTgAEDghfas6diY2PtMd9WUFCgefPmtdheVFSk3r17d/i8mni93g4dXzim/ceuX7++Q88dSh3Nobsgh2ZkEUAOAeTQjCwCWptDbW1tm+YNeZH5y1/+otWrV2vNmjW65JJLVF5erhkzZsjj8SgrKyvUT2fLy8tTbm6u/bimpkaJiYlKS0uT2+3u8Px+v19er1fjxo2T0+ls9zxD5r7Z7mN3zk1v97GhEqocTEcOzcgigBwCyKEZWQS0NYemV1RaK+RF5r777tMDDzygjIwMSdLQoUP1xRdfqKCgQFlZWYqPj5ckVVRUKCEhwT6uoqJCI0aMkCTFx8ersrIyaN7jx4+rqqrKPv7bXC6XXC5Xi+1OpzOkF1BH56trcHToubuKUOdqKnJoRhYB5BBADs3IIqC1ObQ1q5C/a6m2tlYREcHT9ujRQ42NjZKkpKQkxcfHa+PGjfb+mpoalZaWKiUlRZKUkpKi6upqlZWV2WM2bdqkxsZGJScnh3rJAADAUCG/I3P99dfrkUce0cCBA3XJJZfoww8/1KJFi/TLX/5SkuRwODRjxgw9/PDDuuCCC5SUlKTZs2fL4/HoxhtvlCQNHjxY48eP19SpU7VixQr5/X7l5OQoIyODdywBAABbyIvM0qVLNXv2bN11112qrKyUx+PRr371K82ZM8cec//99+vo0aOaNm2aqqurdeWVV2rDhg2Kioqyx6xevVo5OTkaO3asIiIiNHnyZC1ZsiTUywUAAAYLeZHp27evFi9erMWLF3/nGIfDofz8fOXn53/nmNjYWK1ZsybUywMAAN0Iv2sJAAAYK+R3ZM4E5z7wRriXAAAAxB0ZAABgMIoMAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYCyKDAAAMBZFBgAAGIsiAwAAjEWRAQAAxqLIAAAAY1FkAACAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYCyKDAAAMBZFBgAAGIsiAwAAjNUpReYf//iH/v3f/139+vVTr169NHToUG3fvt3eb1mW5syZo4SEBPXq1Uupqanau3dv0BxVVVXKzMyU2+1WTEyMpkyZoiNHjnTGcgEAgKFCXmS+/vprXXHFFXI6nfrrX/+qTz75RH/4wx909tln22MKCwu1ZMkSrVixQqWlperTp4/S09N17Ngxe0xmZqZ27dolr9erdevWqbi4WNOmTQv1cgEAgMF6hnrCBQsWKDExUStXrrS3JSUl2X+3LEuLFy/WrFmzNGnSJEnSs88+q7i4OK1du1YZGRnavXu3NmzYoG3btmn06NGSpKVLl+q6667TY489Jo/HE+plAwAAA4W8yLz22mtKT0/Xz372M23evFnf//73ddddd2nq1KmSpH379snn8yk1NdU+Jjo6WsnJySopKVFGRoZKSkoUExNjlxhJSk1NVUREhEpLS3XTTTe1eN66ujrV1dXZj2tqaiRJfr9ffr+/w+fVNIff75erh9Xh+TqyhnD6Zg5nMnJoRhYB5BBADs3IIqCtObQ1r5AXmf/5n//R8uXLlZubq9///vfatm2bfvOb3ygyMlJZWVny+XySpLi4uKDj4uLi7H0+n08DBgwIXmjPnoqNjbXHfFtBQYHmzZvXYntRUZF69+4dilOTJHm9XhWOCdl0bbJ+/frwPPEJeL3ecC+hSyCHZmQRQA4B5NCMLAJam0NtbW2b5g15kWlsbNTo0aP16KOPSpJGjhypnTt3asWKFcrKygr109ny8vKUm5trP66pqVFiYqLS0tLkdrs7PL/f75fX69W4ceM08pFNHZ6vPXbOTQ/L837TN3NwOp3hXk7YkEMzsggghwByaEYWAW3NoekVldYKeZFJSEjQxRdfHLRt8ODB+q//+i9JUnx8vCSpoqJCCQkJ9piKigqNGDHCHlNZWRk0x/Hjx1VVVWUf/20ul0sul6vFdqfTGdILyOl0qq7BEbL52vrcXUWoczUVOTQjiwByCCCHZmQR0Noc2ppVyN+1dMUVV2jPnj1B2/72t79p0KBBkgI/+BsfH6+NGzfa+2tqalRaWqqUlBRJUkpKiqqrq1VWVmaP2bRpkxobG5WcnBzqJQMAAEOF/I7Mvffeq8svv1yPPvqobrnlFm3dulVPPvmknnzySUmSw+HQjBkz9PDDD+uCCy5QUlKSZs+eLY/HoxtvvFFS4A7O+PHjNXXqVK1YsUJ+v185OTnKyMjgHUsAAMAW8iLzox/9SK+88ory8vKUn5+vpKQkLV68WJmZmfaY+++/X0ePHtW0adNUXV2tK6+8Uhs2bFBUVJQ9ZvXq1crJydHYsWMVERGhyZMna8mSJaFeLgAAMFjIi4wk/fSnP9VPf/rT79zvcDiUn5+v/Pz87xwTGxurNWvWdMbyAABAN8HvWgIAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYCyKDAAAMBZFBgAAGIsiAwAAjNUpH4iH7ufcB96QJLl6WCocIw2Z+2arf3nm3+dP7MylAQDOYNyRAQAAxqLIAAAAY1FkAACAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYi8+RMUjTZ7m0B5/lAgDojrgjAwAAjEWRAQAAxqLIAAAAY1FkAACAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACMxSf7niE68qnAAAB0VdyRAQAAxqLIAAAAY1FkAACAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLE6vcjMnz9fDodDM2bMsLcdO3ZM2dnZ6tevn8466yxNnjxZFRUVQcft379fEydOVO/evTVgwADdd999On78eGcvFwAAGKRTi8y2bdv05z//WcOGDQvafu+99+r111/XSy+9pM2bN+vAgQO6+eab7f0NDQ2aOHGi6uvrtWXLFj3zzDNatWqV5syZ05nLBQAAhum0InPkyBFlZmbqP//zP3X22Wfb2w8dOqSnnnpKixYt0rXXXqtRo0Zp5cqV2rJliz744ANJUlFRkT755BM999xzGjFihCZMmKCHHnpIy5YtU319fWctGQAAGKZnZ02cnZ2tiRMnKjU1VQ8//LC9vaysTH6/X6mpqfa2iy66SAMHDlRJSYkuu+wylZSUaOjQoYqLi7PHpKena/r06dq1a5dGjhzZ4vnq6upUV1dnP66pqZEk+f1++f3+Dp9P0xx+v1+uHlaH5zOVK8IK+t/WCEX+Xc03r4czHVkEkEMAOTQji4C25tDWvDqlyLzwwgvasWOHtm3b1mKfz+dTZGSkYmJigrbHxcXJ5/PZY75ZYpr2N+07kYKCAs2bN6/F9qKiIvXu3bs9p3FCXq9XhWNCNp2xHhrd2Oqx69ev78SVhJfX6w33EroMsggghwByaEYWAa3Noba2tk3zhrzIfPnll7rnnnvk9XoVFRUV6um/U15ennJzc+3HNTU1SkxMVFpamtxud4fn9/v98nq9GjdunEY+sqnD85nKFWHpodGNmr09QnWNjlYds3Nueiev6vT75vXgdDrDvZywIosAcgggh2ZkEdDWHJpeUWmtkBeZsrIyVVZW6tJLL7W3NTQ0qLi4WE888YTefPNN1dfXq7q6OuiuTEVFheLj4yVJ8fHx2rp1a9C8Te9qahrzbS6XSy6Xq8V2p9MZ0gvI6XSqrqF1/wHvzuoaHa3OoTt/AYf6+jIZWQSQQwA5NCOLgNbm0NasQv7DvmPHjtXHH3+s8vJy+8/o0aOVmZlp/93pdGrjxo32MXv27NH+/fuVkpIiSUpJSdHHH3+syspKe4zX65Xb7dbFF18c6iUDAABDhfyOTN++fTVkyJCgbX369FG/fv3s7VOmTFFubq5iY2Pldrt19913KyUlRZdddpkkKS0tTRdffLF+/vOfq7CwUD6fT7NmzVJ2dvYJ77oAAIAzU6e9a+lkHn/8cUVERGjy5Mmqq6tTenq6/vSnP9n7e/TooXXr1mn69OlKSUlRnz59lJWVpfz8/HAsFwAAdFGnpci88847QY+joqK0bNkyLVu27DuPGTRoULd+twsAAOg4ftcSAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYCyKDAAAMBZFBgAAGIsiAwAAjEWRAQAAxqLIAAAAY1FkAACAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYCyKDAAAMBZFBgAAGIsiAwAAjEWRAQAAxqLIAAAAY1FkAACAsXqGesKCggK9/PLL+vTTT9WrVy9dfvnlWrBggS688EJ7zLFjx/Tb3/5WL7zwgurq6pSenq4//elPiouLs8fs379f06dP19tvv62zzjpLWVlZKigoUM+eIV8yOtm5D7zR7mP/Pn9iCFcCAOhuQn5HZvPmzcrOztYHH3wgr9crv9+vtLQ0HT161B5z77336vXXX9dLL72kzZs368CBA7r55pvt/Q0NDZo4caLq6+u1ZcsWPfPMM1q1apXmzJkT6uUCAACDhfz2xoYNG4Ier1q1SgMGDFBZWZmuvvpqHTp0SE899ZTWrFmja6+9VpK0cuVKDR48WB988IEuu+wyFRUV6ZNPPtFbb72luLg4jRgxQg899JBmzpypuXPnKjIyMtTLBgAABur012kOHTokSYqNjZUklZWVye/3KzU11R5z0UUXaeDAgSopKdFll12mkpISDR06NOilpvT0dE2fPl27du3SyJEjWzxPXV2d6urq7Mc1NTWSJL/fL7/f3+HzaJrD7/fL1cPq8HymckVYQf/b2ULxb9cZvnk9nOnIIoAcAsihGVkEtDWHtubVqUWmsbFRM2bM0BVXXKEhQ4ZIknw+nyIjIxUTExM0Ni4uTj6fzx7zzRLTtL9p34kUFBRo3rx5LbYXFRWpd+/eHT0Vm9frVeGYkE1nrIdGN56W51m/fv1peZ728nq94V5Cl0EWAeQQQA7NyCKgtTnU1ta2ad5OLTLZ2dnauXOn3nvvvc58GklSXl6ecnNz7cc1NTVKTExUWlqa3G53h+f3+/3yer0aN26cRj6yqcPzmcoVYemh0Y2avT1CdY2OTn++nXPTO/052uOb14PT6Qz3csKKLALIIYAcmpFFQFtzaHpFpbU6rcjk5ORo3bp1Ki4u1jnnnGNvj4+PV319vaqrq4PuylRUVCg+Pt4es3Xr1qD5Kioq7H0n4nK55HK5Wmx3Op0hvYCcTqfqGjr/P+BdXV2j47Tk0NW/+EN9fZmMLALIIYAcmpFFQGtzaGtWIX/XkmVZysnJ0SuvvKJNmzYpKSkpaP+oUaPkdDq1ceNGe9uePXu0f/9+paSkSJJSUlL08ccfq7Ky0h7j9Xrldrt18cUXh3rJAADAUCG/I5Odna01a9bo1VdfVd++fe2faYmOjlavXr0UHR2tKVOmKDc3V7GxsXK73br77ruVkpKiyy67TJKUlpamiy++WD//+c9VWFgon8+nWbNmKTs7+4R3XQAAwJkp5EVm+fLlkqRrrrkmaPvKlSt15513SpIef/xxRUREaPLkyUEfiNekR48eWrdunaZPn66UlBT16dNHWVlZys/PD/VyAQCAwUJeZCzr1G/LjYqK0rJly7Rs2bLvHDNo0KAu/44VAAAQXvyuJQAAYCyKDAAAMBZFBgAAGIsiAwAAjEWRAQAAxqLIAAAAY1FkAACAsSgyAADAWBQZAABgLIoMAAAwFkUGAAAYiyIDAACMRZEBAADGosgAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYCyKDAAAMBZFBgAAGIsiAwAAjEWRAQAAxqLIAAAAY1FkAACAsSgyAADAWBQZAABgrJ7hXgBwMuc+8Ea7j/37/IkhXAkAoCvijgwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYCyKDAAAMBZFBgAAGItfUYBui19vAADdH3dkAACAsbr0HZlly5Zp4cKF8vl8Gj58uJYuXaoxY8aEe1lAp+EuEgC0TZe9I/Piiy8qNzdXDz74oHbs2KHhw4crPT1dlZWV4V4aAADoIrrsHZlFixZp6tSp+sUvfiFJWrFihd544w09/fTTeuCBB8K8OuC7deSuCgCgbbpkkamvr1dZWZny8vLsbREREUpNTVVJSckJj6mrq1NdXZ39+NChQ5Kkqqoq+f3+Dq/J7/ertrZWX331lXoeP9rh+UzVs9FSbW2jevoj1NDoCPdyOs0PfveXk+53RViaNbJRI/7fy6r7Vg7h+qL66quv2n1scsHGdh97sixOpTRvbLuftyM6cr7fteZvfo9wOp3tnt905NCMLALamsPhw4clSZZltWr+Lllk/vnPf6qhoUFxcXFB2+Pi4vTpp5+e8JiCggLNmzevxfakpKROWeOZ7PZwL6CL6Go59P9D+J67vVmEc83tZeKaARMdPnxY0dHRpxzXJYtMe+Tl5Sk3N9d+3NjYqKqqKvXr108OR8fvHNTU1CgxMVFffvml3G53h+czFTkEkEMzsggghwByaEYWAW3NwbIsHT58WB6Pp1Xzd8ki079/f/Xo0UMVFRVB2ysqKhQfH3/CY1wul1wuV9C2mJiYkK/N7Xaf0RdkE3IIIIdmZBFADgHk0IwsAtqSQ2vuxDTpku9aioyM1KhRo7RxY/Pr2I2Njdq4caNSUlLCuDIAANCVdMk7MpKUm5urrKwsjR49WmPGjNHixYt19OhR+11MAAAAXbbI3Hrrrfq///s/zZkzRz6fTyNGjNCGDRta/ADw6eJyufTggw+2ePnqTEMOAeTQjCwCyCGAHJqRRUBn5+CwWvv+JgAAgC6mS/6MDAAAQGtQZAAAgLEoMgAAwFgUGQAAYCyKTCssW7ZM5557rqKiopScnKytW7eGe0mdqqCgQD/60Y/Ut29fDRgwQDfeeKP27NkTNOaaa66Rw+EI+vPrX/86TCvuPHPnzm1xnhdddJG9/9ixY8rOzla/fv101llnafLkyS0+yLE7OPfcc1vk4HA4lJ2dLan7Xg/FxcW6/vrr5fF45HA4tHbt2qD9lmVpzpw5SkhIUK9evZSamqq9e/cGjamqqlJmZqbcbrdiYmI0ZcoUHTly5DSeRWicLAu/36+ZM2dq6NCh6tOnjzwej+644w4dOHAgaI4TXUfz588/zWfSMae6Ju68884W5zh+/PigMd3hmjhVDif6fuFwOLRw4UJ7TKiuB4rMKbz44ovKzc3Vgw8+qB07dmj48OFKT09XZWVluJfWaTZv3qzs7Gx98MEH8nq98vv9SktL09Gjwb8sc+rUqTp48KD9p7CwMEwr7lyXXHJJ0Hm+99579r57771Xr7/+ul566SVt3rxZBw4c0M033xzG1XaObdu2BWXg9XolST/72c/sMd3xejh69KiGDx+uZcuWnXB/YWGhlixZohUrVqi0tFR9+vRRenq6jh07Zo/JzMzUrl275PV6tW7dOhUXF2vatGmn6xRC5mRZ1NbWaseOHZo9e7Z27Nihl19+WXv27NENN9zQYmx+fn7QdXL33XefjuWHzKmuCUkaP3580Dk+//zzQfu7wzVxqhy+ef4HDx7U008/LYfDocmTJweNC8n1YOGkxowZY2VnZ9uPGxoaLI/HYxUUFIRxVadXZWWlJcnavHmzve3HP/6xdc8994RvUafJgw8+aA0fPvyE+6qrqy2n02m99NJL9rbdu3dbkqySkpLTtMLwuOeee6zzzz/famxstCzrzLgeJFmvvPKK/bixsdGKj4+3Fi5caG+rrq62XC6X9fzzz1uWZVmffPKJJcnatm2bPeavf/2r5XA4rH/84x+nbe2h9u0sTmTr1q2WJOuLL76wtw0aNMh6/PHHO3dxp9GJcsjKyrImTZr0ncd0x2uiNdfDpEmTrGuvvTZoW6iuB+7InER9fb3KysqUmppqb4uIiFBqaqpKSkrCuLLT69ChQ5Kk2NjYoO2rV69W//79NWTIEOXl5am2tjYcy+t0e/fulcfj0XnnnafMzEzt379fklRWVia/3x90fVx00UUaOHBgt74+6uvr9dxzz+mXv/xl0C9kPVOuhyb79u2Tz+cL+vePjo5WcnKy/e9fUlKimJgYjR492h6TmpqqiIgIlZaWnvY1n06HDh2Sw+Fo8Tvv5s+fr379+mnkyJFauHChjh8/Hp4FdqJ33nlHAwYM0IUXXqjp06frq6++svediddERUWF3njjDU2ZMqXFvlBcD132k327gn/+859qaGho8WnCcXFx+vTTT8O0qtOrsbFRM2bM0BVXXKEhQ4bY22+//XYNGjRIHo9HH330kWbOnKk9e/bo5ZdfDuNqQy85OVmrVq3ShRdeqIMHD2revHm66qqrtHPnTvl8PkVGRrb4Rh0XFyefzxeeBZ8Ga9euVXV1te68805725lyPXxT07/xib4/NO3z+XwaMGBA0P6ePXsqNja2W18jx44d08yZM3XbbbcF/ZLA3/zmN7r00ksVGxurLVu2KC8vTwcPHtSiRYvCuNrQGj9+vG6++WYlJSXp888/1+9//3tNmDBBJSUl6tGjxxl5TTzzzDPq27dvi5fdQ3U9UGRwUtnZ2dq5c2fQz4VICno9d+jQoUpISNDYsWP1+eef6/zzzz/dy+w0EyZMsP8+bNgwJScna9CgQfrLX/6iXr16hXFl4fPUU09pwoQJ8ng89rYz5XrAqfn9ft1yyy2yLEvLly8P2pebm2v/fdiwYYqMjNSvfvUrFRQUdJuP8c/IyLD/PnToUA0bNkznn3++3nnnHY0dOzaMKwufp59+WpmZmYqKigraHqrrgZeWTqJ///7q0aNHi3ehVFRUKD4+PkyrOn1ycnK0bt06vf322zrnnHNOOjY5OVmS9Nlnn52OpYVNTEyMfvjDH+qzzz5TfHy86uvrVV1dHTSmO18fX3zxhd566y39x3/8x0nHnQnXQ9O/8cm+P8THx7d4Y8Dx48dVVVXVLa+RphLzxRdfyOv1Bt2NOZHk5GQdP35cf//730/PAsPgvPPOU//+/e2vhTPtmnj33Xe1Z8+eU37PkNp/PVBkTiIyMlKjRo3Sxo0b7W2NjY3auHGjUlJSwriyzmVZlnJycvTKK69o06ZNSkpKOuUx5eXlkqSEhIROXl14HTlyRJ9//rkSEhI0atQoOZ3OoOtjz5492r9/f7e9PlauXKkBAwZo4sSJJx13JlwPSUlJio+PD/r3r6mpUWlpqf3vn5KSourqapWVldljNm3apMbGRrvsdRdNJWbv3r1666231K9fv1MeU15eroiIiBYvtXQn//u//6uvvvrK/lo4k64JKXAHd9SoURo+fPgpx7b7eujwjwt3cy+88ILlcrmsVatWWZ988ok1bdo0KyYmxvL5fOFeWqeZPn26FR0dbb3zzjvWwYMH7T+1tbWWZVnWZ599ZuXn51vbt2+39u3bZ7366qvWeeedZ1199dVhXnno/fa3v7Xeeecda9++fdb7779vpaamWv3797cqKysty7KsX//619bAgQOtTZs2Wdu3b7dSUlKslJSUMK+6czQ0NFgDBw60Zs6cGbS9O18Phw8ftj788EPrww8/tCRZixYtsj788EP7nTjz58+3YmJirFdffdX66KOPrEmTJllJSUnWv/71L3uO8ePHWyNHjrRKS0ut9957z7rgggus2267LVyn1G4ny6K+vt664YYbrHPOOccqLy8P+r5RV1dnWZZlbdmyxXr88cet8vJy6/PPP7eee+4563vf+551xx13hPnM2uZkORw+fNj63e9+Z5WUlFj79u2z3nrrLevSSy+1LrjgAuvYsWP2HN3hmjjV14ZlWdahQ4es3r17W8uXL29xfCivB4pMKyxdutQaOHCgFRkZaY0ZM8b64IMPwr2kTiXphH9WrlxpWZZl7d+/37r66qut2NhYy+VyWT/4wQ+s++67zzp06FB4F94Jbr31VishIcGKjIy0vv/971u33nqr9dlnn9n7//Wvf1l33XWXdfbZZ1u9e/e2brrpJuvgwYNhXHHnefPNNy1J1p49e4K2d+fr4e233z7h10JWVpZlWYG3YM+ePduKi4uzXC6XNXbs2Bb5fPXVV9Ztt91mnXXWWZbb7bZ+8YtfWIcPHw7D2XTMybLYt2/fd37fePvtty3LsqyysjIrOTnZio6OtqKioqzBgwdbjz76aNB/4E1wshxqa2uttLQ063vf+57ldDqtQYMGWVOnTm3xf3y7wzVxqq8Ny7KsP//5z1avXr2s6urqFseH8npwWJZlte0eDgAAQNfAz8gAAABjUWQAAICxKDIAAMBYFBkAAGAsigwAADAWRQYAABiLIgMAAIxFkQEAAMaiyAAAAGNRZAAAgLEoMgAAwFgUGQAAYKz/D2yq2avdAKOAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fcdfa4-0b72-4d0f-b7c1-9a3bbd900c16",
   "metadata": {},
   "source": [
    "Tokenize & Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be9d95c-11a6-42ed-b1eb-7e604336b16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alienware\\miniconda3\\envs\\py310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "Please attend the phone:)\n",
      "[101, 3531, 5463, 1996, 3042, 1024, 1007, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "print(len(tokens_train['input_ids']))# 3900 sentences in the training set, that will be divided in 121 batches of size 32 plus 1 last batch of size 28 (see code below)\n",
    "print(tokens_train.keys())\n",
    "print(train_text.tolist()[44])\n",
    "print(tokens_train['input_ids'][44])\n",
    "print(tokens_train['token_type_ids'][44])\n",
    "print(tokens_train['attention_mask'][44])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf6dc9-03de-476e-8ea2-387024514d49",
   "metadata": {},
   "source": [
    "Test Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4179bb5-db1c-4204-8752-b00bf72e6c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text: Sorry, I'll call later\n",
      "-\n",
      "KEY: input_ids\n",
      "VALUE: [101, 3374, 1010, 1045, 1005, 2222, 2655, 2101, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "DECODE: [CLS] sorry, i'll call later [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "CONVERTtoTOKENS: ['[CLS]', 'sorry', ',', 'i', \"'\", 'll', 'call', 'later', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "LABEL: 0\n",
      "-\n",
      "KEY: token_type_ids\n",
      "VALUE: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "DECODE: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "CONVERTtoTOKENS: ['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "LABEL: 0\n",
      "-\n",
      "KEY: attention_mask\n",
      "VALUE: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "DECODE: [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "CONVERTtoTOKENS: ['[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "LABEL: 0\n",
      "----------------\n",
      "similar text: [\"Sorry, I'lll call later\"]\n",
      "-\n",
      "KEY: input_ids\n",
      "VALUE: [101, 3374, 1010, 1045, 1005, 2222, 2140, 2655, 2101, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "DECODE: [CLS] sorry, i'lll call later [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "CONVERTtoTOKENS: ['[CLS]', 'sorry', ',', 'i', \"'\", 'll', '##l', 'call', 'later', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "-\n",
      "KEY: token_type_ids\n",
      "VALUE: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "DECODE: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "CONVERTtoTOKENS: ['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "-\n",
      "KEY: attention_mask\n",
      "VALUE: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "DECODE: [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "CONVERTtoTOKENS: ['[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "----------------------------------------------------------------------------------\n",
      "Himalayas text: where is Himalayas in the world map?\n",
      "-\n",
      "KEY: input_ids\n",
      "VALUE: [101, 2073, 2003, 26779, 1999, 1996, 2088, 4949, 1029, 102]\n",
      "DECODE: [CLS] where is himalayas in the world map? [SEP]\n",
      "CONVERTtoTOKENS: ['[CLS]', 'where', 'is', 'himalayas', 'in', 'the', 'world', 'map', '?', '[SEP]']\n",
      "-\n",
      "KEY: token_type_ids\n",
      "VALUE: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "DECODE: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "CONVERTtoTOKENS: ['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "-\n",
      "KEY: attention_mask\n",
      "VALUE: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "DECODE: [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0]\n",
      "CONVERTtoTOKENS: ['[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]']\n",
      "----------------\n",
      "Himalayass text: where is Himalayass in the world map?\n",
      "-\n",
      "KEY: input_ids\n",
      "VALUE: [101, 2073, 2003, 26779, 2015, 1999, 1996, 2088, 4949, 1029, 102]\n",
      "DECODE: [CLS] where is himalayass in the world map? [SEP]\n",
      "CONVERTtoTOKENS: ['[CLS]', 'where', 'is', 'himalayas', '##s', 'in', 'the', 'world', 'map', '?', '[SEP]']\n",
      "-\n",
      "KEY: token_type_ids\n",
      "VALUE: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "DECODE: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "CONVERTtoTOKENS: ['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "-\n",
      "KEY: attention_mask\n",
      "VALUE: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "DECODE: [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0]\n",
      "CONVERTtoTOKENS: ['[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]']\n",
      "----------------------------------------------------------------------------------\n",
      "double text: Who was Tony Stark? Anthony Edward Stark known as Tony Stark is a fictional character in Avengers\n",
      "-\n",
      "KEY: input_ids\n",
      "VALUE: [101, 2040, 2001, 4116, 9762, 1029, 102, 4938, 3487, 9762, 2124, 2004, 4116, 9762, 2003, 1037, 7214, 2839, 1999, 14936, 102]\n",
      "DECODE: [CLS] who was tony stark? [SEP] anthony edward stark known as tony stark is a fictional character in avengers [SEP]\n",
      "CONVERTtoTOKENS: ['[CLS]', 'who', 'was', 'tony', 'stark', '?', '[SEP]', 'anthony', 'edward', 'stark', 'known', 'as', 'tony', 'stark', 'is', 'a', 'fictional', 'character', 'in', 'avengers', '[SEP]']\n",
      "-\n",
      "KEY: token_type_ids\n",
      "VALUE: [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "DECODE: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0]\n",
      "CONVERTtoTOKENS: ['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]']\n",
      "-\n",
      "KEY: attention_mask\n",
      "VALUE: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "DECODE: [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0]\n",
      "CONVERTtoTOKENS: ['[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]', '[unused0]']\n"
     ]
    }
   ],
   "source": [
    "print(\"train text:\", train_text.tolist()[8])\n",
    "for key, value in tokens_train.items():\n",
    "    print( '-\\nKEY: {}\\nVALUE: {}\\nDECODE: {}\\nCONVERTtoTOKENS: {}\\nLABEL: {}'.\n",
    "          format(key, value[8], tokenizer.decode(value[8]),tokenizer.convert_ids_to_tokens(value[8]),train_labels.values[8])) \n",
    "    \n",
    "print(\"----------------\")    \n",
    "\n",
    "similar = [\"Sorry, I'lll call later\"]\n",
    "print(\"similar text:\", similar)\n",
    "token_similar = tokenizer.batch_encode_plus(list(similar), max_length = 25, pad_to_max_length=True, truncation=True) #padding = True\n",
    "for key, value in token_similar.items():\n",
    "    print( '-\\nKEY: {}\\nVALUE: {}\\nDECODE: {}\\nCONVERTtoTOKENS: {}'.\n",
    "          format(key, value[0], tokenizer.decode(value[0]),tokenizer.convert_ids_to_tokens(value[0]))) \n",
    "\n",
    "print(\"----------------------------------------------------------------------------------\")    \n",
    "\n",
    "Himalayas = \"where is Himalayas in the world map?\"\n",
    "print(\"Himalayas text:\", Himalayas)\n",
    "token_Himalayas = tokenizer.encode_plus(Himalayas)\n",
    "for key, value in token_Himalayas.items():\n",
    "    print( '-\\nKEY: {}\\nVALUE: {}\\nDECODE: {}\\nCONVERTtoTOKENS: {}'.\n",
    "          format(key, value, tokenizer.decode(value),tokenizer.convert_ids_to_tokens(value))) \n",
    "    \n",
    "print(\"----------------\")    \n",
    "\n",
    "Himalayass = \"where is Himalayass in the world map?\"\n",
    "print(\"Himalayass text:\", Himalayass)\n",
    "token_Himalayass = tokenizer.encode_plus(Himalayass)\n",
    "for key, value in token_Himalayass.items():\n",
    "    print( '-\\nKEY: {}\\nVALUE: {}\\nDECODE: {}\\nCONVERTtoTOKENS: {}'.\n",
    "          format(key, value, tokenizer.decode(value),tokenizer.convert_ids_to_tokens(value))) \n",
    "    \n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "\n",
    "q1 = 'Who was Tony Stark?'\n",
    "c1 = 'Anthony Edward Stark known as Tony Stark is a fictional character in Avengers'\n",
    "print(\"double text:\", q1, c1)\n",
    "encoding = tokenizer.encode_plus(q1, c1)\n",
    "for key, value in encoding.items():\n",
    "    print( '-\\nKEY: {}\\nVALUE: {}\\nDECODE: {}\\nCONVERTtoTOKENS: {}'.\n",
    "          format(key, value, tokenizer.decode(value),tokenizer.convert_ids_to_tokens(value))) \n",
    "    \n",
    "\n",
    "# #another example\n",
    "\n",
    "# sent_idx = 7\n",
    "# print(\"train text:\", train_text.tolist()[sent_idx])\n",
    "# for key, value in tokens_train.items():\n",
    "#     print( '-\\nKEY: {}\\nVALUE: {}\\nDECODE: {}\\nCONVERTtoTOKENS: {}\\nLABEL: {}'.\n",
    "#           format(key, value[sent_idx], tokenizer.decode(value[sent_idx]),tokenizer.convert_ids_to_tokens(value[sent_idx]),test_labels.values[sent_idx]))     \n",
    "# print('-------------')    \n",
    "# print(test_seq[sent_idx])\n",
    "# print(test_ids[sent_idx])\n",
    "# print(test_mask[sent_idx])\n",
    "# print(test_y[sent_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ea873-a872-404a-9fbf-71e035519abc",
   "metadata": {},
   "source": [
    "List to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc380861-d02b-4664-b426-4917d5dc7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids']).cuda()\n",
    "train_ids = torch.tensor(tokens_train['token_type_ids']).cuda()\n",
    "train_mask = torch.tensor(tokens_train['attention_mask']).cuda()\n",
    "train_y = torch.tensor(train_labels.tolist()).cuda()\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids']).cuda()\n",
    "val_ids = torch.tensor(tokens_val['token_type_ids']).cuda()\n",
    "val_mask = torch.tensor(tokens_val['attention_mask']).cuda()\n",
    "val_y = torch.tensor(val_labels.tolist()).cuda()\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids']).cuda()\n",
    "test_ids = torch.tensor(tokens_test['token_type_ids']).cuda()\n",
    "test_mask = torch.tensor(tokens_test['attention_mask']).cuda()\n",
    "test_y = torch.tensor(test_labels.tolist()).cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a6d2a-31ab-46a0-928a-4f560d9f77b7",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bbe26e0-cadb-4cc1-b694-a118284411bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterating over the RandomSampler\n",
      "count: 0 sample: 565\n",
      "count: 1 sample: 3009\n",
      "count: 2 sample: 1415\n",
      "count: 3 sample: 1945\n",
      "count: 4 sample: 47\n",
      "count: 5 sample: 441\n",
      "iterating over the SequentialSampler\n",
      "count: 0 sample: 0\n",
      "count: 1 sample: 1\n",
      "count: 2 sample: 2\n",
      "count: 3 sample: 3\n",
      "count: 4 sample: 4\n",
      "count: 5 sample: 5\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x00000236CE5C6440>\n",
      "<torch.utils.data.sampler.RandomSampler object at 0x00000236CE5C65C0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000236CE5C64D0>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x00000236CE61AE90>\n",
      "<torch.utils.data.sampler.SequentialSampler object at 0x00000236CF6C65F0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000236CF6C5120>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "#Every DataLoader has a Sampler which is used internally to get the indices for each batch\n",
    "\n",
    "# sampler for sampling the data during training (shuffled random indexes)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "print('iterating over the RandomSampler')\n",
    "for count, sample in enumerate(train_sampler):\n",
    "        print('count:', count, 'sample:',sample)\n",
    "        if (count >= 5):\n",
    "            break\n",
    "    \n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during validation (non shuffled sequential indexes)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "print('iterating over the SequentialSampler')\n",
    "for count, sample in enumerate(val_sampler):\n",
    "        print('count:', count, 'sample:',sample)\n",
    "        if (count >= 5):\n",
    "            break\n",
    "    \n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "\n",
    "print(train_data)\n",
    "print(train_sampler)\n",
    "print(train_dataloader)\n",
    "print(val_data)\n",
    "print(val_sampler)\n",
    "print(val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f60aef02-0042-4296-9219-e64b94538aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: tensor([  101,  2748,  1045,  2318,  2000,  4604, 11186,  2000,  2191,  2009,\n",
      "         2021,  3255,  2234,  2067,  2061,  1045,  1005,  1049,  2067,  1999,\n",
      "         2793,  1012,  3313,  7824,   102], device='cuda:0') \n",
      "mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], device='cuda:0') \n",
      "label: tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for ids, mask, label in val_dataloader: #sequential indexes\n",
    "    print('index:',ids[0],'\\nmask:',mask[0],'\\nlabel:',label[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa01af21-b85c-41ce-88a0-48bf676e646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: tensor([  101, 10261,  2017,  1037,  3376,  2154,  1012,  2169,  2617,  8669,\n",
      "         2130,  2062,  2477,  2000,  2562,  2017,  5629,  1012,  2079,  5959,\n",
      "         2009,  1012,   102,     0,     0], device='cuda:0') \n",
      "mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0], device='cuda:0') \n",
      "label: tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for ids, mask, label in train_dataloader: #shuffled indexes\n",
    "    print('index:',ids[0],'\\nmask:',mask[0],'\\nlabel:',label[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2707c2-38eb-4c01-a5f9-630e1de48c9b",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad2ea1e5-90b5-4e7e-9bb8-501a1028fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing the BERT model parameters. This means that during training, the gradients for these parameters will not be calculated, and thus, they won't be updated, to:\n",
    "# Reduce Computational Load: Saves memory and speeds up training by not calculating gradients for frozen layers.\n",
    "# Fine-Tuning Specific Layers: Allows you to train only the new layers added on top of BERT, which can be useful for fine-tuning for a specific task.\n",
    "# Prevent Overfitting: Helps maintain the pre-trained knowledge of BERT while focusing the training on task-specific parameters.\n",
    "\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "    # print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd6c0ac0-3d71-4f2d-b4bd-0e374cc647cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512) # 768 because the last bert model layer: (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "      \n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2) # classification layer for binary classification\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1) \n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        \n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "      \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12605397-4743-4dd4-9fea-aff8876852de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our defined architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b191c4eb-dee2-483b-a314-0e685afbf935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e8a8c7f-0602-4f81-b5c1-f110d880cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model.parameters():\n",
    "#     print(i.is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6f4a1c0-8751-4d6c-8040-5833c394d14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alienware\\miniconda3\\envs\\py310\\lib\\site-packages\\transformers\\optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),lr = 1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd37c1da-d1cc-4d9e-9864-dadd534b8572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.57743559 3.72848948]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#Class Weights calculated to be reused in the Weighted Cross Entropy formula, for imbalanced dataset\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight(class_weight ='balanced', classes = np.unique(train_labels), y = train_labels)\n",
    "\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99f80851-f2b0-49df-aab5-597f116666d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.865897\n",
       "1    0.134103\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.value_counts(normalize=True) # same proportion as the wights above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46fd8076-3b0f-47da-b8f8-d624d6a2fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) # Negative Log Likelihood Loss \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd975d-5a9c-43ef-a1f1-5d584f4423ec",
   "metadata": {},
   "source": [
    "Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc6e77d0-f8ca-4de9-be1d-821e2aab6039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    \n",
    "    model.train() # To train the model, you should first set it back in training mode with model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # progress update after every 30 batches.\n",
    "        if step % 30 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        \n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    " \n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch - average per epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02011913-2df7-4b88-aa24-63d35949dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    \n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # deactivate dropout layers\n",
    "    model.eval() # is a kind of switch for some specific layers/parts of the model \n",
    "                 # that behave differently during training and inference (evaluating) time. \n",
    "                 # For example, Dropouts Layers, BatchNorm Layers etc. \n",
    "                 # You need to turn them off during model evaluation, and .eval() will do it for you\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "        \n",
    "        # Progress update every 30 batches.\n",
    "        if step % 30 == 0 and not step == 0:\n",
    "            \n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad(): #we don't compute or use gradients during evaluation, so turning off the autograd will speed up execution and will reduce memory usage\n",
    "            \n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "505c760c-bd52-489e-9bd6-e3403f444555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch # 0 (32, 2)\n",
      "[[-0.7584998  -0.6318047 ]\n",
      " [-0.64107037 -0.7480856 ]\n",
      " [-0.72417665 -0.6630516 ]\n",
      " [-0.71084094 -0.67576104]\n",
      " [-0.6884782  -0.697838  ]\n",
      " [-0.68326855 -0.70312434]\n",
      " [-0.6351935  -0.7546671 ]\n",
      " [-0.6140341  -0.779061  ]\n",
      " [-0.7230811  -0.66408336]\n",
      " [-0.6290417  -0.7616455 ]\n",
      " [-0.6610404  -0.72631896]\n",
      " [-0.68599796 -0.70034784]\n",
      " [-0.6377073  -0.75184196]\n",
      " [-0.6925959  -0.69369876]\n",
      " [-0.65400964 -0.733879  ]\n",
      " [-0.6942425  -0.6920531 ]\n",
      " [-0.6677069  -0.7192517 ]\n",
      " [-0.7643821  -0.62665105]\n",
      " [-0.64556676 -0.74310505]\n",
      " [-0.6822188  -0.7041964 ]\n",
      " [-0.7000039  -0.6863372 ]\n",
      " [-0.5529033  -0.8563184 ]\n",
      " [-0.6250542  -0.76621777]\n",
      " [-0.6471532  -0.741359  ]\n",
      " [-0.6718228  -0.71493626]\n",
      " [-0.6901509  -0.69615245]\n",
      " [-0.65125465 -0.7368718 ]\n",
      " [-0.5769191  -0.82468283]\n",
      " [-0.7945112  -0.60111874]\n",
      " [-0.65306926 -0.7348987 ]\n",
      " [-0.7191669  -0.6677873 ]\n",
      " [-0.69064075 -0.6956599 ]]\n",
      "batch # 1 (32, 2)\n",
      "[[-0.67733145 -0.70921713]\n",
      " [-0.7484579  -0.640736  ]\n",
      " [-0.69110745 -0.6951912 ]\n",
      " [-0.5280191  -0.8910425 ]\n",
      " [-0.69454265 -0.6917537 ]\n",
      " [-0.69221705 -0.69407827]\n",
      " [-0.68010014 -0.70636666]\n",
      " [-0.6476257  -0.74084014]\n",
      " [-0.5512239  -0.85859764]\n",
      " [-0.6844952  -0.70187473]\n",
      " [-0.6676503  -0.7193113 ]\n",
      " [-0.6210992  -0.770792  ]\n",
      " [-0.69855887 -0.6877646 ]\n",
      " [-0.63509977 -0.75477296]\n",
      " [-0.70224464 -0.68413174]\n",
      " [-0.6484929  -0.739889  ]\n",
      " [-0.6342656  -0.75571394]\n",
      " [-0.70607626 -0.68038315]\n",
      " [-0.74124026 -0.6472613 ]\n",
      " [-0.5899494  -0.8082333 ]\n",
      " [-0.752779   -0.63687205]\n",
      " [-0.61531115 -0.7775569 ]\n",
      " [-0.5568343  -0.85101867]\n",
      " [-0.6440166  -0.7448168 ]\n",
      " [-0.7004931  -0.68585485]\n",
      " [-0.7298826  -0.6577136 ]\n",
      " [-0.7264593  -0.6609091 ]\n",
      " [-0.7172201  -0.66964024]\n",
      " [-0.79315597 -0.60223705]\n",
      " [-0.66515285 -0.7219477 ]\n",
      " [-0.7209198  -0.6661252 ]\n",
      " [-0.6374463  -0.75213456]]\n",
      "pred percent list length: 2\n",
      "pred percent list reshaped: (64, 2)\n"
     ]
    }
   ],
   "source": [
    "# example to illustrate how to process batches of data and gather predictions from the model.\n",
    "\n",
    "pred_perc_list = []\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    sent_id = batch[0]\n",
    "    # print(sent_id)\n",
    "    mask = batch[1]\n",
    "    # print(mask)\n",
    "    label = batch[2]\n",
    "    # print(label)\n",
    "    \n",
    "# prediction_percent are in the form of:      no. of batches (122), size of batch (32) , no. of classes (2).\n",
    "# reshape the predictions_percent in form of: number of samples (3900), no. of classes(2).\n",
    "    \n",
    "    pred_perc = model(sent_id, mask) # tensor of 32, as batch size\n",
    "    pred_perc = pred_perc.detach().cpu().numpy()\n",
    "    print('batch #', len(pred_perc_list), pred_perc.shape)    \n",
    "    print(pred_perc)\n",
    "    pred_perc_list.append(pred_perc)  \n",
    "    \n",
    "    if step == 1: # to print only the first two batches\n",
    "        break    \n",
    "    \n",
    "pred_perc_list_reshaped  = np.concatenate(pred_perc_list, axis=0)\n",
    "print('pred percent list length:',len(pred_perc_list))\n",
    "print('pred percent list reshaped:', pred_perc_list_reshaped.shape)\n",
    "# print('last pred perc:', pred_perc.shape, '\\n', pred_perc) #last one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9dec6842-a50a-4369-b8d9-9f298ff162ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n",
      "  Batch    30  of    122.\n",
      "  Batch    60  of    122.\n",
      "  Batch    90  of    122.\n",
      "  Batch   120  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.680\n",
      "Validation Loss: 0.656\n",
      "\n",
      " Epoch 2 / 10\n",
      "  Batch    30  of    122.\n",
      "  Batch    60  of    122.\n",
      "  Batch    90  of    122.\n",
      "  Batch   120  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.646\n",
      "Validation Loss: 0.625\n",
      "\n",
      " Epoch 3 / 10\n",
      "  Batch    30  of    122.\n",
      "  Batch    60  of    122.\n",
      "  Batch    90  of    122.\n",
      "  Batch   120  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.616\n",
      "Validation Loss: 0.596\n",
      "\n",
      " Epoch 4 / 10\n",
      "  Batch    30  of    122.\n",
      "  Batch    60  of    122.\n",
      "  Batch    90  of    122.\n",
      "  Batch   120  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.592\n",
      "Validation Loss: 0.570\n",
      "\n",
      " Epoch 5 / 10\n",
      "  Batch    30  of    122.\n",
      "  Batch    60  of    122.\n",
      "  Batch    90  of    122.\n",
      "  Batch   120  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.569\n",
      "Validation Loss: 0.545\n",
      "\n",
      " Epoch 6 / 10\n",
      "  Batch    30  of    122.\n",
      "  Batch    60  of    122.\n",
      "  Batch    90  of    122.\n",
      "  Batch   120  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.544\n",
      "Validation Loss: 0.522\n",
      "\n",
      " Epoch 7 / 10\n",
      "  Batch    30  of    122.\n",
      "  Batch    60  of    122.\n",
      "  Batch    90  of    122.\n",
      "  Batch   120  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.529\n",
      "Validation Loss: 0.501\n",
      "\n",
      " Epoch 8 / 10\n",
      "  Batch    30  of    122.\n",
      "  Batch    60  of    122.\n",
      "  Batch    90  of    122.\n",
      "  Batch   120  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.509\n",
      "Validation Loss: 0.484\n",
      "\n",
      " Epoch 9 / 10\n",
      "  Batch    30  of    122.\n",
      "  Batch    60  of    122.\n",
      "  Batch    90  of    122.\n",
      "  Batch   120  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.498\n",
      "Validation Loss: 0.465\n",
      "\n",
      " Epoch 10 / 10\n",
      "  Batch    30  of    122.\n",
      "  Batch    60  of    122.\n",
      "  Batch    90  of    122.\n",
      "  Batch   120  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.484\n",
      "Validation Loss: 0.448\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "caa856bb-4bd1-4965-b134-7b457df5b8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce68bd1-0ebf-499a-b6ef-f627d92e036c",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fbcfd4de-d15c-43b1-8c6f-72a65d391a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad(): #no gradients computation needed\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2304c15-897c-4e2b-9e5e-49e6311afadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92       724\n",
      "           1       0.50      0.80      0.62       112\n",
      "\n",
      "    accuracy                           0.87       836\n",
      "   macro avg       0.73      0.84      0.77       836\n",
      "weighted avg       0.90      0.87      0.88       836\n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "test_y = test_y.detach().cpu().numpy()\n",
    "preds_01 = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds_01))\n",
    "\n",
    "print(type(test_y))\n",
    "print(type(preds_01))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
